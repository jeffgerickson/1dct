<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Jeff Erickson" />
  <title>Minimum Cuts^\beta</title>
  <style>
    div.sitenav { display: flex; flex-direction: row; flex-wrap: wrap; }
    span.navlink { flex: 1; }
    span.navlink-label { display: inline-block; min-width: 4em; }
    html {
      font-size: 18px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 50em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<nav id="sitenav">
<div class="sitenav">
<span class="navlink">
<span class="navlink-label">Up:</span> <a href="index.html" accesskey="u" rel="up">One-Dimensional Computational Topology</a>
</span>
<span class="navlink">
<span class="navlink-label">Top:</span> <a href="index.html" accesskey="t" rel="top">One-Dimensional Computational Topology</a>
</span>
</div>
<div class="sitenav">
<span class="navlink">
<span class="navlink-label">Next:</span> <a href="21-faster-minimum-cuts-fr-dijkstraalpha.html" accesskey="n" rel="next">Faster Minimum Cuts (FR-Dijkstra)<span
class="math inline">\(^\alpha\)</span></a>
</span>
<span class="navlink">
<span class="navlink-label">Previous:</span> <a href="19-fast-shortest-paths-in-planar-graphsbeta.html" accesskey="p" rel="previous">Fast Shortest Paths in Planar Graphs<span
class="math inline">\(^\beta\)</span></a>
</span>
</div>
</nav>
<h1 data-number="20" id="minimum-cutsbeta"><span
class="header-section-number">20</span> Minimum Cuts<span
class="math inline">\(^\beta\)</span></h1>
<p>Let <span class="math inline">\(G\)</span> be an arbitrary graph, and
let <span class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> be two vertices of <span
class="math inline">\(G\)</span>. An <em><span class="math inline">\((s,
t)\)</span>-cut</em> (or more formally, an <span
class="math inline">\((s,t)\)</span>-edge-cut) is a subset <span
class="math inline">\(X\)</span> of the edges of <span
class="math inline">\(G\)</span> that intersects every path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> in <span
class="math inline">\(G\)</span>. A <em>minimum <span
class="math inline">\((s,t)\)</span>-cut</em> is an <span
class="math inline">\((s,t)\)</span>-cut of minimum size, or of minimum
total weight if the edges of <span class="math inline">\(G\)</span> are
weighted. (In this context, edge weights are normally called
<em>capacities</em>.)</p>
<p>The fastest method to compute minimum <span class="math inline">\((s,
t)\)</span>-cuts in <em>arbitrary</em> graphs is to compute a maximum
<span class="math inline">\((s, t)\)</span>-flow and then exploit the
classical proof of the maxflow-mincut theorem. In undirected
<em>planar</em> graphs, however, this dependency is reversed; the
fastest method to compute maximum flows actually computes minimum cuts
first.</p>
<h2 data-number="20.1" id="duality-shortest-essential-cycle"><span
class="header-section-number">20.1</span> Duality: Shortest essential
cycle</h2>
<p>Let <span class="math inline">\(\Sigma\)</span> be an undirected
planar <em>map</em>, each of whose edges <span
class="math inline">\(e\)</span> has a non-negative capacity <span
class="math inline">\(c(e)\)</span>, and let <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> be vertices of <span
class="math inline">\(\Sigma\)</span>. The first step in our fast
minimum-cut algorithm is to view the problem through the lens of
duality. It is helpful to think of the source vertex <span
class="math inline">\(s\)</span> and the target vertex <span
class="math inline">\(t\)</span> as <em>punctures</em> or
<em>obstacles</em> — points that are missing from the plane — and
similarly to think of the corresponding faces <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> as <em>holes</em> in the dual map
<span class="math inline">\(\Sigma^*\)</span>. In other words, we should
think of the dual map <span class="math inline">\(\Sigma^*\)</span> as a
decomposition of the <em>annulus</em> <span class="math inline">\(A =
\mathbb{R}^2 \setminus (s^*\cup t^*)\)</span> rather than a map on the
plane or a disk. Without loss of generality, assume that <span
class="math inline">\(t^*\)</span> is the outer face of <span
class="math inline">\(\Sigma^*\)</span>.</p>
<p>A simple cycle <span class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> is <em>essential</em> if it
satisfies any of the following equivalent conditions:</p>
<ul>
<li><span class="math inline">\(\gamma\)</span> separates <span
class="math inline">\(s^*\)</span> from <span
class="math inline">\(t^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> has winding number <span
class="math inline">\(\pm 1\)</span> around <span
class="math inline">\(s^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> is homotopic in <span
class="math inline">\(A\)</span> to the boundary of <span
class="math inline">\(s^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> is homotopic in <span
class="math inline">\(A\)</span> to the boundary of <span
class="math inline">\(t^*\)</span>.</li>
</ul>
<p>Each edge <span class="math inline">\(e^*\)</span> in the dual map
<span class="math inline">\(\Sigma^*\)</span> has a <em>cost</em> or
<em>length</em> <span class="math inline">\(c^*(e^*)\)</span> equal to
the capacity of the corresponding primal edge <span
class="math inline">\(e\)</span>. Whitney’s duality between simple
cycles in <span class="math inline">\(\Sigma\)</span> and and minimal
cuts (bonds) in <span class="math inline">\(\Sigma^*\)</span>
immediately implies the following:</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>A subset <span class="math inline">\(X\)</span> of edges is a
minimum <span class="math inline">\((s,t)\)</span>-cut in <span
class="math inline">\(\Sigma\)</span> if and only if the corresponding
set <span class="math inline">\(X^*\)</span> of dual edges is a
minimum-cost essential cycle in <span
class="math inline">\(\Sigma^*\)</span>.</em>
</dd>
</dl>
<figure>
<img src="Fig/mincut-primal-dual.png" style="width:90.0%"
alt="A minimum (s,t)-cut in a planar graph is dual to a shortest essential cycle in the annular dual map." />
<figcaption aria-hidden="true">A minimum <span
class="math inline">\((s,t)\)</span>-cut in a planar graph is dual to a
shortest essential cycle in the annular dual map.</figcaption>
</figure>
<h2 data-number="20.2" id="crossing-at-most-once"><span
class="header-section-number">20.2</span> Crossing at most once</h2>
<p>Now let <span class="math inline">\(\pi\)</span> be a shortest path
in <span class="math inline">\(\Sigma^*\)</span> from any vertex of
<span class="math inline">\(s^*\)</span> to any vertex of <span
class="math inline">\(t^*\)</span>. We can measure the winding number of
any directed cycle <span class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> by counting the number of times
<span class="math inline">\(\gamma\)</span> crosses <span
class="math inline">\(\pi\)</span> in either direction. We have to
define “crossing” carefully here, because <span
class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\pi\)</span> could share edges.</p>
<p>Suppose <span class="math inline">\(\pi = p_0\mathord\to
p_1\mathord\to \cdots \mathord\to p_k\)</span>, where <span
class="math inline">\(p_0\)</span> lies on <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(p_k\)</span> lies on <span
class="math inline">\(t^*\)</span>. To simplify the following
definition, we add two “ghost” darts <span
class="math inline">\(p_{-1}\mathord\to p_0\)</span> and <span
class="math inline">\(p_k\mathord\to p_{k+1}\)</span>, where <span
class="math inline">\(p_{-1}\)</span> lies inside <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(p_{k+1}\)</span> lies inside <span
class="math inline">\(t^*\)</span>. We say that a dart <span
class="math inline">\(q\mathord\to p_i\)</span> <em>enters <span
class="math inline">\(\pi\)</span> from the left</em> (resp. <em>from
the right</em>) if the darts <span
class="math inline">\(p_{i-1}\mathord\to p_i\)</span>, <span
class="math inline">\(q\mathord\to p_i\)</span>, and <span
class="math inline">\(p_{i+1}\mathord\to p_i\)</span> are ordered
clockwise (resp. counterclockwise) around <span
class="math inline">\(p_i\)</span>. Symmetrically, we say that a dart
<em>leaves <span class="math inline">\(\pi\)</span> to the left</em>
(resp. <em>to the right</em>) if its reversal enters <span
class="math inline">\(\pi\)</span> from the left (resp. from the right).
The same dart can leave <span class="math inline">\(\pi\)</span> to the
right and enter <span class="math inline">\(\pi\)</span> to the left, or
vice versa.</p>
<figure>
<img src="Fig/left-right.png" style="width:15.0%"
alt="Edges incident to both sides of \pi." />
<figcaption aria-hidden="true">Edges incident to both sides of <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<p>A <em>positive crossing</em> between <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(\gamma\)</span> is a subpath of <span
class="math inline">\(\gamma\)</span> that starts with a dart entering
<span class="math inline">\(\pi\)</span> from the right and ends with a
dart leaving <span class="math inline">\(\pi\)</span> to the left, and a
<em>negative crossing</em> is defined similarly. Intuitively, for
purposes of defining crossings, we are shifting the path <span
class="math inline">\(\pi\)</span> very slightly to the left, so that it
intersects the edges of <span class="math inline">\(\Sigma^*\)</span>
transversely. It follows that the winding number <span
class="math inline">\(\textsf{wind}(\gamma, s^*)\)</span> is the number
of darts in <span class="math inline">\(\gamma\)</span> that leave <span
class="math inline">\(\pi\)</span> to the left, minus the number of
darts in <span class="math inline">\(\gamma\)</span> that enter <span
class="math inline">\(\pi\)</span> from the left.</p>
<dl>
<dt><strong>Crossing Lemma [Itai and Shiloach (1979)]:</strong></dt>
<dd>
<em>The shortest essential cycle in <span
class="math inline">\(\Sigma^*\)</span> crosses <span
class="math inline">\(\pi\)</span> exactly once.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We follow the same intuition that we used for shortest homotopic paths
in the plane. Let <span class="math inline">\(\gamma\)</span> be any
essential cycle in <span class="math inline">\(\Sigma^*\)</span>,
directed so that <span class="math inline">\(\textsf{wind}(\gamma, s^*)
= 1\)</span>, that crosses <span class="math inline">\(\pi\)</span> more
than once. Then somewhere <span class="math inline">\(\gamma\)</span>
must have be a negative crossing followed immediately by a positive
crossing. It follows that <span class="math inline">\(\gamma\)</span>
has a subpath <span class="math inline">\(p_i\mathord\to
q\mathord\to\cdots\mathord\to r\mathord\to p_j\)</span>, where <span
class="math inline">\(p_i\mathord\to q\)</span> leaves <span
class="math inline">\(\pi\)</span> to the right, <span
class="math inline">\(r\mathord\to p_j\)</span> enters <span
class="math inline">\(\pi\)</span> from the right. Let <span
class="math inline">\(\gamma’\)</span> be the cycle obtained from <span
class="math inline">\(\gamma\)</span> by replacing this subpath with the
subpath of <span class="math inline">\(\pi\)</span> from <span
class="math inline">\(p_i\)</span> to <span
class="math inline">\(p_j\)</span>. Because <span
class="math inline">\(\pi\)</span> is a shortest path, <span
class="math inline">\(\gamma’\)</span> must be shorter than <span
class="math inline">\(\gamma\)</span>. We conclude that <span
class="math inline">\(\gamma’\)</span> is not the <em>shortest</em>
essential cycle in <span class="math inline">\(\Sigma^*\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<figure>
<img src="Fig/shortcut.png" style="width:13.0%"
alt="Any essential cycle that crosses \pi more than once can be shortened." />
<figcaption aria-hidden="true">Any essential cycle that crosses <span
class="math inline">\(\pi\)</span> more than once can be
shortened.</figcaption>
</figure>
<h2 data-number="20.3" id="slicing-along-a-path"><span
class="header-section-number">20.3</span> Slicing along a path</h2>
<p>Now let <span class="math inline">\(\Delta := \Sigma^*
\backslash\!\!\backslash \pi\)</span> denote the planar map obtained by
<em>slicing</em> the annular map <span
class="math inline">\(\Sigma^*\)</span> along path <span
class="math inline">\(\pi\)</span>. The slicing operation replaces <span
class="math inline">\(\pi\)</span> with two copies <span
class="math inline">\(\pi^+\)</span> and <span
class="math inline">\(\pi^-\)</span>. Then for every vertex <span
class="math inline">\(p_i\)</span> of <span
class="math inline">\(\pi\)</span>, all edges incident to <span
class="math inline">\(p_i\)</span> on the left are redirected to <span
class="math inline">\(p_i^+\)</span>, and all edges incident to <span
class="math inline">\(p_i\)</span> on the left are redirected to <span
class="math inline">\(p_i^-\)</span>. The channel between two two paths
<span class="math inline">\(\pi^+\)</span> and <span
class="math inline">\(\pi^-\)</span> joins <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> into a single outer face. Thus, we
should think of <span class="math inline">\(\Delta\)</span> as being
embedded on a disk. Every face of <span
class="math inline">\(\Sigma^*\)</span> except <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> appears as a face in <span
class="math inline">\(\Delta\)</span>.</p>
<figure>
<img src="Fig/slice-path.png" style="width:35.0%"
alt="Slicing along \pi." />
<figcaption aria-hidden="true">Slicing along <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<p>For any index <span class="math inline">\(i\)</span>, let <span
class="math inline">\(\sigma_i\)</span> denote the shortest path in
<span class="math inline">\(\Delta\)</span> from <span
class="math inline">\(p_i^+\)</span> to <span
class="math inline">\(p_i^-\)</span>. The shortest essential cycle <span
class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> appears in <span
class="math inline">\(\Delta\)</span> as one of the shortest paths <span
class="math inline">\(\sigma_i\)</span>. Thus, to compute the minimum
<span class="math inline">\((s,t)\)</span>-cut in our original planar
map <span class="math inline">\(\Sigma\)</span>, it suffices to compute
the length of <em>every</em> shortest path <span
class="math inline">\(\sigma_i\)</span> in <span
class="math inline">\(\Delta\)</span>.</p>
<figure>
<img src="Fig/mincut-dual-surgery.png" style="width:100.0%"
alt="Slicing along \pi transforms the shortest essential cycle into a shortest path between clones of some vertex of \pi." />
<figcaption aria-hidden="true">Slicing along <span
class="math inline">\(\pi\)</span> transforms the shortest essential
cycle into a shortest path between clones of some vertex of <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<h2 data-number="20.4" id="algorithms"><span
class="header-section-number">20.4</span> Algorithms</h2>
<p>The simplest way to compute these <span
class="math inline">\(k\)</span> shortest-path distances is to run
Dijkstra’s algorithm at each vertex <span
class="math inline">\(p_i^+\)</span>. Assuming <span
class="math inline">\(\pi\)</span> has <span
class="math inline">\(k\)</span> edges, so there are <span
class="math inline">\(k+1\)</span> terminal pairs <span
class="math inline">\(p_i^\pm\)</span>, this algorithm runs in <span
class="math inline">\(O(kn\log n)\)</span> time, which is <span
class="math inline">\(O(n^2\log n)\)</span> time in the worst case. We
can reduce the running time to <span class="math inline">\(O(kn\log\log
n)\)</span> using the faster shortest-path algorithm we described in the
previous lecture note, or even to <span
class="math inline">\(O(kn)\)</span> using a linear-time shortest-path
algorithm.</p>
<p>Alternatively, we can compute all <span
class="math inline">\(k\)</span> of these shortest paths using a
multiple-source shortest-paths algorithm. The parametric MSSP algorithms
of Klein and Cabello et al. both require <span
class="math inline">\(O(n\log n)\)</span> time, which is faster in the
worst case than <span class="math inline">\(O(kn)\)</span>, but slower
when <span class="math inline">\(k\)</span> is small. In particular,
even when <span class="math inline">\(k=2\)</span>, that algorithm could
require <span class="math inline">\(\Omega(n)\)</span> pivots. The more
recent recursive contraction algorithm runs in <span
class="math inline">\(O(n\log n\log k)\)</span> time if we use
Dijkstra’s algorithm to compute shortest paths, or in <span
class="math inline">\(O(n\log k)\)</span> time if we use a linear-time
shortest-path algorithm.</p>
<p>An older and simpler divide-and-conquer algorithm, proposed by John
Reif in 1983, exactly matches the recursive contraction MSSP algorithm.
Reif’s algorithm computes the median shortest path <span
class="math inline">\(\sigma_m\)</span>, where <span
class="math inline">\(m = \lfloor k/2 \rfloor\)</span>, and then
recurses in each component of the sliced map <span
class="math inline">\(\Delta \backslash\!\!\backslash \sigma_m\)</span>.
One of these components contains the terminal pairs <span
class="math inline">\(p_0^\pm, p_1^\pm, \dots, p^\pm_m\)</span>; the
other contains the terminal pairs <span class="math inline">\(p_m^\pm,
p_{m+1}^\pm, \dots, p_k^\pm\)</span>.</p>
<figure>
<img src="Fig/Reif-split.png" style="width:60.0%"
alt="Reif’s algorithm: Slice along the median shortest path and recurse." />
<figcaption aria-hidden="true">Reif’s algorithm: Slice along the median
shortest path and recurse.</figcaption>
</figure>
<p>Reif’s algorithm falls back on Dijkstra’s algorithm in two base
cases. First, if <span class="math inline">\(k\le 2\)</span>, we can
obviously compute each of the <span class="math inline">\(k\)</span>
shortest paths directly. A more subtle base case happens when the
“floor” and “ceiling” paths collide. Let <span
class="math inline">\(\alpha\)</span> denote the boundary path from
<span class="math inline">\(p_0^+\)</span> to <span
class="math inline">\(p_0^-\)</span>, and let <span
class="math inline">\(\beta\)</span> denote the boundary path from <span
class="math inline">\(p_k^+\)</span> to <span
class="math inline">\(p_k^-\)</span>. If <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> share a vertex <span
class="math inline">\(x\)</span>, then for every index <span
class="math inline">\(i\)</span> we have <span
class="math inline">\(\textsl{dist}(p_i^+, p_i^-) = \textsl{dist}(p_i^+,
x) + \textsl{dist}(x, p_i^-)\)</span>; thus, instead of recursing, we
can compute all <span class="math inline">\(k\)</span> shortest-path
distances by computing a single shortest-path tree rooted at <span
class="math inline">\(x\)</span>. (This second base case is not
necessary for the correctness of Reif’s algorithm, but it is necessary
for efficiency.)</p>
<figure>
<img src="Fig/Reif-collapse.png" style="width:30.0%"
alt="Base case of Reif’s algorithm." />
<figcaption aria-hidden="true">Base case of Reif’s
algorithm.</figcaption>
</figure>
<p>Let <span class="math inline">\(T(n,k)\)</span> denote the running
time of Reif’s algorithm, where <span class="math inline">\(k+1\)</span>
is the number of terminal pairs and <span
class="math inline">\(n\)</span> is the total number of vertices in the
map <span class="math inline">\(\Delta\)</span>. This function obeys the
recurrence <span class="math display">\[
    T(n,k) = T(n_1, \lfloor k/2 \lfloor) + T(n_1, \lceil k/2 \rceil) +
O(n\log n).
\]</span> where <span class="math inline">\(n_1\)</span> and <span
class="math inline">\(n_2\)</span> are the number of vertices in the two
components of <span class="math inline">\(\Delta
\backslash\!\!\backslash \sigma_m\)</span>. The second base case ensures
that each vertex and edge of <span class="math inline">\(\Delta\)</span>
appears in at most <span class="math inline">\(O(1)\)</span> subproblems
at any level of the recursion tree.<a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> Thus, the total work at
any level of recursion is <span class="math inline">\(O(n\log
n)\)</span>. The recursion tree has depth at most <span
class="math inline">\(O(\log k)\)</span>, so the overall algorithm runs
in <span class="math inline">\(O(n\log n\log k)\)</span> time.</p>
<p>If we use a linear-time shortest-path algorithm instead of Dijkstra,
the running time improves to <span class="math inline">\(O(n\log
k)\)</span>. This improvement was first described by Greg Frederickson
in 1987, as one of the earliest applications of <span
class="math inline">\(r\)</span>-divisions.</p>
<h2 data-number="20.5"
id="faster-shortest-paths-with-negative-lengths"><span
class="header-section-number">20.5</span> Faster Shortest Paths with
Negative Lengths</h2>
<p><strong><em>[[[This is still really sketchy!]]]</em></strong></p>
<p>In the previous lecture note, we described a 2009 algorithm by Klein,
Mozes, and Weimann to compute shortest paths in directed planar maps,
possibly with negative dart lengths, in <span
class="math inline">\(O(n\log^2 n)\)</span> time. In 2010, Shay Mozes
and Christian Wulff-Nilsen improved this algorithm even further by using
a good <span class="math inline">\(r\)</span>-division at each level of
recursion (with <span class="math inline">\(r \approx n/\log n\)</span>)
instead of just one separator cycle; their improved algorithm runs in
<span class="math inline">\(O(n\log^2n /\log\log n)\)</span>.</p>
<p>Recall the high-level description of the Klein-Mozes-Weimann
algorithm:</p>
<ol start="0" type="1">
<li>Split the map <span class="math inline">\(\Sigma\)</span> into two
smaller maps <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> along a single cycle separator <span
class="math inline">\(S\)</span>.</li>
<li>Recursively compute <span class="math inline">\(\textsf{dist}_A(r,
A)\)</span> and <span class="math inline">\(\textsf{dist}_B(r,
B)\)</span></li>
<li>Compute <span class="math inline">\(\textsf{dist}_A(S,S)\)</span>
and <span class="math inline">\(\textsf{dist}_B(S,S)\)</span> using MSSP
in <span class="math inline">\(O(n\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,S)\)</span> using
FR-Bellman-Ford in <span class="math inline">\(O(n\alpha(n))\)</span>
time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(s,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
</ol>
<p>Steps 1, 4, and 5 of Mozes and Wulff-Nilsen’s faster algorithm are
identical. In step 2, the only minor different is that we need to run
MSSP around the boundary of each hole of each piece, instead of just
once around the sole cycle separator. The total time for each piece is
<span class="math inline">\(O(r\log r)\)</span>, so the total time for
this step across the entire <span
class="math inline">\(r\)</span>-division is <span
class="math inline">\(O(n/r)\cdot O(r\log r) = O(n\log r)\)</span>.</p>
<p>The only major change to the algorithm is in step 3; we need to
modify FR-Bellman-Ford to deal with holes in each piece of the <span
class="math inline">\(r\)</span>-division.</p>
<p>In step 2, we compute all boundary-to-boundary distances within each
piece of the <span class="math inline">\(r\)</span>-division using MSSP.
Specifically, within each piece <span class="math inline">\(P\)</span>,
we run MSSP around each of the <span class="math inline">\(O(1)\)</span>
boundary cycles of <span class="math inline">\(P\)</span>. The total
time for each piece is <span class="math inline">\(O(r\log r)\)</span>,
so the total time for this step across the entire <span
class="math inline">\(r\)</span>-division is <span
class="math inline">\(O(n/r)\cdot O(r\log r) = O(n\log r)\)</span>.</p>
<p>Modifying step 3 is more interesting. Recall that a good <span
class="math inline">\(r\)</span>-division <span
class="math inline">\(\mathcal{R}\)</span> breaks <span
class="math inline">\(\Sigma\)</span> into <span
class="math inline">\(O(n/r)\)</span> pieces, each with <span
class="math inline">\(O(r)\)</span> vertices, <span
class="math inline">\(O(\sqrt{r})\)</span> boundary vertices, and <span
class="math inline">\(O(1)\)</span> holes; thus, overall, <span
class="math inline">\(\mathcal{R}\)</span> has <span
class="math inline">\(O(n/\sqrt{r})\)</span> boundary vertices,
organized into <span class="math inline">\(O(n/r)\)</span> cycles. We
construct a complete directed multigraph <span
class="math inline">\(\hat{R}\)</span> over the boundary vertices of the
<span class="math inline">\(r\)</span>-division, with an edge <span
class="math inline">\(u{\to}v\)</span> with weight <span
class="math inline">\(\textsf{dist}_P(u,v)\)</span> for every piece
<span class="math inline">\(P\)</span> containing both <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>.</p>
<p>Bellman-Ford computes shortest-path distances in <span
class="math inline">\(\hat{R}\)</span> in <span
class="math inline">\(O(n/\sqrt{r})\)</span> phases; in each phase, we
find and relax all tense edges. Our modification of FR-Bellman-Ford
breaks each relaxation phase into subphases:</p>
<pre><code>for each piece P:
   for each boundary cycle S of P:
       for each boundary cycle T of P:
           relax every edge within P from S to T</code></pre>
<p>We already described how to relax every edge in <span
class="math inline">\(P\)</span> from a boundary cycle <em>to
itself</em> in <span class="math inline">\(O(k\alpha(k))\)</span> time
(or <span class="math inline">\(O(k)\)</span> expected time). It remains
to show how to relax all edges from one boundary cycle <span
class="math inline">\(S\)</span> to a different boundary cycle <span
class="math inline">\(T\)</span>.</p>
<p>Without loss of generality, let’s assume that <span
class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span> are the only two boundary cycles in
<span class="math inline">\(P\)</span>; we’ll treat any other boundary
cycles as faces of <span class="math inline">\(P\)</span>. Thus, <span
class="math inline">\(P\)</span> is a map of an <em>annulus</em>. Let
<span class="math inline">\(s_1, s_2, \dots, s_k\)</span> and <span
class="math inline">\(t_1, t_2, \dots, t_l\)</span> denote the sequences
of vertices of <span class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span>, respectively.</p>
<p>Let <span class="math inline">\(\pi\)</span> be the shortest path in
<span class="math inline">\(P\)</span> from <span
class="math inline">\(s_1\)</span> to <span
class="math inline">\(t_1\)</span>, and let <span
class="math inline">\(\Delta = P \mathbin{\backslash\!\!\backslash}
\pi\)</span> be the map obtained by slicing <span
class="math inline">\(\Sigma\)</span> along the path <span
class="math inline">\(\pi\)</span>. As before, the slicing operation
duplicates the path <span class="math inline">\(\pi\)</span> and merges
the faces <span class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span> into a single outer face.</p>
<p>Let <span class="math inline">\(\Delta’\)</span> be a duplicate of
<span class="math inline">\(\Delta\)</span>, and let <span
class="math inline">\(\Delta^2\)</span> denote the map obtained by
gluing the “right” copy of <span class="math inline">\(\pi\)</span> in
<span class="math inline">\(\Delta\)</span> to the “left” copy of <span
class="math inline">\(\pi\)</span> in <span
class="math inline">\(\Delta’\)</span>.</p>
<p><strong>Lemma:</strong> <em>For all indices <span
class="math inline">\(i\)</span> and <span
class="math inline">\(j\)</span>, we have <span
class="math display">\[\textsf{dist}_P(s_i,t_j) = \min\big\{
\textsf{dist}_{\Delta^2}(s_i,t_j),~ \textsf{dist}_{\Delta^2}(s’_i,t_j),~
\textsf{dist}_{\Delta^2}(a_i,b’_j) \big\}\]</span>.</em></p>
<p><strong><em>[[[This is already claimed, but without proof, in the
next lecture note.]]]</em></strong></p>
<figure>
<img src="Fig/ddg-annulus-surgery.png" style="width:100.0%"
alt="Reducing the boundary-to-boundary distance array of an annulus to a Monge array; compare with Figure 5." />
<figcaption aria-hidden="true">Reducing the boundary-to-boundary
distance array of an annulus to a Monge array; compare with Figure
5.</figcaption>
</figure>
<p>The matrix of distances from the “top edge” of <span
class="math inline">\(\Delta^2\)</span> to the “bottom edge” of <span
class="math inline">\(\Delta^2\)</span> is Monge! So we can relax all
the edges from <span class="math inline">\(A\)</span> to <span
class="math inline">\(B\)</span> in <span
class="math inline">\(O(k+l)\)</span> time with one invocation of
SMAWK.</p>
<p>Suppose <span class="math inline">\(P\)</span> has <span
class="math inline">\(h = O(1)\)</span> holes, with <span
class="math inline">\(k_1, k_2, \dots, k_h\)</span> boundary vertices;
recall that <span class="math inline">\(k = \sum_i k_i =
O(\sqrt{r})\)</span>. Then the total time to relax all
boundary-to-boundary edges in <span class="math inline">\(P\)</span> is
<span class="math display">\[
    \sum_{i=1}^h O(k_i\alpha(k_i))
    +
    \sum_{i=1}^h \sum_{j=1}^h O(k_i + k_j)
    ~=~
    O(k\alpha(k) + kh)
    ~=~
    O(\sqrt{r}\,\alpha(r)).
\]</span> It follows that the time to relax <em>all</em> edges of <span
class="math inline">\(\mathcal{R}\)</span> is <span
class="math inline">\(O((n/\sqrt{r})\alpha(r)) = o(n)\)</span></p>
<h2 data-number="20.6" id="faster-minimum-cuts-fr-dijkstra"><span
class="header-section-number">20.6</span> Faster Minimum Cuts:
FR-Dijkstra</h2>
<p>Frederickson held the record for fastest planar minimum-cut algorithm
for almost two and a half decades; the record was finally broken in 2011
by two independent pairs of researchers, who ultimately published their
result jointly: Giuseppe Italiano, Yahav Nussbaum, Piotr Sankowski, and
Christian Wulff-Nilsen. Their <span class="math inline">\(O(n\log\log
n)\)</span>-time algorithm relies on an improvement to Dijkstra’s
algorithm in dense distance graphs, proposed by Jittat Fakcharoenphol
and Satish Rao in 2001, and now usually called <em>FR-Dijkstra</em>.</p>
<p>Recall from the previous lecture on shortest paths that we can
compute a dense distance graph for a nice <span
class="math inline">\(r\)</span>-division in <span
class="math inline">\(O(n\log r)\)</span> time. The dense distance graph
has <span class="math inline">\(O(n/\sqrt{r})\)</span> vertices—the
boundary vertices of the pieces of the <span
class="math inline">\(r\)</span>-division—and <span
class="math inline">\(O(n)\)</span> edges. So Dijkstra’s algorithm with
a Fibonacci heap runs in <span class="math inline">\(O(E + V\log V) =
O(n + (n/\sqrt{r})\log n)\)</span> time.</p>
<p>FR-Dijkstra removes the <span class="math inline">\(O(n)\)</span>
term from this running time. Specifically, within each piece of the
<span class="math inline">\(r\)</span>-division, the algorithm exploits
the Monge structure in the boundary-to-boundary distances to avoid
looking at every pair of boundary vertices. This is the same high-level
strategy that we previously used with FR-Bellman-Ford, but with one
significant difference: We do not know the relevant Monge arrays in
advance. Instead, portions of each Monge array are revealed each time
the Dijkstra wavefront touches the corresponding piece of the <span
class="math inline">\(r\)</span>-division.</p>
<p>I’ll discuss FR-Dijkstra in detail, along with the faster planar
minimum-cut algorithm, in the next lecture.</p>
<h2 data-number="20.7" id="references-12"><span
class="header-section-number">20.7</span> References</h2>
<ol type="1">
<li><p>Greg N. Frederickson. <a
href="https://doi.org/10.1137/0216064">Fast algorithms for shortest
paths in planar graphs with applications</a>. <em>SIAM J. Comput.</em>
16(8):1004–1004, 1987.</p></li>
<li><p>Alon Itai and Yossi Shiloach. <a
href="https://doi.org/10.1137/0208012">Maximum flow in planar
networks</a>. <em>SIAM J. Comput.</em> 8:135–150, 1979.</p></li>
<li><p>Giuseppe F. Italiano, Yahav Nussbaum, Piotr Sankowski, and
Christian Wulff-Nilsen. <a
href="https://doi.org/10.1145/1993636.1993679">Improved algorithms for
min cut and max flow in undirected planar graphs</a>. <em>Proc. 43rd
Ann. ACM Symp. Theory Comput.</em>, 313–322, 2011.</p></li>
<li><p>Shay Mozes and Christian Wulff-Nilsen. <a
href="https://doi.org/10.1007/978-3-642-15781-3_18">Shortest paths in
planar graphs with real lengths in <span class="math inline">\(O(n
\log^2 n/\log\log n)\)</span> time</a>. <em>Proc. 18th Ann. Europ. Symp.
Algorithms</em>, 206–217, 2010. Lecture Notes Comput. Sci. 6347,
Springer-Verlag. arXiv:<a
href="https://arxiv.org/abs/0911.4963">0911.4963</a>.</p></li>
<li><p>John Reif. <a href="https://doi.org/10.1137/0212005">Minimum
<span class="math inline">\(s\)</span>-<span
class="math inline">\(t\)</span> cut of a planar undirected network in
<span class="math inline">\(O(n\log^2 n)\)</span> time</a>. <em>SIAM J.
Comput.</em> 12(1):71–81, 1983.</p></li>
<li><p>Hassler Whitney. <a
href="https://doi.org/10.1090/S0002-9947-1932-1501641-2">Non-separable
and planar graphs</a>. <em>Trans. Amer. Math. Soc.</em> 34:339–362,
1932.</p></li>
<li><p>Hassler Whitney. <a
href="https://doi.org/10.4064/fm-21-1-73-84">Planar graphs</a>.
<em>Fund. Math.</em> 21:73–84, 1933.</p></li>
</ol>
<h2 data-number="20.8" id="aptly-named-sir-not-3"><span
class="header-section-number">20.8</span> Aptly Named Sir Not</h2>
<ul>
<li>Maximum cuts (or minimum cuts with negative capacities) [Hadlock
1975]</li>
<li>Deriving maximum flows from minimum cuts [Hassin Johnson 1985]</li>
<li><span class="math inline">\(O(n)\)</span> time for unweighted graphs
[Weihe 1997, Eisenstat Klein 2013, Balzotti Franciosa 2022]</li>
<li>Global minimum cuts (dual to shortest weighted cycle) [Łącki
Sankowski 2011]</li>
<li>Minimum cuts in directed planar graphs, via double cover [Janiga
Koubek 1992 but fixed, Erickson 2011, Fox 2013]</li>
<li>Faster directed planar minimum cuts [Mozes Nikolaev Nussbaum Weimann
SODA 2018]</li>
</ul>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Without the second base case, it is possible for a
constant fraction of the vertices to appear in a constant fraction of
the recursive subproblems, leading to a running time of <span
class="math inline">\(O(kn\log n)\)</span>.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</body>
</html>
