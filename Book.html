<!doctype html>
<html >
<head>
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Style-Type" content="text/css" />

    <!-- <link rel="stylesheet" type="text/css" href="template.css" /> -->
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/template.css" />

    <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />

    <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
    <!-- <script type='text/javascript' src='menu/js/jquery.cookie.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.hoverIntent.minified.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.dcjqaccordion.2.7.min.js'></script> -->

    <!-- <link href="menu/css/skins/blue.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/graphite.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/grey.css" rel="stylesheet" type="text/css" /> -->
  
    <!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
        
  
    <!-- <script src="script.js"></script> -->
  
    <!-- <script src="jquery.sticky-kit.js "></script> -->
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.cookie.js'></script>
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.hoverIntent.minified.js'></script>
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/ryangrose/easy-pandoc-templates@948e28e5/css/elegant_bootstrap.css" rel="stylesheet" type="text/css" />
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
    <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/script.js"></script>
  
    <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/jquery.sticky-kit.js"></script>
    <meta name="generator" content="pandoc" />
  <meta name="author" content="Jeff Erickson" />
  <title>One-Dimensional Computational Topology</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  
</head>
<body>

    
    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">One-Dimensional Computational
Topology</span>
        <ul class="nav pull-right doc-info">
                    <li><p class="navbar-text">Jeff Erickson</p></li>
                            </ul>
      </div>
    </div>
  </div>
    <div class="container">
    <div class="row">
            <div id="TOC" class="span3">
        <div class="well toc">

        <ul>
        <li><a href="#forewardalpha"
        id="toc-forewardalpha">Foreward<span
        class="math inline">\(^\alpha\)</span></a></li>
        <li><a href="#simple-polygonsbeta"
        id="toc-simple-polygonsbeta"><span
        class="toc-section-number">1</span> Simple Polygons<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#definitions" id="toc-definitions"><span
        class="toc-section-number">1.1</span> Definitions</a></li>
        <li><a href="#proof-of-the-jordan-polygon-theorem"
        id="toc-proof-of-the-jordan-polygon-theorem"><span
        class="toc-section-number">1.2</span> Proof of the Jordan
        Polygon Theorem</a></li>
        <li><a href="#point-in-polygon-test"
        id="toc-point-in-polygon-test"><span
        class="toc-section-number">1.3</span> Point-in-Polygon
        Test</a></li>
        <li><a href="#polygons-can-be-triangulated"
        id="toc-polygons-can-be-triangulated"><span
        class="toc-section-number">1.4</span> Polygons Can Be
        Triangulated</a></li>
        <li><a href="#computing-a-triangulation"
        id="toc-computing-a-triangulation"><span
        class="toc-section-number">1.5</span> Computing a
        Triangulation</a></li>
        <li><a href="#the-dehn-schönflies-theorem"
        id="toc-the-dehn-schönflies-theorem"><span
        class="toc-section-number">1.6</span> The Dehn-Schönflies
        Theorem</a></li>
        <li><a
        href="#and-the-aptly-named-sir-not-appearing-in-this-film"
        id="toc-and-the-aptly-named-sir-not-appearing-in-this-film"><span
        class="toc-section-number">1.7</span> and the aptly named Sir
        Not Appearing in This Film</a></li>
        <li><a href="#references" id="toc-references"><span
        class="toc-section-number">1.8</span> References</a></li>
        </ul></li>
        <li><a href="#winding-numbersbeta"
        id="toc-winding-numbersbeta"><span
        class="toc-section-number">2</span> Winding Numbers<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a
        href="#let-me-not-be-pent-up-sir-i-will-fast-being-loose."
        id="toc-let-me-not-be-pent-up-sir-i-will-fast-being-loose."><span
        class="toc-section-number">2.1</span> Let me not be pent up,
        sir; I will fast, being loose.</a></li>
        <li><a href="#shoelaces-and-signed-areas"
        id="toc-shoelaces-and-signed-areas"><span
        class="toc-section-number">2.2</span> Shoelaces and Signed
        Areas</a></li>
        <li><a href="#winding-numbers" id="toc-winding-numbers"><span
        class="toc-section-number">2.3</span> Winding numbers</a></li>
        <li><a href="#homotopy" id="toc-homotopy"><span
        class="toc-section-number">2.4</span> Homotopy</a></li>
        <li><a href="#vertex-moves" id="toc-vertex-moves"><span
        class="toc-section-number">2.5</span> Vertex moves</a></li>
        <li><a href="#polygon-homotopies-are-sequences-of-vertex-moves"
        id="toc-polygon-homotopies-are-sequences-of-vertex-moves"><span
        class="toc-section-number">2.6</span> Polygon homotopies are
        sequences of vertex moves</a></li>
        <li><a href="#homotopy-invariant"
        id="toc-homotopy-invariant"><span
        class="toc-section-number">2.7</span> Homotopy
        Invariant</a></li>
        <li><a
        href="#and-the-aptly-named-sir-not-appearing-in-this-film-1"
        id="toc-and-the-aptly-named-sir-not-appearing-in-this-film-1"><span
        class="toc-section-number">2.8</span> …and the Aptly Named Sir
        Not Appearing in This Film</a></li>
        <li><a href="#references-1" id="toc-references-1"><span
        class="toc-section-number">2.9</span> References</a></li>
        </ul></li>
        <li><a href="#homotopy-testingbeta"
        id="toc-homotopy-testingbeta"><span
        class="toc-section-number">3</span> Homotopy Testing<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#multiple-obstacles"
        id="toc-multiple-obstacles"><span
        class="toc-section-number">3.1</span> Multiple
        Obstacles</a></li>
        <li><a href="#crossing-sequences"
        id="toc-crossing-sequences"><span
        class="toc-section-number">3.2</span> Crossing
        Sequences</a></li>
        <li><a href="#reductions" id="toc-reductions"><span
        class="toc-section-number">3.3</span> Reductions</a></li>
        <li><a href="#varations" id="toc-varations"><span
        class="toc-section-number">3.4</span> Varations</a></li>
        <li><a
        href="#and-the-aptly-named-sir-not-appearing-in-this-film-2"
        id="toc-and-the-aptly-named-sir-not-appearing-in-this-film-2"><span
        class="toc-section-number">3.5</span> …and the Aptly Named Sir
        Not Appearing in This Film</a></li>
        </ul></li>
        <li><a href="#faster-homotopy-testingbeta"
        id="toc-faster-homotopy-testingbeta"><span
        class="toc-section-number">4</span> Faster Homotopy Testing<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#trapezoidal-decomposition"
        id="toc-trapezoidal-decomposition"><span
        class="toc-section-number">4.1</span> Trapezoidal
        decomposition</a></li>
        <li><a href="#vertical-and-horizontal-ranks"
        id="toc-vertical-and-horizontal-ranks"><span
        class="toc-section-number">4.2</span> Vertical and horizontal
        ranks</a></li>
        <li><a href="#rectification" id="toc-rectification"><span
        class="toc-section-number">4.3</span> Rectification</a></li>
        <li><a href="#reduction" id="toc-reduction"><span
        class="toc-section-number">4.4</span> Reduction</a></li>
        <li><a href="#layered-range-trees"
        id="toc-layered-range-trees"><span
        class="toc-section-number">4.5</span> Layered Range
        Trees</a></li>
        <li><a href="#final-analysis" id="toc-final-analysis"><span
        class="toc-section-number">4.6</span> Final Analysis</a></li>
        <li><a href="#dots-and-the-aptly-named-et-cetera-ad-nauseam"
        id="toc-dots-and-the-aptly-named-et-cetera-ad-nauseam"><span
        class="toc-section-number">4.7</span> <span
        class="math inline">\(\dots\)</span> And the Aptly Named Et
        Cetera Ad Nauseam</a></li>
        <li><a href="#references-2" id="toc-references-2"><span
        class="toc-section-number">4.8</span> References</a></li>
        </ul></li>
        <li><a href="#shortest-homotopic-pathsbeta"
        id="toc-shortest-homotopic-pathsbeta"><span
        class="toc-section-number">5</span> Shortest (Homotopic)
        Paths<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#shortest-paths-in-simple-polygons"
        id="toc-shortest-paths-in-simple-polygons"><span
        class="toc-section-number">5.1</span> Shortest Paths in Simple
        Polygons</a></li>
        <li><a href="#triangulations-and-dual-graphs"
        id="toc-triangulations-and-dual-graphs"><span
        class="toc-section-number">5.2</span> Triangulations and Dual
        Graphs</a></li>
        <li><a href="#crossing-sequences-1"
        id="toc-crossing-sequences-1"><span
        class="toc-section-number">5.3</span> Crossing
        Sequences</a></li>
        <li><a href="#sleeves" id="toc-sleeves"><span
        class="toc-section-number">5.4</span> Sleeves</a></li>
        <li><a href="#growing-funnels" id="toc-growing-funnels"><span
        class="toc-section-number">5.5</span> Growing Funnels</a></li>
        <li><a href="#polygons-with-holes"
        id="toc-polygons-with-holes"><span
        class="toc-section-number">5.6</span> Polygons with
        Holes</a></li>
        <li><a href="#the-universal-cover"
        id="toc-the-universal-cover"><span
        class="toc-section-number">5.7</span> The Universal
        Cover</a></li>
        <li><a href="#covering-spaces" id="toc-covering-spaces"><span
        class="toc-section-number">5.8</span> Covering Spaces</a></li>
        <li><a href="#dotsand-the-aptly-named-yadda-yadda"
        id="toc-dotsand-the-aptly-named-yadda-yadda"><span
        class="toc-section-number">5.9</span> <span
        class="math inline">\(\dots\)</span>and the Aptly Named Yadda
        Yadda</a></li>
        <li><a href="#references-3" id="toc-references-3"><span
        class="toc-section-number">5.10</span> References</a></li>
        </ul></li>
        <li><a href="#generic-planar-curvesalpha"
        id="toc-generic-planar-curvesalpha"><span
        class="toc-section-number">6</span> Generic Planar Curves<span
        class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#technicalities" id="toc-technicalities"><span
        class="toc-section-number">6.1</span> Technicalities</a></li>
        <li><a href="#image-graphs" id="toc-image-graphs"><span
        class="toc-section-number">6.2</span> Image graphs</a></li>
        <li><a href="#gauss-codes-and-gauss-diagrams"
        id="toc-gauss-codes-and-gauss-diagrams"><span
        class="toc-section-number">6.3</span> Gauss codes and Gauss
        diagrams</a></li>
        <li><a href="#tracing-faces" id="toc-tracing-faces"><span
        class="toc-section-number">6.4</span> Tracing Faces</a></li>
        <li><a href="#homotopy-moves" id="toc-homotopy-moves"><span
        class="toc-section-number">6.5</span> Homotopy moves</a></li>
        <li><a href="#planarity-testing"
        id="toc-planarity-testing"><span
        class="toc-section-number">6.6</span> Planarity testing</a></li>
        <li><a href="#dotsand-the-aptly-named-yadda-yadda-1"
        id="toc-dotsand-the-aptly-named-yadda-yadda-1"><span
        class="toc-section-number">6.7</span> <span
        class="math inline">\(\dots\)</span>and the Aptly Named Yadda
        Yadda</a></li>
        <li><a href="#references-4" id="toc-references-4"><span
        class="toc-section-number">6.8</span> References</a></li>
        <li><a href="#possible-reorganization"
        id="toc-possible-reorganization"><span
        class="toc-section-number">6.9</span> Possible
        reorganization</a></li>
        </ul></li>
        <li><a href="#unsigned-gauss-codesbeta"
        id="toc-unsigned-gauss-codesbeta"><span
        class="toc-section-number">7</span> Unsigned Gauss codes<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#winding-numbers-again"
        id="toc-winding-numbers-again"><span
        class="toc-section-number">7.1</span> Winding numbers
        again</a></li>
        <li><a href="#smoothing" id="toc-smoothing"><span
        class="toc-section-number">7.2</span> Smoothing</a></li>
        <li><a href="#gausss-parity-condition"
        id="toc-gausss-parity-condition"><span
        class="toc-section-number">7.3</span> Gauss’s parity
        condition</a></li>
        <li><a href="#dehns-non-crossing-condition"
        id="toc-dehns-non-crossing-condition"><span
        class="toc-section-number">7.4</span> Dehn’s non-crossing
        condition</a></li>
        <li><a href="#tree-onion-figures"
        id="toc-tree-onion-figures"><span
        class="toc-section-number">7.5</span> Tree-onion
        figures</a></li>
        <li><a href="#bipartite-interlacement"
        id="toc-bipartite-interlacement"><span
        class="toc-section-number">7.6</span> Bipartite
        interlacement</a></li>
        <li><a href="#recrossing" id="toc-recrossing"><span
        class="toc-section-number">7.7</span> Recrossing</a></li>
        <li><a href="#algorithm-summary"
        id="toc-algorithm-summary"><span
        class="toc-section-number">7.8</span> Algorithm summary</a></li>
        <li><a href="#faster-faster" id="toc-faster-faster"><span
        class="toc-section-number">7.9</span> Faster! Faster!</a></li>
        <li><a href="#dotsand-the-aptly-named-yadda-yadda-2"
        id="toc-dotsand-the-aptly-named-yadda-yadda-2"><span
        class="toc-section-number">7.10</span> <span
        class="math inline">\(\dots\)</span>and the Aptly Named Yadda
        Yadda</a></li>
        <li><a href="#references-5" id="toc-references-5"><span
        class="toc-section-number">7.11</span> References</a></li>
        </ul></li>
        <li><a href="#curve-homotopy-and-curve-invariantsalpha"
        id="toc-curve-homotopy-and-curve-invariantsalpha"><span
        class="toc-section-number">8</span> Curve homotopy and curve
        invariants<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#steinitzs-contraction-algorithm"
        id="toc-steinitzs-contraction-algorithm"><span
        class="toc-section-number">8.1</span> Steinitz’s contraction
        algorithm</a></li>
        <li><a href="#rotation-number" id="toc-rotation-number"><span
        class="toc-section-number">8.2</span> Rotation number</a></li>
        <li><a href="#regular-homotopy" id="toc-regular-homotopy"><span
        class="toc-section-number">8.3</span> Regular homotopy</a></li>
        <li><a href="#strangeness" id="toc-strangeness"><span
        class="toc-section-number">8.4</span> Strangeness</a></li>
        <li><a href="#defect" id="toc-defect"><span
        class="toc-section-number">8.5</span> Defect</a></li>
        <li><a href="#aptly-yadda-yadda"
        id="toc-aptly-yadda-yadda"><span
        class="toc-section-number">8.6</span> Aptly Yadda Yadda</a></li>
        </ul></li>
        <li><a href="#planar-graphsbeta"
        id="toc-planar-graphsbeta"><span
        class="toc-section-number">9</span> Planar Graphs<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#abstract-graphs" id="toc-abstract-graphs"><span
        class="toc-section-number">9.1</span> Abstract graphs</a></li>
        <li><a href="#data-structures" id="toc-data-structures"><span
        class="toc-section-number">9.2</span> Data structures</a></li>
        <li><a href="#topological-graphs"
        id="toc-topological-graphs"><span
        class="toc-section-number">9.3</span> Topological
        graphs</a></li>
        <li><a href="#planar-graphs-and-planar-maps"
        id="toc-planar-graphs-and-planar-maps"><span
        class="toc-section-number">9.4</span> Planar graphs and planar
        maps</a></li>
        <li><a href="#rotation-systems" id="toc-rotation-systems"><span
        class="toc-section-number">9.5</span> Rotation systems</a></li>
        <li><a href="#formalities-and-trivialities"
        id="toc-formalities-and-trivialities"><span
        class="toc-section-number">9.6</span> Formalities and
        Trivialities</a></li>
        <li><a href="#caveat-lector" id="toc-caveat-lector"><span
        class="toc-section-number">9.7</span> Caveat Lector</a></li>
        <li><a href="#duality" id="toc-duality"><span
        class="toc-section-number">9.8</span> Duality</a></li>
        <li><a href="#self-dual-data-structures"
        id="toc-self-dual-data-structures"><span
        class="toc-section-number">9.9</span> Self-dual data
        structures</a></li>
        <li><a href="#endianity" id="toc-endianity"><span
        class="toc-section-number">9.10</span> Endianity</a></li>
        <li><a href="#other-derived-maps"
        id="toc-other-derived-maps"><span
        class="toc-section-number">9.11</span> Other derived
        maps</a></li>
        <li><a href="#aptly-yadda-yadda-1"
        id="toc-aptly-yadda-yadda-1"><span
        class="toc-section-number">9.12</span> Aptly Yadda
        Yadda</a></li>
        <li><a href="#revision" id="toc-revision"><span
        class="toc-section-number">9.13</span> Revision?</a></li>
        </ul></li>
        <li><a href="#tree-cotree-decompositionsbeta"
        id="toc-tree-cotree-decompositionsbeta"><span
        class="toc-section-number">10</span> Tree-Cotree
        Decompositions<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#important-graph-definitions-yawn"
        id="toc-important-graph-definitions-yawn"><span
        class="toc-section-number">10.1</span> Important graph
        definitions (yawn)</a></li>
        <li><a href="#deletion-and-contraction"
        id="toc-deletion-and-contraction"><span
        class="toc-section-number">10.2</span> Deletion and
        Contraction</a></li>
        <li><a href="#spanning-trees" id="toc-spanning-trees"><span
        class="toc-section-number">10.3</span> Spanning trees</a></li>
        <li><a href="#deletion-and-contraction-in-planar-maps"
        id="toc-deletion-and-contraction-in-planar-maps"><span
        class="toc-section-number">10.4</span> Deletion and Contraction
        in Planar Maps</a></li>
        <li><a href="#tree-cotree-decompositions"
        id="toc-tree-cotree-decompositions"><span
        class="toc-section-number">10.5</span> Tree-Cotree
        Decompositions</a></li>
        <li><a href="#eulers-formula" id="toc-eulers-formula"><span
        class="toc-section-number">10.6</span> Euler’s Formula</a></li>
        <li><a href="#the-combinatorial-gauss-bonnet-theorem"
        id="toc-the-combinatorial-gauss-bonnet-theorem"><span
        class="toc-section-number">10.7</span> The Combinatorial
        Gauss-Bonnet Theorem</a></li>
        <li><a href="#historical-digression"
        id="toc-historical-digression"><span
        class="toc-section-number">10.8</span> Historical
        Digression</a></li>
        <li><a href="#aptly-named" id="toc-aptly-named"><span
        class="toc-section-number">10.9</span> Aptly Named</a></li>
        </ul></li>
        <li><a href="#straight-line-planar-mapsbeta"
        id="toc-straight-line-planar-mapsbeta"><span
        class="toc-section-number">11</span> Straight-line Planar
        Maps<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#simple-triangulations"
        id="toc-simple-triangulations"><span
        class="toc-section-number">11.1</span> Simple
        triangulations</a></li>
        <li><a href="#inner-induction-hole-filling"
        id="toc-inner-induction-hole-filling"><span
        class="toc-section-number">11.2</span> Inner Induction (Hole
        Filling)</a></li>
        <li><a href="#outer-induction-canonical-ordering"
        id="toc-outer-induction-canonical-ordering"><span
        class="toc-section-number">11.3</span> Outer Induction
        (Canonical Ordering)</a></li>
        <li><a href="#schnyder-woods" id="toc-schnyder-woods"><span
        class="toc-section-number">11.4</span> Schnyder Woods</a></li>
        <li><a href="#grid-embedding" id="toc-grid-embedding"><span
        class="toc-section-number">11.5</span> Grid embedding</a></li>
        <li><a href="#references-6" id="toc-references-6"><span
        class="toc-section-number">11.6</span> References</a></li>
        <li><a href="#not-appearing" id="toc-not-appearing"><span
        class="toc-section-number">11.7</span> Not Appearing</a></li>
        </ul></li>
        <li><a href="#tuttes-spring-embedding-theorembeta"
        id="toc-tuttes-spring-embedding-theorembeta"><span
        class="toc-section-number">12</span> Tutte’s Spring Embedding
        Theorem<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#outer-face-is-outer"
        id="toc-outer-face-is-outer"><span
        class="toc-section-number">12.1</span> Outer Face is
        Outer</a></li>
        <li><a href="#laplacian-linear-systems-and-energy-minimization"
        id="toc-laplacian-linear-systems-and-energy-minimization"><span
        class="toc-section-number">12.2</span> Laplacian linear systems
        and energy minimization</a></li>
        <li><a href="#slicing-with-lines"
        id="toc-slicing-with-lines"><span
        class="toc-section-number">12.3</span> Slicing with
        Lines</a></li>
        <li><a href="#no-degenerate-vertex-neighborhoods"
        id="toc-no-degenerate-vertex-neighborhoods"><span
        class="toc-section-number">12.4</span> No Degenerate Vertex
        Neighborhoods</a></li>
        <li><a href="#no-degenerate-faces"
        id="toc-no-degenerate-faces"><span
        class="toc-section-number">12.5</span> No Degenerate
        Faces</a></li>
        <li><a href="#whitneys-uniqueness-theorem"
        id="toc-whitneys-uniqueness-theorem"><span
        class="toc-section-number">12.6</span> Whitney’s Uniqueness
        Theorem</a></li>
        <li><a href="#not-appearing-1" id="toc-not-appearing-1"><span
        class="toc-section-number">12.7</span> Not Appearing</a></li>
        </ul></li>
        <li><a href="#maxwellcremona-correspondencebeta"
        id="toc-maxwellcremona-correspondencebeta"><span
        class="toc-section-number">13</span> Maxwell–Cremona
        Correspondence<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#dramatis-personae"
        id="toc-dramatis-personae"><span
        class="toc-section-number">13.1</span> Dramatis
        Personae</a></li>
        <li><a href="#reciprocal-diagrams"
        id="toc-reciprocal-diagrams"><span
        class="toc-section-number">13.2</span> Reciprocal
        diagrams</a></li>
        <li><a href="#polyhedral-lifts" id="toc-polyhedral-lifts"><span
        class="toc-section-number">13.3</span> Polyhedral lifts</a></li>
        <li><a href="#a-non-obvious-example-the-anticube"
        id="toc-a-non-obvious-example-the-anticube"><span
        class="toc-section-number">13.4</span> A Non-Obvious Example:
        The “Anticube”</a></li>
        <li><a href="#steinitzs-theorem"
        id="toc-steinitzs-theorem"><span
        class="toc-section-number">13.5</span> Steinitz’s
        Theorem</a></li>
        <li><a href="#non-3-connected-frameworks"
        id="toc-non-3-connected-frameworks"><span
        class="toc-section-number">13.6</span> Non-3-connected
        Frameworks</a></li>
        <li><a href="#non-planar-frameworks"
        id="toc-non-planar-frameworks"><span
        class="toc-section-number">13.7</span> Non-Planar
        Frameworks</a></li>
        <li><a href="#references-7" id="toc-references-7"><span
        class="toc-section-number">13.8</span> References</a></li>
        <li><a href="#aptly-named-1" id="toc-aptly-named-1"><span
        class="toc-section-number">13.9</span> Aptly Named</a></li>
        </ul></li>
        <li><a href="#circle-packingvarnothing"
        id="toc-circle-packingvarnothing"><span
        class="toc-section-number">14</span> Circle Packing<span
        class="math inline">\(^\varnothing\)</span></a></li>
        <li><a href="#multiple-source-shortest-pathsalpha"
        id="toc-multiple-source-shortest-pathsalpha"><span
        class="toc-section-number">15</span> Multiple-Source Shortest
        Paths<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#problem-statement"
        id="toc-problem-statement"><span
        class="toc-section-number">15.1</span> Problem
        Statement</a></li>
        <li><a href="#shortest-paths-and-slacks"
        id="toc-shortest-paths-and-slacks"><span
        class="toc-section-number">15.2</span> Shortest paths and
        slacks</a></li>
        <li><a href="#compact-output" id="toc-compact-output"><span
        class="toc-section-number">15.3</span> Compact Output</a></li>
        <li><a href="#parametric-shortest-paths"
        id="toc-parametric-shortest-paths"><span
        class="toc-section-number">15.4</span> Parametric Shortest
        Paths</a></li>
        <li><a href="#dynamic-forest-data-structures"
        id="toc-dynamic-forest-data-structures"><span
        class="toc-section-number">15.5</span> Dynamic Forest Data
        Structures</a></li>
        <li><a href="#the-pivoting-algorithm"
        id="toc-the-pivoting-algorithm"><span
        class="toc-section-number">15.6</span> The Pivoting
        Algorithm</a></li>
        <li><a href="#applications" id="toc-applications"><span
        class="toc-section-number">15.7</span> Applications</a></li>
        <li><a href="#enforcing-unique-shortest-paths"
        id="toc-enforcing-unique-shortest-paths"><span
        class="toc-section-number">15.8</span> Enforcing Unique Shortest
        Paths</a></li>
        <li><a href="#leftmost-shortest-paths"
        id="toc-leftmost-shortest-paths"><span
        class="toc-section-number">15.9</span> Leftmost shortest
        paths</a></li>
        <li><a href="#references-8" id="toc-references-8"><span
        class="toc-section-number">15.10</span> References</a></li>
        <li><a href="#sir-not-appearing"
        id="toc-sir-not-appearing"><span
        class="toc-section-number">15.11</span> Sir not
        appearing</a></li>
        </ul></li>
        <li><a href="#multiple-source-shortest-paths-revisitedalpha"
        id="toc-multiple-source-shortest-paths-revisitedalpha"><span
        class="toc-section-number">16</span> Multiple-Source Shortest
        Paths, Revisited<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#problem-formulation"
        id="toc-problem-formulation"><span
        class="toc-section-number">16.1</span> Problem
        formulation</a></li>
        <li><a href="#overview" id="toc-overview"><span
        class="toc-section-number">16.2</span> Overview</a></li>
        <li><a href="#properly-shared-edges"
        id="toc-properly-shared-edges"><span
        class="toc-section-number">16.3</span> Properly shared
        edges</a></li>
        <li><a href="#contraction" id="toc-contraction"><span
        class="toc-section-number">16.4</span> Contraction</a></li>
        <li><a href="#distance-queries" id="toc-distance-queries"><span
        class="toc-section-number">16.5</span> Distance Queries</a></li>
        <li><a href="#space-and-time-analysis"
        id="toc-space-and-time-analysis"><span
        class="toc-section-number">16.6</span> Space and Time
        Analysis</a></li>
        <li><a href="#references-9" id="toc-references-9"><span
        class="toc-section-number">16.7</span> References</a></li>
        </ul></li>
        <li><a href="#planar-separatorsbeta"
        id="toc-planar-separatorsbeta"><span
        class="toc-section-number">17</span> Planar Separators<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#tree-separators" id="toc-tree-separators"><span
        class="toc-section-number">17.1</span> Tree separators</a></li>
        <li><a href="#fundamental-cycle-separators"
        id="toc-fundamental-cycle-separators"><span
        class="toc-section-number">17.2</span> Fundamental cycle
        separators</a></li>
        <li><a href="#breadth-first-level-separators"
        id="toc-breadth-first-level-separators"><span
        class="toc-section-number">17.3</span> Breadth-first level
        separators</a></li>
        <li><a href="#cycle-separators" id="toc-cycle-separators"><span
        class="toc-section-number">17.4</span> Cycle separators</a></li>
        <li><a href="#good-r-divisions-and-subdivision-hierarchies"
        id="toc-good-r-divisions-and-subdivision-hierarchies"><span
        class="toc-section-number">17.5</span> Good <span
        class="math inline">\(r\)</span>-divisions and Subdivision
        Hierarchies</a></li>
        <li><a href="#history" id="toc-history"><span
        class="toc-section-number">17.6</span> History</a></li>
        <li><a href="#references-10" id="toc-references-10"><span
        class="toc-section-number">17.7</span> References</a></li>
        <li><a href="#aptly-named-sir-not"
        id="toc-aptly-named-sir-not"><span
        class="toc-section-number">17.8</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#branch-decompositionsvarnothing"
        id="toc-branch-decompositionsvarnothing"><span
        class="toc-section-number">18</span> Branch Decompositions<span
        class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#branchwidth" id="toc-branchwidth"><span
        class="toc-section-number">18.1</span> Branchwidth</a></li>
        <li><a href="#treewidth" id="toc-treewidth"><span
        class="toc-section-number">18.2</span> Treewidth</a></li>
        <li><a href="#width-versus-diameter"
        id="toc-width-versus-diameter"><span
        class="toc-section-number">18.3</span> Width versus
        diameter</a></li>
        <li><a href="#local-approximation"
        id="toc-local-approximation"><span
        class="toc-section-number">18.4</span> Local
        approximation</a></li>
        <li><a href="#aptly-named-sir-not-1"
        id="toc-aptly-named-sir-not-1"><span
        class="toc-section-number">18.5</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#fast-shortest-paths-in-planar-graphsbeta"
        id="toc-fast-shortest-paths-in-planar-graphsbeta"><span
        class="toc-section-number">19</span> Fast Shortest Paths in
        Planar Graphs<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#dense-distance-graphs"
        id="toc-dense-distance-graphs"><span
        class="toc-section-number">19.1</span> Dense Distance
        Graphs</a></li>
        <li><a href="#beating-dijkstra" id="toc-beating-dijkstra"><span
        class="toc-section-number">19.2</span> Beating Dijkstra</a></li>
        <li><a href="#beating-bellman-ford-nested-dissection"
        id="toc-beating-bellman-ford-nested-dissection"><span
        class="toc-section-number">19.3</span> Beating Bellman-Ford:
        Nested Dissection</a></li>
        <li><a href="#aside-computing-spring-embeddings"
        id="toc-aside-computing-spring-embeddings"><span
        class="toc-section-number">19.4</span> Aside: Computing Spring
        Embeddings</a></li>
        <li><a href="#repricing" id="toc-repricing"><span
        class="toc-section-number">19.5</span> Repricing</a></li>
        <li><a href="#nested-dissection-revisited"
        id="toc-nested-dissection-revisited"><span
        class="toc-section-number">19.6</span> Nested Dissection
        Revisited</a></li>
        <li><a href="#monge-arrays-and-smawk"
        id="toc-monge-arrays-and-smawk"><span
        class="toc-section-number">19.7</span> Monge arrays and
        SMAWK</a></li>
        <li><a href="#planar-distance-matrices-are-almost-monge"
        id="toc-planar-distance-matrices-are-almost-monge"><span
        class="toc-section-number">19.8</span> Planar distance matrices
        are (almost) Monge</a></li>
        <li><a href="#beating-nested-dissection"
        id="toc-beating-nested-dissection"><span
        class="toc-section-number">19.9</span> Beating Nested
        Dissection</a></li>
        <li><a href="#references-11" id="toc-references-11"><span
        class="toc-section-number">19.10</span> References</a></li>
        <li><a href="#aptly-named-sir-not-2"
        id="toc-aptly-named-sir-not-2"><span
        class="toc-section-number">19.11</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#minimum-cutsbeta" id="toc-minimum-cutsbeta"><span
        class="toc-section-number">20</span> Minimum Cuts<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#duality-shortest-essential-cycle"
        id="toc-duality-shortest-essential-cycle"><span
        class="toc-section-number">20.1</span> Duality: Shortest
        essential cycle</a></li>
        <li><a href="#crossing-at-most-once"
        id="toc-crossing-at-most-once"><span
        class="toc-section-number">20.2</span> Crossing at most
        once</a></li>
        <li><a href="#slicing-along-a-path"
        id="toc-slicing-along-a-path"><span
        class="toc-section-number">20.3</span> Slicing along a
        path</a></li>
        <li><a href="#algorithms" id="toc-algorithms"><span
        class="toc-section-number">20.4</span> Algorithms</a></li>
        <li><a href="#faster-shortest-paths-with-negative-lengths"
        id="toc-faster-shortest-paths-with-negative-lengths"><span
        class="toc-section-number">20.5</span> Faster Shortest Paths
        with Negative Lengths</a></li>
        <li><a href="#faster-minimum-cuts-fr-dijkstra"
        id="toc-faster-minimum-cuts-fr-dijkstra"><span
        class="toc-section-number">20.6</span> Faster Minimum Cuts:
        FR-Dijkstra</a></li>
        <li><a href="#references-12" id="toc-references-12"><span
        class="toc-section-number">20.7</span> References</a></li>
        <li><a href="#aptly-named-sir-not-3"
        id="toc-aptly-named-sir-not-3"><span
        class="toc-section-number">20.8</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#faster-minimum-cuts-fr-dijkstraalpha"
        id="toc-faster-minimum-cuts-fr-dijkstraalpha"><span
        class="toc-section-number">21</span> Faster Minimum Cuts
        (FR-Dijkstra)<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#monge-heaps" id="toc-monge-heaps"><span
        class="toc-section-number">21.1</span> Monge Heaps</a></li>
        <li><a href="#monge-structure-of-nice-r-divisions"
        id="toc-monge-structure-of-nice-r-divisions"><span
        class="toc-section-number">21.2</span> Monge structure of nice
        <span class="math inline">\(r\)</span>-divisions</a></li>
        <li><a href="#fr-dijkstra" id="toc-fr-dijkstra"><span
        class="toc-section-number">21.3</span> FR-Dijkstra</a></li>
        <li><a href="#back-to-minimum-cut"
        id="toc-back-to-minimum-cut"><span
        class="toc-section-number">21.4</span> Back to minimum
        cut</a></li>
        <li><a href="#aptly-named-sir-not-4"
        id="toc-aptly-named-sir-not-4"><span
        class="toc-section-number">21.5</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#distributive-flow-latticesvarnothing"
        id="toc-distributive-flow-latticesvarnothing"><span
        class="toc-section-number">22</span> Distributive Flow
        Lattices<span class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#pseudoflows-and-circulations"
        id="toc-pseudoflows-and-circulations"><span
        class="toc-section-number">22.1</span> Pseudoflows and
        Circulations</a></li>
        <li><a href="#aptly-named-sir-not-5"
        id="toc-aptly-named-sir-not-5"><span
        class="toc-section-number">22.2</span> Aptly Named Sir
        Not</a></li>
        </ul></li>
        <li><a href="#maximum-flowvarnothingalpha"
        id="toc-maximum-flowvarnothingalpha"><span
        class="toc-section-number">23</span> Maximum Flow<span
        class="math inline">\(^{\varnothing/\alpha}\)</span></a>
        <ul>
        <li><a href="#background" id="toc-background"><span
        class="toc-section-number">23.1</span> Background</a></li>
        <li><a href="#planar-circulations"
        id="toc-planar-circulations"><span
        class="toc-section-number">23.2</span> Planar
        Circulations</a></li>
        <li><a href="#feasible-planar-circulations-and-shortest-paths"
        id="toc-feasible-planar-circulations-and-shortest-paths"><span
        class="toc-section-number">23.3</span> Feasible Planar
        Circulations and Shortest Paths</a></li>
        <li><a href="#our-first-planar-max-flow-algorithm"
        id="toc-our-first-planar-max-flow-algorithm"><span
        class="toc-section-number">23.4</span> Our First Planar Max-flow
        Algorithm</a></li>
        <li><a href="#parametric-shortest-paths-1"
        id="toc-parametric-shortest-paths-1"><span
        class="toc-section-number">23.5</span> Parametric Shortest
        Paths</a></li>
        <li><a href="#active-darts" id="toc-active-darts"><span
        class="toc-section-number">23.6</span> Active Darts</a></li>
        <li><a href="#fast-pivots" id="toc-fast-pivots"><span
        class="toc-section-number">23.7</span> Fast Pivots</a></li>
        <li><a href="#universal-cover-analysis"
        id="toc-universal-cover-analysis"><span
        class="toc-section-number">23.8</span> Universal Cover
        Analysis</a></li>
        <li><a href="#references-13" id="toc-references-13"><span
        class="toc-section-number">23.9</span> References</a></li>
        <li><a href="#aptly-not" id="toc-aptly-not"><span
        class="toc-section-number">23.10</span> Aptly Not</a></li>
        </ul></li>
        <li><a href="#surface-mapsbeta" id="toc-surface-mapsbeta"><span
        class="toc-section-number">24</span> Surface Maps<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a
        href="#surfaces-polygonal-schemata-and-cellular-embeddings"
        id="toc-surfaces-polygonal-schemata-and-cellular-embeddings"><span
        class="toc-section-number">24.1</span> Surfaces, Polygonal
        Schemata, and Cellular Embeddings</a></li>
        <li><a href="#orientability" id="toc-orientability"><span
        class="toc-section-number">24.2</span> Orientability</a></li>
        <li><a href="#band-decompositions"
        id="toc-band-decompositions"><span
        class="toc-section-number">24.3</span> Band
        Decompositions</a></li>
        <li><a href="#reflection-systems"
        id="toc-reflection-systems"><span
        class="toc-section-number">24.4</span> Reflection
        Systems</a></li>
        <li><a href="#equivalence" id="toc-equivalence"><span
        class="toc-section-number">24.5</span> Equivalence</a></li>
        <li><a href="#duality-1" id="toc-duality-1"><span
        class="toc-section-number">24.6</span> Duality</a></li>
        <li><a href="#loops-and-isthmuses-deletion-and-contraction"
        id="toc-loops-and-isthmuses-deletion-and-contraction"><span
        class="toc-section-number">24.7</span> Loops and Isthmuses;
        Deletion and Contraction</a></li>
        <li><a href="#references-14" id="toc-references-14"><span
        class="toc-section-number">24.8</span> References</a></li>
        <li><a href="#sir-not-appearing-1"
        id="toc-sir-not-appearing-1"><span
        class="toc-section-number">24.9</span> Sir Not
        Appearing</a></li>
        </ul></li>
        <li><a href="#surface-classificationbeta"
        id="toc-surface-classificationbeta"><span
        class="toc-section-number">25</span> Surface Classification<span
        class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#tree-cotree-decompositions-and-systems-of-loops"
        id="toc-tree-cotree-decompositions-and-systems-of-loops"><span
        class="toc-section-number">25.1</span> Tree-Cotree
        Decompositions and Systems of Loops</a></li>
        <li><a href="#handles" id="toc-handles"><span
        class="toc-section-number">25.2</span> Handles</a></li>
        <li><a href="#twists" id="toc-twists"><span
        class="toc-section-number">25.3</span> Twists</a></li>
        <li><a href="#dycks-surface" id="toc-dycks-surface"><span
        class="toc-section-number">25.4</span> Dyck’s Surface</a></li>
        <li><a href="#canonical-polygonal-schemata"
        id="toc-canonical-polygonal-schemata"><span
        class="toc-section-number">25.5</span> Canonical Polygonal
        Schemata</a></li>
        <li><a href="#oilers-formula" id="toc-oilers-formula"><span
        class="toc-section-number">25.6</span> “Oiler’s”
        Formula</a></li>
        <li><a href="#references-15" id="toc-references-15"><span
        class="toc-section-number">25.7</span> References</a></li>
        <li><a href="#aptly-named-sir" id="toc-aptly-named-sir"><span
        class="toc-section-number">25.8</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#homotopy-in-surface-mapsalpha"
        id="toc-homotopy-in-surface-mapsalpha"><span
        class="toc-section-number">26</span> Homotopy in Surface
        Maps<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#cut-graphs" id="toc-cut-graphs"><span
        class="toc-section-number">26.1</span> Cut Graphs</a></li>
        <li><a href="#systems-of-loops-and-homotopy"
        id="toc-systems-of-loops-and-homotopy"><span
        class="toc-section-number">26.2</span> Systems of Loops and
        Homotopy</a></li>
        <li><a href="#whats-a-curve" id="toc-whats-a-curve"><span
        class="toc-section-number">26.3</span> What’s a
        “curve”?</a></li>
        <li><a href="#spur-and-face-moves"
        id="toc-spur-and-face-moves"><span
        class="toc-section-number">26.4</span> Spur and Face
        Moves</a></li>
        <li><a href="#characterizing-homotopy"
        id="toc-characterizing-homotopy"><span
        class="toc-section-number">26.5</span> Characterizing
        Homotopy</a></li>
        <li><a href="#references-16" id="toc-references-16"><span
        class="toc-section-number">26.6</span> References</a></li>
        <li><a href="#aptly-named-sir-1"
        id="toc-aptly-named-sir-1"><span
        class="toc-section-number">26.7</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#planarization-and-separationalphabeta"
        id="toc-planarization-and-separationalphabeta"><span
        class="toc-section-number">27</span> Planarization and
        Separation<span
        class="math inline">\(^{\alpha/\beta}\)</span></a>
        <ul>
        <li><a href="#multiple-short-cycles"
        id="toc-multiple-short-cycles"><span
        class="toc-section-number">27.1</span> Multiple Short
        Cycles</a></li>
        <li><a href="#slabification" id="toc-slabification"><span
        class="toc-section-number">27.2</span> Slabification</a></li>
        <li><a href="#nice-r-divisions" id="toc-nice-r-divisions"><span
        class="toc-section-number">27.3</span> Nice <span
        class="math inline">\(r\)</span>-divisions</a></li>
        <li><a href="#applications-1" id="toc-applications-1"><span
        class="toc-section-number">27.4</span> Applications</a></li>
        <li><a href="#references-17" id="toc-references-17"><span
        class="toc-section-number">27.5</span> References</a></li>
        <li><a href="#aptly-named-sir-2"
        id="toc-aptly-named-sir-2"><span
        class="toc-section-number">27.6</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#homotopy-testing-on-surface-mapsbeta"
        id="toc-homotopy-testing-on-surface-mapsbeta"><span
        class="toc-section-number">28</span> Homotopy Testing on Surface
        Maps<span class="math inline">\(^\beta\)</span></a>
        <ul>
        <li><a href="#reducing-to-a-system-of-loops"
        id="toc-reducing-to-a-system-of-loops"><span
        class="toc-section-number">28.1</span> Reducing to a System of
        Loops</a></li>
        <li><a href="#universal-cover" id="toc-universal-cover"><span
        class="toc-section-number">28.2</span> Universal Cover</a></li>
        <li><a href="#dehns-lemma" id="toc-dehns-lemma"><span
        class="toc-section-number">28.3</span> Dehn’s Lemma</a></li>
        <li><a href="#dehns-algorithm" id="toc-dehns-algorithm"><span
        class="toc-section-number">28.4</span> Dehn’s
        algorithm!</a></li>
        <li><a href="#system-of-quads" id="toc-system-of-quads"><span
        class="toc-section-number">28.5</span> System of quads</a></li>
        <li><a href="#brackets" id="toc-brackets"><span
        class="toc-section-number">28.6</span> Brackets</a></li>
        <li><a href="#reduction-algorithm"
        id="toc-reduction-algorithm"><span
        class="toc-section-number">28.7</span> Reduction
        algorithm</a></li>
        <li><a href="#references-18" id="toc-references-18"><span
        class="toc-section-number">28.8</span> References</a></li>
        <li><a href="#sir-not" id="toc-sir-not"><span
        class="toc-section-number">28.9</span> Sir Not</a></li>
        </ul></li>
        <li><a href="#systems-of-cycles-and-homologyalpha"
        id="toc-systems-of-cycles-and-homologyalpha"><span
        class="toc-section-number">29</span> Systems of Cycles and
        Homology<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#cycles-and-boundaries"
        id="toc-cycles-and-boundaries"><span
        class="toc-section-number">29.1</span> Cycles and
        Boundaries</a></li>
        <li><a href="#homology" id="toc-homology"><span
        class="toc-section-number">29.2</span> Homology</a></li>
        <li><a href="#relax-its-just-linear-algebra"
        id="toc-relax-its-just-linear-algebra"><span
        class="toc-section-number">29.3</span> Relax, it’s just linear
        algebra!</a></li>
        <li><a href="#crossing-numbers" id="toc-crossing-numbers"><span
        class="toc-section-number">29.4</span> Crossing Numbers</a></li>
        <li><a href="#systems-of-cocycles-and-cohomology"
        id="toc-systems-of-cocycles-and-cohomology"><span
        class="toc-section-number">29.5</span> Systems of Cocycles and
        Cohomology</a></li>
        <li><a href="#homology-signatures"
        id="toc-homology-signatures"><span
        class="toc-section-number">29.6</span> Homology
        Signatures</a></li>
        <li><a href="#separating-cycles"
        id="toc-separating-cycles"><span
        class="toc-section-number">29.7</span> Separating
        Cycles</a></li>
        <li><a href="#references-19" id="toc-references-19"><span
        class="toc-section-number">29.8</span> References</a></li>
        <li><a href="#aptly-named-sir-3"
        id="toc-aptly-named-sir-3"><span
        class="toc-section-number">29.9</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#shortest-interesting-cyclesalpha"
        id="toc-shortest-interesting-cyclesalpha"><span
        class="toc-section-number">30</span> Shortest Interesting
        Cycles<span class="math inline">\(^\alpha\)</span></a>
        <ul>
        <li><a href="#properties-of-shortest-nontrivial-cycles"
        id="toc-properties-of-shortest-nontrivial-cycles"><span
        class="toc-section-number">30.1</span> Properties of Shortest
        Nontrivial Cycles</a></li>
        <li><a href="#a-polynomial-time-algorithm"
        id="toc-a-polynomial-time-algorithm"><span
        class="toc-section-number">30.2</span> A polynomial-time
        algorithm</a></li>
        <li><a href="#near-quadratic-time"
        id="toc-near-quadratic-time"><span
        class="toc-section-number">30.3</span> Near-quadratic
        time</a></li>
        <li><a href="#multiple-source-shortest-paths"
        id="toc-multiple-source-shortest-paths"><span
        class="toc-section-number">30.4</span> Multiple-Source Shortest
        Paths</a></li>
        <li><a href="#shortest-nonseparating-cycles-in-near-linear-time"
        id="toc-shortest-nonseparating-cycles-in-near-linear-time"><span
        class="toc-section-number">30.5</span> Shortest Nonseparating
        Cycles in Near-Linear Time</a></li>
        <li><a
        href="#shortest-noncontractible-cycles-in-near-linear-time-sketch"
        id="toc-shortest-noncontractible-cycles-in-near-linear-time-sketch"><span
        class="toc-section-number">30.6</span> Shortest Noncontractible
        Cycles in Near-Linear Time (sketch)</a></li>
        <li><a href="#references-20" id="toc-references-20"><span
        class="toc-section-number">30.7</span> References</a></li>
        <li><a href="#aptly-named-sir-4"
        id="toc-aptly-named-sir-4"><span
        class="toc-section-number">30.8</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#surfaces-with-boundaryvarnothing"
        id="toc-surfaces-with-boundaryvarnothing"><span
        class="toc-section-number">31</span> Surfaces with Boundary<span
        class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#arcs-and-slicing" id="toc-arcs-and-slicing"><span
        class="toc-section-number">31.1</span> Arcs and Slicing</a></li>
        <li><a href="#forest-cotree-decompositions"
        id="toc-forest-cotree-decompositions"><span
        class="toc-section-number">31.2</span> Forest-Cotree
        Decompositions</a></li>
        <li><a href="#cut-graphs-and-systems-of-arcs"
        id="toc-cut-graphs-and-systems-of-arcs"><span
        class="toc-section-number">31.3</span> Cut Graphs and Systems of
        Arcs</a></li>
        <li><a
        href="#tree-coforest-decompositions-and-systems-of-coarcs"
        id="toc-tree-coforest-decompositions-and-systems-of-coarcs"><span
        class="toc-section-number">31.4</span> Tree-Coforest
        Decompositions and Systems of Coarcs</a></li>
        <li><a href="#references-21" id="toc-references-21"><span
        class="toc-section-number">31.5</span> References</a></li>
        <li><a href="#aptly-named-sir-5"
        id="toc-aptly-named-sir-5"><span
        class="toc-section-number">31.6</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#minimum-cuts-in-surface-graphsvarnothing"
        id="toc-minimum-cuts-in-surface-graphsvarnothing"><span
        class="toc-section-number">32</span> Minimum Cuts in Surface
        Graphs<span class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#duality-with-even-subgraphs"
        id="toc-duality-with-even-subgraphs"><span
        class="toc-section-number">32.1</span> Duality with Even
        Subgraphs</a></li>
        <li><a href="#mathbbz_2-homology-cover"
        id="toc-mathbbz_2-homology-cover"><span
        class="toc-section-number">32.2</span> <span
        class="math inline">\(\mathbb{Z}_2\)</span>-Homology
        Cover</a></li>
        <li><a href="#mathbbz_2-minimal-cycles"
        id="toc-mathbbz_2-minimal-cycles"><span
        class="toc-section-number">32.3</span> <span
        class="math inline">\(\mathbb{Z}_2\)</span>-Minimal
        Cycles</a></li>
        <li><a href="#mathbbz_2-minimal-even-subgraphs"
        id="toc-mathbbz_2-minimal-even-subgraphs"><span
        class="toc-section-number">32.4</span> <span
        class="math inline">\(\mathbb{Z}_2\)</span>-Minimal Even
        Subgraphs</a></li>
        <li><a href="#np-hardness" id="toc-np-hardness"><span
        class="toc-section-number">32.5</span> NP-hardness (??)</a></li>
        <li><a href="#references-22" id="toc-references-22"><span
        class="toc-section-number">32.6</span> References</a></li>
        <li><a href="#aptly-named-sir-6"
        id="toc-aptly-named-sir-6"><span
        class="toc-section-number">32.7</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#maximum-flows-in-surface-graphsvarnothing"
        id="toc-maximum-flows-in-surface-graphsvarnothing"><span
        class="toc-section-number">33</span> Maximum Flows in Surface
        Graphs<span class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#real-homology" id="toc-real-homology"><span
        class="toc-section-number">33.1</span> Real Homology</a></li>
        <li><a href="#homologous-feasible-flows"
        id="toc-homologous-feasible-flows"><span
        class="toc-section-number">33.2</span> Homologous Feasible
        Flows</a></li>
        <li><a href="#shortest-paths-with-negative-edges"
        id="toc-shortest-paths-with-negative-edges"><span
        class="toc-section-number">33.3</span> Shortest Paths with
        Negative Edges</a></li>
        <li><a href="#ellipsoid-method-sketch"
        id="toc-ellipsoid-method-sketch"><span
        class="toc-section-number">33.4</span> Ellipsoid Method
        (Sketch)</a></li>
        <li><a href="#summary" id="toc-summary"><span
        class="toc-section-number">33.5</span> Summary</a></li>
        <li><a href="#references-23" id="toc-references-23"><span
        class="toc-section-number">33.6</span> References</a></li>
        <li><a href="#aptly-named-sir-7"
        id="toc-aptly-named-sir-7"><span
        class="toc-section-number">33.7</span> Aptly Named Sir</a></li>
        </ul></li>
        <li><a href="#geodesic-embeddingsvarnothing"
        id="toc-geodesic-embeddingsvarnothing"><span
        class="toc-section-number">34</span> Geodesic Embeddings<span
        class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#flat-torus" id="toc-flat-torus"><span
        class="toc-section-number">34.1</span> Flat Torus</a></li>
        <li><a href="#spring-embeddings-on-other-surfaces"
        id="toc-spring-embeddings-on-other-surfaces"><span
        class="toc-section-number">34.2</span> Spring Embeddings on
        Other Surfaces</a></li>
        <li><a href="#circle-packing-on-other-surfaces"
        id="toc-circle-packing-on-other-surfaces"><span
        class="toc-section-number">34.3</span> Circle Packing on Other
        Surfaces</a></li>
        <li><a href="#references-24" id="toc-references-24"><span
        class="toc-section-number">34.4</span> References</a></li>
        <li><a href="#named-sir-not" id="toc-named-sir-not"><span
        class="toc-section-number">34.5</span> Named Sir Not</a></li>
        </ul></li>
        <li><a href="#closing-the-loopvarnothing"
        id="toc-closing-the-loopvarnothing"><span
        class="toc-section-number">35</span> Closing the Loop<span
        class="math inline">\(^\varnothing\)</span></a>
        <ul>
        <li><a href="#simple-polygons" id="toc-simple-polygons"><span
        class="toc-section-number">35.1</span> Simple Polygons</a></li>
        <li><a href="#winding-numbers-1"
        id="toc-winding-numbers-1"><span
        class="toc-section-number">35.2</span> Winding Numbers</a></li>
        <li><a href="#curve-homotopy" id="toc-curve-homotopy"><span
        class="toc-section-number">35.3</span> Curve Homotopy</a></li>
        <li><a href="#shortest-homotopic-paths-and-cycles"
        id="toc-shortest-homotopic-paths-and-cycles"><span
        class="toc-section-number">35.4</span> Shortest Homotopic Paths
        and Cycles</a></li>
        <li><a href="#gauss-codes" id="toc-gauss-codes"><span
        class="toc-section-number">35.5</span> Gauss codes</a></li>
        <li><a href="#curve-invariants-and-simplification"
        id="toc-curve-invariants-and-simplification"><span
        class="toc-section-number">35.6</span> Curve Invariants and
        Simplification</a></li>
        <li><a href="#geodesic-embeddings"
        id="toc-geodesic-embeddings"><span
        class="toc-section-number">35.7</span> Geodesic
        Embeddings</a></li>
        <li><a href="#maxwellcremona" id="toc-maxwellcremona"><span
        class="toc-section-number">35.8</span> Maxwell–Cremona</a></li>
        <li><a href="#references-25" id="toc-references-25"><span
        class="toc-section-number">35.9</span> References</a></li>
        </ul></li>
        </ul>

        </div>
      </div>
            <div class="span9">

      
      <h1 class="unnumbered" id="forewardalpha">Foreward<span
class="math inline">\(^\alpha\)</span></h1>
<p>This book consists of lecture notes from a special-topics class on
topological graph algorithms that I have taught several times at the
University of Illinois. These lecture notes (and other course materials)
are available under a <a
href="https://creativecommons.org/licenses/by/4.0/">Creative Commons
Attribution license (CC BY 4.0)</a>.</p>
<figure>
<img src="Fig/cc-by.png" style="width:15.0%" alt="CC BY 4.0" />
<figcaption aria-hidden="true">CC BY 4.0</figcaption>
</figure>
<p>I drafted most of these notes in Fall 2020 and revised them in Spring
2023; a handful of chapters (13, 16, 26, 27, 29, 30) were first drafted
in Spring 2023. Even after a second round of revision, these are all
still very rough drafts. Most of the missing chapters either cover
material I did not discussed in class, or cover material from my own
research papers.</p>
<p>I’ve <em>attempted</em>, with various degrees of success, to write
the first draft of each note to exactly cover one 75-minute lecture, to
force myself to prioritize the most fundamental results, sometimes at
the expense of technical details, prerequisite material (like point-set
topology or dynamic-forest data structures), accurate reflection of the
state of the art, and historical anecdotes. Later revisions tend to
include more technical details that I don’t actually cover in lecture,
except to say “You can find more details in the notes.” In practice, I
can cover at most 5 pages of material in detail in one lecture (and each
semester has only 25 lectures).</p>
<p>Similarly, I am writing these notes in Markdown instead of LaTeX, in
part to intentionally focus my time on <em>writing</em> instead of
typography, and in part to make the final output more accessible by
producing HTML and ePub versions. As a result, the notes are
typographically rather awkward/ugly. Some day I will figure out how to
use Pandoc templates and filters, or better yet, a more modern system
like Quarto. (Real Soon Now, Honest.) For similar reasons, many notes
are embarrassingly short on figures and/or references.</p>
<p>I think I’m about 2/3 of the way to a complete first draft of an
actual book. I’m reasonably happy with the current <em>set</em> of
chapters, plus or minus one, but less so about their order, especially
in the last third. If I stick to the current outline, the final book
should be just over 400 pages long in its current format (or about 600
pages in a more book-friendly format). Depending their degree of
completion, each chapter titles has one of the following annotations:<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<ul>
<li><span class="math inline">\(\varnothing\)</span>: mostly (or
completely) unwritten</li>
<li><span class="math inline">\(\alpha\)</span>: mostly written, but
missing significant details, or only used once</li>
<li><span class="math inline">\(\beta\)</span>: reasonably polished, but
possibly missing some minor details</li>
<li><span class="math inline">\(\delta\)</span>: complete and totally
polished (so needs only five more rounds of copy editing)</li>
<li>Nothing: actually done</li>
</ul>
<p>Once I have a complete draft of the entire book, I plan to make the
source files available on Github to attract bug reports, feature
requests, and pull requests. Stay tuned!</p>
<h1 data-number="1" id="simple-polygonsbeta"><span
class="header-section-number">1</span> Simple Polygons<span
class="math inline">\(^\beta\)</span></h1>
<p>The Jordan Curve Theorem and its generalizations are the formal
foundations of many results, if not <em>every</em> result, in
two-dimensional topology. In its simplest form, the theorem states that
any simple closed curve partitions the plane into two connected subsets,
exactly one of which is bounded. Although this statement is intuitively
clear, perhaps even obvious, the generality of the term “simple closed
curve” makes a formal proof of the theorem incredibly challenging. A
complete proof must work not only for sane curves like circles and
polygons, but also for more exotic beasts like fractals and
space-filling curves. Fortunately, these exotic curves rarely occur in
practice, except as counterexamples in point-set topology textbooks.</p>
<p>A full proof of the Jordan Curve Theorem requires machinery that we
won’t cover in this class (either point-set topology or singular
homology). Here I’ll consider only the important special case of
<em>simple polygons</em>. Polygons are by far the most common type of
closed curve employed in practice, so this special case has immediate
practical consequences.</p>
<p>Most published proofs of the full Jordan Curve Theorem both dismiss
this special case as trivial and rely on it as a key lemma. Indeed, the
proof is ultimately <em>elementary</em>. Nevertheless, the Jordan
Polygon Theorem and its proof are the foundation of several fundamental
algorithmic tools in computational geometry and topology.</p>
<h2 data-number="1.1" id="definitions"><span
class="header-section-number">1.1</span> Definitions</h2>
<p>A <em>path</em> in the plane is an arbitrary continuous function
<span class="math inline">\(\pi\colon [0, 1] \to \mathbb{R}^2\)</span>,
where <span class="math inline">\([0, 1]\)</span> is the unit interval
on the real line. The points <span class="math inline">\(\pi(0)\)</span>
and <span class="math inline">\(\pi(1)\)</span> are called the
<em>endpoints</em> of the path. A <em>closed curve</em> (or
<em>cycle</em>) in the plane is a continuous function from the unit
circle <span class="math inline">\(S^1 = \{(x,y)\in\mathbb{R}^2 \mid
x^2+y^2=1\}\)</span> to the plane.</p>
<p>A path or cycle is <em>simple</em> if it is injective, or
intuitively, if it does not “self-intersect”. To avoid excessive
formality, we do not normally distinguish between a simple path or cycle
(formally a function) and its image (formally a subset of the plane).<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<p>A subset <span class="math inline">\(X\)</span> of the plane is
<em>(path-)connected</em> if there is a path in <span
class="math inline">\(X\)</span> from any point in <span
class="math inline">\(X\)</span> to any other point in <span
class="math inline">\(X\)</span>. A <em>(path-)component</em> of <span
class="math inline">\(X\)</span> is a maximal path-connected subset of
<span class="math inline">\(X\)</span>.</p>
<dl>
<dt><strong>Theorem (The Jordan Curve Theorem).</strong></dt>
<dd>
<em>The complement <span class="math inline">\(\mathbb{R}^2\setminus
C\)</span> of any simple closed curve <span
class="math inline">\(C\)</span> in the plane has exactly two
components.</em>
</dd>
</dl>
<p>A <em>polygonal chain</em> is a path that passes through a finite
sequence of points <span class="math inline">\(p_0, p_1, \dots,
p_n\)</span>, such that for each index <span
class="math inline">\(i\)</span>, the subpath from <span
class="math inline">\(p_{i-1}\)</span> to <span
class="math inline">\(p_i\)</span> is the straight line segment <span
class="math inline">\(p_{i-1}p_i\)</span>. The points <span
class="math inline">\(p_i\)</span> are called the <em>vertices</em> of
the polygonal chain, and the segments <span
class="math inline">\(p_{i-1}p_i\)</span> are called its <em>edges</em>.
We usually assume without loss of generality that no pair of consecutive
edges is collinear, and in particular, that no two consecutive vertices
coincide.</p>
<p>A polygonal chain is <em>closed</em> if it has at least one edge and
its first and last vertices coincide (that is, if <span
class="math inline">\(p_0 = p_n\)</span>) and <em>open</em> otherwise.
Closed polygonal chains are also called <em>polygons</em>; a polygon
with <span class="math inline">\(n\)</span> vertices and <span
class="math inline">\(n\)</span> edges is also called an <em><span
class="math inline">\(n\)</span>-gon</em>. We can regard any polygon as
a closed curve in the plane. Every simple polygon has at least three
vertices.</p>
<figure>
<img src="Fig/Damien-tsp3-filled.png" style="width:40.0%"
alt="A simple 10000-gon, with interior shaded" />
<figcaption aria-hidden="true">A simple 10000-gon, with interior
shaded</figcaption>
</figure>
<dl>
<dt><strong>Theorem (The Jordan Polygon Theorem).</strong></dt>
<dd>
<em>The complement <span class="math inline">\(\mathbb{R}^2\setminus
P\)</span> of any simple polygon <span class="math inline">\(P\)</span>
in the plane has exactly two components.</em>
</dd>
</dl>
<p>Let me emphasize that even though this theorem considers only
<em>polygonal</em> closed curves, the definitions of “connected” and
“component” allows for <em>arbitrary</em> paths between points.</p>
<h2 data-number="1.2" id="proof-of-the-jordan-polygon-theorem"><span
class="header-section-number">1.2</span> Proof of the Jordan Polygon
Theorem</h2>
<p>Fix a simple polygon <span class="math inline">\(P\)</span> with
<span class="math inline">\(n\)</span> vertices. Without loss of
generality, assume no two vertices of <span
class="math inline">\(P\)</span> have equal <span
class="math inline">\(x\)</span>-coordinates. The vertical lines through
the vertices partition the plane into <span
class="math inline">\(n+1\)</span> <em>slabs</em>, two of which (the
leftmost and rightmost) are actually halfplanes. The edges of <span
class="math inline">\(P\)</span> subdivide each slab into a finite
number of regions we call <em>trapezoids</em>, even though some of these
regions are actually triangles, and others are unbounded in one or more
directions.</p>
<figure>
<img src="Fig/polygon-slab-decomp.png" style="width:35.0%"
alt="A slab decomposition of a simple polygon, with trapezoids in one slab highlighted" />
<figcaption aria-hidden="true">A slab decomposition of a simple polygon,
with trapezoids in one slab highlighted</figcaption>
</figure>
<p>The boundary of each trapezoid consists of (at most) four line
segments: the <em>floor</em> and <em>ceiling</em>, which are segments of
polygon edges, and the <em>left</em> and <em>right walls</em>, which are
segments of the vertical slab boundaries. The endpoints of each vertical
wall (if any) lie on the polygon <span
class="math inline">\(P\)</span>.</p>
<p>Formally, we define each trapezoid to include its walls but not its
floor, its ceiling, or any vertex on its walls. Thus, each trapezoid is
connected, any two trapezoids intersect in a common wall or not at all,
and the union of all the trapezoids is <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span>. In particular, a
trapezoid is a convex (and therefore connected) region in the plane, but
it is not a polygon!</p>
<dl>
<dt><strong>Lemma <span class="math inline">\(\le\)</span>
2.</strong></dt>
<dd>
<em><span class="math inline">\(\mathbb{R}^2\setminus P\)</span> has at
most two components.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Direct the edges of <span class="math inline">\(P\)</span> in increasing
index order (modulo <span class="math inline">\(n\)</span>). Informally,
we label every trapezoid <em>left</em> or <em>right</em> depending on
whether a person walking around <span class="math inline">\(P\)</span>
would see that trapezoid immediately to their left or immediately to
their right. More formally, we label every trapezoid that satisfies at
least one of the following conditions <em>left</em>:
</dd>
<dd>
<ul>
<li>The ceiling is directed from right to left.</li>
</ul>
</dd>
<dd>
<ul>
<li>The floor is directed from left to right.</li>
</ul>
</dd>
<dd>
<ul>
<li>The right wall contains a vertex <span
class="math inline">\(p_i\)</span>, and the incoming edge <span
class="math inline">\(p_{i-1}p_i\)</span> is below the outgoing edge
<span class="math inline">\(p_i p_{i+1}\)</span></li>
</ul>
</dd>
<dd>
<ul>
<li>The left wall contains a vertex <span
class="math inline">\(p_i\)</span>, and the incoming edge <span
class="math inline">\(p_{i-1}p_i\)</span> is above the outgoing edge
<span class="math inline">\(p_i p_{i+1}\)</span></li>
</ul>
</dd>
<dd>
These conditions apply verbatim to unbounded and degenerate trapezoids.
There are four symmetric conditions for labeling a trapezoid
<em>right</em>. Every trapezoid is labeled left or right <em>or (as far
as we know at this point) possibly both</em>.
</dd>
<dd>
<figure>
<img src="Fig/left-trapezoids.png" style="width:50.0%"
alt="Left trapezoids" />
<figcaption aria-hidden="true">Left trapezoids</figcaption>
</figure>
</dd>
<dd>
<p>Now imagine imagine walking once around the polygon, facing directly
forward along edges and turning at vertices, and consider the sequence
of trapezoids immediately to our left, as suggested by the white arrows
in Figure 2 above. Without loss of generality, start at the leftmost
vertex <span class="math inline">\(p_0\)</span>. Whenever we traverse a
directed edge <span class="math inline">\(p_{i-1}p_i\)</span> from right
to left, our left hand sweeps through all trapezoids immediately below
that edge. Whenever we reach a vertex <span
class="math inline">\(p_i\)</span> whose neighbors are both to the right
of <span class="math inline">\(p_i\)</span>, where the edges make a
right (clockwise turn), our hand sweeps through the trapezoid just to
the left of <span class="math inline">\(p_i\)</span>. The other cases
are symmetric. The resulting sequence of trapezoids contains every left
trapezoid at least once (and at most four times); moreover, any adjacent
pair of trapezoids in this sequence share a wall and thus have a
connected union. So the union of the left trapezoids is connected.</p>
</dd>
<dd>
<p>A symmetric argument implies that the union of the right trapezoids
is also connected, which completes the proof.</p>
</dd>
</dl>
<p>It’s worth noting here that Lemma <span
class="math inline">\(\le\)</span> 2 holds for simple closed curves on
arbitrary <em>surfaces</em>, including non-orientable surfaces like the
Klein bottle, but it can fail for more complex topological spaces.</p>
<dl>
<dt><strong>Lemma <span class="math inline">\(\ge\)</span>
2.</strong></dt>
<dd>
<em><span class="math inline">\(\mathbb{R}^2\setminus P\)</span> has at
least two components.</em>
</dd>
<dt><strong>Proof (Jordan):</strong></dt>
<dd>
Label each trapezoid <em>even</em> or <em>odd</em> depending on the
parity of the number of polygon edges directly above the trapezoid.
Thus, within each slab, the highest trapezoid is even, and the
trapezoids alternate between even and odd. For example, in Figure 1, the
blue slabs are even, and the orange slabs are odd.
</dd>
<dd>
<p>Consider any path <span class="math inline">\(\pi\)</span> that
intersects exactly two trapezoids <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span>. If <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> lie in the same slab, this path
must intersect at least one edge of <span
class="math inline">\(P\)</span>. (I am <em>not</em> invoking the Jordan
curve theorem here, but rather a much more basic fact called the
<em>plane separation axiom</em>.<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>) Otherwise, <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> must lie in adjacent slabs, because
<span class="math inline">\(\pi\)</span> is continuous, and therefore
must share a vertical wall.</p>
</dd>
<dd>
<p>Suppose this wall lies on the vertical line <span
class="math inline">\(\ell\)</span> through <span
class="math inline">\(p_i\)</span>, and without loss of generality,
<span class="math inline">\(\tau\)</span> lies on the left of <span
class="math inline">\(\ell\)</span> and <span
class="math inline">\(\tau’\)</span> on the right. If vertices <span
class="math inline">\(p_{i-1}\)</span> and <span
class="math inline">\(p_{i+1}\)</span> are on opposite sides of <span
class="math inline">\(\ell\)</span>, exactly the same number of polygon
edges are above <span class="math inline">\(\tau\)</span> and above
<span class="math inline">\(\tau’\)</span>. Suppose <span
class="math inline">\(p_{i-1}\)</span> and <span
class="math inline">\(p_{i+1}\)</span> lie to the left of <span
class="math inline">\(\ell\)</span>. If <span
class="math inline">\(p_i\)</span> lies below the wall <span
class="math inline">\(\tau\cap\tau’\)</span>, then <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> are below the same number of edges;
otherwise, <span class="math inline">\(\tau\)</span> is below two more
edges than <span class="math inline">\(\tau’\)</span>. Similar cases
arise when <span class="math inline">\(p_{i-1}\)</span> and <span
class="math inline">\(p_{i+1}\)</span> both lie to the right of <span
class="math inline">\(\ell\)</span>. In all cases, <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> have the same parity.</p>
</dd>
<dd>

</dd>
<dd>
<p>More generally, consider any two trapezoids <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> in the same component of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span>. There must be a
path <span class="math inline">\(\pi\colon [0,1]\to
\mathbb{R}^2\setminus P\)</span> with <span
class="math inline">\(\pi(0)\in \tau\)</span> and <span
class="math inline">\(\pi(1)\in \tau’\)</span>. Let <span
class="math inline">\(\tau_0, \tau_1, \dots, \tau_N\)</span> be the
sequence of trapezoids that <span class="math inline">\(\pi\)</span>
intersects, sorted in order of their first intersection. Thus, <span
class="math inline">\(\tau_0 = \tau\)</span> and for each index <span
class="math inline">\(i&gt;0\)</span>, the path <span
class="math inline">\(\pi\)</span> enters trapezoid <span
class="math inline">\(\tau_i\)</span> for the first time from some
trapezoid <span class="math inline">\(\tau_j\)</span> with <span
class="math inline">\(j&lt;i\)</span>. Our earlier arguments imply that
<span class="math inline">\(\pi\)</span> must leave <span
class="math inline">\(\tau_j\)</span> and enter <span
class="math inline">\(\tau_i\)</span> through a common wall, so these
two trapezoids have the same parity. It follows by induction that every
trapezoid <span class="math inline">\(\tau_i\)</span> has the same
parity as <span class="math inline">\(\tau_0\)</span>; in particular,
<span class="math inline">\(\tau\)</span> and <span
class="math inline">\(\tau’\)</span> have the same parity.</p>
</dd>
<dd>
<p>We conclude that any two trapezoids in the same component of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span> have the same
parity, which completes the proof.</p>
</dd>
</dl>
<p>It’s worth noting here that Lemma <span
class="math inline">\(\le\)</span> 2 holds for more complex planar
shapes, such as polygons with holes, but it fails for any surface that
is no homeomorphic to a subspace of the sphere.</p>
<p>The Jordan Polygon Theorem now follows immediately from Lemmas <span
class="math inline">\(\le 2\)</span> and <span class="math inline">\(\ge
2\)</span>. In particular, if the polygon is oriented counterclockwise
(the way god intended), then “right” and “even” (and blue) mean
“outside”, and “left” and “odd” (and orange) mean “inside”.</p>
<p>In contexts where polygons are assumed to be simple, it is standard
practice to use the single word ”polygon” (and the same variable names,
and the same data structures) to refer <em>both</em> to a simple closed
polygonal chain <em>and</em> to (the closure of) the interior of that
polygonal chain, with the precise meaning <em>hopefully</em> clear from
context. For example, the slab decomposition we used in this section
decomposes <em>the polygon</em> into trapezoids, and in later lectures
we will consider <em>polygons with holes</em>. This polysemy is
justified by the Jordan Polygon Theorem.</p>
<h2 data-number="1.3" id="point-in-polygon-test"><span
class="header-section-number">1.3</span> Point-in-Polygon Test</h2>
<p>The parity proof of Lemma <span class="math inline">\(\ge 2\)</span>
immediately suggests a standard algorithm to test whether a point lies
in the interior of a simple polygon in the plane in linear time: Shoot
an arbitrary ray from the query point, count the number of times this
ray crosses the polygon, and return <span
class="math inline">\(\textsf{true}\)</span> if and only if this number
is odd. This algorithm appears in Gauss’ notes (written around 1830 but
only published after his death); it has been rediscovered many times
since then.</p>
<p>To make the ray-parity algorithm concrete, we need one numerical
primitive from computational geometry. A triple <span
class="math inline">\((q, r, s)\)</span> of points in the plane is
<em>oriented counterclockwise</em> if walking from <span
class="math inline">\(q\)</span> to <span
class="math inline">\(r\)</span> and then to <span
class="math inline">\(s\)</span> requires a left turn, or <em>oriented
clockwise</em> if the walk requires a right turn. More explicitly,
consider the <span class="math inline">\(3\times 3\)</span> determinant
<span class="math display">\[
    \Delta(q,r,s) =
    \det
    \begin{bmatrix}
        1 &amp; q.x &amp; q.y \\
        1 &amp; r.x &amp; r.y \\
        1 &amp; s.x &amp; s.y
    \end{bmatrix}
    = (r.x - q.x)(s.y - q.y) - (r.y - q.y)(s.x - q.x).
\]</span> The triple <span class="math inline">\((q,r,s)\)</span> is
oriented counterclockwise if <span class="math inline">\(\Delta(q,r,s)
&gt; 0\)</span>, oriented clockwise if <span
class="math inline">\(\Delta(q,r,s) &lt; 0\)</span>, and collinear if
<span class="math inline">\(\Delta(q,r,s) = 0\)</span>. (The absolute
value of <span class="math inline">\(\Delta(q,r,s)\)</span> is twice the
area of the triangle <span class="math inline">\(\triangle
qrs\)</span>.)</p>
<p>Straightforward case analysis implies that the vertical ray from
<span class="math inline">\(q\)</span> crosses the line segment <span
class="math inline">\(rs\)</span> if and only if <span
class="math inline">\(q\)</span> lies between the vertical lines through
<span class="math inline">\(r\)</span> and <span
class="math inline">\(s\)</span>, and <span
class="math inline">\(\Delta(q,r,s)\)</span> has the same sign as <span
class="math inline">\(r.x-s.x\)</span>.</p>
<figure>
<img src="Fig/ray-crossings.png" style="width:50.0%"
alt="Ray-crossing test" />
<figcaption aria-hidden="true">Ray-crossing test</figcaption>
</figure>
<p>Finally, here is the algorithm in (pseudo)Python. The input polygon
<span class="math inline">\(P\)</span> is represented by an array of
consecutive vertices. The algorithm returns <span
class="math inline">\(+1\)</span>, <span
class="math inline">\(-1\)</span>, or <span
class="math inline">\(0\)</span> to indicate that the query point <span
class="math inline">\(q\)</span> lies inside, outside, or directly on
<span class="math inline">\(P\)</span>, respectively. To correctly
handle ties between <span class="math inline">\(x\)</span>-coordinates,
the algorithm treats any polygon vertex on the vertical line through
<span class="math inline">\(q\)</span> (but not actually coincident with
<span class="math inline">\(q\)</span>) as though it were slightly to
the left. The algorithm clearly runs in <span
class="math inline">\(O(n)\)</span> time.</p>
<pre><code>def PtInPolygon(P, q):
    sign = -1                       // outside if no crossings
    n = len(P)
    for i in range(n):
        r = P[i]
        s = P[(i+1)% n]
        Delta = (r.x - q.x)*(s.y - q.y) - (r.y - q.y)*(s.x - q.x)
        if s.x &lt;= q.x &lt; r.x         // positive crossing?
            if Delta &gt; 0:
                sign = -sign
            elif Delta == 0:
                return 0
        elif r.x &lt;= q.x &lt; s.x       // negative crossing?
            if Delta &lt; 0:
                sign = -sign
            elif Delta == 0:
                return 0
    return sign</code></pre>
<h2 data-number="1.4" id="polygons-can-be-triangulated"><span
class="header-section-number">1.4</span> Polygons Can Be
Triangulated</h2>
<p>Most algorithms that operate on simple polygons actually require a
decomposition of the polygon into simple pieces that are easier to
manage. We’ve already seen one such decomposition, first into vertical
slabs, and then into trapezoids. For many geometric and topological
algorithms, the most natural decomposition breaks the interior of the
polygon into triangles that meet edge-to-edge. More formally, a
<em>triangulation</em> is a triple of sets <span
class="math inline">\((V, E, T)\)</span> with the following
properties.</p>
<ul>
<li><span class="math inline">\(T\)</span> is a finite set of triangles
in the plane with disjoint interiors.</li>
<li><span class="math inline">\(E\)</span> is the set of edges of
triangles in <span class="math inline">\(T\)</span>.</li>
<li>Any two segments in <span class="math inline">\(E\)</span> have
disjoint interiors.</li>
<li><span class="math inline">\(V\)</span> is the set of vertices of
triangles in <span class="math inline">\(T\)</span>.</li>
</ul>
<p>The third condition guarantees that the intersection of any two
triangles in <span class="math inline">\(T\)</span> is either an edge of
both, a vertex of both, or empty.</p>
<p>If the union of the triangles in <span
class="math inline">\(T\)</span> is equal to the closure of the interior
of a simple polygon <span class="math inline">\(P\)</span>, we call
<span class="math inline">\((V, E, T)\)</span> a <em>triangulation of
<span class="math inline">\(P\)</span></em>. If moreover <span
class="math inline">\(V\)</span> is the set of vertices of <span
class="math inline">\(P\)</span>, then <span class="math inline">\((V,
E, T)\)</span> is called a <em>frugal</em> triangulation of <span
class="math inline">\(P\)</span>. Every edge of a frugal triangulation
is either an edge of <span class="math inline">\(P\)</span> or an
<em>(interior) diagonal</em>, meaning a line segment between two
vertices of <span class="math inline">\(P\)</span> whose interior lies
in the interior of <span class="math inline">\(P\)</span>.</p>
<figure>
<img src="Fig/triangular-decomp.png" style="width:80.0%"
alt="A frugal triangulation, a non-frugal triangulation, and a non-triangulation of a simple polygon" />
<figcaption aria-hidden="true">A frugal triangulation, a non-frugal
triangulation, and a non-triangulation of a simple polygon</figcaption>
</figure>
<p>After playing with a few examples, it may seem obvious that every
simple polygon has a frugal triangulation, but a formal proof of this
fact is surprisingly subtle; several incorrect (or at least incomplete)
proofs appear in the literature. The first complete, correct, axiomatic
proofs were developed by Dehn (1899, unpublished) and Lennes (1911),
although some components of their arguments already appear in the
Gauss’s posthumously published notes.</p>
<p>The following proof is somewhat more complicated (and intentionally
<em>less</em> formal!) than Dehn’s and Lennes’s arguments, but it
directly motivates a faster algorithm for constructing
triangulations.</p>
<dl>
<dt><strong>Diagonal Lemma (Dehn, Lennes):</strong></dt>
<dd>
<em>Every simple polygon with at least four vertices has an interior
diagonal.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(P\)</span> be a simple polygon with
vertices <span class="math inline">\(p_0, p_1, \dots, p_{n-1}\)</span>
for some <span class="math inline">\(n\ge 4\)</span>. As before, we
assume without loss of generality that no two vertices of <span
class="math inline">\(P\)</span> lie on a common vertical line. We begin
by subdividing the closed interior of <span
class="math inline">\(P\)</span> into trapezoids with vertical line
<em>segments</em> through the vertices. Specifically, for each vertex
<span class="math inline">\(p_i\)</span>, we cut along the longest
vertical segment through <span class="math inline">\(p_i\)</span> in the
closure of the interior of~<span class="math inline">\(P\)</span>. The
resulting subdivision, which is called a <em>trapezoidal
decomposition</em> of <span class="math inline">\(P\)</span>, can also
be obtained from the slab decomposition we used to prove the Jordan
polygon theorem by removing every exterior wall and every wall that does
not end at a vertex of <span class="math inline">\(P\)</span>.
</dd>
<dd>
<figure>
<img src="Fig/polygon-trap-decomp.png" style="width:35.0%"
alt="A trapezoidal decomposition of a simple polygon" />
<figcaption aria-hidden="true">A trapezoidal decomposition of a simple
polygon</figcaption>
</figure>
</dd>
<dd>
<p>Every trapezoid in the decomposition has exactly two polygon vertices
on its boundary. Call a trapezoid <em>boring</em> if the line segment
between these two vertices cuts through the interior of the trapezoid,
and therefore is a diagonal of <span class="math inline">\(P\)</span>,
and <em>interesting</em> otherwise. Every interesting trapezoid either
has two vertices of <span class="math inline">\(P\)</span> on its
ceiling, or two vertices of <span class="math inline">\(P\)</span> on
its floor.</p>
</dd>
<dd>
<figure>
<img src="Fig/polygon-mono-mountains.png" style="width:35.0%"
alt="Boring diagonals" />
<figcaption aria-hidden="true">Boring diagonals</figcaption>
</figure>
</dd>
<dd>
<p>If any of the trapezoids is boring, we immediately have a diagonal.
Yawn.</p>
</dd>
<dd>
<p>Any path through the interior of <span
class="math inline">\(P\)</span> that starts in a ceiling trapezoid and
ends in a floor trapezoid must pass through a boring trapezoid. So if
every trapezoid is interesting, then every trapezoid is interesting
<em>the same way</em>—either every trapezoid has two vertices on its
ceiling, or every trapezoid has two vertices on its floor. Thus, <span
class="math inline">\(P\)</span> is a special type of polygon we call a
<em>monotone mountain</em>: any vertical line intersects at most two
edges of <span class="math inline">\(P\)</span>, and the leftmost and
rightmost vertices of <span class="math inline">\(P\)</span> are
connected by a single edge of <span
class="math inline">\(P\)</span>.</p>
</dd>
<dd>
<figure>
<img src="Fig/monotone-mountain.png" style="width:40.0%"
alt="Four diagonals in a monotone mountain" />
<figcaption aria-hidden="true">Four diagonals in a monotone
mountain</figcaption>
</figure>
</dd>
<dd>
<p>Without loss of generality, suppose <span
class="math inline">\(p_0\)</span> is the leftmost vertex, <span
class="math inline">\(p_{n-1}\)</span> is the rightmost vertex, and
every other vertex is above the edge <span
class="math inline">\(p_0p_{n-1}\)</span> (so every trapezoid has two
vertices on its ceiling). Call a vertex <span
class="math inline">\(p_i\)</span> <em>convex</em> if the interior angle
at that vertex is less than <span class="math inline">\(\pi\)</span>, or
equivalently, if the triple <span class="math inline">\((p_{i-1}, p_i,
p_{i+1})\)</span> is oriented <em>clockwise</em>. Every monotone
mountain has at least one convex vertex <span
class="math inline">\(p_i\)</span> other than <span
class="math inline">\(p_0\)</span> and <span
class="math inline">\(p_{n-1}\)</span>; take, for example, the vertex
furthest above the floor <span
class="math inline">\(p_0p_{n-1}\)</span>. For any such vertex <span
class="math inline">\(p_i\)</span>, the line segment <span
class="math inline">\(p_{i-1}p_{i+1}\)</span> is a diagonal.</p>
</dd>
</dl>
<!---
**Proof:**
: Let $P$ be a simple polygon with at least four vertices.  Let $q$ be the rightmost vertex of $P$ (breaking ties arbitrarily), and let $p$ and $r$ be the vertices immediately before and after $q$ in order around $P$.

: First suppose the segment $pr$ does not otherwise intersect $P$.  For any point $x$ in the interior of $pr$, the ray from $x$ through $q$ crosses $P$ exactly once, at the point $q$.  (The Jordan _triangle_ theorem implies that $P$ does not intersect the interior of $\triangle pqr$, and therefore does not intersect the segment $xq$.}  Similarly, the ray from $q$ leading directly away from $x$ does not intersect $P$, because $q$ is the rightmost vertex of $P$.)  It follows that $pr$ lies in the interior of $P$ and thus is a diagonal.  In this case, we call $\triangle pqr$ an _ear_ of $P$.

: Otherwise, $P$ intersects the interior of $pr$.  In this case, the Jordan _triangle_ theorem implies that $\triangle pqr$ contains at least one vertex of $P$ in its interior.  Let $s$ the rightmost vertex in the interior of $\triangle pqr$.  (In fact, we can take $s$ to be any vertex in the interior of $\triangle pqr$ such that some line through $s$ separates $q$ from all other vertices in the interior of $\triangle pqr$.)  The line segment $qs$ lies in the interior of $P$ and thus is a diagonal.
--->
<dl>
<dt><strong>Triangulation Theorem:</strong></dt>
<dd>
<em>Every simple polygon has a frugal triangulation.</em>
</dd>
<dt><strong>Proof (Dehn, Lennes):</strong></dt>
<dd>
The theorem follows by induction from the diagonal lemma. Intuitively,
to triangulate any nontrivial polygon, we can split any polygon along a
diagonal and then recursively triangulate each of the two resulting
smaller polygons.
</dd>
<dd>
<p>Let <span class="math inline">\(P\)</span> be a simple polygon with
<span class="math inline">\(n\)</span> vertices <span
class="math inline">\(p_0, p_1, p_2, \dots, p_{n-1}\)</span>. If <span
class="math inline">\(P\)</span> is a triangle, it has a trivial
triangulation, so assume <span class="math inline">\(n&gt;3\)</span>.
Suppose without loss of generality (reindexing the vertices if
necessary) that <span class="math inline">\(d = p_0p_i\)</span> is a
diagonal of <span class="math inline">\(P\)</span>, for some index <span
class="math inline">\(i\)</span>. Let <span
class="math inline">\(P^+\)</span> and <span
class="math inline">\(P^-\)</span> denote the polygons with vertices
<span class="math inline">\(p_0, p_i, p_{i+1}, \dots, p_{n-1}\)</span>
and <span class="math inline">\(p_0, p_1, p_2, \dots, p_i\)</span>,
respectively. The definition of “diagonal” implies that both <span
class="math inline">\(P^+\)</span> and <span
class="math inline">\(P^-\)</span> are simple. Color each edge of <span
class="math inline">\(P\)</span> <em>red</em> if it is an edge of <span
class="math inline">\(P^+\)</span> and <em>blue</em> otherwise; every
blue edge is an edge of <span class="math inline">\(P^-\)</span>.</p>
</dd>
<dd>
<p>Now we need to prove that the diagonal <span
class="math inline">\(d\)</span> partitions the interior of <span
class="math inline">\(P\)</span> into the interiors of <span
class="math inline">\(P^+\)</span> and <span
class="math inline">\(P^-\)</span>. Proving this claim is surprisingly
subtle.</p>
</dd>
<dd>
<p>Let <span class="math inline">\(U\)</span> be any open disk in the
interior of <span class="math inline">\(P\)</span> that intersects <span
class="math inline">\(d\)</span>; such a disk exists because <span
class="math inline">\(d\)</span> is an <em>interior</em> diagonal. (We
had to use that fact somewhere!) The set <span
class="math inline">\(U\setminus p_0p_i\)</span> has exactly two
components.[^pasch2] Choose arbitrary points <span
class="math inline">\(q^+\)</span> and <span
class="math inline">\(q^-\)</span>, one in each component. Let <span
class="math inline">\(R^+\)</span> and <span
class="math inline">\(R^-\)</span> be parallel rays starting at <span
class="math inline">\(q^+\)</span> and <span
class="math inline">\(q^-\)</span>, respectively, such that <span
class="math inline">\(R^+\)</span> contains <span
class="math inline">\(R^-\)</span>. Then <span
class="math inline">\(R^+\)</span> crosses <span
class="math inline">\(d\)</span> but <span
class="math inline">\(R^-\)</span> does not, and <span
class="math inline">\(R^+\)</span> and <span
class="math inline">\(R^-\)</span> cross exactly the same edges of <span
class="math inline">\(P\)</span>.</p>
</dd>
<dd>
<p>[^pasch2] We are invoking the plane separation axion again here.</p>
</dd>
<dd>
<figure>
<img src="Fig/diagonal.png" style="width:40.0%"
alt="Partitioning a polygon with an interior diagonal" />
<figcaption aria-hidden="true">Partitioning a polygon with an interior
diagonal</figcaption>
</figure>
</dd>
<dd>
<p>As above, <span class="math inline">\(R^+\)</span> (and therefore
<span class="math inline">\(R^-\)</span>) crosses an odd number of edges
of <span class="math inline">\(P\)</span>. Without loss of generality,
suppose <span class="math inline">\(R^+\)</span> (and therefore <span
class="math inline">\(R^-\)</span>) crosses an even number of red edges
and an odd number of blue edges. Then, because <span
class="math inline">\(R^+\)</span> crosses <span
class="math inline">\(d\)</span>, the point <span
class="math inline">\(q^+\)</span> lies inside <span
class="math inline">\(P^+\)</span> and outside <span
class="math inline">\(P^-\)</span>. Similarly, <span
class="math inline">\(q^-\)</span> lies inside <span
class="math inline">\(P^-\)</span> and outside <span
class="math inline">\(P^+\)</span>, because <span
class="math inline">\(R^-\)</span> does not cross <span
class="math inline">\(d\)</span>. We conclude (finally!) that the
interiors of <span class="math inline">\(P^+\)</span> and <span
class="math inline">\(P^-\)</span> are disjoint subsets of the interior
of <span class="math inline">\(P\)</span>. Whew!</p>
</dd>
<dd>
<p>The inductive hypothesis implies that <span
class="math inline">\(P^+\)</span> has a frugal triangulation <span
class="math inline">\((V^+, E^+, T^+)\)</span> and that <span
class="math inline">\(P^-\)</span> has a frugal triangulation <span
class="math inline">\((V^-,E^-,T^-)\)</span>. One can now verify
mechanically that <span class="math inline">\((V^+\cup V^-,\)</span>
<span class="math inline">\(E^+\cup E^-, T^+\cup T^-)\)</span> is a
frugal triangulation of <span class="math inline">\(P\)</span>.</p>
</dd>
</dl>
<h2 data-number="1.5" id="computing-a-triangulation"><span
class="header-section-number">1.5</span> Computing a Triangulation</h2>
<p>The proof of the diagonal lemma implies an efficient algorithm to
triangulate any simple polygon. I’ll only sketch the algorithm here; for
further details, see your favorite computational geometry textbook.
First, we construct a trapezoidal decomposition in <span
class="math inline">\(O(n\log n)\)</span> time using a
<em>sweepline</em> algorithm. Intuitively, we sweep a vertical line from
left to right across the plane, maintaining its intersection with the
polygon in a balanced binary search tree, and inserting a new vertical
wall whenever the line touches a vertex. (In fact, we only visit the
vertices in order from left to right.) Second, we insert diagonals
inside every boring trapezoid; these diagonals decompose <span
class="math inline">\(P\)</span> into monotone mountains in <span
class="math inline">\(O(n)\)</span> time. Finally, we triangulate each
monotone mountain in <span class="math inline">\(O(n)\)</span> time by
cutting off convex vertices in order from left to right.</p>
<p>The overall running time is <span class="math inline">\(O(n\log
n)\)</span>; the running time is dominated by the time to construct the
trapezoidal decomposition. Theoretically faster algorithms for that
construction are known—in particular, Chazelle described a famously
complex <span class="math inline">\(O(n)\)</span>-time algorithm—but it
is unclear whether any of these improvements is faster in practice, or
indeed if any of them have actually been implemented.</p>
<p>I’ll leave the following corollaries of the polygon triangulation
theorem as exercises.</p>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Every frugal triangulation of a simple <span
class="math inline">\(n\)</span>-gon contains exactly <span
class="math inline">\(n-2\)</span> triangles and exactly <span
class="math inline">\(n-3\)</span> diagonals.</em>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Every simple polygon with at least four vertices has at least two
<strong>ears</strong>, where an ear is an internal diagonal that cuts
off a single triangle.</em>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Let <span class="math inline">\(P\)</span> be a simple polygon with
vertices <span class="math inline">\(p_0, p_1, \dots, p_{n-1}\)</span>.
Let <span class="math inline">\(i,j,k,l\)</span> be four distinct
indices with <span class="math inline">\(i&lt;j\)</span> and <span
class="math inline">\(k&lt;l\)</span>, such that both <span
class="math inline">\(p_ip_j\)</span> and <span
class="math inline">\(p_kp_l\)</span> are interior diagonals of <span
class="math inline">\(P\)</span>. These two diagonals cross if and only
if either <span class="math inline">\(i&lt;k&lt;j&lt;l\)</span> or <span
class="math inline">\(k&lt;i&lt;l&lt;j\)</span>.</em>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Any maximal set of non-crossing interior diagonals in a simple
polygon <span class="math inline">\(P\)</span> yields a frugal
triangulation of <span class="math inline">\(P\)</span>.</em>
</dd>
</dl>
<h2 data-number="1.6" id="the-dehn-schönflies-theorem"><span
class="header-section-number">1.6</span> The Dehn-Schönflies
Theorem</h2>
<dl>
<dt><strong>The Dehn-Schönflies Theorem:</strong></dt>
<dd>
<em>For any simple polygon <span class="math inline">\(P\)</span>, there
is a homeomorphism <span class="math inline">\(H \colon \mathbb{R}^2 \to
\mathbb{R}^2\)</span> that maps <span class="math inline">\(P\)</span>
to a convex polygon <span class="math inline">\(Q\)</span> and maps the
interior of <span class="math inline">\(P\)</span> to the interior of
<span class="math inline">\(Q\)</span>.</em>
</dd>
<dt><strong>Proof (Dehn):</strong></dt>
<dd>
[to be written]
</dd>
</dl>
<h2 data-number="1.7"
id="and-the-aptly-named-sir-not-appearing-in-this-film"><span
class="header-section-number">1.7</span> and the aptly named Sir Not
Appearing in This Film</h2>
<ul>
<li>Basic geometric algorithms:
<ul>
<li>Details of sweepline algorithm</li>
<li>Der Dreigroschenalgorithmus</li>
<li>Faster decomposition/triangulation algorithms</li>
</ul></li>
<li>Triangulating polygons with holes</li>
<li>Compatible triangulations</li>
<li>Weakly simple polygons</li>
<li>Proof (via Hex and Y) of the full Jordan Curve Theorem</li>
<li>Geodesic polygons on other surfaces (see exercises)</li>
</ul>
<h2 data-number="1.8" id="references"><span
class="header-section-number">1.8</span> References</h2>
<ol type="1">
<li><p>Mark de Berg, Otfried Cheong, Marc van Kreveld, and Mark
Overmars. <em>Computational Geometry: Algorithms and Applications</em>,
3rd edition. Springer-Verlag, 2008. Your favorite computational geometry
textbook.</p></li>
<li><p>Bernard Bolzano. Anti-Euklid. Unpublished manuscript, c. 1840.
Published posthumously in [10].</p></li>
<li><p>Max Dehn. Beweis des Satzes, daß jedes geradlinige geschlossene
Polygon ohne Doppelpunkte ‘die Ebene in zwei Teile teilt’. Unpublished
manuscript, c.1899. Max Dehn Papers archive, University of Texas at
Austin. Cited and described in detail by Guggenheimer [4]. Proof of the
Jordan Polygon Theorem.</p></li>
<li><p>Heinrich W. Guggenheimer. The Jordan curve theorem and an
unpublished manuscript of Max Dehn. <em>Arch. History Exact Sci.</em>
17:193–200, 1977.</p></li>
<li><p>Camille Jordan. Courbes continues. <em>Cours d’Analyse de l’École
Polytechnique</em>, 1st edition, vol. 3, 587–594, 1887.</p></li>
<li><p>Camille Jordan. Lignes continues. <em>Cours d’Analyse de l’École
Polytechnique</em>, 2nd edition, vol. 1, 90–99, 1893.</p></li>
<li><p>Nels Johann Lennes. Theorems on the simple finite polygon and
polyhedron. <em>Amer. J. Math.</em> 33:37–62, 1911. Read to the AMS in
April, 1903. Proof of the Jordan Polygon Theorem.</p></li>
<li><p>Joseph O’Rourke. <em>Computational Geometry in C</em>, 2nd
edition. Cambridge University Press, 1998. Your favorite computational
geometry textbook.</p></li>
<li><p>Moritz Pasch. <em>Vorlesung über neuere Geometrie</em>. Teubner,
1882.</p></li>
<li><p>Kazimír Večerka. Bernard Bolzano: Anti-Euklid. <em>Sbornik pro
dějiny přirodnich věd a teckniky / Acta Hist. Rerum Natur. Nec Non
Tech.</em> 11:203–216, 1967. In Czech, with German summary.</p></li>
</ol>
<h1 data-number="2" id="winding-numbersbeta"><span
class="header-section-number">2</span> Winding Numbers<span
class="math inline">\(^\beta\)</span></h1>
<h2 data-number="2.1"
id="let-me-not-be-pent-up-sir-i-will-fast-being-loose."><span
class="header-section-number">2.1</span> Let me not be pent up, sir; I
will fast, being loose.</h2>
<p><em>Fast and Loose</em> is the name of a family of magic tricks (or
con games) performed with ropes, chains, and belts that have been
practiced since at least the 14th century; the con game is mentioned in
three different Shakespeare plays. In one such trick, now sometimes
called the <em>Endless Chain</em>, the con artist arranges a closed loop
of chain into a doubled figure-8, and then asks the mark to put their
finger on the table inside one of the loops. The con artist them pulls
the chain along the table. If the chain catches on the mark’s finger,
then the chain is <em>fast</em> and the mark wins; if the con artist can
pull the chain completely off the table, the chain is <em>loose</em> and
the mark loses.</p>
<p>The con artist shows the mark that there are two different ways for
the loops to fall. (Notice how the chain crosses itself in the lower
corners.) Because the chain is bright and shiny and bumpy, it’s
impossible for the mark to tell which way the chain is actually
arranged, but because these are the only possibilities, the mark should
have a 50-50 chance of winning. Right? <em>Riiiight?</em></p>
<figure>
<img src="Fig/fast-and-loose.png" style="width:65.0%"
alt="Two arrangements of the Endless Chain" />
<figcaption aria-hidden="true">Two arrangements of the Endless
Chain</figcaption>
</figure>
<p>Oh, you sweet summer child. Of course not! As soon as the mark places
money <em>on the barrelhead</em>, the con artist wins every time. The
con artists was lying; there is a third arrangement of the chain that is
<em>always</em> loose, no matter where the mark puts their finger.<a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></p>
<figure>
<img src="Fig/fast-and-loose-cheat.png" style="width:30.0%"
alt="The actual arrangement of the Endless Chain" />
<figcaption aria-hidden="true">The actual arrangement of the Endless
Chain</figcaption>
</figure>
<h2 data-number="2.2" id="shoelaces-and-signed-areas"><span
class="header-section-number">2.2</span> Shoelaces and Signed Areas</h2>
<p><strong><em>Swap this section and next? This is historical order, but
the narrative is a bit clunky.</em></strong></p>
<p>Before discussing the mathematical reasons you just lost all your
money, let’s consider a basic computational geometry problem: How
quickly can we compute the area enclosed by a given polygon <span
class="math inline">\(P\)</span>?</p>
<p>A particularly simple algorithm was described by Albrecht Meister in
1785. In principle, we can calculate the area of <span
class="math inline">\(P\)</span> by cutting <span
class="math inline">\(P\)</span> into disjoint triangles and then
summing the triangle areas, each of which can can compute in <span
class="math inline">\(O(1)\)</span> time, but it would be more than a
century before anyone knew how to cut polygons into triangles. Meister’s
insight was to consider the <em>signed</em> areas of
<em>overlapping</em> oriented triangles.</p>
<p>The signed area of a triangle depends not only on its vertex
coordinates, but on the orientation of its three vertices. By
convention, counterclockwise triangles have positive signed area, and
clockwise triangles have negative signed area. Recall that a triple of
points <span class="math inline">\((q,r,s)\)</span> is oriented
counterclockwise or clockwise if and only if the following determinant
is positive or negative, respectively: <span class="math display">\[
    \Delta(q,r,s) =
    \det
    \begin{bmatrix}
        1 &amp; q.x &amp; q.y \\
        1 &amp; r.x &amp; r.y \\
        1 &amp; s.x &amp; s.y
    \end{bmatrix}
    = (r.x - q.x)(s.y - q.y) - (r.y - q.y)(s.x - q.x).
\]</span> The <em>signed area</em> of the triangle <span
class="math inline">\(\triangle qrs\)</span> is <span
class="math inline">\(\frac{1}{2} \Delta(q,r,s)\)</span>.</p>
<p>Let <span class="math inline">\(o\)</span> be an <em>arbitrary</em>
point in the plane. Meister observed that the <em>signed</em> area of
any <em>oriented</em> polygon <span class="math inline">\(P\)</span> is
the sum of the signed areas of the triangles determined by <span
class="math inline">\(o\)</span> and the edges of <span
class="math inline">\(P\)</span>: <span class="math display">\[
    \textsf{area}(P) =
    \frac{1}{2}
        \sum_{i=0}^{n-1}
        \Delta(o, p_i, p_{i+1})
\]</span> (To simplify notation, I’ll omit “<span
class="math inline">\({}\bmod n\)</span>” from all index arithmetic.) In
particular, if we take <span class="math inline">\(o\)</span> to be the
origin <span class="math inline">\((0,0)\)</span>, we have <span
class="math display">\[
    \textsf{area}(P)
    ~=~
    \frac{1}{2}
        \sum_{i=0}^{n-1}
        (x_i \cdot y_{i+1} - y_i \cdot x_{i+1})
    ~=~
    \frac{1}{2}
        \sum_{i=0}^{n-1}
        \det
            \begin{bmatrix}
                x_i &amp; y_i \\
                x_{i+1} &amp; y_{i+1} \\
            \end{bmatrix}
\]</span> where <span class="math inline">\(p_i = (x_i,y_i)\)</span> for
each index <span class="math inline">\(i\)</span>. This expression of
Meister’s algorithm is commonly known as the <em>shoelace formula</em>,
because the pattern of multiplications resembles the usual method for
threading shoelaces: <span class="math display">\[
    \begin{bmatrix}
        x_0 &amp;&amp; x_1 &amp;&amp; x_2 &amp;&amp; x_3 &amp;&amp;
\dots  \\[-1ex]
        &amp;\times&amp; &amp;\times&amp; &amp;\times&amp;
&amp;\times&amp; \\[-1ex]
        y_0 &amp;&amp; y_1 &amp;&amp; y_2 &amp;&amp; y_3 &amp;&amp;
\dots
    \end{bmatrix}
\]</span></p>
<p>Proving that that the shoelace algorithm correctly computes areas is
straightforward. First, we can prove that the formula is correct for
<em>triangles</em>, either by verifying<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> the
algebraic identity <span class="math display">\[
    \Delta(q,r,s) = \Delta(o,q,r) + \Delta(o,r,s) + \Delta(o,s,q)
\]</span> or by geometric case analysis, as suggested by the figure
below. Areas outside the triangle are either counted once positively and
once negatively, or not counted at all; areas inside the triangle are
counted exactly once, with the correct sign.</p>
<figure>
<img src="Fig/shoelace-triangles.png" style="width:75.0%"
alt="Lacing a triangle: Add the green (counterclockwise) triangles and subtract the pink (clockwise) triangles." />
<figcaption aria-hidden="true">Lacing a triangle: Add the green
(counterclockwise) triangles and subtract the pink (clockwise)
triangles.</figcaption>
</figure>
<p>Then to prove the shoelace formula correct for any larger polygon
<span class="math inline">\(P\)</span>, we can sum the signed areas of
all triangles in any frugal triangulation of <span
class="math inline">\(P\)</span> and observe that the terms involving
diagonals of the triangulation cancel out. As expected, the resulting
signed area is positive if <span class="math inline">\(P\)</span> is
oriented counterclockwise (that is, with the interior on the left) and
negative if <span class="math inline">\(P\)</span> is oriented
clockwise.</p>
<p>Meister actually used his shoelace formula to define the signed areas
of an <em>arbitrary</em> polygon, even if that polygon is not simple.
Here it’s somewhat less clear that the formula is <em>correct</em> for
non-convex polygons, but we can verify two facts that suggest that it is
at least <em>sensible</em>. First, the resulting signed area is still
independent of the choice of point <span
class="math inline">\(o\)</span>. Second, the formula counts the area of
each component of <span class="math inline">\(\mathbb{R}^2\setminus
P\)</span> some integer number of times; in particular, the (infinite)
area of the unbounded region is not counted at all. The resulting
assignment of integers to the components of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span> is called the
<em>Alexander numbering</em> of <span
class="math inline">\(P\)</span>.</p>
<figure>
<img src="Fig/Meister-nonsimple-polygon.png" style="width:30.0%"
alt="Computing the signed area of a polygon, from Meister (1785)" />
<figcaption aria-hidden="true">Computing the signed area of a polygon,
from Meister (1785)</figcaption>
</figure>
<figure>
<img src="Fig/Meister-polygon-shoelace.png" style="width:30.0%"
alt="One positive triangle and one negative triangle for Meister’s polygon" />
<figcaption aria-hidden="true">One positive triangle and one negative
triangle for Meister’s polygon</figcaption>
</figure>
<figure>
<img src="Fig/Meister-polygon-winding.png" style="width:30.0%"
alt="The Alexander numbering of Meister’s polygon" />
<figcaption aria-hidden="true">The Alexander numbering of Meister’s
polygon</figcaption>
</figure>
<figure>
<img src="Fig/Mobius-Alexander-Numbering.png" style="width:30.0%"
alt="Another Alexander numbering, from Möbius (1865)" />
<figcaption aria-hidden="true">Another Alexander numbering, from Möbius
(1865)</figcaption>
</figure>
<h2 data-number="2.3" id="winding-numbers"><span
class="header-section-number">2.3</span> Winding numbers</h2>
<p>The <em>winding number</em> of a polygon <span
class="math inline">\(P\)</span> around a point <span
class="math inline">\(o\)</span> is intuitively (and not surprisingly)
the number of times that <span class="math inline">\(P\)</span> winds
counterclockwise around <span class="math inline">\(o\)</span>. For
example, if <span class="math inline">\(P\)</span> is a <em>simple</em>
polygon, its winding number around any exterior point is zero, and its
winding number around any interior point is either <span
class="math inline">\(+1\)</span> or <span
class="math inline">\(-1\)</span>, depending on how the polygon is
oriented. If the polygon winds <em>clockwise</em> around <span
class="math inline">\(o\)</span>, the winding number is negative.
Crucially, the winding number is only well defined if the polygon does
not <em>contain</em> the point <span
class="math inline">\(o\)</span>.</p>
<p>We can define the winding number more formally as follows. Let <span
class="math inline">\(p_0, p_1, \dots, p_{n-1}\)</span> denote the
vertices of <span class="math inline">\(P\)</span> in order. For each
index <span class="math inline">\(i\)</span>, let <span
class="math inline">\(\theta_i\)</span> denote the interior angle at
<span class="math inline">\(o\)</span> in the triangle <span
class="math inline">\(\triangle p_i o p_{i+1}\)</span>, with positive
sign if <span class="math inline">\((o, p_i, p_{i+1})\)</span> is
oriented counterclockwise, and with negative sign if <span
class="math inline">\((o, p_i, p_{i+1})\)</span> is oriented clockwise.
Assuming angles are measured in <em>circles</em>,<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> the
winding number of <span class="math inline">\(P\)</span> around <span
class="math inline">\(o\)</span> is the sum <span
class="math inline">\(\sum_i \theta_i\)</span>.</p>
<figure>
<img src="Fig/winding-number.png" style="width:40.0%"
alt="Winding number as a sum of angles, after Meister" />
<figcaption aria-hidden="true">Winding number as a sum of angles, after
Meister</figcaption>
</figure>
<p>Actually computing the winding number according to this definition
requires inverse trigonometric functions, square roots, and other
numerical madness. Fortunately, there is an equivalent definition that
builds on our ray-shooting test from the previous lecture. Let <span
class="math inline">\(R\)</span> be a vertical ray shooting upward from
<span class="math inline">\(o\)</span>. We distinguish two types of
crossings between the <span class="math inline">\(R\)</span> and the
polygon, depending on the orientation of the crossed edges.
Specifically, if the crossed edge is directed from right to left, we
have a <em>positive</em> crossing; otherwise, we have a
<em>negative</em> crossing. Equivalently, when <span
class="math inline">\(R\)</span> crosses an edge <span
class="math inline">\(p_ip_{i+1}\)</span>, the sign of the crossing is
the sign of the determinant <span class="math inline">\(\Delta(o, p_i,
p_{i+1})\)</span>.</p>
<figure>
<img src="Fig/ray-crossings.png" style="width:50.0%"
alt="A positive crossing (left) and a negative crossing (right)" />
<figcaption aria-hidden="true">A positive crossing (left) and a negative
crossing (right)</figcaption>
</figure>
<p>I’ll leave the equivalence of these two definitions as an exercise.
(Hint: prove equivalence for triangles, and then look at Meister’s
figure again!)</p>
<p>Here is the ray-shooting algorithm in (pseudo)Python. Any
similarities with the point-in-polygon algorithm from the previous
lecture are purely intentional.</p>
<pre><code>def windingNumber(P, o):
    wind = 0
    n = size(P)
    for i in range(n):
        p = P[i]
        q = P[(i+1)%n]
        Delta = (p.x - o.x)*(q.y - o.y) - (p.y - o.y)*(q.x - o.x)
        if p.x &lt;= o.x &lt; q.x &amp;&amp; Delta &gt; 0:
            wind += 1
        elif q.x &lt;= o.x &lt; p.x &amp;&amp; Delta &lt; 0:
            wind -= 1
    return wind</code></pre>
<p>Winding numbers has a third useful interpretation, which we’ve
already seen in this lecture. Case analysis similar to our proof of
Lemma <span class="math inline">\(\le 2\)</span> from the previous
lecture implies that if <span class="math inline">\(o\)</span> and <span
class="math inline">\(o’\)</span> are two points in the same component
of <span class="math inline">\(\mathbb{R}^2\setminus P\)</span>, then
<span class="math inline">\(P\)</span> has the same winding number
around both points. Moreover, if <span class="math inline">\(o\)</span>
and <span class="math inline">\(o’\)</span> are in components of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span> that share a
segment of some polygon edge <span class="math inline">\(e\)</span> on
their boundary, then the winding numbers around <span
class="math inline">\(o\)</span> and <span
class="math inline">\(o’\)</span> differ by <span
class="math inline">\(1\)</span>, with the higher winding number to the
left of <span class="math inline">\(e\)</span>.</p>
<p>This assignment of winding numbers to the components of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span> is identical to
the Alexander numbering of <span class="math inline">\(P\)</span> that
we defined earlier. That is, the winding number of <span
class="math inline">\(P\)</span> around any point <span
class="math inline">\(q \not\in P\)</span> is precisely the number of
times that the area around <span class="math inline">\(q\)</span> is
counted by the shoelace formula. Thus, the signed area of any polygon
<span class="math inline">\(P\)</span> can expressed in terms of winding
numbers as <span class="math display">\[
    \textsf{area}(P) = \sum_c \textsf{wind}(P, c) \cdot \textsf{area}(c)
\]</span> where the sum is over the components of <span
class="math inline">\(\mathbb{R}^2\setminus P\)</span>.</p>
<figure>
<img src="Fig/Meister-winding.png" style="width:40.0%"
alt="Another non-simple polygon from Meister, with winding numbers indicated by shading (1785)" />
<figcaption aria-hidden="true">Another non-simple polygon from Meister,
with winding numbers indicated by shading (1785)</figcaption>
</figure>
<h2 data-number="2.4" id="homotopy"><span
class="header-section-number">2.4</span> Homotopy</h2>
<p>Now let’s go back to the Endless Chain. A bit of case analysis should
convince you—or should at least <em>strongly suggest</em>—that in all
three configurations, the chain is loose around your finger if and only
if the winding number of the Chain around your finger is zero.</p>
<figure>
<img src="Fig/fast-and-loose-winding.png" style="width:95.0%"
alt="Winding numbers of the Endless Chain around various points" />
<figcaption aria-hidden="true">Winding numbers of the Endless Chain
around various points</figcaption>
</figure>
<p>But in the actual game, we aren’t dealing with a single fixed closed
curve. The con man grabs one side of the chain and pulls, causing the
chain to move continuously across the barrelhead and around your finger,
until it either gets stuck Fast or pulls Loose. Instead of thinking
about how a fixed polygon wraps with a changing point, we need a way to
reason about how a <em>continuously changing</em> curve wraps around a
<em>fixed</em> point.</p>
<p>A <em>homotopy</em> between two closed curves is a continuous
deformation—a morph—from one curve to the other. Homotopies can be
defined between curves in any topological space, but for purposes of
illustration, let’s restrict ourselves to curves in the punctured plane
<span class="math inline">\(\mathbb{R}^2\setminus o\)</span>, where
<span class="math inline">\(o\)</span> is an arbitrary point called the
<em>obstacle</em>. (In Fast and Loose, the obstacle is your finger.)
Without loss of generality, I will assume that <span
class="math inline">\(o\)</span> is actually the origin <span
class="math inline">\((0,0)\)</span>.</p>
<p>Formally, a <em>homotopy</em> between two closed curves in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span> is a continuous
function <span class="math inline">\(h\colon [0,1]\times S^1\to
\mathbb{R}^2\setminus o\)</span>, such that <span
class="math inline">\(h(0, \cdot)\)</span> and <span
class="math inline">\(h(1, \cdot)\)</span> are the initial and final
closed curves, respectively. For each <span
class="math inline">\(0&lt;t&lt;1\)</span>, the function <span
class="math inline">\(h(t, \cdot)\)</span> is the intermediate closed
curve at “time” <span class="math inline">\(t\)</span>. Crucially, none
of these intermediate curves touches the obstacle point <span
class="math inline">\(o\)</span>.</p>
<p>Two closed curves in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span> are
<em>homotopic</em>, or in the same <em>homotopy class</em>, if there is
a homotopy from one to the other in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span>. Homotopy is an
equivalence relation.</p>
<p>A closed curve is <em>contractible</em> in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span> if it is
homotopic to a single point (or more formally, to a constant curve).</p>
<!--
We also need a definition of homotopy between _paths_; this is a little more subtle.  Let $\pi\colon [0,1]\to \mathbb{R}^2\setminus o$ and $\sigma\colon[0,1]\to \mathbb{R}^2\setminus o$ be two paths in the punctured plane with the same endpoints: $\pi(0)=\sigma(0)$ and $\pi(1)=\sigma(1)$.  A _path homotopy_ from $\pi$ to $\sigma$ is a continuous function $h\colon [0,1]\times[0,1]\to \mathbb{R}^2\setminus o$ that satisfies four conditions:

* $H(0, t) = \pi(t)$ for all $t$
* $H(1, t) = \sigma(t)$ for all $t$
* $H(s, 0) = \pi(0) = \sigma(0)$ for all $s$
* $H(s, 1) = \pi(1) = \sigma(1)$ for all $s$

Intuitively, you should think of a path homotopy as a continuous deformation of one path into the other, keeping the endpoints fixed at all times.  Again, for each $0<s<1$, the function $h(t, \cdot)$ is the intermediate path at “time” $s$, and none of these intermediate paths touches the obstacle point $o$.

I’ll typically use the word “homotopy” for both free homotopy and path homotopy, in the hope that the precise type is clear from context.
-->
<h2 data-number="2.5" id="vertex-moves"><span
class="header-section-number">2.5</span> Vertex moves</h2>
<p>Similar to the definition of “connected”, the definition of
“homotopy” allows intermediate curves to be arbitrarily wild closed
curves even if the initial and final curves are polygons.</p>
<p>Fortunately, there is a general principle that allows us to “tame”
homotopies between tame curves like polygons, by decomposing them into a
sequence of elementary <em>moves</em>. (This principle is similar to the
observation that any closed curve can be approximated by a sequence of
line segments, otherwise known as a polygon.)</p>
<p>Let <span class="math inline">\(P\)</span> be any polygon. A
<em>vertex move</em> translates exactly one point <span
class="math inline">\(p\)</span> of <span
class="math inline">\(P\)</span> along a straight line from its current
location to a new location <span class="math inline">\(p’\)</span>,
yielding a new polygon <span class="math inline">\(P’\)</span>. As the
point <span class="math inline">\(p\)</span> moves, the edges incident
to <span class="math inline">\(p\)</span> pivot around their other
endpoints. Typically the moving point <span
class="math inline">\(p\)</span> is a vertex of the initial polygon
<span class="math inline">\(P\)</span> and the final point <span
class="math inline">\(p’\)</span> is a vertex of the final polygon <span
class="math inline">\(P’\)</span>, but neither of these restrictions is
required by the definition. We are allowed to freely introduce new
vertices in the middle of edges, or freely delete “flat” vertices
between two collinear edges.</p>
<figure>
<img src="Fig/one-vertex-move.png" style="width:50.0%"
alt="A vertex move." />
<figcaption aria-hidden="true">A vertex move.</figcaption>
</figure>
<p>Now suppose the polygon <span class="math inline">\(P\)</span> lives
in the punctured place <span class="math inline">\(\mathbb{R}^2\setminus
o\)</span>. Let <span class="math inline">\(p, q, r\)</span> be three
consecutive vertices of <span class="math inline">\(P\)</span>. The
vertex move <span class="math inline">\(q\mapsto q’\)</span> is
<em>safe</em> if neither of the triangles <span
class="math inline">\(\triangle p q q’\)</span> or <span
class="math inline">\(\triangle q q’ r\)</span>. contains the obstacle
point <span class="math inline">\(o\)</span>. Equivalently, during a
safe vertex move, the continuously changing polygon never touches <span
class="math inline">\(o\)</span>.</p>
<figure>
<img src="Fig/safe-vertex-move.png" style="width:80.0%"
alt="An unsafe vertex move and a safe vertex move." />
<figcaption aria-hidden="true">An unsafe vertex move and a safe vertex
move.</figcaption>
</figure>
<p>It follows that every safe vertex move is a homotopy in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span>. We can build up
more complex homotopies by concatenating several safe vertex moves. In
fact, <em>any</em> sequence of safe vertex moves describes a homotopy in
<span class="math inline">\(\mathbb{R}^2\setminus o\)</span>.</p>
<h2 data-number="2.6"
id="polygon-homotopies-are-sequences-of-vertex-moves"><span
class="header-section-number">2.6</span> Polygon homotopies are
sequences of vertex moves</h2>
<p>Unfortunately, the converse of this observation is false; not every
homotopy is a sequence of vertex moves. Consider, for example, a simple
translation or rotation of the entire polygon! Nevertheless, every
homotopy can be <em>approximated</em> by a sequence of safe vertex
moves.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
If two polygons in <span class="math inline">\(\mathbb{R}^2\setminus
o\)</span> are homotopic, then they are homotopic by a sequence of safe
vertex moves.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix a homotopy <span class="math inline">\(h\colon [0,1]\times S^1 \to
\mathbb{R}^2\setminus o\)</span> between two polygons <span
class="math inline">\(P_0 = h(0,\cdot)\)</span> and <span
class="math inline">\(P_1 = h(1,\cdot)\)</span>.
</dd>
<dd>
<p>For any parameters <span class="math inline">\(t\)</span> and <span
class="math inline">\(\theta\)</span>, let <span
class="math inline">\(d(t, \theta)\)</span> be the Euclidean distance
from <span class="math inline">\(h(t, \theta)\)</span> to the origin
<span class="math inline">\(o\)</span>, and let <span
class="math inline">\(\varepsilon = \min_{t,\theta}
d(t,\theta)\)</span>. Because the cylinder <span
class="math inline">\([0,1]\times S^1\)</span> is compact, this minimum
is well-defined and positive.</p>
</dd>
<dd>
<p>We subdivide the cylinder <span class="math inline">\([0,1]\times
S^1\)</span> into triangles as follows. First, cut the cylinder into a
grid of <span class="math inline">\(\delta\times\delta\)</span> squares
<span class="math inline">\(\square(i,j) = [i\delta, (i+1)\delta] \times
[j\delta, (j+1)\delta \bmod 1]\)</span>, where <span
class="math inline">\(\delta&gt;0\)</span> is chosen so that the
diameter of <span class="math inline">\(h(\square(i,j))\)</span> is at
most <span class="math inline">\(\varepsilon/2\)</span>. (The existence
of <span class="math inline">\(\delta\)</span> is guaranteed by
continuity.) Then further subdivide each grid square into two right
isosceles triangles, as shown in the figure below. Without loss of
generality, assume each vertex of <span
class="math inline">\(P_0\)</span> and <span
class="math inline">\(P_1\)</span> the image of some vertex on the
boundary of the resulting triangle mesh <span
class="math inline">\(\Delta\)</span>.</p>
</dd>
<dd>
<p>The homotopy <span class="math inline">\(h\)</span> maps any cycle in
this mesh to a closed curve, which consists of <span
class="math inline">\(O(1/\delta)\)</span> curve segments, each with
diameter at most <span class="math inline">\(\varepsilon/2\)</span>, and
each with distance at least <span
class="math inline">\(\varepsilon\)</span> from <span
class="math inline">\(o\)</span>. Define a new homotopy <span
class="math inline">\(h’ \colon [0,1]\times S^1 \to
\mathbb{R}^2\setminus o\)</span> that agrees with <span
class="math inline">\(h\)</span> at every grid vertex and linearly
interpolates within each grid triangle. Changing from <span
class="math inline">\(h\)</span> to <span
class="math inline">\(h’\)</span> changes the image of any grid cycle by
replacing each short curve segment with a straight line segment.</p>
</dd>
<dd>

</dd>
<dd>
<p>We can easily construct a sequence of <span class="math inline">\(1 +
2/\delta^2\)</span> cycles in <span
class="math inline">\(\Delta\)</span> that starts with one boundary
<span class="math inline">\(0\times S^1\)</span> and ends with the other
boundary <span class="math inline">\(1\times S^1\)</span>, such that the
symmetric difference between two adjacent cycles is the boundary of one
triangle in <span class="math inline">\(\Delta\)</span>. Two adjacent
cycles in this sequence are shown on the right in the following
fugure.</p>
</dd>
<dd>
<figure>
<img src="Fig/cylinder-grid.png" style="width:60.0%"
alt="A grid on the unit cylinder." />
<figcaption aria-hidden="true">A grid on the unit cylinder.</figcaption>
</figure>
</dd>
<dd>
<p>The piecewise-linear homotopy <span class="math inline">\(h’\)</span>
maps any two adjacent cycles in this sequence to a pair of polygons
<span class="math inline">\(P_t\)</span> and <span
class="math inline">\(P_{t+1}\)</span> that differ by a single vertex
move. Every vertex of each intermediate polygon has distance at least
<span class="math inline">\(\varepsilon\)</span> from the origin, each
edge has length at most <span
class="math inline">\(\varepsilon/2\)</span>, and each vertex move
translates its vertex a distance of at most <span
class="math inline">\(\varepsilon/2\)</span>. It follows that every
vertex move in this sequence is safe.</p>
</dd>
<dd>
<p>We conclude that <span class="math inline">\(P_0\)</span> can be
transformed into <span class="math inline">\(P_1\)</span> by a sequence
of <span class="math inline">\(1 + 2/\delta^2\)</span> safe vertex
moves.</p>
</dd>
</dl>
<p>This lemma is a special case of a more general <em>simplicial
approximation theorem</em>, which intuitively states that any continuous
map between <em>nice</em> topological spaces (formally, geometric
simplicial complexes) can be approximated by a <em>nice</em> continuous
map (formally, simplicial maps between finite subdivisions of the
original complexes); moreover, the original map can be continuously
deformed to its approximation.</p>
<h2 data-number="2.7" id="homotopy-invariant"><span
class="header-section-number">2.7</span> Homotopy Invariant</h2>
<p>Winding numbers are our first example of a <em>topological
invariant</em>, and specifically a <em>complete homotopy</em> invariant.
A topological invariant is any property of objects or spaces that is
unchanged by some form of topological equivalence. One simple example is
the number of components of a subset of the plane; another standard
example is the <em>genus</em> of a surface. A <em>homotopy</em>
invariant is any property that is preserved by homotopy; a homotopy
invariant is <em>complete</em> if it takes on different values for two
objects that are not homotopic.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
Two polygons are homotopic in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span> if and only if
they have the same winding number around the origin <span
class="math inline">\(o\)</span>. Thus, winding number is a complete
homotopy invariant for polygons in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span>.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix two polygons <span class="math inline">\(P_0\)</span> and <span
class="math inline">\(P_1\)</span> in <span
class="math inline">\(\mathbb{R}^2\setminus o\)</span>. If these two
polygons are homotopic, then by the previous lemma, they are connected
by a sequence of safe triangle moves. A safe triangle move does not
change the winding number of a polygon around the origin. Thus, by
induction, <span class="math inline">\(P_0\)</span> and <span
class="math inline">\(P_1\)</span> have the same winding number.
</dd>
<dd>
<p>To prove the converse, I’ll describe a sequence of safe triangle
moves that transforms any polygon <span class="math inline">\(P\)</span>
into a <em>canonical</em> polygon <span
class="math inline">\(\Diamond^w\)</span> with the same winding number
<span class="math inline">\(w\)</span> around the origin. (The notation
<span class="math inline">\(\Diamond^w\)</span> will make sense later,
honest.) Thus, if <span class="math inline">\(P_0\)</span> and <span
class="math inline">\(P_1\)</span> have the same winding number <span
class="math inline">\(w\)</span>, we can deform <span
class="math inline">\(P_0\)</span> into <span
class="math inline">\(P_1\)</span> by concatenating the move sequence
that takes <span class="math inline">\(P_0\)</span> to <span
class="math inline">\(\lozenge^w\)</span> and the reverse of the move
sequence that takes <span class="math inline">\(P_1\)</span> to <span
class="math inline">\(\lozenge^w\)</span>.</p>
</dd>
<dd>
<p>Our homotopy consists of several stages. First let’s consider the
case where the winding number of <span class="math inline">\(P\)</span>
around <span class="math inline">\(0\)</span> is not zero.</p>
</dd>
<dd>
<ul>
<li>Let <span class="math inline">\(p_i\)</span> be any vertex of <span
class="math inline">\(P\)</span>, and let <span
class="math inline">\(p_{i-1}\)</span> and <span
class="math inline">\(p_{i+1}\)</span> be the next and previous
vertices. We call <span class="math inline">\(q\)</span>
<em>redundant</em> if the triangle <span class="math inline">\(\triangle
p_{i-1}p_ip_{i+1}\)</span> does not contain the origin. In particular,
if the triples <span class="math inline">\((o,p_{i-1},p_i)\)</span> and
<span class="math inline">\((o,p_i,p_{i+1})\)</span> have opposite
orientations, one clockwise and the other counterclockwise, then <span
class="math inline">\(p_i\)</span> is redundant. In the first phase of
our homotopy, we repeatedly remove redundant vertices, by moving each
redundant vertex <span class="math inline">\(q\)</span> to one of its
neighbors, until none are left. The resulting polygon <span
class="math inline">\(P&#39;\)</span> is <em>angularly monotone</em>:
every triple <span class="math inline">\((o,p_i,p_{i+1})\)</span> has
the same orientation.</li>
</ul>
</dd>
<dd>
<figure>
<img src="Fig/winding-canonize-redundant.png" style="width:95.0%"
alt="Removing three redundant vertices" />
<figcaption aria-hidden="true">Removing three redundant
vertices</figcaption>
</figure>
</dd>
<dd>
<ul>
<li>Next, we subdivide <span class="math inline">\(P&#39;\)</span> by
adding vertices at its intersections with rays pointing up, down, left,
and right from the origin <span class="math inline">\(o\)</span>. After
this subdivision, any vertex that is <em>not</em> on one of these rays
is redundant. So in the second phase of the homotopy, we remove all
non-ray vertices using safe vertex moves. The resulting polygon <span
class="math inline">\(P&#39;&#39;\)</span> is still angularly
monotone.</li>
</ul>
</dd>
<dd>
<ul>
<li>Finally, we move each vertex so that is distance from the origin is
<span class="math inline">\(1\)</span>; each of these vertex moves is
safe. The resulting polygon <span
class="math inline">\(\Diamond^w\)</span> has vertices only at the
points <span class="math inline">\((0,1)\)</span>, <span
class="math inline">\((1,0)\)</span>, <span
class="math inline">\((0,-1)\)</span>, and <span
class="math inline">\((-1,0)\)</span>; the polygon winds around this
diamond <span class="math inline">\(|w|\)</span> times, counterclockwise
if <span class="math inline">\(w&gt;0\)</span> and clockwise if <span
class="math inline">\(w&lt;0\)</span>.</li>
</ul>
</dd>
<dd>
<figure>
<img src="Fig/winding-canonize.png" style="width:95.0%"
alt="Making an angularly monotone polygon canonical" />
<figcaption aria-hidden="true">Making an angularly monotone polygon
canonical</figcaption>
</figure>
</dd>
<dd>
<p>The special case where <span class="math inline">\(P\)</span> has
winding number <span class="math inline">\(0\)</span> is even simpler.
The first phase (removing redundant vertices) actually reduces <span
class="math inline">\(P\)</span> to a single point; we can then
translate this point to <span class="math inline">\(\diamond^0 =
(1,0)\)</span> using one more safe vertex move.</p>
</dd>
</dl>
<p>This theorem immediately implies a linear-time algorithm to decide if
two polygons are homotopic in the punctured plane: Count positive and
negative crossings between each polygon and an arbitrary ray from the
origin.</p>
<h2 data-number="2.8"
id="and-the-aptly-named-sir-not-appearing-in-this-film-1"><span
class="header-section-number">2.8</span> …and the Aptly Named Sir Not
Appearing in This Film</h2>
<ul>
<li>rotation number = total turning angle = smiles <span
class="math inline">\(-\)</span> frowns</li>
<li>regular homotopy = vertex moves without spurs</li>
<li>rotation number is a regular homotopy invariant</li>
<li>complex root finding / fundamental theorem of algebra</li>
<li>signed volumes of self-intersecting polyhedra (hic utres
unilaterales nascuntur)</li>
</ul>
<h2 data-number="2.9" id="references-1"><span
class="header-section-number">2.9</span> References</h2>
<ol type="1">
<li><p>James W. Alexander. Topological invariants of knots and links.
<em>Trans. Amer. Math. Soc.</em> 30(2):275–306, 1928. The reason we call
it “Alexander numbering”.</p></li>
<li><p>Brian Brushwood. <a
href="https://www.youtube.com/watch?v=1-zL3_F0lHw">Fast and Loose.</a>
YouTube, October 19, 2015.</p></li>
<li><p>Brian Brushwood. <a
href="https://www.youtube.com/watch?v=NlKuKi1l78c">Pricking the
Garter.</a>. YouTube, June 26, 2017.</p></li>
<li><p>Albrecht Ludwig Friedrich Meister. Generalia de genesi figurarum
planarum, et independentibus earum affectionibus. <em>Novi Commentarii
Soc. Reg. Scient. Gott.</em> 1:144–180 + 9 plates, 1769/1770. Presented
January 6, 1770. The shoelace formula.</p></li>
<li><p>August F. Möbius. Über der Bestimmung des Inhaltes eines
Polyëders. <em>Ber. Sächs. Akad. Wiss. Leipzig, Math.-Phys. Kl.</em>
17:31–68, 1865. <em>Gesammelte Werke</em> 2:473–512, Liepzig, 1886. An
earlier appearance of Alexander numbering.</p></li>
</ol>
<h1 data-number="3" id="homotopy-testingbeta"><span
class="header-section-number">3</span> Homotopy Testing<span
class="math inline">\(^\beta\)</span></h1>
<h2 data-number="3.1" id="multiple-obstacles"><span
class="header-section-number">3.1</span> Multiple Obstacles</h2>
<p>Now let’s generalize the homotopy problem from the last lecture to
the case of more than one obstacle. Let <span class="math inline">\(O =
\{a, b, c, \dots\}\)</span> be an arbitrary finite set of points in the
plane. The definitions of homotopy and contractible easily generalize to
polygons (and other closed curves) in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span>. How quickly can
we tell whether two polygons in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> are
homotopic?</p>
<figure>
<img src="Fig/fast-and-loose-cheat.png" style="width:30.0%"
alt="The Endless Chain again" />
<figcaption aria-hidden="true">The Endless Chain again</figcaption>
</figure>
<p>The game Fast and Loose shows some of the subtlety of this problem.
Let <span class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> be arbitrarily points in each of the
two loops of the curve <span class="math inline">\(C\)</span> that the
con artist actually uses. It’s not hard to see that <span
class="math inline">\(wind(c, a) = wind(C, b) = 0\)</span>; any ray
upward from either <span class="math inline">\(a\)</span> or <span
class="math inline">\(b\)</span> has one positive crossing and one
negative crossing. Thus, the curve is contractible in the plane with
only <em>one</em> of these punctures; in other words, the chain is loose
if we only use one finger. But the curve <span
class="math inline">\(C\)</span> is <em>not</em> contractible in <span
class="math inline">\(\mathbb{R}^2 \setminus \{a, b\}\)</span>; we can
hold the chain fast by placing a finger in each loop. Winding numbers
are <em>not</em> a homotopy invariant when there is more than one
obstacle.</p>
<p>Just as in the one-obstacle setting, we can (approximately) decompose
any homotopy between two polygons in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> into safe vertex
moves, where now a vertex move is <em>safe</em> if the moving vertex and
its incident edges avoids <em>all</em> points in <span
class="math inline">\(O\)</span>. Essentially the same argument from the
previous lecture implies the following:</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
Two polygons in <span class="math inline">\(\mathbb{R}^2\setminus
O\)</span> are homotopic if and only if they are connected by a sequence
of safe vertex moves.
</dd>
</dl>
<h2 data-number="3.2" id="crossing-sequences"><span
class="header-section-number">3.2</span> Crossing Sequences</h2>
<p>However, we can still define a homotopy invariant by shooting rays
out of <em>every</em> obstacle, and recording how the polygon intersects
these rays. Specifically, we record not only the <em>number</em> of
times the polygon crosses each ray, but the actual order and directions
of these crossings.</p>
<p>As usual, we will assume without loss of generality that the
obstacles have distinct <span
class="math inline">\(x\)</span>-coordinates. Shoot a vertical ray
upward from each obstacle point; I’ll call these vertical rays
<em>fences</em>. The <em>crossing sequence</em> of a polygon <span
class="math inline">\(P\)</span> in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> is the sequence
of intersections between the fences and the polygon, in order along the
polygon, along with the sign of each crossing (positive if the polygon
crosses the fence to the left, negative if the polygon crosses the fence
to the right).</p>
<p>Figure 2 shows a polygon in the plane with two obstacle points <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span>. If we orient the polygon as indicated
by the arrows, starting at the lower left corner, the crossing sequence
is <strong><code>BAabBAabB</code></strong>, where each upper-case letter
denotes a positive crossing through the corresponding fence, and each
lower-case letter denotes a negative crossing through the corresponding
fence.</p>
<figure>
<img src="Fig/crossing-sequence.png" style="width:30.0%"
alt="A polygon with crossing sequence BAabBAabB" />
<figcaption aria-hidden="true">A polygon with crossing sequence
<code>BAabBAabB</code></figcaption>
</figure>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
Two polygons in <span class="math inline">\(\mathbb{R}^2\setminus
O\)</span> with the same crossing sequence are homotopic.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
I’ll describe a homotopy that transforms any polygon <span
class="math inline">\(P\)</span> into a <em>canonical</em> polygon with
the same crossing sequence. (With more care, the homotopy can be
described explicitly as a sequence of safe vertex moves.)
</dd>
<dd>
<p>First, we define two new <em>sentinel</em> points <span
class="math inline">\(a^\flat\)</span> and <span
class="math inline">\(a^\sharp\)</span> just above and on either side of
each obstacle <span class="math inline">\(a\)</span>. These points are
close enough to <span class="math inline">\(a\)</span> that no vertex of
<span class="math inline">\(P\)</span>, no other obstacle, and no other
sentinel point lies on or between the vertical lines through <span
class="math inline">\(a^\flat\)</span> and <span
class="math inline">\(a^\sharp\)</span>.</p>
</dd>
<dd>
<p>Next, we <em>divert</em> edges through the sentinel points, by adding
two additional vertices near each intersection between <span
class="math inline">\(P\)</span> and any fence, and then moving those
new vertices to the sentinel points near the corresponding obstacle.</p>
</dd>
<dd>
<ul>
<li>If the original edge crosses <span
class="math inline">\(a\)</span>’s fence from right to left (a positive
crossing), the diverted edge passes through sentinel points <span
class="math inline">\(a^\sharp\)</span> and <span
class="math inline">\(a^\flat\)</span> in that order.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the original edge crosses <span
class="math inline">\(a\)</span>’s fence from left to right (a negative
crossing), the diverted edge passes through sentinel points <span
class="math inline">\(a^\flat\)</span> and <span
class="math inline">\(a^\sharp\)</span> in that order.</li>
</ul>
</dd>
<dd>
See Figure 3. The resulting polygon <span
class="math inline">\(P&#39;\)</span> has the same crossing sequence as
the original polygon <span class="math inline">\(P\)</span>.
</dd>
<dd>
<p>Finally, we divert the rest of the polygon to a single point far
below any obstacle. First we add a new vertex at the midpoint of each
edge of <span class="math inline">\(P&#39;\)</span> between two sentinel
points of different obstacles. Then we choose a point <span
class="math inline">\(z\)</span> sufficiently far below the polygon and
the sentinel points that for any polygon vertex <span
class="math inline">\(p\)</span>, the segment <span
class="math inline">\(zp\)</span> does not cross any of the fences.
Finally, we move every vertex of <span
class="math inline">\(P&#39;\)</span> that is <em>not</em> a sentinel
point directly to this new bottom point <span
class="math inline">\(z\)</span>. Again, this deformation does not
change the polygon’s crossing sequence.</p>
</dd>
<dd>
<p>The resulting canonical polygon <span
class="math inline">\(P&#39;&#39;\)</span> is a concatenation of loops
of the form <span class="math inline">\(z a^\flat a^\sharp z\)</span>
(for each negative crossing) or <span class="math inline">\(z a^\sharp
a^\flat z\)</span> (for each positive crossing).</p>
</dd>
</dl>
<figure>
<img src="Fig/edge-divert.png" style="width:65.0%"
alt="Diverting one edge of a polygon" />
<figcaption aria-hidden="true">Diverting one edge of a
polygon</figcaption>
</figure>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
Any polygon in <span class="math inline">\(\mathbb{R}^2\setminus
O\)</span> with an empty crossing sequence is contractible.
</dd>
</dl>
<p>Unfortunately, the converses of these two results are false; a
homotopy that moves one polygon vertex across one fence either inserts
or deletes a pair of crossings in the polygon’s crossing sequence. Thus,
crossing sequences are not homotopy invariants. Fortunately, this is the
<em>only</em> way that a homotopy can change the crossing sequence.</p>
<h2 data-number="3.3" id="reductions"><span
class="header-section-number">3.3</span> Reductions</h2>
<p>We regard signed crossing sequences as strings of abstract symbols,
where each symbol <span class="math inline">\(a\)</span> has a formal
“inverse” <span class="math inline">\(\bar{a}\)</span>. In our earlier
example, each upper case letter is the inverse of the corresponding
lower-case letter, and vice versa. Let <span
class="math inline">\(x\cdot y\)</span> denote the concatenation of
strings <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>, and let <span
class="math inline">\(\varepsilon\)</span> denote the empty string.</p>
<p>An <em>elementary reduction</em> is a transformation of the form
<span class="math inline">\(x\cdot a\bar{a}\cdot y \mapsto x\cdot
y\)</span>, where <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> are (possibly empty) strings and <span
class="math inline">\(a\)</span> is a single symbol. An <em>elementary
expansion</em> is the reverse transformation <span
class="math inline">\(x\cdot y \mapsto x\cdot a\bar{a}\cdot y\)</span>.
Two strings are <em>equivalent</em> if once can be transformed into the
other by a sequence of elementary reductions and expansions. (Check for
yourself that equivalence is in fat an equivalence relation!) We call a
string <em>trivial</em> if it is equivalent to the empty string <span
class="math inline">\(\varepsilon\)</span>. Finally, a string is
<em>reduced</em> if no elementary reductions are possible; for example,
the empty string <span class="math inline">\(\varepsilon\)</span> is
trivially reduced, as is any string of length <span
class="math inline">\(1\)</span>.</p>
<p>Crossing sequences of polygons are actually <em>cyclic</em> strings.
Formally, a cyclic string is an equivalence class of linear strings:
<span class="math display">\[
    (w) := \{ y\cdot x \mid x\cdot y = w \}
\]</span> For example, (<code>ABbA</code>) = {<code>ABbA</code>,
<code>BbAA</code>, <code>bAAB</code>, <code>AABb</code>} and <span
class="math inline">\((\varepsilon) = \{\varepsilon\}\)</span>. I’ll
write <span class="math inline">\(w \sim z\)</span> to denote that <span
class="math inline">\(w\)</span> is a cyclic shift of <span
class="math inline">\(z\)</span>, or equivalently <span
class="math inline">\(w\in(z)\)</span>, or equivalently <span
class="math inline">\(z\in (w)\)</span>. To emphasize that elementary
reductions can “wrap around” cyclic strings, we say that a cyclic string
is <em>cyclically reduced</em> if no elementary reductions are possible.
A (cyclic) string is <em>trivial</em> if it is equivalent to the empty
(cyclic) string.</p>
<p>For example, the cyclic string
(<code>EcaCbaABcEeEeAdbcCBaEdDeADCe</code>) is trivial; two different
sequences of elementary reductions are shown below (using interpuncts to
represent missing symbols). In the first sequence, each elementary
reduction removes the <em>leftmost</em> matching pair; the second
sequence is more haphazard. In fact, as the following lemma implies,
<em>any</em> sequence of elementary reductions eventually reduces this
string to nothing.</p>
<pre><code>EcaCbaABcEeEeAdbcCBaEdDeADCe
EcaCb··BcEeEeAdbcCBaEdDeADCe
EcaC····cEeEeAdbcCBaEdDeADCe
Eca······EeEeAdbcCBaEdDeADCe
Eca········EeAdbcCBaEdDeADCe
Eca··········AdbcCBaEdDeADCe
Ec············dbcCBaEdDeADCe
Ec············db··BaEdDeADCe
Ec············d····aEdDeADCe
Ec············d····aE··eADCe
Ec············d····a····ADCe
Ec············d··········DCe
Ec························Ce
E··························e
···························· </code></pre>
<pre><code>EcaCbaABcEeEeAdbcCBaEdDeADCe
EcaCbaABcEeEeAdb··BaEdDeADCe
EcaCb··BcEeEeAdb··BaEdDeADCe
·caCb··BcEeEeAdb··BaEdDeADC·
·caC····cEeEeAdb··BaEdDeADC·
·caC····cE··eAdb··BaEdDeADC·
·caC····cE··eAdb··BaE··eADC·
·caC····cE··eAdb··Ba····ADC·
·caC····cE··eAd····a····ADC·
··aC····cE··eAd····a····AD··
··aC····c····Ad····a····AD··
··aC····c····Ad··········D··
··a··········Ad··········D··
··a··········A··············
····························</code></pre>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
Every cyclic string is equivalent to exactly one cyclically reduced
cyclic string.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(w\)</span> be a cyclic string that
allows two elementary reductions <span class="math inline">\(w\mapsto
x\)</span> and <span class="math inline">\(w\mapsto y\)</span>, meaning
two different pairs of symbols are deleted. We claim that either <span
class="math inline">\(x=y\)</span> or there is another string <span
class="math inline">\(z\)</span> such that <span
class="math inline">\(x\mapsto z\)</span> and <span
class="math inline">\(y\mapsto z\)</span> are elementary reductions.
</dd>
<dd>
<ul>
<li>If the pairs of symbols deleted by <span
class="math inline">\(w\mapsto x\)</span> and <span
class="math inline">\(w\mapsto y\)</span> are disjoint, then we can
write <span class="math inline">\(w = (a \bar{a} \cdot w_1 \cdot
c\bar{c} \cdot w_2)\)</span> for some (possibly empty) linear strings
<span class="math inline">\(w_1\)</span> and <span
class="math inline">\(w_2\)</span> and (possibly equal, possibly
inverse) symbols <span class="math inline">\(a\)</span> and <span
class="math inline">\(c\)</span>. Without loss of generality we have
<span class="math inline">\(x = (w_1 \cdot c\bar{c} \cdot w_2)\)</span>
and <span class="math inline">\(y = (w_2 \cdot a\bar{a} \cdot
w_1)\)</span>. In this case, we can take <span class="math inline">\(z =
(w_1 w_2)\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the pairs of symbols deleted by <span
class="math inline">\(w\mapsto x\)</span> and <span
class="math inline">\(w\mapsto y\)</span> overlap, then we can write
<span class="math inline">\(w = (a \bar{a} a \cdot w&#39;)\)</span> for
some (possibly empty) linear string <span
class="math inline">\(w&#39;\)</span> and some symbol <span
class="math inline">\(a\)</span>. In this case we have <span
class="math inline">\(x = y = (a \cdot w&#39;)\)</span>.</li>
</ul>
</dd>
<dd>
<p>It follows that applying <em>only</em> elementary reductions leads to
a unique reduced string; however, equivalence also allows elementary
<em>expansions</em>. Consider two equivalent but distinct cyclic strings
<span class="math inline">\(x\ne y\)</span>, and let <span
class="math inline">\(x = w_1 \leftrightarrow w_2 \leftrightarrow \cdots
\leftrightarrow w_n = y\)</span> be a sequence of strings, each
connected to its success by an elementary reduction in one direction
<span class="math inline">\(w_i \mapsto w_{i+1}\)</span> or the other
<span class="math inline">\(w_{i+1} \mapsto w_i\)</span>.</p>
</dd>
<dd>
<p>Suppose for some index <span class="math inline">\(i\)</span>, we
have reductions <span class="math inline">\(w_i \mapsto w_{i-1}\)</span>
and <span class="math inline">\(w_i \mapsto w_{i+1}\)</span>. If <span
class="math inline">\(w_{i-1} = w_{i+1}\)</span>, then we can remove
<span class="math inline">\(w_{i-1}\)</span> and <span
class="math inline">\(w_i\)</span> to obtain a shorter transformation
sequence. Otherwise, there is another string <span
class="math inline">\(z_i\)</span> such that <span
class="math inline">\(w_{i-1}\mapsto z_i\)</span> and <span
class="math inline">\(w_{i+1} \mapsto z_i\)</span>. Thus, by induction,
we can modify our transformation sequence so that every reduction
appears before every expansion.</p>
</dd>
<dd>
<p>Let <span class="math inline">\(z\)</span> be the shortest string in
this normalized sequence. Both <span class="math inline">\(x\)</span>
and <span class="math inline">\(y\)</span> can be reduced to <span
class="math inline">\(z\)</span> using only elementary reductions.
Because <span class="math inline">\(x\ne y\)</span>, either <span
class="math inline">\(x \ne z\)</span> or <span
class="math inline">\(y\ne z\)</span>; we conclude that at most one of
<span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> is reduced.</p>
</dd>
<dt><strong>Lemma:</strong></dt>
<dd>
Any cyclic crossing sequence of length <span
class="math inline">\(x\)</span> can be cyclically reduced in <span
class="math inline">\(O(x)\)</span> time.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
The following (pseudo-)python code assumes the input <code>X</code> is
an array of non-zero integers, with inverses indicated by negation. The
algorithm runs in two phases. The first phase reduces the
<em>linear</em> sequence <span class="math inline">\(X\)</span> by
repeatedly removes the leftmost matching pair, using the output array as
a stack. The second phase performs any remaining cyclic reductions that
“wrap around” the ends of the array.
</dd>
</dl>
<pre><code>def LeftGreedyReduce(X):
    n = size(X)
    Y = [0] * n                             // reduced sequence = stack
    top = -1                                // top stack index
    // ————— linear reduction —————
    for i in range(n):
        if top &lt; 0 || (X[i] != -Y[top]):    // empty or no match
            top = top + 1
            Y[top] = X[i]                   // push 
        else:
            top = top - 1                   // pop
    // ————— cyclic reduction —————
    bot = 0
    while (bot &lt; top) and (Y[bot] = -Y[top]):
        bot = bot + 1
        top = top - 1
    // ————— done! —————
    return Y[bot:top+1]</code></pre>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
Two polygons are homotopic in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> if and only if
their crossing sequences are equivalent.
</dd>
<dt><strong>Proof (sketch):</strong></dt>
<dd>
A single safe vertex move changes the signed crossing sequence by a
finite number of elementary reductions and their inverses, at most one
per obstacle.
</dd>
<dd>
<p>Conversely, any elementary reduction of the signed crossing sequence
can be modeled by a sequence of safe vertex moves, performed either
directly on the original polygon or (more easily) on the canonical
polygon with the same crossing sequence.</p>
</dd>
</dl>
<p>We finally have all the ingredients of our homotopy-testing
algorithm.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
For any set <span class="math inline">\(O\)</span> of <span
class="math inline">\(k\)</span> points in <span
class="math inline">\(\mathbb{R}^2\)</span>, and any two <span
class="math inline">\(n\)</span>-gons <span
class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span> in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span>, we can determine
whether <span class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span> are homotopic in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> in <span
class="math inline">\(O(k\log k + kn)\)</span> time.
</dd>
<dt><strong>Proof (sketch):</strong></dt>
<dd>
As usual we assume without loss of generality that the obstacles and
polygon vertices all have distinct <span
class="math inline">\(x\)</span>-coordinates. First we sort the
obstacles from left to right in <span class="math inline">\(O(k\log
k)\)</span> time. Then we compute the crossing sequence of <span
class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span>, in constant time per crossing, plus
constant time per vertex. Each crossing sequence has length <span
class="math inline">\(O(nk)\)</span>. Then we cyclically reduce the two
crossing sequences in <span class="math inline">\(O(nk)\)</span> time.
Finally, we check whether the two reduced crossing sequences are equal
(as <em>cyclic</em> strings) in linear time using Knuth-Morris-Pratt (or
any other fast string-matching algorithm).
</dd>
</dl>
<p>Let me emphasize here that the algorithm does not construct an
explicit homotopy between the two polygons.</p>
<h2 data-number="3.4" id="varations"><span
class="header-section-number">3.4</span> Varations</h2>
<p><strong>To be written</strong></p>
<ul>
<li><p>Polygons with holes: Replace each hole with a sentinel
point.</p></li>
<li><p>Paths:</p>
<ul>
<li>Paths, concatenation, reversal, loops, path homotopy</li>
<li>Two paths <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\sigma\)</span> are homotopic if and only if the
loop <span class="math inline">\(\pi\cdot\bar\sigma\)</span> is
contractible.</li>
<li>Two polygonal paths <span class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span> are homotopic if and only if they have
the same (<strong>not</strong> cyclically) reduced crossing
sequence.</li>
</ul></li>
</ul>
<h2 data-number="3.5"
id="and-the-aptly-named-sir-not-appearing-in-this-film-2"><span
class="header-section-number">3.5</span> …and the Aptly Named Sir Not
Appearing in This Film</h2>
<ul>
<li>alternative fences: vertical lines, spanning tree + ray</li>
<li>picture hanging puzzles</li>
</ul>
<h1 data-number="4" id="faster-homotopy-testingbeta"><span
class="header-section-number">4</span> Faster Homotopy Testing<span
class="math inline">\(^\beta\)</span></h1>
<p>In the previous lecture, we saw an algorithm to decide if one polygon
is contractible, or if two polygons are homotopic, in the plane with
several points removed. The algorithm runs in <span
class="math inline">\(O(k\log k + nk)\)</span> time, where <span
class="math inline">\(k\)</span> is the number of obstacle points; in
the worst case, this running time is quadratic in the input size.</p>
<p>A running time of <span class="math inline">\(\Omega(nk)\)</span> is
inevitable if we are required to compute an explicit reduced crossing
sequence; consider the polygon and obstacles below. But if a polygon is
<em>contractible</em>—homotopic to a single point—its reduced crossing
sequence is empty. Similarly the (non-reduced) crossing sequence of a
polygon can have length <span class="math inline">\(\Omega(nk)\)</span>,
even if the polygon is contractible, but nothing requires us to compute
explicit crossing sequences!</p>
<figure>
<img src="Fig/long-crossing-sequence.png" style="width:30.0%"
alt="A polygon and obstacles with a long reduced crossing sequence" />
<figcaption aria-hidden="true">A polygon and obstacles with a long
reduced crossing sequence</figcaption>
</figure>
<p>In this lecture, I’ll describe another algorithm to test
contractibility of polygons in punctured planes, which is faster either
when the polygon has few self-intersections or when the number of
obstacles is significantly larger than the number of polygon vertices.
This algorithm is based on an algorithm of Cabello et al. [1], with some
improvements by Efrat et al. [2]. Variations of this algorithm compute
reduced crossing sequences <em>without</em> explicitly computing
non-reduced crossing sequences first.</p>
<p>The key observation is that we are free to modify <em>both</em> the
polygon <em>and</em> the obstacles, as long as our modifications do not
change the reduced crossing sequence. In short, we are solving a
<em>topology</em> problem, so we should feel free to choose whatever
<em>geometry</em> is most convenient for our purposes.</p>
<p>To make the following discussion concrete, let <span
class="math inline">\(O\)</span> be an arbitrary set <span
class="math inline">\(k\)</span> of obstacle points in the plane, and
let <span class="math inline">\(P\)</span> be an arbitrary <span
class="math inline">\(n\)</span>-vertex polygon in <span
class="math inline">\(\mathbb{R}^2 \setminus O\)</span>. As usual, we
assume these objects are in <em>general position</em>: no two
interesting points (obstacles, polygon vertices, or self-intersection
points) lie on a common vertical line, and no three polygon vertices lie
on a common line. In particular, no edge of <span
class="math inline">\(P\)</span> is vertical, and every point where
<span class="math inline">\(P\)</span> self-intersects is a transverse
intersection between two edges. This assumption can be enforced with
probability <span class="math inline">\(1\)</span> by randomly rotating
the coordinate system and randomly perturbing the vertices.</p>
<h2 data-number="4.1" id="trapezoidal-decomposition"><span
class="header-section-number">4.1</span> Trapezoidal decomposition</h2>
<p>This first stage of our algorithm, like our earlier polygon
triangulation algorithm, first constructs a <em>trapezoidal
decomposition</em> of the input. We define the decomposition by
extending vertical segments, which we call <em>fences</em>, upward and
downward from each obstacle, from each vertex of <span
class="math inline">\(P\)</span>, and from each self-intersection point
of <span class="math inline">\(P\)</span>, until they hit edges of <span
class="math inline">\(P\)</span> (or escape to infinity). These fences,
together with the edges of <span class="math inline">\(P\)</span>,
decompose the plane into trapezoids, some of which are unbounded and
others degenerate. See Figure 2.</p>
<figure>
<img src="Fig/trap-decomp.png" style="width:40.0%"
alt="A trapezoidal decomposition of a self-intersecting polygon and four obstacles" />
<figcaption aria-hidden="true">A trapezoidal decomposition of a
self-intersecting polygon and four obstacles</figcaption>
</figure>
<p>A classical sweepline algorithm of Bentley and Ottmann constructs
this decomposition in <span class="math inline">\(O((n + k + s)\log
(n+k))\)</span> time, where <span class="math inline">\(s\)</span> is
the number of self-intersection points. (There are several faster
algorithms, especially when the number of self-intersections is small,
but the Bentley-Ottmann algorithm is much simpler to describe and
implement, and using these faster alternatives would not significantly
improve the overall running time of our contractibility algorithm.)</p>
<p>Think of the <span class="math inline">\(n\)</span> polygon edges and
<span class="math inline">\(k\)</span> obstacle points as <span
class="math inline">\(n+k\)</span> line segments (<span
class="math inline">\(k\)</span> of which have length zero). Any
vertical line intersects t most <span class="math inline">\(n+1\)</span>
of these segments. The Bentley-Ottman algorithm sweeps a vertical line
<span class="math inline">\(\ell\)</span> across the plane, maintaining
the sorted sequence of segments intersecting <span
class="math inline">\(\ell\)</span> in a balanced binary search tree, so
that segments can be inserted or deleted in <span
class="math inline">\(O(\log n)\)</span> time. The <span
class="math inline">\(x\)</span>-coordinates where this intersection
sequence changes are called <em>events</em>; there are two types of
events:</p>
<ul>
<li><em>vertex</em> events, where <span
class="math inline">\(\ell\)</span> passes through a vertex of <span
class="math inline">\(P\)</span> or a point in <span
class="math inline">\(O\)</span>, and</li>
<li><em>intersection</em> events, where <span
class="math inline">\(\ell\)</span> passes through a self-intersection
point of <span class="math inline">\(P\)</span>.</li>
</ul>
<p>The algorithm processes these events in order from left to right.</p>
<p>The vertices and obstacles are all known in advance, so after an
initial <span class="math inline">\(O((n+k)\log(n+k))\)</span> sorting
phase, it is easy to find the next vertex event. Intersections are
<em>not</em> known in advance, and computing them by brute force in
<span class="math inline">\(O(n^2)\)</span> time would take too long.
Instead, we observe that the <em>next</em> intersection event must occur
at the intersection of two consecutive segments along <span
class="math inline">\(\ell\)</span>. Thus, for each consecutive pair of
segments that intersects to the right of <span
class="math inline">\(\ell\)</span>, we have a <em>potential</em>
intersection event. We maintain these <span
class="math inline">\(O(n)\)</span> potential intersection events in a
priority queue, so that we can find the next <em>actual</em>
intersection event in <span class="math inline">\(O(\log n)\)</span>
time.</p>
<p>At each event, we insert a single fence, perform <span
class="math inline">\(O(1)\)</span> binary-tree operations to maintain
the intersection sequence with <span
class="math inline">\(\ell\)</span>, and then perform <span
class="math inline">\(O(1)\)</span> priority-queue operations. There are
<span class="math inline">\(O(n + k + s)\)</span> events, each requiring
<span class="math inline">\(O(\log n)\)</span> time, so including the
initial sort, the overall running time is <span
class="math inline">\(O((n + k + s)\log (n + k))\)</span>.</p>
<p>As a by-product of the sweep-line algorithm, we obtain the complete
list of self-intersection points. We subdivide <span
class="math inline">\(P\)</span> by introducing two coincident vertices
at each self-intersection point, increasing the number of vertices from
<span class="math inline">\(n\)</span> to <span
class="math inline">\(n+2s\)</span>, and ensuring that the edges of
<span class="math inline">\(P\)</span> intersect only at vertices.</p>
<h2 data-number="4.2" id="vertical-and-horizontal-ranks"><span
class="header-section-number">4.2</span> Vertical and horizontal
ranks</h2>
<p>Next, we replace <span class="math inline">\(P\)</span> and <span
class="math inline">\(O\)</span> with a new <em>orthogonal</em> polygon
<span class="math inline">\(\bar{P}\)</span> and a new set of obstacles
<span class="math inline">\(\bar{O}\)</span> that define exactly the
same crossing sequence. At a high level, we replace each edge of <span
class="math inline">\(P\)</span> with a horizontal line segment and each
vertex of <span class="math inline">\(P\)</span> with a vertical line
segment.</p>
<p>The <span class="math inline">\(y\)</span>-coordinates of the
horizontal segments are determined by the following <em>vertical
ranking</em> of the polygon edges and obstacle points. Let <span
class="math inline">\(S\)</span> be the set of <span
class="math inline">\(m = n+2s+k\)</span> interior-disjoint segments,
consisting of the subdivided edges of <span
class="math inline">\(P\)</span> and the obstacles <span
class="math inline">\(O\)</span>. For any two segments <span
class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span> in <span
class="math inline">\(S\)</span>, write <span
class="math inline">\(\sigma\Uparrow\tau\)</span> (and say “sigma is
above tau”) if there is a vertical segment with positive length whose
upper endpoint lies on <span class="math inline">\(\sigma\)</span> and
whose lower endpoint lies on <span
class="math inline">\(\tau\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
For <strong>any</strong> set <span class="math inline">\(S\)</span> of
interior-disjoint non-vertical line segments, the <span
class="math inline">\(\Uparrow\)</span> relation is acyclic.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
For the sake of argument, let <span class="math inline">\(\sigma_1
\Uparrow \sigma_2 \Uparrow \cdots \Uparrow \sigma_r \Uparrow
\sigma_1\)</span> be a minimum-length cycle of segments in <span
class="math inline">\(S\)</span>. Obviously <span
class="math inline">\(r \ge 2\)</span>, because no segment is above
itself. Similarly, <span class="math inline">\(r \ge 3\)</span>, because
<span class="math inline">\(\sigma_1 \Uparrow \sigma_2\)</span> and
<span class="math inline">\(\sigma_2 \Uparrow \sigma_1\)</span> would
imply that <span class="math inline">\(\sigma_1\)</span> and <span
class="math inline">\(\sigma_2\)</span> have intersecting interiors.
</dd>
<dd>
<p>Rotate the indices if necessary, so that the right endpoint of <span
class="math inline">\(\sigma_1\)</span> has strictly smaller <span
class="math inline">\(x\)</span>-coordinate than the right endpoint of
any other segment <span class="math inline">\(\sigma_i\)</span> in the
cycle. In particular, the right endpoints of <span
class="math inline">\(\sigma_2\)</span> and <span
class="math inline">\(\sigma_r\)</span> are both strictly to the right
of <span class="math inline">\(\sigma_1\)</span>. Thus, the right
endpoint of <span class="math inline">\(\sigma_1\)</span> is both
directly above some point of <span
class="math inline">\(\sigma_2\)</span> and directly below some point of
<span class="math inline">\(\sigma_r\)</span>. It follows that <span
class="math inline">\(\sigma_r \Uparrow \sigma_2\)</span>, which
contradicts the minimality of the cycle.</p>
</dd>
</dl>
<p>Now write <span class="math inline">\(\sigma\uparrow \tau\)</span>
(and say “sigma is <em>immediately</em> above tau”) of some fence in the
trapezoidal decomposition of <span class="math inline">\(S\)</span>
touches both <span class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span>, and in particular touches <span
class="math inline">\(\sigma\)</span> above the point where it touches
<span class="math inline">\(\tau\)</span>. Because <span
class="math inline">\(\sigma\uparrow \tau\)</span> immediately implies
<span class="math inline">\(\sigma\Uparrow \tau\)</span>, the relation
<span class="math inline">\(\uparrow\)</span> is also acyclic; in fact,
our earlier relation <span class="math inline">\(\Uparrow\)</span> is
the transitive closure of <span class="math inline">\(\uparrow\)</span>.
We can easily extract a directed acyclic graph <span
class="math inline">\(G^\uparrow\)</span> representing the relation
<span class="math inline">\(\uparrow\)</span> (and thus its transitive
closure <span class="math inline">\(\Uparrow\)</span>) directly from the
trapezoidal decomposition of <span class="math inline">\(S\)</span>.</p>
<p>(Any linear extension of <span
class="math inline">\(\Uparrow\)</span> is called a of <span
class="math inline">\(D\)</span>; the previous lemma implies that such
an order always exists.)</p>
<p>Now index the segments <span class="math inline">\(S = \{\sigma_1,
\sigma_2, \dots, \sigma_m \}\)</span> according to an arbitrary
topological ordering of the graph <span
class="math inline">\(G^\uparrow\)</span>, so that <span
class="math inline">\(\sigma_i \Uparrow \sigma_j\)</span> implies <span
class="math inline">\(i &lt; j\)</span>. For any segment <span
class="math inline">\(\sigma_i\)</span>, let <span
class="math inline">\(\textsf{obsbelow}(\sigma_i)\)</span> denote the
number of <em>obstacle</em> segments <span
class="math inline">\(\sigma_j\)</span> such that <span
class="math inline">\(j &lt; i\)</span>. Finally, we define the
<em>vertical rank</em> <span
class="math inline">\(\textsf{vrank}(\sigma_i)\)</span> as follows:</p>
<ul>
<li>If <span class="math inline">\(\sigma_i\)</span> is a polygon
segment, then <span class="math inline">\(\textsf{vrank}(\sigma_i) =
2\cdot \textsf{obsbelow}(\sigma_i)\)</span>.</li>
<li>If <span class="math inline">\(\sigma_i\)</span> is an obstacle
segment, then <span class="math inline">\(\textsf{vrank}(\sigma_i) =
2\cdot \textsf{obsbelow}(\sigma_i) + 1\)</span>.</li>
</ul>
<p>Thus, all vertical ranks are integers between <span
class="math inline">\(0\)</span> and <span
class="math inline">\(2k\)</span>, every obstacle has odd vertical rank,
and every polygon edge has even vertical rank.</p>
<p>We also define the <em>horizontal rank</em> of any polygon vertex or
an obstacle point <span class="math inline">\(p\)</span> as follows. Let
<span class="math inline">\(\textsf{obsleft}(p)\)</span> to be the
number of obstacles with strictly smaller <span
class="math inline">\(x\)</span>-coordinates than <span
class="math inline">\(p\)</span>.</p>
<ul>
<li>If <span class="math inline">\(p\)</span> is a polygon vertex, then
<span class="math inline">\(\textsf{hrank}(p) = 2\cdot
\textsf{obsleft}(p)\)</span>.</li>
<li>If <span class="math inline">\(p\)</span> is an obstacle point, then
<span class="math inline">\(\textsf{hrank}(p) = 2\cdot
\textsf{obsleft}(p) + 1\)</span>.</li>
</ul>
<p>Thus, all horizontal ranks are integers between <span
class="math inline">\(0\)</span> and <span
class="math inline">\(2k\)</span>, every obstacle has odd horizontal
rank, and every polygon vertex has even horizontal rank.</p>
<h2 data-number="4.3" id="rectification"><span
class="header-section-number">4.3</span> Rectification</h2>
<p>Now we define a <em>rectified</em> polygon <span
class="math inline">\(\bar{P}\)</span> and new obstacles <span
class="math inline">\(\bar{O}\)</span> as follows:</p>
<ul>
<li><p>Replace each edge <span class="math inline">\(pq\)</span> of
<span class="math inline">\(P\)</span> with a horizontal segment between
<span class="math inline">\((\textsf{hrank}(p),
\textsf{vrank}(pq))\)</span> and <span
class="math inline">\((\textsf{hrank}(q), \textsf{vrank}(pq))\)</span>.
Similarly, replace each vertex <span class="math inline">\(q\)</span> of
<span class="math inline">\(P\)</span>, with adjacent edges <span
class="math inline">\(pq\)</span> and <span
class="math inline">\(qr\)</span>, with a vertical segment between <span
class="math inline">\((\textsf{hrank}(q), \textsf{vrank}(pq))\)</span>
and <span class="math inline">\((\textsf{hrank}(q),
\textsf{vrank}(qr))\)</span>. Connecting these horizontal and vertical
segments in sequence around <span class="math inline">\(P\)</span> gives
us an orthogonal polygon <span
class="math inline">\(\bar{P}\)</span>.</p></li>
<li><p>For each obstacle <span class="math inline">\(o\)</span>, let
<span class="math inline">\(\bar{o} = (\textsf{hrank}(o),
\textsf{vrank}(o))\)</span>. The set of all such points is our new
obstacle set <span class="math inline">\(\bar{O}\)</span>.</p></li>
</ul>
<p>By construction, every vertex of <span
class="math inline">\(\bar{P}\)</span> has even integer coordinates, and
every obstacle in <span class="math inline">\(\bar{O}\)</span> has odd
integer coordinates, so <span class="math inline">\(\bar{P}\)</span> is
a polygon in <span class="math inline">\(\mathbb{R}^2\setminus
\bar{O}\)</span>. Moreover, the crossing sequence of the rectified
polygon <span class="math inline">\(\bar{P}\)</span> with respect to the
new obstacles <span class="math inline">\(\bar{O}\)</span> is
<em>identical</em> to the crossing sequence of the original polygon
<span class="math inline">\(P\)</span> with respect to the original
obstacles <span class="math inline">\(O\)</span>. Thus, <span
class="math inline">\(P\)</span> is contractible in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span> if and only if
<span class="math inline">\(\bar{P}\)</span> is contractible in <span
class="math inline">\(\mathbb{R}^2\setminus \bar{O}\)</span>.</p>
<figure>
<img src="Fig/same-crossing-sequence.png" style="width:75.0%"
alt="A polygon and its rectification (perturbed to show overlapping and zero-length edges) defining the same (trivial) crossing sequence abdDCBAabcdAaDBA" />
<figcaption aria-hidden="true">A polygon and its rectification
(perturbed to show overlapping and zero-length edges) defining the same
(trivial) crossing sequence <code>abdDCBAabcdAaDBA</code></figcaption>
</figure>
<p>It is actually possible to construct an explicit deformation of <span
class="math inline">\(P\)</span> and <span
class="math inline">\(O\)</span> into <span
class="math inline">\(\bar{P}\)</span> and <span
class="math inline">\(\bar{O}\)</span>, as a sequence of elementary
moves of two types: safe vertex moves (translate a vertex of <span
class="math inline">\(P\)</span> without touching any obstacle) and
“safe obstacle moves” (translate one obstacle in <span
class="math inline">\(O\)</span> without touching <span
class="math inline">\(P\)</span>). Moreover, we can guarantee that
throughout the entire deformation, the crossing sequence of the polygon
with respect to the obstacles remains unchanged. Fortunately, we don’t
actually need an explicit homotopy; the invariance of the crossing
sequence is enough.</p>
<h2 data-number="4.4" id="reduction"><span
class="header-section-number">4.4</span> Reduction</h2>
<p>So why did we go through this madness? We have now reduced our
problem from <em>arbitrary</em> polygons to particularly well-behaved
<em>orthogonal</em> polygons. Restricting to orthogonal polygons allows
us to represent and manipulate the crossing sequence of <span
class="math inline">\(\bar{P}\)</span> <em>implicitly</em> using
relatively simple data structures.</p>
<p>Let <span class="math inline">\(\bar{n} = 2n+4s\)</span> denote the
number of vertices in the rectified polygon <span
class="math inline">\(\bar{P}\)</span>. Without loss of generality, we
can assume that the <span class="math inline">\(i\)</span>th edge <span
class="math inline">\(\bar{p}_i \bar{p}_{i+1}\)</span> of <span
class="math inline">\(\bar{P}\)</span> is horizontal if <span
class="math inline">\(i\)</span> is even and vertical if <span
class="math inline">\(i\)</span> is odd. Thus, we can represent <span
class="math inline">\(\bar{P}\)</span> itself using an alternating
sequence of <span class="math inline">\(x\)</span>- and <span
class="math inline">\(y\)</span>-coordinates: <span
class="math display">\[
    x_0, y_1, x_2, y_3, \dots, x_{\bar{n}-2}, y_{\bar{n}-1},
\]</span> where <span class="math inline">\(\bar{p}_i = (x_i,
y_{i+1})\)</span> if <span class="math inline">\(i\)</span> is even, and
<span class="math inline">\(\bar{p}_i = (x_{i+1}, y_i)\)</span> if <span
class="math inline">\(i\)</span> is odd. We store these coordinates in
any data structure that allows us to change one coordinate or remove any
adjacent pair of coordinates <span class="math inline">\(x_i, y_{i\pm
1}\)</span> in <span class="math inline">\(O(1)\)</span> time—for
example, a circular doubly-linked list.</p>
<p>We now <em>reduce</em> <span class="math inline">\(\bar{P}\)</span>
by repeatedly applying two operations, called <em>eliding</em> and
<em>sliding</em>, which simplify the polygon without changing its
homotopy class. Each operation requires <span
class="math inline">\(O(\log k)\)</span> time, and the reduction
requires at most <span class="math inline">\(O(\bar{n})\)</span> of
these operations, so the overall reduction time is is <span
class="math inline">\(O(\bar{n}\log k) = O((n+s)\log k)\)</span>. If the
reduced polygon is <em>empty</em>, we correctly report that <span
class="math inline">\(P\)</span> is contractible; otherwise, we
correctly report that <span class="math inline">\(P\)</span> is not
contractible.</p>
<h3 data-number="4.4.1" id="eliding-zero-length-edges"><span
class="header-section-number">4.4.1</span> Eliding Zero-Length
Edges</h3>
<p><strong><em>This makes the pictures nicer, but it isn’t actually
necessary; consider removing.</em></strong></p>
<p>The rectified polygon <span class="math inline">\(\bar{P}\)</span>
can contain edges with length zero; we <em>elide</em> (that is, remove)
all such edges in a preprocessing phase. <em>Geometrically,</em> there
are two types of zero-length edges:</p>
<ul>
<li>A <em>bump</em> is a zero-length edge whose previous and next edges
have the same orientation. Removing a bump merges the previous and next
edges into a single edge.</li>
<li>A <em>spur</em> is a zero-length edge whose previous and next edges
do overlap. Removing a spur replaces those two edges with their
<em>difference</em>, which could have length zero, making more elisions
possible.</li>
</ul>
<p>However, our representation of <span
class="math inline">\(\bar{P}\)</span> as a list of alternating <span
class="math inline">\(x\)</span>- and <span
class="math inline">\(y\)</span>-coordinates allows us to treat these
two cases identically in <span class="math inline">\(O(1)\)</span> time.
To remove the zero-length edge edge <span
class="math inline">\(\bar{p}_{i-1}\bar{p}_i\)</span>, we delete the
<span class="math inline">\((i-1)\)</span>th and <span
class="math inline">\(i\)</span>th coordinates from our coordinate list.
Specifically:</p>
<ul>
<li>if <span class="math inline">\(i\)</span> is odd, so <span
class="math inline">\(y_{i-1} = y_{i+1}\)</span> and the zero-length
edge is “horizontal”, we delete <span
class="math inline">\(y_{i-1}\)</span> and <span
class="math inline">\(x_i\)</span>.</li>
<li>If <span class="math inline">\(i\)</span> is even, so <span
class="math inline">\(x_{i-1} = x_{i+1}\)</span> and the zero-length
edge is “vertical”, we delete <span
class="math inline">\(x_{i-1}\)</span> and <span
class="math inline">\(y_i\)</span>.</li>
</ul>
<p>Equivalently, we can remove any zero-length edge <span
class="math inline">\(\bar{p}_{i-1}\bar{p}_i\)</span> using two safe
vertex moves:</p>
<ul>
<li>First (formally) move <span
class="math inline">\(\bar{p}_{i-1}\)</span> to <span
class="math inline">\(\bar{p}_i\)</span>, merging those two
vertices.</li>
<li>Then move <span class="math inline">\(\bar{p}_i\)</span> either
<span class="math inline">\(\bar{p}_{i-2}\)</span> and <span
class="math inline">\(\bar{p}_{i+1}\)</span>, whichever is closer. It
follows that removing a zero-length edge does not change the homotopy
class of <span class="math inline">\(\bar{P}\)</span>.</li>
</ul>
<p>We can remove all zero-length edges from <span
class="math inline">\(\bar{P}\)</span> in <span
class="math inline">\(O(\bar{n})\)</span> time using a “left-greedy”
algorithm similar to the crossing-word reduction algorithm in the
previous lecture.</p>
<figure>
<img src="Fig/rectified-elided.png" style="width:70.0%"
alt="Eliding all zero-length edges in the rectified polygon" />
<figcaption aria-hidden="true">Eliding all zero-length edges in the
rectified polygon</figcaption>
</figure>
<h3 data-number="4.4.2" id="sliding-brackets"><span
class="header-section-number">4.4.2</span> Sliding Brackets</h3>
<p>We call a positive-length edge of <span
class="math inline">\(\bar{P}\)</span> a <em>bracket</em> if both of its
neighboring edges are on the same side of the line through the edge.
That is, the edge and its neighbors look like <span
class="math inline">\(\sqcup\)</span>, <span
class="math inline">\(\sqsubset\)</span>, <span
class="math inline">\(\sqcap\)</span>, or <span
class="math inline">\(\sqsupset\)</span>. <em>Sliding</em> a bracket
moves it as far inward as possible, shortening the neighboring edges,
until at least one of two conditions is met:</p>
<ul>
<li><p>The bracket has distance <span class="math inline">\(1\)</span>
from an obstacle inside the bracket; we call such a bracket
<em>frozen</em>. Sliding a frozen bracket further would change the
crossing sequence of <span class="math inline">\(\bar{P}\)</span> by
either adding or deleting a <em>single</em> crossing, thereby changing
the homotopy class.</p></li>
<li><p>At least one of the edges adjacent to the bracket has length
zero, which we can safely elide, just as in the previous phase. (If the
zero-length edge is a spur, several elisions may be required to ensure
that all edges have positive length.)</p></li>
</ul>
<p>Sliding a bracket requires changing exactly one coordinate in our
alternating coordinate list, and then deleting zero or more pairs of
coordinates (to elide zero-length edges created by the slide).</p>
<p>The reduction algorithm ends either when all remaining brackets are
frozen (and all edges have positive length), or when no edges are left
at all. For example, if <span class="math inline">\(\bar{P}\)</span> is
a rectangle that doesn’t not contain any obstacles, the first bracket
slide creates two zero-length edges; eliding these edges removes
<em>every</em> edge from the polygon.</p>
<p>Because each bracket slide (and ensuing elisions) either freezes a
bracket or decreases the number of polygon vertices, the reduction ends
after at most after <span class="math inline">\(O(\bar{n})\)</span>
bracket slides. (A bracket slide can <em>increase</em> the number of
polygon <em>self-intersections</em>, but we don’t care about that; we
only needed to find self-intersections so that we could compute vertical
ranks.) The figure on the next page shows a sequence of bracket slides
contracting a rectified cycle.</p>
<figure>
<img src="Fig/bracket-slide-sequence.png" style="width:95.0%"
alt="A sequence of bracket slides (and spur elisions). Heavy blue edges are frozen." />
<figcaption aria-hidden="true">A sequence of bracket slides (and spur
elisions). Heavy blue edges are frozen.</figcaption>
</figure>
<p>The correctness of this algorithm rests on the following lemma.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
The rectified polygon <span class="math inline">\(\bar{P}\)</span> is
contractible in <span class="math inline">\(\mathbb{R}^2\setminus
\bar{O}\)</span> if and only if it reduces to a single point.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
One direction is easy: Every sequence of elisions and bracket slides is
a homotopy. Thus, if <span class="math inline">\(\bar{P}\)</span>
reduced to a single point, it must be contractible.
</dd>
<dd>
<p>The other direction is more interesting. We actually need to reason
about the crossing sequence defined by both upward <em>and downward</em>
rays from each obstacle. Suppose <span
class="math inline">\(\bar{P}\)</span> is contractible. Then our earlier
arguments imply that the mixed crossing sequence of <span
class="math inline">\(\bar{P}\)</span> can be reduced to the empty
string, suing exactly the same algorithm as usual. There are two cases
to consider.</p>
</dd>
<dd>
<p>First suppose both mixed crossing sequences of <span
class="math inline">\(\bar{P}\)</span> is actually empty. Then <span
class="math inline">\(\bar{P}\)</span> does not cross the vertical line
through any obstacle. It follows that every vertex of <span
class="math inline">\(\bar{P}\)</span> has the same even <span
class="math inline">\(x\)</span>-coordinate, and thus every “horizontal”
edge of <span class="math inline">\(\bar{P}\)</span> has length zero. It
follows by induction that <span class="math inline">\(\bar{P}\)</span>
can be reduced to a single point by eliding every horizontal edge.</p>
</dd>
<dd>
<p>Otherwise, because <span class="math inline">\(\bar{P}\)</span> is
contractible, its mixed crossing sequence contains an elementary
reduction. So there must be a subpath of <span
class="math inline">\(\bar{P}\)</span> that crosses the same obstacle
ray twice in a row, without crossing the vertical line through any
obstacle in between. (These two crossings would be canceled by an
elementary reduction.) Without loss of generality, suppose this subpath
crosses some upward obstacle ray from right to left, and then crosses
that same ray from left to tight. Then the leftmost vertical edge of
that subpath forms a bracket, and sliding that bracket reduces the
complexity of either the polygon or its crossing sequence. It follows by
induction that <span class="math inline">\(\bar{P}\)</span> can be
reduced to a polygon with an empty crossing sequence, and thus to a
single point.</p>
</dd>
</dl>
<p>A close reading of this proof reveals that we only ever need to
perform <em>horizontal</em> bracket slides; even eliding zero-length
edges is unnecessary.</p>
<h2 data-number="4.5" id="layered-range-trees"><span
class="header-section-number">4.5</span> Layered Range Trees</h2>
<p>To implement bracket slides efficiently, we preprocess the rectified
obstacles <span class="math inline">\(\bar{O}\)</span> that supports
fast queries of the following form: Given a horizontal query segment
<span class="math inline">\(\sigma\)</span>, report the lowest obstacle
(if any) that lies directly above <span
class="math inline">\(\sigma\)</span>. Symmetric data structures can
report the highest sentinel point below a horizontal segment, or the
closest sentinel points to the left and right of a vertical segment.</p>
<p><strong>Lemma:</strong> Any set <span
class="math inline">\(\bar{O}\)</span> of <span
class="math inline">\(k\)</span> points in the plane can be preprocessed
in <span class="math inline">\(O(k\log k)\)</span> time into a data
structure of size <span class="math inline">\(O(k\log k)\)</span>, so
that the lowest point (if any) above an arbitrary horizontal query
segment can be computed in <span class="math inline">\(O(\log
k)\)</span> time.</p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
We use a data structure called a <em>layered range tree</em>, first
described by Willard [3]. The layered range tree of <span
class="math inline">\(\bar{O}\)</span> consists of a balanced binary
search tree <span class="math inline">\(T\)</span> over the <span
class="math inline">\(x\)</span>-coordinates of <span
class="math inline">\(\bar{O}\)</span>, with additional information
stored at each node. To simplify queries, the (odd) <span
class="math inline">\(x\)</span>-coordinates of <span
class="math inline">\(\bar{O}\)</span> are stored only at the leaves of
<span class="math inline">\(T\)</span>; the search keys for internal
nodes are intermediate (even) <span
class="math inline">\(x\)</span>-coordinates.
</dd>
<dd>
<p>For each node <span class="math inline">\(v\)</span> of <span
class="math inline">\(T\)</span>, let <span
class="math inline">\(l_v\)</span> and <span
class="math inline">\(r_v\)</span> denote the smallest and largest <span
class="math inline">\(x\)</span>-coordinates in stored in the subtree
rooted at <span class="math inline">\(v\)</span>, and let <span
class="math inline">\(\bar{O}_v\)</span> denote the subset of obstacle
points with <span class="math inline">\(x\)</span>-coordinates between
<span class="math inline">\(l_v\)</span> and <span
class="math inline">\(r_v\)</span>. Each node <span
class="math inline">\(v\)</span> in <span
class="math inline">\(T\)</span> stores the following information, in
addition to the search key <span class="math inline">\(x_v\)</span>.</p>
</dd>
<dd>
<ul>
<li>The <span class="math inline">\(x\)</span>-coordinates <span
class="math inline">\(l_v\)</span> and <span
class="math inline">\(r_v\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>The points <span class="math inline">\(\bar{O}_v\)</span>, sorted by
<span class="math inline">\(y\)</span>-coordinate.</li>
</ul>
</dd>
<dd>
<ul>
<li>For each point <span class="math inline">\(\bar{O}_v\)</span>, the
number of points in <span
class="math inline">\(\bar{O}_{\textsf{left}(v)}\)</span> with larger
<span class="math inline">\(y\)</span>-coordinate.</li>
</ul>
</dd>
<dd>
<ul>
<li>For each point <span class="math inline">\(\bar{O}_v\)</span>, the
number of points in <span
class="math inline">\(\bar{O}_{\textsf{right}(v)}\)</span> with larger
<span class="math inline">\(y\)</span>-coordinate.</li>
</ul>
</dd>
<dd>
<p>It is possible to construct a layered range tree for <span
class="math inline">\(\bar{O}\)</span> in <span
class="math inline">\(O(k\log k)\)</span> time; the total size of the
data structure is also <span class="math inline">\(O(k\log
k)\)</span>.</p>
</dd>
<dd>
<figure>
<img src="Fig/layered-range-tree.png" style="width:95.0%"
alt="A layered range tree for 15 points (with some internal structure omitted)." />
<figcaption aria-hidden="true">A layered range tree for 15 points (with
some internal structure omitted).</figcaption>
</figure>
</dd>
<dd>
<p>Now consider a query segment <span
class="math inline">\(\sigma\)</span> with endpoints <span
class="math inline">\((l,b)\)</span> and <span
class="math inline">\((r,b)\)</span> with <span
class="math inline">\(l&lt;r\)</span>. We call a node <span
class="math inline">\(v\)</span> <em>active</em> for this segment if
<span class="math inline">\(l_v\le l\)</span> and <span
class="math inline">\(r\le r_v\)</span>, but the parent of <span
class="math inline">\(v\)</span> is not active. There are at most two
active nodes at each level of the tree, so there are <span
class="math inline">\(O(\log k)\)</span> active nodes altogether. We can
easily find these active nodes in <span class="math inline">\(O(\log
h)\)</span> time by searching down from the root.</p>
</dd>
<dd>
<p>For any node <span class="math inline">\(v\)</span>, let <span
class="math inline">\(\textsf{lowest}(v,b)\)</span> denote the index of
the lowest point in <span class="math inline">\(\bar{O}_v\)</span> that
lies above the line <span class="math inline">\(y=b\)</span>, or <span
class="math inline">\(0\)</span> if there is no such point. We can
compute <span
class="math inline">\(\textsf{lowest}(\textsf{root}(T),b)\)</span> in
<span class="math inline">\(O(\log h)\)</span> time by binary search;
for any other node <span class="math inline">\(v\)</span>, we can
compute <span class="math inline">\(\textsf{lowest}(v,b)\)</span> in
<span class="math inline">\(O(1)\)</span> time from <span
class="math inline">\(\textsf{lowest}(\textsf{parent}(v), b)\)</span>
and the left or right ranks stored at <span
class="math inline">\(\textsf{parent}(v)\)</span>. Thus, we can compute
<span class="math inline">\(\textsf{lowest}(v,b)\)</span> for every
active node <span class="math inline">\(v\)</span> in <span
class="math inline">\(O(\log h)\)</span> time. The answer to our query
is the lowest of these <span class="math inline">\(O(\log h)\)</span>
points.</p>
</dd>
<dd>
<figure>
<img src="Fig/layered-range-tree-query.png" style="width:95.0%"
alt="Answering a query in a layered range tree (with some details omitted." />
<figcaption aria-hidden="true">Answering a query in a layered range tree
(with some details omitted.</figcaption>
</figure>
</dd>
</dl>
<h2 data-number="4.6" id="final-analysis"><span
class="header-section-number">4.6</span> Final Analysis</h2>
<p>Now let’s put all the ingredients of the algorithm together. Recall
that the original input is a set <span class="math inline">\(O\)</span>
containing <span class="math inline">\(k\)</span> sentinel points, and a
polygon <span class="math inline">\(P\)</span> in <span
class="math inline">\(\mathbb{R}^2\setminus O\)</span>.</p>
<ul>
<li><p>First we sort the obstacles in <span
class="math inline">\(O\)</span> from left to right in <span
class="math inline">\(O(k\log k)\)</span> time.</p></li>
<li><p>Next we compute the trapezoidal decomposition of <span
class="math inline">\(P\)</span> and <span
class="math inline">\(O\)</span> using the Bentley-Ottmann sweepline
algorithm in <span class="math inline">\(O((n+k+s)\log (n+k))\)</span>
time, where <span class="math inline">\(s\)</span> is the number of
self-intersection points of <span class="math inline">\(P\)</span>. We
subdivide the edges of <span class="math inline">\(P\)</span> at its
self-intersection points, increasing the number of vertices of <span
class="math inline">\(P\)</span> to <span class="math inline">\(m = n +
2s\)</span>.</p></li>
<li><p>Then we compute the vertical ranks of the obstacles and the edges
of <span class="math inline">\(P\)</span> in <span
class="math inline">\(O(m+k) = O(n+k+s)\)</span> time. We also compute
the horizontal ranks of the obstacles and the vertices of <span
class="math inline">\(P\)</span> in <span class="math inline">\(O(m \log
m + k)\)</span> time, by sorting the vertices of <span
class="math inline">\(P\)</span> and merging them with the sorted list
of obstacles.</p></li>
<li><p>Next we compute the rectified polygon <span
class="math inline">\(\bar{P}\)</span> and obstacles <span
class="math inline">\(\bar{O}\)</span> in <span
class="math inline">\(O(m + k)\)</span> time.</p></li>
<li><p>Then, we reduce <span class="math inline">\(\bar{P}\)</span> as
much as possible by eliding zero-length edges and sliding brackets.
After an <span class="math inline">\(O(m)\)</span>-time initial pass,
each elision takes <span class="math inline">\(O(1)\)</span> time, and
each bracket slide takes <span class="math inline">\(O(\log k)\)</span>
time. Each operation either freezes a bracket or reduces the complexity
of <span class="math inline">\(\bar{P}\)</span>, so after <span
class="math inline">\(O(m)\)</span> operations, performed in <span
class="math inline">\(O(m\log k)\)</span> time, <span
class="math inline">\(\bar{P}\)</span> is reduced as much as
possible.</p></li>
<li><p>Finally, we report that <span class="math inline">\(P\)</span> is
contractible if and only if the reduced rectified polygon is
empty.</p></li>
</ul>
<p>Altogether, this algorithm runs in <span
class="math inline">\(O((n+k+s)\log(n+k))\)</span> time.</p>
<p>This is faster than the brute-force reduction algorithm from the
previous lecture when <em>either</em> the polygon has few
self-intersections <em>or</em> the number of obstacles is significantly
larger than the number of polygon vertices. Specifically, the running
time of the new algorithm is smaller than the old running time <span
class="math inline">\(O(k\log k + nk)\)</span> whenever <span
class="math inline">\(s = o(nk/\log(n+k))\)</span>. Even in the worst
case, when <span class="math inline">\(s = \Theta(n^2)\)</span>, the
running time of the new algorithm simplifies to <span
class="math inline">\(O((k+n^2)\log(n+k))\)</span>, which is still
smaller than <span class="math inline">\(O(k\log k + nk)\)</span> when
<span class="math inline">\(n = o(k/log n)\)</span>.</p>
<h2 data-number="4.7"
id="dots-and-the-aptly-named-et-cetera-ad-nauseam"><span
class="header-section-number">4.7</span> <span
class="math inline">\(\dots\)</span> And the Aptly Named Et Cetera Ad
Nauseam</h2>
<ul>
<li><p>Extracting reduced crossing sequences from the reduced rectified
polygon.</p></li>
<li><p>Testing if a polygon made from two (almost) simple paths is
contractible.</p></li>
<li><p>Testing if two polygons, <em>each</em> with few
self-intersections, are homotopic.</p></li>
<li><p>Faster three-sided range query structures for integer points and
ranges.</p></li>
<li><p>Avoiding computing self-intersections (Bespanyatnikh)</p></li>
</ul>
<h2 data-number="4.8" id="references-2"><span
class="header-section-number">4.8</span> References</h2>
<ol type="1">
<li><p>Sergio Cabello, Yuanxin Liu, Andrea Mantler, and Jack Snoeyink.
<a href="https://doi.org/10.1007/s00454-003-2949-y">Testing homotopy for
paths in the plane</a>. <em>Discrete Comput. Geom.</em> 31(1):61–81,
2004.</p></li>
<li><p>Alon Efrat, Stephen G. Kobourov, and Anna Lubiw. <a
href="https://doi.org/10.1016/j.comgeo.2006.03.003">Computing homotopic
shortest paths efficiently</a>. <em>Comput. Geom. Theory Appl.</em>
35(3):162–172, 2006. arXiv:<a
href="http://arxiv.org/abs/cs/0204050">cs/0204050</a>.</p></li>
<li><p>Dan E. Willard. <a href="https://doi.org/10.1137/0214019">New
data structures for orthogonal range queries</a>. <em>SIAM J.
Comput.</em> 24 14(1):232–253, 1985. Layered range trees.</p></li>
</ol>
<h1 data-number="5" id="shortest-homotopic-pathsbeta"><span
class="header-section-number">5</span> Shortest (Homotopic) Paths<span
class="math inline">\(^\beta\)</span></h1>
<p>In this lecture, we’ll consider a problem that combines both geometry
and topology that arises in VLSI design (or at least <em>did</em> arise
in VLSI design in the 1980s). Suppose we have an environment <span
class="math inline">\(X\)</span> that can be modeled as a <em>polygon
with holes</em>; this is the area bounded between a simple outer polygon
<span class="math inline">\(P_0\)</span> and several disjoint simple
polygons or “holes” <span class="math inline">\(P_1, P_2, \dots,
P_h\)</span>, each of which lies in the interior of <span
class="math inline">\(P_0\)</span>. (Yes, previously we used “polygon”
to refer to the boundary, and now we’re using “polygon with holes” to
refer to the area. Welcome to mathematical jargon.)</p>
<p>We are also given a polygonal path <span
class="math inline">\(\pi\)</span> in the interior of <span
class="math inline">\(X\)</span>. Recall that two <em>paths</em> are
homotopic if one can be continuously deformed to the other within <span
class="math inline">\(X\)</span> while keeping both endpoints fixed at
all times. Our problem is to find the shortest path (that is, the path
of minimum Euclidean length) that is homotopic in <span
class="math inline">\(X\)</span> to the given path <span
class="math inline">\(\pi\)</span>.</p>
<p>Although we could reduce to our earlier notion of homotopy by using
the vertices of <span class="math inline">\(X\)</span> as point
obstacles, the pictures will be nicer (and the algorithms arguably
simpler) if we use <span class="math inline">\(X\)</span> itself as our
underlying space. Our earlier formal definition of homotopy extends
directly to this setting: A homotopy between two paths <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> in <span
class="math inline">\(X\)</span> is a continuous function <span
class="math inline">\(h\colon[0,1]\times[0,1]\to X\)</span> such that
the restrictions <span class="math inline">\(h(\cdot,0)\)</span> and
<span class="math inline">\(h(\cdot,1)\)</span> are constant functions,
and the restrictions <span class="math inline">\(h(0,\cdot)\)</span> and
<span class="math inline">\(h(1, \cdot)\)</span> are the paths <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>, respectively.</p>
<p>Throughout this section, <span class="math inline">\(n\)</span>
denotes the number of vertices of the environment <span
class="math inline">\(X\)</span>, and <span
class="math inline">\(k\)</span> denotes the number of vertices in the
input path <span class="math inline">\(\pi\)</span>. (Yes, this is
reversed from the previous lecture.) Let <span
class="math inline">\(s\)</span> (“source”) and <span
class="math inline">\(t\)</span> (“target”) denote the first and last
vertices of <span class="math inline">\(\pi\)</span>.</p>
<h2 data-number="5.1" id="shortest-paths-in-simple-polygons"><span
class="header-section-number">5.1</span> Shortest Paths in Simple
Polygons</h2>
<p>Let’s start with the topologically trivial case where <span
class="math inline">\(X\)</span> is the interior of a simple polygon
with no holes. A strengthening of the Jordan Curve Theorem due to
Schönflies implies that <span class="math inline">\(X\)</span> is
homeomorphic to an open circular disk. It follows that any two paths in
<span class="math inline">\(X\)</span> with the same endpoints are
homotopic. Thus, we are now looking for the globally shortest path in
<span class="math inline">\(X\)</span> between the endpoints of <span
class="math inline">\(\pi\)</span>.</p>
<p>The shortest path between two points <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> in a simple polygon <span
class="math inline">\(P\)</span> is a polygonal chain, whose interior
vertices lie at concave vertices of <span
class="math inline">\(P\)</span>. Imagine a taut rubber band between
<span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>; the rubber band will be straight
everywhere, except at concave corners that it must wrap around.</p>
<figure>
<img src="Fig/polygon-shortest-path.png" style="width:50.0%"
alt="The shortest path between two points in a simple polygon" />
<figcaption aria-hidden="true">The shortest path between two points in a
simple polygon</figcaption>
</figure>
<p>I’ll describe an algorithm for this special case <em>as through</em>
the topology of the problem were non-trivial; in particular, even though
the output depends only on the endpoints of the input path <span
class="math inline">\(\pi\)</span>, I will still use the entire input
path to guide the algorithm.</p>
<h2 data-number="5.2" id="triangulations-and-dual-graphs"><span
class="header-section-number">5.2</span> Triangulations and Dual
Graphs</h2>
<p>The first step of our shortest-path algorithm is to triangulate the
polygon <span class="math inline">\(X\)</span>. We saw an algorithm in
the first lecture that computes a frugal triangulation of <span
class="math inline">\(X\)</span> in <span class="math inline">\(O(n\log
n)\)</span> time.</p>
<p>The <em>(weak) dual graph</em> of a polygon triangulation has a
vertex for each triangle and an edge for each diagonal; two vertices are
connected by an edge in the dual graph if and only if the corresponding
triangles share a diagonal. We can draw the dual graph by placing each
vertex at the centroid of its triangle, and drawing each edge as a
polygonal path through the midpoint of the corresponding diagonal.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>The dual graph of any frugal triangulation of a polygon without
holes is a tree.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Suppose to the contrary that the dual graph contains a cycle <span
class="math inline">\(C\)</span>. The image of <span
class="math inline">\(C\)</span> in our drawing is a simple polygon,
which I’ll also call <span class="math inline">\(C\)</span> (at the risk
of confusing the reader). Any diagonal <span
class="math inline">\(d\)</span> whose dual edge is in <span
class="math inline">\(C\)</span> crosses <span
class="math inline">\(C\)</span> exactly once at the midpoint of <span
class="math inline">\(d\)</span>. It follows that one endpoint of <span
class="math inline">\(d\)</span> is inside <span
class="math inline">\(C\)</span> and the other endpoint is outside. So
the Jordan curve theorem implies that the polygon <span
class="math inline">\(X\)</span> intersects <span
class="math inline">\(C\)</span>. But that’s impossible, because <span
class="math inline">\(X\)</span> does not intersect the dual graph.
</dd>
</dl>
<figure>
<img src="Fig/polygon-triangulation-dual.png" style="width:50.0%"
alt="The dual graph of a polygon triangulation" />
<figcaption aria-hidden="true">The dual graph of a polygon
triangulation</figcaption>
</figure>
<h2 data-number="5.3" id="crossing-sequences-1"><span
class="header-section-number">5.3</span> Crossing Sequences</h2>
<p>Next we apply the same strategy that we previously used to test
contractibility. We compute the <em>crossing sequence</em> of <span
class="math inline">\(\pi\)</span> and then <em>reduce</em> it as much
as possible. (Two paths are homotopic if and only if they have identical
reduced crossing sequences.) In this setting, the crossing sequence is
the sequence of diagonals crossed by <span
class="math inline">\(\pi\)</span>, in order along <span
class="math inline">\(\pi\)</span>.</p>
<figure>
<img src="Fig/polygon-triangulation-path.png" style="width:50.0%"
alt="A path with crossing sequence ABCDDDEFHLKJJKLMNUUTSRQPPQQOOQRSTUVWWWXYYXXYZ" />
<figcaption aria-hidden="true">A path with crossing sequence
<code>ABCDDDEFHLKJJKLMNUUTSRQPPQQOOQRSTUVWWWXYYXXYZ</code></figcaption>
</figure>
<p>In our earlier homotopy-testing algorithm, we also recorded the
<em>sign</em> of each crossing, but that information is actually
redundant in our current setting. Recall from our proof of the polygon
triangulation theorem that any interior diagonal partitions the interior
of a polygon into two disjoint subsets. Thus, if <span
class="math inline">\(\pi\)</span> crosses the same diagonal multiple
times, those crossings must alternate between positive and negative. It
also follows that we can reduce the crossing sequence by removing
arbitrary adjacent pairs of <em>equal</em> symbols; for any such pair,
the corresponding crossings have opposite signs. For example, the
crossing sequence
<code>ABCDDDEFHLKJJKLMNUUTSRQPPQQOOQRSTUVWWWXYYXXYZ</code> of the path
in the previous figure reduces to <code>ABCDEFHMNUVWXYZ</code>.</p>
<p>We can compute the crossing sequence of <span
class="math inline">\(\pi\)</span> in <span class="math inline">\(O(n +
k + x)\)</span> time, where <span class="math inline">\(x =
O(kn)\)</span> is the length of the crossing sequence. Specifically, we
find the triangle containing <span class="math inline">\(s\)</span> by
brute force; then we can repeatedly find the next crossing (if any)
along the current edge of <span class="math inline">\(\pi\)</span> in
<span class="math inline">\(O(1)\)</span> time. Finally, we can reduce
the crossing sequence in <span class="math inline">\(O(x)\)</span> time
using left-greedy cancellation.</p>
<p>(The reduced crossing sequence of <span
class="math inline">\(\pi\)</span> contains precisely the edge labels
that appear an odd number of times in the unreduced crossing sequence;
moreover, these labels appear in the same order as their first (or last)
occurrences in the unreduced crossing sequence.)</p>
<h2 data-number="5.4" id="sleeves"><span
class="header-section-number">5.4</span> Sleeves</h2>
<p>Let <span class="math inline">\(\bar{x}\)</span> denote the length of
the reduced crossing sequence. The reduced crossing sequence defines a
sequence of <span class="math inline">\(\bar{x}+1\)</span> triangles in
the triangulation of <span class="math inline">\(X\)</span>, starting
with the triangle containing the first vertex <span
class="math inline">\(\pi_0\)</span> of <span
class="math inline">\(\pi\)</span>, and ending with the triangle
containing the last vertex <span class="math inline">\(\pi_k\)</span> of
<span class="math inline">\(\pi\)</span>. The union of these triangles
is called the <em>sleeve</em> of the reduced crossing sequence.</p>
<figure>
<img src="Fig/polygon-sleeve.png" style="width:50.0%"
alt="The sleeve of the reduced crossing sequence ABCDEFHMNUVWXYZ" />
<figcaption aria-hidden="true">The sleeve of the reduced crossing
sequence <code>ABCDEFHMNUVWXYZ</code></figcaption>
</figure>
<p>Any path <span class="math inline">\(\alpha\)</span> in <span
class="math inline">\(X\)</span> from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> that leaves the sleeve must cross a
diagonal <span class="math inline">\(d\)</span> on the boundary of the
sleeve. The endpoints <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> lie in the same component of <span
class="math inline">\(X\setminus d\)</span>, so the path must cross
<span class="math inline">\(d\)</span> and even number of times. Let
<span class="math inline">\(p\)</span> and <span
class="math inline">\(q\)</span> be the first and last intersection
points along <span class="math inline">\(\alpha\)</span>. The line
segment <span class="math inline">\(pq\)</span> is shorter than the
subpath of <span class="math inline">\(\alpha\)</span> from <span
class="math inline">\(p\)</span> to <span
class="math inline">\(q\)</span>, so <span
class="math inline">\(\alpha\)</span> cannot be a shortest path.</p>
<p>Alternatively, the crossing sequence describes a walk in the dual
graph of the triangulation, starting at the vertex dual to the triangle
containing <span class="math inline">\(s\)</span>. Reducing the crossing
sequence removes <em>spurs</em> from this walk—subpaths that consist of
the same edge twice in a row, necessarily in opposite directions. Thus,
the <em>reduced</em> crossing sequence describes a <em>shortest</em>
walk—in fact, the unique simple path between its endpoints—in the dual
graph. This path is also the dual graph of the induced triangulation of
the sleeve.</p>
<p>Note that we do not actually need to <em>construct</em> the sleeve;
the sequence of diagonals that the funnel crosses is exactly the reduced
crossing sequence of <span class="math inline">\(\pi\)</span>.</p>
<h2 data-number="5.5" id="growing-funnels"><span
class="header-section-number">5.5</span> Growing Funnels</h2>
<p>To compute the actual shortest path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>, we use an algorithm independently
discovered by Tompa (1981), Chazelle (1982), Lee and Preparata (1984),
and Leiserson and Maley (1985). (My presentation most closely follows
Lee and Preparata’s.) The <em>funnel</em> of any diagonal <span
class="math inline">\(d\)</span> of the sleeve is the union of the
shortest paths the from the source point <span
class="math inline">\(s\)</span> to all points on <span
class="math inline">\(e\)</span>.</p>
<p>The funnel consists of a polygonal path, called the <em>tail</em>,
from <span class="math inline">\(s\)</span> to a point a called the
<em>apex</em>, plus a simple polygon called the <em>fan</em>. The tail
may be empty, in which case <span class="math inline">\(s\)</span> is
the apex. The fan is bounded by the diagonal <span
class="math inline">\(d\)</span> and two concave chains joining the apex
to the endpoints of <span class="math inline">\(d\)</span>. The shortest
path from <span class="math inline">\(s\)</span> to either endpoint of
<span class="math inline">\(d\)</span> consists of the tail plus one of
the concave chains bounding the fan. Extending the edges of the concave
chains to infinite rays defines a series of <em>wedges</em>, which
subdivide both the fan and the triangle just beyond <span
class="math inline">\(d\)</span>.</p>
<figure>
<img src="Fig/funnel.png" style="width:50.0%" alt="A typical funnel" />
<figcaption aria-hidden="true">A typical funnel</figcaption>
</figure>
<p>Beginning with a single triangle joining <span
class="math inline">\(s\)</span> to the first edge in the reduced
crossing sequence, we extend the funnel through the entire sleeve one
diagonal at a time. Each diagonal in the sleeve shares one endpoint with
the previous diagonal; suppose we are extending the funnel from diagonal
<span class="math inline">\(pq\)</span> to diagonal <span
class="math inline">\(qr\)</span>. Let <span
class="math inline">\(o\)</span> be the predecessor of <span
class="math inline">\(p\)</span> on the shortest path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(p\)</span>.</p>
<p>There are two cases to consider, depending on whether <span
class="math inline">\(q\)</span> and <span
class="math inline">\(r\)</span> lie on the same sides of the line
through <span class="math inline">\(o\)</span> and <span
class="math inline">\(p\)</span> or on opposite sides. We can actually
detect this case in <span class="math inline">\(O(1)\)</span> time with
a single orientation test.</p>
<ul>
<li>If <span class="math inline">\(q\)</span> and <span
class="math inline">\(r\)</span> lie on opposite sides of line <span
class="math inline">\(op\)</span>, then the new endpoint <span
class="math inline">\(r\)</span> does not lie inside any wedge of the
current fan. We can detect this case in <span
class="math inline">\(O(1)\)</span> time with a single orientation test,
and then extend the tunnel in <span class="math inline">\(O(1)\)</span>
time by inserting <span class="math inline">\(r\)</span> as a new fan
vertex.</li>
</ul>
<figure>
<img src="Fig/funnel-expand.png" style="width:85.0%"
alt="Growing the funnel" />
<figcaption aria-hidden="true">Growing the funnel</figcaption>
</figure>
<ul>
<li>If <span class="math inline">\(q\)</span> and <span
class="math inline">\(r\)</span> lie on the same side of line <span
class="math inline">\(op\)</span>, we <em>contract</em> the funnel,
intuitively by moving <span class="math inline">\(p\)</span>
continuously along the boundary edge <span
class="math inline">\(pr\)</span>. Each time the moving point crosses
the boundary of a wedge, we remove a vertex from the fan. If the removed
vertex is the apex, the next vertex on that side of the fan (on the
shortest path from <span class="math inline">\(s\)</span> to <span
class="math inline">\(r\)</span>) becomes the new apex. We can detect
whether the moving point will cross any wedge boundary in <span
class="math inline">\(O(1)\)</span> time using our standard orientation
test. Thus, the total time in this case is <span
class="math inline">\(O(\delta + 1)\)</span>, where <span
class="math inline">\(\delta\)</span> is the number of vertices deleted
from the fan. The total number of deleted vertices cannot exceed the
total number of previously inserted vertices, so the <em>amortized</em>
time for this case is also <span
class="math inline">\(O(1)\)</span>.</li>
</ul>
<figure>
<img src="Fig/funnel-contract.png" style="width:95.0%"
alt="Shrinking the funnel" />
<figcaption aria-hidden="true">Shrinking the funnel</figcaption>
</figure>
<p>Let <span class="math inline">\(yz\)</span> be the last diagonal in
the reduced crossing sequence. To end the algorithm, we treat the line
segment <span class="math inline">\(tz\)</span> as another diagonal and
extend the funnel one more time. The shortest path homotopic to <span
class="math inline">\(\pi\)</span> then consists of the tail of the
funnel plus the concave chain of the fan containing <span
class="math inline">\(t\)</span>; we can extract this shortest path in
<span class="math inline">\(O(1)\)</span> time per edge.</p>
<p>Summing up, we spend <span class="math inline">\(O(n\log n)\)</span>
time triangulating <span class="math inline">\(X\)</span>, then <span
class="math inline">\(O(k+x) = O(nk)\)</span> time computing the
crossing sequence of <span class="math inline">\(\pi\)</span>, then
<span class="math inline">\(O(x) = O(nk)\)</span> time reducing the
crossing sequence, <span class="math inline">\(O(\bar{x}) =
O(nk)\)</span> time growing the funnel, and finally <span
class="math inline">\(O(\bar{x}) = O(nk)\)</span> extracting the
shortest path from the final funnel.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Given a polygonal path <span class="math inline">\(\pi\)</span> in a
simple polygon <span class="math inline">\(X\)</span> <strong>without
holes</strong>, we can compute the shortest path in <span
class="math inline">\(X\)</span> homotopic to <span
class="math inline">\(\pi\)</span> in <span
class="math inline">\(O(n\log n + nk)\)</span> time.</em>
</dd>
</dl>
<h2 data-number="5.6" id="polygons-with-holes"><span
class="header-section-number">5.6</span> Polygons with Holes</h2>
<p>Now let’s consider the more general case where <span
class="math inline">\(X\)</span> has one or more holes. Perhaps
surprisingly, the previous algorithm needs <em>no modifications
whatsoever</em> to compute the shortest path homotopic to <span
class="math inline">\(\pi\)</span> in <span
class="math inline">\(O(n\log n + nk)\)</span> time.</p>
<ul>
<li><p>Triangulate <span class="math inline">\(X\)</span> in <span
class="math inline">\(O(n\log n)\)</span> time using the algorithm
described in the first lecture. First build a trapezoidal decomposition
using a sweep-line algorithm (such as Bentley-Ottmann). Then insert
diagonals inside every boring trapezoid in <span
class="math inline">\(O(n)\)</span> time, partitioning <span
class="math inline">\(X\)</span> into monotone mountains. Finally,
triangulate these monotone mountains in <span
class="math inline">\(O(n)\)</span> total time.</p></li>
<li><p>Compute the crossing sequence of <span
class="math inline">\(\pi\)</span> with respect to this triangulation in
<span class="math inline">\(O(n + k + x)\)</span> time, where <span
class="math inline">\(x\)</span> is the number of crossings. Locate the
triangle containing <span class="math inline">\(s\)</span> in <span
class="math inline">\(O(n)\)</span> time by brute force, then repeatedly
find the next crossing (if any) along the current edge in <span
class="math inline">\(O(1)\)</span> time.</p></li>
<li><p>Reduce the resulting crossing sequence in <span
class="math inline">\(O(x)\)</span> time using the left-greedy reduction
algorithm.</p></li>
<li><p>Extend the funnel through the sleeve of the reduced crossing
sequence in <span class="math inline">\(O(\bar{x}) = O(nk)\)</span> time
using the standard funnel algorithm.</p></li>
<li><p>Finally, extract the shortest homotopic path from the final
funnel in <span class="math inline">\(O(1)\)</span> time per
edge.</p></li>
</ul>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Given a polygonal path <span class="math inline">\(\pi\)</span> in a
simple polygon <span class="math inline">\(X\)</span> <strong>with
holes</strong>, we can compute the shortest path in <span
class="math inline">\(X\)</span> homotopic to <span
class="math inline">\(\pi\)</span> in <span
class="math inline">\(O(n\log n + nk)\)</span> time.</em>
</dd>
</dl>
<p>Same algorithm, same running time, same everything. This strikes many
people as counterintuitive. After all, the sleeve can runs through the
same triangle multiple times, and the funnel can self-intersect; why
doesn’t this cause any problems?</p>
<p>One way to answer this question is that <em>the algorithm doesn’t
look for self-intersections, so it’s behavior can’t be affected by
them</em>. Or said differently: <em>the algorithm only makes local
decisions, but self-intersection is a global property</em>. Every branch
in our algorithm is based on either a comparison between two <span
class="math inline">\(x\)</span>-coordinates or an orientation test on
some triple of points. As far as the algorithm is concerned, every time
the funnel enters a triangle, it is entering that triangle for the very
first time, or equivalently, it is entering a <em>new copy</em> of that
triangle. So the sleeve of the reduced crossing sequence, while not
being <em>geometrically</em> a triangulated simple polygon, is still
<em>topologically</em> a triangulated simple polygon: a collection of
triangles glued together along common edges into a topological disk.</p>
<figure>
<img src="Fig/coversleeve.png" style="width:50.0%"
alt="The sleeve of a reduced path in a polygon with holes" />
<figcaption aria-hidden="true">The sleeve of a reduced path in a polygon
with holes</figcaption>
</figure>
<p>There is a reasonable analogy here with classical graph traversal
algorithms: depth-first search, breadth-first search, and their more
complex descendants. All of these algorithms maintain a set of vertices;
at each iteration, each algorithm pulls one vertex <span
class="math inline">\(v\)</span> out of this set, <em>marks</em> that
vertex, and then puts the <em>unmarked</em> neighbors of <span
class="math inline">\(v\)</span> into the set. Without the marking
logic, unless the input graph is a tree, these algorithms will visit at
least one vertex infinitely many times, each time treating it as a
brand-new vertex.</p>
<p>In fact, even the original shortest-path algorithm does not actually
require the environment <span class="math inline">\(X\)</span> to be a
simple polygon. We only require that (1) <span
class="math inline">\(X\)</span> is assembled from <em>any</em> set of
Euclidean triangles by identifying disjoint pairs of equal-length edges,
(2) all triangle vertices are on the boundary of <span
class="math inline">\(X\)</span>, and (3) the dual graph of the
triangulation is a tree (equivalently, <span
class="math inline">\(X\)</span> is homeomorphic to a disk in the
plane). More generally, the shortest-homotopic-path algorithm applies to
any triangulated space satisfying conditions (1) and (2); these spaces
can reasonably be called <em>boundary-triangulated flat surfaces</em>.
For example, without modification, our algorithm can compute shortest
homotopic paths on a triangulated Möbius band.</p>
<figure>
<img src="Fig/Mobius-band.png" style="width:70.0%"
alt="A flat Möbius band assembled from nine Euclidean triangles" />
<figcaption aria-hidden="true">A flat Möbius band assembled from nine
Euclidean triangles</figcaption>
</figure>
<h2 data-number="5.7" id="the-universal-cover"><span
class="header-section-number">5.7</span> The Universal Cover</h2>
<p>Another explanation that may be more familiar to topologists is that
our algorithm is effectively exploring the <em>universal cover</em> of
the input polygon. Informally, the universal cover (of <em>universal
covering space</em>) of <span class="math inline">\(X\)</span> is the
infinite topological space constructed by a breadth-first search of
<span class="math inline">\(X\)</span> <em>without memory</em>.</p>
<p>We can define the universal cover more constructively in terms of a
triangulation of <span class="math inline">\(X\)</span> as follows. Fix
a starting point <span class="math inline">\(s\)</span>. For every
reduced crossing sequence <span class="math inline">\(w\)</span> of a
path starting at <span class="math inline">\(s\)</span>, let <span
class="math inline">\(\Delta_w\)</span> denote <em>an independent
copy</em> of the triangle containing the final point in that path. For
example, <span class="math inline">\(\Delta_\varepsilon\)</span> is a
copy of the triangle containing <span class="math inline">\(s\)</span>.
Two triangles <span class="math inline">\(\Delta_w\)</span> and <span
class="math inline">\(\Delta_x\)</span> are <em>neighbors</em> if <span
class="math inline">\(x = wd\)</span> for some diagonal <span
class="math inline">\(d\)</span>; glue every such pair together along
their copies of <span class="math inline">\(d\)</span>. For example, if
<span class="math inline">\(w =\)</span> <code>ABCB</code> and <span
class="math inline">\(x =\)</span> <code>ABCBD</code>, then we would
identify the copies of edge <code>D</code> in <span
class="math inline">\(\Delta_w\)</span> and <span
class="math inline">\(\Delta_x\)</span>. We call each triangle <span
class="math inline">\(\Delta_w\)</span> a <em>lift</em> of the
corresponding triangle in the triangulation of <span
class="math inline">\(X\)</span>, and we call the original triangle a
<em>projection</em> of <span
class="math inline">\(\Delta_w\)</span>.</p>
<p><strong><em>Figure! Polygonal annulus to infinite polygonal parking
garage?</em></strong></p>
<p>The dual graph of the universal cover of <span
class="math inline">\(X\)</span>—or equivalently, the universal cover of
the dual graph of <span class="math inline">\(X\)</span>—has a vertex
for every possible reduced crossing sequence (of a path starting at
<span class="math inline">\(s\)</span>), and an edge between two reduced
crossing sequences if they differ by exactly one crossing. Unless the
input polygon <span class="math inline">\(X\)</span> has no holes, the
universal cover of the dual graph is an infinite tree. The crossing
sequence describes a walk from some vertex <span
class="math inline">\(\hat{s}\)</span> to another vertex <span
class="math inline">\(\hat{t}\)</span> in this infinite tree; removing
all spurs computes the <em>unique</em> path in that tree between <span
class="math inline">\(\hat{s}\)</span> and <span
class="math inline">\(\hat{t}\)</span>.</p>
<p><strong><em>Figure?</em></strong></p>
<h2 data-number="5.8" id="covering-spaces"><span
class="header-section-number">5.8</span> Covering Spaces</h2>
<p>The universal cover is an example of a <em>covering space</em>. We
will see several other examples of covering spaces in this course, so
let me start here with some formal definitions.</p>
<p>A <em>covering map</em> is a continuous surjective function <span
class="math inline">\(p\colon \widehat{X}\to X\)</span>, such that every
point <span class="math inline">\(x\in X\)</span> has an open
neighborhood <span class="math inline">\(U\)</span> whose preimage <span
class="math inline">\(p^{-1}(U)\)</span> is the disjoint union of open
sets <span class="math inline">\(\bigsqcup_{i\in I} U_i\)</span>, such
that the restriction of the function <span
class="math inline">\(p\)</span> to each open set <span
class="math inline">\(U_i\)</span> is a homeomorphism to <span
class="math inline">\(U\)</span>. The open sets <span
class="math inline">\(U_i\)</span> are sometimes called <em>sheets</em>
over <span class="math inline">\(U\)</span>. If there is a covering map
from <span class="math inline">\(\widehat{X}\)</span> to <span
class="math inline">\(X\)</span>, we call <span
class="math inline">\(\widehat{X}\)</span> a <em>covering space</em> of
<span class="math inline">\(X\)</span>. By convention, we require
covering spaces to be connected.</p>
<p>The <em>universal</em> covering space <span
class="math inline">\(\widetilde{X}\)</span> can be defined in several
different ways:</p>
<ul>
<li><p><span class="math inline">\(\widetilde{X}\)</span> is the unique
covering space of <span class="math inline">\(X\)</span> that also
covers every covering space of <span
class="math inline">\(X\)</span>.</p></li>
<li><p><span class="math inline">\(\widetilde{X}\)</span> is the unique
<em>simply-connected</em> covering space of <span
class="math inline">\(X\)</span>. (Recall that a space is <em>simply
connected</em> if every closed curve in that space is
contractible.)</p></li>
<li><p><span class="math inline">\(\widetilde{X}\)</span> is the space
of all <em>homotopy classes</em> of paths from some fixed basepoint
<span class="math inline">\(s\in X\)</span>: <span
class="math display">\[
  \widetilde{X} := \big\{ [\pi] \bigm| \pi\colon [0,1]\to X \text{~and~}
\pi(0) = s \big\}
\]</span> The covering map <span class="math inline">\(p\colon
\widetilde{X}\to X\)</span> maps each homotopy class <span
class="math inline">\([\pi]\)</span> of paths to their common final
endpoint <span class="math inline">\(\pi(1)\)</span>.</p></li>
</ul>
<p>In our construction by gluing labeled triangles, the covering map
sends each triangle <span class="math inline">\(\Delta_w\)</span> to the
corresponding triangle in the triangulation of <span
class="math inline">\(X\)</span>.</p>
<p><strong><em>Concrete examples?</em></strong></p>
<h2 data-number="5.9" id="dotsand-the-aptly-named-yadda-yadda"><span
class="header-section-number">5.9</span> <span
class="math inline">\(\dots\)</span>and the Aptly Named Yadda Yadda</h2>
<ul>
<li>Technicalities for point obstacles</li>
<li>Bundling homotopic subpaths</li>
<li>Minimum-link (homotopic) paths</li>
<li>Thick non-crossing paths</li>
<li>Shortest non-crossing walks / wire routing</li>
</ul>
<h2 data-number="5.10" id="references-3"><span
class="header-section-number">5.10</span> References</h2>
<ol type="1">
<li><p>Bernard Chazelle. <a
href="https://doi.org/10.1109/SFCS.1982.58">A theorem on polygon cutting
with applications.</a> <em>Proc. 23rd Ann. IEEE Symp. Found. Comput.
Sci.</em>, 339–349, 1982. The funnel algorithm.</p></li>
<li><p>Shaodi Gao, Mark Jerrum, Michael Kaufmann, Kurt Mehlhorn, and
Wolfgang Rülling. <a href="https://doi.org/10.1145/73393.73433">On
continuous homotopic one layer routing</a>. <em>Proc. 4th Ann. Symp.
Comput. Geom.</em>, 15 392–402, 1988.</p></li>
<li><p>John Hershberger and Jack Snoeyink. <a
href="https://doi.org/10.1016/0925-7721(94)90010-8">Computing minimum
length paths of a given homotopy class</a>. <em>Comput. Geom. Theory
Appl.</em> 4:63–98, 1994.</p></li>
<li><p>Der-Tsai Lee and Franco P. Preparata. <a
href="https://doi.org/10.1002/net.3230140304">Euclidean shortest paths
in the presence of rectilinear barriers</a>. <em>Networks</em>
14:393–410, 1984. The funnel algorithm.</p></li>
<li><p>Charles E. Leiserson and F. Miller Maley. <a
href="https://doi.org/10.1145/22145.22153">Algorithms for routing and
testing routability of planar VLSI layouts</a>. <em>Proc. 17th Ann. ACM
Symp. Theory Comput.</em>, 69–78, 1985. The funnel algorithm.</p></li>
<li><p>Martin Tompa. <a
href="https://doi.org/10.1016/0022-0000(81)90010-6">An optimal solution
to a wire-routing problem</a>. <em>J. Comput. System Sci.</em>
23:127–150, 1981. The funnel algorithm.</p></li>
</ol>
<h1 data-number="6" id="generic-planar-curvesalpha"><span
class="header-section-number">6</span> Generic Planar Curves<span
class="math inline">\(^\alpha\)</span></h1>
<p>Recall that a <em>closed curve</em> in the plane is any continuous
function from the circle to the plane. Previously we considered a common
representation of closed curves as <em>polygons</em>: circular sequences
of line segments joined at common endpoints. Polygons are convenient for
reasoning about intersections with other simple geometric structures
like vertical rays, trapezoidal decompositions, and triangulations, but
in other ways the geometry of the representation is irrelevant. Starting
with this lecture, I’ll consider a more abstract representation that
records only how the curve intersects <em>itself</em>.</p>
<p>A self-intersection <span class="math inline">\(\gamma(t) =
\gamma(t&#39;)\)</span> of a closed curve <span
class="math inline">\(\gamma\)</span> is <em>transverse</em> if, for all
sufficiently small <span class="math inline">\(\varepsilon &gt;
0\)</span> the subpaths <span
class="math inline">\(\gamma(t-\varepsilon, t+\varepsilon)\)</span> and
<span class="math inline">\(\gamma(t&#39;-\varepsilon,
t&#39;+\varepsilon)\)</span> are homeomorphic to two orthogonal lines. A
closed curve is <em>generic</em> if every self-intersection is
transverse (in particular, there are no self-tangencies or repeated
curve <em>segments</em>) and there are no triple self-intersections
<span class="math inline">\(\gamma(t) = \gamma(t&#39;) =
\gamma(t&#39;&#39;)\)</span>.</p>
<figure>
<img src="Fig/Gauss-curve.png" style="width:40.0%"
alt="A generic closed curve with eleven crossings" />
<figcaption aria-hidden="true">A generic closed curve with eleven
crossings</figcaption>
</figure>
<p>Two generic curves are <em>isotopic</em> if one can be continuously
deformed to the other without ever changing the number of
self-intersections. For example, all simple closed curves are isotopic
to each other. A homotopy that always preserves the number of
self-intersections is called an <em>isotopy</em>. In fact, two planar
curves <span class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\gamma’\)</span> are isotopic if and only if there
is an orientation-preserving homeomorphism <span
class="math inline">\(h\colon \mathbb{R}^2 \to \mathbb{R}^2\)</span>
such that <span class="math inline">\(\gamma’ = h\circ \gamma\)</span>.
At least in the next few lectures, we really don’t care about the
<em>geometry</em> of these curves, so we won’t distinguish between
isotopic curves.</p>
<h2 data-number="6.1" id="technicalities"><span
class="header-section-number">6.1</span> Technicalities</h2>
<p>Generic closed curves are sometimes called <em>immersions</em> or
<em>regular</em> curves, but the latter term more commonly refers to
closed curves with continuous non-zero derivatives. In fact, the most
common word used to describe this class of closed curves is “curve”! The
definition of generic curves does <em>not</em> require continuous,
non-zero, or even well-defined derivatives at <em>any</em> point, much
less at <em>every</em> point. Despite this freedom, the following
standard <em>compactness argument</em> implies that generic curves are
well-behaved.</p>
<p><strong>Lemma:</strong> <em>Every generic closed curve has a finite
number of self-intersection points.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Call a point <span class="math inline">\(t\in S^1\)</span>
<em>singular</em> if <span class="math inline">\(\gamma(t) =
\gamma(t&#39;)\)</span> for some <span class="math inline">\(t&#39;\ne
t\)</span>, and <em>regular</em> otherwise. For each point <span
class="math inline">\(t\in S^1\)</span>, we define an open interval
<span class="math inline">\(U_t\)</span> as follows:
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(t\)</span> is singular, let <span
class="math inline">\(U_t = (t-\varepsilon, t+\varepsilon)\)</span>,
such that <span class="math inline">\(\gamma(t-\varepsilon,
t+\varepsilon)\)</span> and some other arc <span
class="math inline">\(\gamma(t&#39;-\varepsilon,
t&#39;+\varepsilon)\)</span> are homeomorphic to two orthogonal
lines.</li>
</ul>
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(t\)</span> is regular, let <span
class="math inline">\(U_t\)</span> be any open interval that contains
<span class="math inline">\(t\)</span> but no singular points.</li>
</ul>
</dd>
<dd>
<p>The open sets <span class="math inline">\(\mathcal{C} = \{ U_t \mid
t\in S^1 \}\)</span> clearly <em>cover</em> the circle, meaning <span
class="math inline">\(\bigcup_{t\in S^1} U_t = S^1\)</span>. Because
<span class="math inline">\(S^1\)</span> is compact, there must be a
finite subset <span class="math inline">\(\mathcal{F} \subset
\mathcal{C}\)</span> that also covers <span
class="math inline">\(S^1\)</span>. Let <span class="math inline">\(F
\subset S^1\)</span> be the (necessarily finite) index set of the finite
subcover <span class="math inline">\(\mathcal{F}\)</span>, meaning <span
class="math inline">\(\mathcal{F} = \{ U_t \mid t\in F \}\)</span>.</p>
</dd>
<dd>
<p>The only set in <span class="math inline">\(\mathcal{U}\)</span> that
contains a singular point <span class="math inline">\(t\)</span> is its
own interval <span class="math inline">\(U_t\)</span>. Thus, the finite
set <span class="math inline">\(T\)</span> must contain every singular
point.</p>
</dd>
</dl>
<p>The adjective “generic” is justified by the observation that
<em>every</em> closed curve can be approximated arbitrarily closely by a
generic closed curve. Previously we argued that every closed curve can
be approximated arbitrarily closely by a <em>polygon</em>. (This is the
<em>simplicial approximation theorem</em>.) An arbitrarily small
perturbation of any polygon ensures that all vertices are distinct, no
vertex lies in the interior of an edge, and no three edges share a
common point. Any polygon satisfying these conditions <em>is</em> a
generic closed curve.</p>
<p>A more careful application of simplicial approximation and
compactness implies that any generic closed curve <span
class="math inline">\(\gamma\)</span> can be approximated arbitrarily
closely by a polygon that is <em>isotopic</em> to <span
class="math inline">\(\gamma\)</span>. Thus, even though generic curves
are not polygons <em>by definition</em>, they are polygons <em>without
loss of generality</em>. In fact, results in future lectures imply that
each generic curve with <span class="math inline">\(n\)</span>
self-intersection points is isotopic to a polygon with only <span
class="math inline">\(O(n)\)</span> vertices.</p>
<h2 data-number="6.2" id="image-graphs"><span
class="header-section-number">6.2</span> Image graphs</h2>
<p>Any non-simple generic closed curve can be naturally represented by
its <em>image graph</em>, which is a connected 4-regular plane graph<a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> whose vertices are the
self-intersection points of the curve, and whose edges are curve
segments between vertices. Image graphs are not necessary
<em>simple</em>; they can contain loops and parallel edges. The image
graph of a <em>simple</em> closed curve is obviously a simple cycle.</p>
<figure>
<img src="Fig/Gauss-curve-graph.png" style="width:40.0%"
alt="The image graph of the curve in Figure 1" />
<figcaption aria-hidden="true">The image graph of the curve in Figure
1</figcaption>
</figure>
<p>However, not every 4-regular plane graph is the image graph of a
generic closed curve. Any generic curve is a particular Euler tour of
its image graph. Recall that an <em>Euler tour</em> of a graph <span
class="math inline">\(G\)</span> is any closed walk that traverses each
edge of <span class="math inline">\(G\)</span> exactly once. A closed
walk is <em>Gaussian</em> if, whenever the walk visits a vertex <span
class="math inline">\(v\)</span>, it enters and exits <span
class="math inline">\(v\)</span> along <em>opposing</em> edges. A
4-regular graph is <em>unicursal</em> if it contains a Gaussian Euler
tour; every <em>unicursal</em> 4-regular plane graph is the image of a
non-simple generic curve.</p>
<p>Any generic planar curve partitions the plane into regions called the
<em>faces</em> of the curve. The Jordan-Schönflies theorem implies that
every planar curve has one unbounded face that is homeomorphic to the
complement of a closed disk, and every other face is homeomorphic to an
open disk. The faces of a curve are also the faces of its image graph. A
face is called a <em>monogon</em> if it has only one edge on its
boundary, a <em>bigon</em> if it has two boundary edges, and a
<em>triangle</em> if it has three boundary edges.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>More generally, a <em>multicurve</em> is a continuous map of the
disjoint union of circles into the plane; a multicurve is
<em>generic</em> if it has only transverse pairwise self-intersections.
The restriction of a multicurve to one of its circles is a generic
closed curve called a <em>constituent</em> of the multicurve. Every
4-regular plane graph <span class="math inline">\(G\)</span> is the
image graph of a generic multicurve, whose constituents are the Gaussian
walks in <span class="math inline">\(G\)</span>. Most of the results
I’ll discuss in this set of lectures extend easily to multicurves, but
for ease of exposition I’ll discuss only curves explicitly.</p>
<h2 data-number="6.3" id="gauss-codes-and-gauss-diagrams"><span
class="header-section-number">6.3</span> Gauss codes and Gauss
diagrams</h2>
<p>In the mid-1800s, Gauss developed a symbolic representation of closed
curves similar to the crossing sequences that we previously used for
homotopy testing.</p>
<p>Assign a unique label to each vertex of the image graph of the curve.
The <em>Gauss code</em> of a curve is the sequence of labels encountered
by a point moving once around the curve, starting at an arbitrary
<em>basepoint</em> and moving in an arbitrary direction. In other words,
a Gauss code is a <em>self-crossing</em> sequence. Different choices of
basepoint and direction lead to different Gauss codes. Specifically,
changing the basepoint cyclically shifts the Gauss code, and changing
direction reverses the Gauss code.</p>
<p>A <em>signed</em> Gauss code also records <em>how</em> the curve
crosses itself at each vertex. Imagine a point moving along the curve in
the chosen direction, starting at the chosen basepoint. The signed Gauss
code records a <em>positive</em> crossing whenever the point crosses the
curve from right to left, and a <em>negative</em> crossing whenever the
point crosses the curve from left to right. (This is exactly the same
sign convention that we used to compute winding number, <em>from the
point of view of the polygon</em>.) Each vertex of the image graph of a
curve appears twice in the curve’s signed Gauss code, once with each
sign. I’ll typically indicate positive and negative crossings using
upper- and lower-case letters, respectively. Again, different choices of
basepoint and direction lead to different signed Gauss codes.</p>
<figure>
<img src="Fig/sign-convention.png" style="width:15.0%"
alt="Gauss’s sign convention for positive and negative crossings." />
<figcaption aria-hidden="true">Gauss’s sign convention for positive and
negative crossings.</figcaption>
</figure>
<p>Figure 4 shows the curve from Figure 1, with a direction indicated by
arrows and a basepoint on the far left indicated by a white arrowhead.
Each vertex is labeled positive or negative according to the sign of the
<em>first</em> crossing through that vertex. The resulting signed Gauss
code is <code>ABcdeFGChaIgDjKHbifEJK</code>; by forgetting the signs, we
recover the unsigned Gauss code <code>ABCDEFGCHAIGDJKHBIFEJK</code>.</p>
<figure>
<img src="Fig/Gauss-code-curve.png" style="width:40.0%"
alt="A based directed curve with signed Gauss code ABcdeFGChaIgDjKHbifEJK." />
<figcaption aria-hidden="true">A based directed curve with signed Gauss
code <code>ABcdeFGChaIgDjKHbifEJK</code>.</figcaption>
</figure>
<p><em>Gauss diagrams</em> are an equivalent graphical representation of
Gauss codes. A Gauss diagram for a curve with <span
class="math inline">\(n\)</span> self-intersections consists of an
undirected cycle of <span class="math inline">\(2n\)</span> nodes
labeled by crossings, in the order they appear along the curve, along
with edges joining the two appearances of each crossing point, directed
from the negative crossing to the positive crossing. (Using directed
edges here is slightly non-standard.)</p>
<figure>
<img src="Fig/directed-Gauss-diagram.png" style="width:40.0%"
alt="A Gauss diagram for the signed Gauss code ABcdeFGChaIgDjKHbifEJK." />
<figcaption aria-hidden="true">A Gauss diagram for the signed Gauss code
<code>ABcdeFGChaIgDjKHbifEJK</code>.</figcaption>
</figure>
<h2 data-number="6.4" id="tracing-faces"><span
class="header-section-number">6.4</span> Tracing Faces</h2>
<p>Perhaps surprisingly, we can completely recover the combinatorial
structure of a curve from its signed Gauss code. I’ll justify this claim
in more generality later, when we’ve built up more background on planar
graphs, but we can already show one example, observed by Carter in the
early 1990s [2]: The signed Gauss code implicitly encodes the
<em>faces</em> of the curve.</p>
<p>Imagine a point moving counterclockwise around the boundary of some
face (or clockwise if the face is unbounded); the face always lies just
to the left of the moving point. Between vertices, the point is either
moving forward or backward along some edge of the image graph. At each
crossing, the point turns to the <em>left</em>, as follows:</p>
<ul>
<li>After entering a positive crossing forward, leave the corresponding
negative crossing backward.</li>
<li>After entering a negative crossing forward, leave the corresponding
positive crossing forward.</li>
<li>After entering a positive crossing backward, leave the corresponding
negative crossing forward.</li>
<li>After entering a negative crossing backward, leave the corresponding
positive crossing backward.</li>
</ul>
<p>Similar case analysis allows us to trace a face to the right of a
moving point, in clockwise order around the face, by turning right at
every vertex.</p>
<figure>
<img src="Fig/face-tracing.png" style="width:40.0%"
alt="Turning left or turning right at a vertex." />
<figcaption aria-hidden="true">Turning left or turning right at a
vertex.</figcaption>
</figure>
<p>(Pseudo)python (pseudo)code for Cater’s face-tracing algorithm is
shown below. The first function computes the matching between different
occurrences of the same crossing point; obviously this matching only
needs to be extracted once if we want to trace several faces. With
careful bookkeeping, we can extract <em>all</em> the faces of the curve
directly from the signed Gauss code in <span
class="math inline">\(O(n)\)</span> time. Different Gauss codes for the
same curve yield the same set of faces (but possibly with the vertices
of each face rotated and/or reflected).</p>
<pre><code># extract matching between crossings from a signed Gauss code
#   input:  code = signed Gauss code
#           = permutation of list(range(-n,0)) + list(range(1,n+1))
#   output:  array match, defined by code[match[i]] = -code[i]
def indexCode(code):
    N = len(code)/2
    posindex = [0] * (N/2)
    match = [0} * N
    for i in range(N):
        if code[i] &gt; 0:
            posindex[code[i] - 1] = i
    for i in range(N):
        if code[i] &lt; 0:
            match[i] = posindex[1 - code[i]]
            match[match[i]] = i
    return match    </code></pre>
<pre><code># trace the face to the right of a moving point
#   code = signed Gauss code (integers)
#   start = index of starting edge (basepoint edge = 0) 
#   forward = boolean indicating starting direction
def traceFace(code, starti, forward):
    match = matchCode(code)
    N = len(code)
    i = starti
    while True:
        next = forward ? i : (i + N - 1)%N
        print(code[next])
        if code[next] &gt; 0:
            forward = !forward
        i = match[next]
        if i = starti:
            break</code></pre>
<p>The clockwise tracing process can be visualized on the Gauss diagram
as follows. We start by tracing just inside an arc of the outer circle.
Whenever we reach a crossing, we follow the interior edge across the
diagram to its partner. If the crossing is positive, we stay on the same
side of the interior edge; if the crossing is negative, we switch to the
opposite side of the interior edge. Again, we can visualize
counterclockwise tracing by a symmetric case analysis.</p>
<figure>
<img src="Fig/directed-Gauss-diagram-face.png" style="width:40.0%"
alt="Tracing the outer face of our example curve (to the right of the basepoint)" />
<figcaption aria-hidden="true">Tracing the outer face of our example
curve (to the right of the basepoint)</figcaption>
</figure>
<h2 data-number="6.5" id="homotopy-moves"><span
class="header-section-number">6.5</span> Homotopy moves</h2>
<p>Every closed curve in the plane is homotopic to a point, and
therefore to every other closed curve in the plane. However, it is still
useful to study the <em>structure</em> of homotopies between generic
curves. Recall that the simplicial approximation theorem let us
approximate any homotopy between <em>polygons</em> as a finite sequence
of <em>vertex</em> moves. If we make sufficiently small vertex moves
that preserve genericity, each move incurs only a small local change in
the pattern of self-intersections.</p>
<p>Careful case analysis implies that every homotopy between generic
curves can be approximated by a finite sequence of <em>homotopy
moves</em> of five different types. Each homotopy move modifies the
curve only within a small neighborhood containing at most three
vertices, leaving the rest of the curve unchanged outside this
neighborhood.</p>
<ul>
<li><span class="math inline">\(1\mathord\to 0\)</span>: remove a
monogon</li>
<li><span class="math inline">\(0\mathord\to 1\)</span>: create a
monogon</li>
<li><span class="math inline">\(2\mathord\to 0\)</span>: remove a bigon
by separating two subpaths.</li>
<li><span class="math inline">\(0\mathord\to 2\)</span>: create a bigon
by overlapping two subpaths.</li>
<li><span class="math inline">\(3\mathord\to 3\)</span>: flip a triangle
by moving one subpath over the opposite crossing.</li>
</ul>
<figure>
<img src="Fig/homotopy-moves.png" style="width:90.0%"
alt="1\mathord\to 0, 2\mathord\to 0, and 3\mathord\to 3 homotopy moves" />
<figcaption aria-hidden="true"><span class="math inline">\(1\mathord\to
0\)</span>, <span class="math inline">\(2\mathord\to 0\)</span>, and
<span class="math inline">\(3\mathord\to 3\)</span> homotopy
moves</figcaption>
</figure>
<p>In particular, we have the following:</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every generic closed curve in the plane can be transformed into a
simple closed curve by a finite sequence of homotopy moves.</em>
</dd>
</dl>
<figure>
<img src="Fig/Gauss-curve-homotopy.png" style="width:95.0%"
alt="A sequence of homotopy moves simplifying the curve in Figure 1" />
<figcaption aria-hidden="true">A sequence of homotopy moves simplifying
the curve in Figure 1</figcaption>
</figure>
<p>The proof of this theorem (via simplicial approximation) follows from
the foundational work of Alexander and Briggs [1] and Reidemeister [2]
on knot diagrams.<a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a> This proof is fundamentally
non-constructive; the number of homotopy moves we need depends on the
geometric structure of the “given” homotopy. In a future lecture, we
will see an <em>algorithm</em>, implicit in the work of Steinitz [3,4] a
decade before Alexander, Briggs, or Reidemeister, that contracts any
closed curve with <span class="math inline">\(n\)</span> vertices using
at most <span class="math inline">\(O(n^2)\)</span> homotopy moves.</p>
<p>Each homotopy move can be implemented by locally modifying the Gauss
code/diagram, or the equivalent data structures, as follows.</p>
<ul>
<li><span class="math inline">\(1\mathord\to 0\)</span>: remove a
consecutive pair of crossings of the same vertex, for example:
<code>···Aa···</code></li>
<li><span class="math inline">\(2\mathord\to 0\)</span>: remove two
consecutive pairs, each with opposing signs, that cover two vertices,
for eaxmple: <code>···Ab···Ba···</code> or
<code>···aB···Ab···</code></li>
<li><span class="math inline">\(3\mathord\to 3\)</span>: reverse three
consecutive pairs that cover exactly three vertices, for example:
<code>···AB···bc···aC···</code> <span
class="math inline">\(\mapsto\)</span>
<code>···BA···cb···Ca···</code>.</li>
</ul>
<h2 data-number="6.6" id="planarity-testing"><span
class="header-section-number">6.6</span> Planarity testing</h2>
<p>Every signed Gauss code is a <em>signed double-permutation</em>: A
string of even length, in which each symbol appears exactly twice, once
positive and once negative. However, not every signed double-permutation
is the signed Gauss code of a planar curve. For example, no planar curve
has the signed Gauss code <code>ABab</code>. (This is in fact the signed
Gauss code of a closed curve on the <em>torus</em>!) However, signed
Gauss codes of planar curves have a very simple characterization.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every generic closed curve in the plane with <span
class="math inline">\(n\)</span> vertices has exactly <span
class="math inline">\(n+2\)</span> faces.</em>
</dd>
<dt><strong>Proof (via homotopy):</strong></dt>
<dd>
Consider two generic closed curves <span
class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\gamma&#39;\)</span> that differ by one homotopy
move. Suppose <span class="math inline">\(\gamma\)</span> has <span
class="math inline">\(n\)</span> vertices and <span
class="math inline">\(f\)</span> faces, and <span
class="math inline">\(\gamma&#39;\)</span> has <span
class="math inline">\(n&#39;\)</span> vertices and <span
class="math inline">\(f&#39;\)</span> faces.
</dd>
<dd>
<ul>
<li>If the move has type <span class="math inline">\(1\mathord\to
0\)</span>, then <span class="math inline">\(n&#39; = n-1\)</span> and
<span class="math inline">\(f&#39; = f-1\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the move has type <span class="math inline">\(0\mathord\to
1\)</span>, then <span class="math inline">\(n&#39; = n+1\)</span> and
<span class="math inline">\(f&#39; = f+1\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the move has type <span class="math inline">\(2\mathord\to
0\)</span>, then <span class="math inline">\(n&#39; = n-2\)</span> and
<span class="math inline">\(f&#39; = f-2\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the move has type <span class="math inline">\(0\mathord\to
2\)</span>, then <span class="math inline">\(n&#39; = n+2\)</span> and
<span class="math inline">\(f&#39; = f+2\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If the move has type <span class="math inline">\(3\mathord\to
3\)</span>, then <span class="math inline">\(n&#39; = n\)</span> and
<span class="math inline">\(f&#39; = f\)</span>.</li>
</ul>
</dd>
<dd>
<p>In all five cases, we have <span class="math inline">\(f-n =
f&#39;-n&#39;\)</span>.</p>
</dd>
<dd>
<p>It follows by induction that if <span
class="math inline">\(\gamma&#39;\)</span> is any curve reachable from
<span class="math inline">\(\gamma\)</span> by a finite sequence of
homotopy moves, then <span class="math inline">\(f-n =
f&#39;-n&#39;\)</span>. In particular, if <span
class="math inline">\(\gamma&#39;\)</span> is simple, then <span
class="math inline">\(n&#39;=0\)</span> and (by the Jordan curve
theorem!) <span class="math inline">\(f&#39;=2\)</span>, and therefore
<span class="math inline">\(f-n = 2\)</span>.</p>
</dd>
<dt><strong>Proof (sketch, via smoothing):</strong></dt>
<dd>
<strong><em>[[Define smoothing!]]</em></strong> Consider two generic
closed curves <span class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\gamma’\)</span> where <span
class="math inline">\(\gamma’\)</span> is the result of smoothing one
vertex of <span class="math inline">\(\gamma\)</span>. If <span
class="math inline">\(\gamma\)</span> has <span
class="math inline">\(n\)</span> vertices and <span
class="math inline">\(f\)</span> faces, then <span
class="math inline">\(\gamma&#39;\)</span> has <span
class="math inline">\(n-1\)</span> vertices and <span
class="math inline">\(f-1\)</span> faces. Every simple curve has <span
class="math inline">\(0\)</span> vertices and <span
class="math inline">\(2\)</span> faces. The lemma follows immediately by
induction on the number of vertices.
</dd>
</dl>
<p>In fact, the converse of this lemma is also true, although we don’t
yet have the tools to prove it:</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>A signed double-permutation is the signed Gauss code of a planar
curve if and only if it has two more faces than vertices.</em>
</dd>
</dl>
<p>If you have played with played with planar graphs before, you might
recognize this theorem as an avatar of <em>Euler’s formula</em> <span
class="math inline">\(V-E+F = 2\)</span>. Because every vertex in the
image graph of any non-simple curve has degree <span
class="math inline">\(4\)</span>, the number of edges is exactly twice
the number of vertices.</p>
<h2 data-number="6.7" id="dotsand-the-aptly-named-yadda-yadda-1"><span
class="header-section-number">6.7</span> <span
class="math inline">\(\dots\)</span>and the Aptly Named Yadda Yadda</h2>
<ul>
<li>Knots and knot diagrams</li>
<li>Carter surfaces of non-planar Gauss codes</li>
</ul>
<h2 data-number="6.8" id="references-4"><span
class="header-section-number">6.8</span> References</h2>
<ol type="1">
<li><p>James W. Alexander and Garland B. Briggs. <a
href="https://doi.org/10.2307/1968399">On types of knotted curves</a>.
<em>Ann. Math.</em> 28(1/4):562–586, 1926–1927. <em>Reidemeister moves,
with pictures.</em></p></li>
<li><p>J. Scott Carter. <a
href="https://doi.org/10.1090/S0002-9939-1991-1043406-7">Classifying
immersed curves</a>. Proc. Amer. Math. Soc. 111(1):281–287, 1991.
<em>The face-tracing algorithm to reconstruct curves from signed Gauss
codes.</em></p></li>
<li><p>Kurt Reidemeister. Elementare Begründung der Knotentheorie.
<em>Abh. Math. Sem. Hamburg</em> 5:24–32, 1927. <em>Reidemeister moves,
without pictures.</em></p></li>
<li><p>Ernst Steinitz. <a
href="http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN360609767&amp;DMDID=dmdlog203">Polyeder
und Raumeinteilungen.</a> <em>Enzyklopädie der mathematischen
Wissenschaften mit Einschluss ihrer Anwendungen</em> III.AB(12):1–139,
1916. <em>Proof of “Steinitz’s theorem” — Every 3-connected planar graph
is the 1-skeleton of a convex polyhedron — using <span
class="math inline">\(3\mathord\to 3\)</span> homotopy moves in the
medial graph. I promise those words will eventually make
sense.</em></p></li>
<li><p>Ernst Steinitz and Hans Rademacher. <em>Vorlesungen über die
Theorie der Polyeder: unter Einschluß der Elemente der Topologie</em>.
Grundlehren der mathematischen Wissenschaften 41. Springer-Verlag, 1934.
Reprinted 1976. <em>More detailed proof of “Steinitz’s theorem”, with
pictures.</em></p></li>
</ol>
<h2 data-number="6.9" id="possible-reorganization"><span
class="header-section-number">6.9</span> Possible reorganization</h2>
<p>Consider shuffling the topics in lectures 6–8:</p>
<ul>
<li>Generic curves intro
<ul>
<li>image graphs</li>
<li>oriented and connected smoothing</li>
<li>winding numbers</li>
<li>signed crossings</li>
<li>rotation numbers: smiles and frowns, writhe (via smoothing)</li>
</ul></li>
<li>Gauss codes
<ul>
<li>motivation for studying these things!</li>
<li>signed: Gauss diagrams, face tracing, Euler’s formula (via
smoothing)</li>
<li>unsigned: Nagy graphs, Dehn codes, interlacement</li>
</ul></li>
<li>Homotopy
<ul>
<li>homotopy moves</li>
<li>Steinitz’s contraction</li>
<li>regular homotopy, Whitney-Graustein, Nowik’s algorithm</li>
<li>defect and strangeness</li>
</ul></li>
</ul>
<h1 data-number="7" id="unsigned-gauss-codesbeta"><span
class="header-section-number">7</span> Unsigned Gauss codes<span
class="math inline">\(^\beta\)</span></h1>
<p>In the last lecture, we saw a simple algorithm to test whether a
signed Gauss code is consistent with a generic curve in the plane: Count
the faces (by symbol-chasing) and return true if and only if the number
of faces is exactly two more than the number of crossings.</p>
<p>In his unpublished notes, written around 1840, Gauss was asked how to
determine whether an <em>unsigned</em> Gauss code is consistent with a
planar curve [3]. The same question was published about 40 years later
by Tait [8]. I regard this as the first problem in computational
topology. (Euler’s famous Bridges of Königsberg is the <em>zeroth</em>
problem in computational topology.) B oht Gauss and Tait described a
<em>partial</em> solution to his problem. The first complete solution
was proposed by Julius Nagy almost a century later [4].<a href="#fn10"
class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<figure>
<img src="Fig/Nagy-census.png" style="width:60.0%"
alt="Nagy’s 1927 census of unsigned Gauss codes of lengths 6 through 10" />
<figcaption aria-hidden="true">Nagy’s 1927 census of unsigned Gauss
codes of lengths 6 through 10</figcaption>
</figure>
<p>In this lecture, I’ll describe an <span
class="math inline">\(O(n^2)\)</span>-time <em>algorithm</em> originally
described by Max Dehn in 1936 [1], with some simplifications suggested
by Nagy’s solution and more modern graph algorithms, as suggested by
Read and Rosenstiehl [11], Rosenstiehl and Tarjan [12], and de Fraysseix
and Ossona de Mendez [3].<a href="#fn11" class="footnote-ref"
id="fnref11" role="doc-noteref"><sup>11</sup></a> My presentation of
Dehn’s algorithm also closely follows Kaufmann. <strong><em>[[Fix
reference numbers]]</em></strong></p>
<h2 data-number="7.1" id="winding-numbers-again"><span
class="header-section-number">7.1</span> Winding numbers again</h2>
<p>Recall that the winding number of a polygon <span
class="math inline">\(P\)</span> around a point <span
class="math inline">\(o\)</span> can be computed by shooting a vertical
ray from <span class="math inline">\(o\)</span> and counting positive
and negative crossings with the polygon. The same characterization
extends to generic curves, but it’s a little unsatisfying, for a couple
of reasons. First, we only care about curves <em>up to isotopy</em>, but
the ray-shooting algorithm requires choosing a specific (arbitrary)
curve in the isotopy class. We can soften this objection somewhat by
observing that we don’t really need to count crossings with a
<em>ray</em>; any path from <span class="math inline">\(o\)</span> to
infinity that crosses the curve a finite number of times will work.</p>
<p>But there’s a more serious objection. Our representation of closed
curves (signed Gauss codes) doesn’t include any geometric information.
But how do we represent the point? We can’t give <em>coordinates</em>,
because different curves with the same representation have different
winding numbers around any <em>fixed</em> point!</p>
<p>Instead, we specify the obstacle point <span
class="math inline">\(o\)</span> by declaring which <em>face</em> of the
curve contains it. More cleanly, we define the winding number of a curve
<span class="math inline">\(\gamma\)</span> around each of its
<em>faces</em> using an <em>Alexander numbering</em>, we defined in
Lecture 2 for polygons. For any directed edge <span
class="math inline">\(e\)</span> of the image graph, let <span
class="math inline">\(\textsf{left}(e)\)</span> and <span
class="math inline">\(\textsf{right}(e)\)</span> denote the faces
immediately to the left and right of <span
class="math inline">\(e\)</span> (relative to the orientation of <span
class="math inline">\(e\)</span>).</p>
<ul>
<li>If <span class="math inline">\(f\)</span> is the outer face, then
<span class="math inline">\(\textsf{wind}(\gamma, f) = 0\)</span>.</li>
<li>For every directed edge <span class="math inline">\(e\)</span>, we
have <span class="math inline">\(\textsf{wind}(\textsf{left}(e)) =
\textsf{wind}(\textsf{right}(e)) + 1\)</span></li>
</ul>
<figure>
<img src="Fig/Listing-Alexander-numbering.png" style="width:30.0%"
alt="The Alexander numbering of a curve; bars indicate negation (Listing 1847)" />
<figcaption aria-hidden="true">The Alexander numbering of a curve; bars
indicate negation (Listing 1847)</figcaption>
</figure>
<h2 data-number="7.2" id="smoothing"><span
class="header-section-number">7.2</span> Smoothing</h2>
<p>Gauss observed that we can also define winding numbers by
<em>smoothing</em> the curve at each vertex. Smoothing replaces a
neighborhood of a single vertex with a pair of disjoint curve segments.
In fact there are two different smoothing operations, depending on how
the disjoint curve segments are attached. One smoothing operation
disconnects the curve (or connects two constituents of a multicurve) but
preserves the direction of both subcurves. The other keeps the curve
connected, but requires the direction of part of the curve to be
reversed.</p>
<figure>
<img src="Fig/Gauss-curve-smooth.png" style="width:95.0%"
alt="Smoothing a curve at a vertex. Left: preserving direction. Right: preserving connection." />
<figcaption aria-hidden="true">Smoothing a curve at a vertex. Left:
preserving direction. Right: preserving connection.</figcaption>
</figure>
<p>Gauss observed that by smoothing <em>every</em> vertex of a curve to
preserve direction, we can decompose the curve into a finite set of
disjoint <em>simple</em> curves. This collection of simple curves is
called the <em>Seifert</em> decomposition of the curve. Each of these
simple curves has winding number <span class="math inline">\(+1\)</span>
or <span class="math inline">\(-1\)</span> around its interior,
depending whether the curve is oriented counterclockwise or
clockwise.</p>
<p>The winding number of a curve <span
class="math inline">\(\gamma\)</span> around any point <span
class="math inline">\(o\)</span> (far from the vertices) is equal to the
sum of the winding numbers of the curves in the Seifert decomposition of
<span class="math inline">\(\gamma\)</span> around <span
class="math inline">\(o\)</span>. Equivalently, <span
class="math inline">\(\textsf{wind}(\gamma, 0)\)</span> is equal to the
number of counterclockwise cycles that contain <span
class="math inline">\(o\)</span> minus the number of clockwise cycles
that contain <span class="math inline">\(o\)</span>.</p>
<figure>
<img src="Fig/Gauss-Nachlass-example.png" style="width:35.0%"
alt="Gauss’s example of a Seifert decomposition" />
<figcaption aria-hidden="true">Gauss’s example of a Seifert
decomposition</figcaption>
</figure>
<h2 data-number="7.3" id="gausss-parity-condition"><span
class="header-section-number">7.3</span> Gauss’s parity condition</h2>
<p>Gauss observed without proof that the unsigned Gauss code of every
planar curve satisfies a simple parity condition: Every substring that
starts and ends with the same symbol has even length, or equivalently,
each symbol appears once at an even index and once at an odd index. This
parity condition was first proved necessary by Nagy. The following
simpler combinatorial proof is due to Rademacher and Toeplitz.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every pair of generic closed curves that intersect only transversely
intersect at an even number of points.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> be a transverse pair of generic
closed curves, directed arbitrarily. Imagine a point moving around <span
class="math inline">\(\alpha\)</span>. Each time this point crosses
<span class="math inline">\(\beta\)</span>, the winding number of <span
class="math inline">\(\beta\)</span> around that point changes by <span
class="math inline">\(1\)</span>, and therefore changes from even to odd
or vice versa. The moving point starts and ends in the same face of
<span class="math inline">\(\beta\)</span>, so its winding number change
parity an even number of times.
</dd>
</dl>
<p>Now let <span class="math inline">\(X\)</span> be a string of length
2n, in which each of the <span class="math inline">\(n\)</span> unique
symbols appears twice.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>If <span class="math inline">\(X\)</span> is the Gauss code of a
planar curve, then every substring of <span
class="math inline">\(X\)</span> that starts and ends with the same
symbol has even length.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\gamma\)</span> be a planar closed
curve. Smoothing <span class="math inline">\(\gamma\)</span> at any
vertex produces two subcurves <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>. Up to a cyclic shift (reflecting a
change of basepoint), the Gauss code for <span
class="math inline">\(\gamma\)</span> can be written as <span
class="math inline">\(axay\)</span>, where <span
class="math inline">\(a\)</span> is the label of the vertex, substring
<span class="math inline">\(x\)</span> encodes the crossings along <span
class="math inline">\(\alpha\)</span>, and string <span
class="math inline">\(y\)</span> encodes the crossings along <span
class="math inline">\(\beta\)</span>. Each self-intersection point of
<span class="math inline">\(\alpha\)</span> is encoded in <span
class="math inline">\(x\)</span> twice, and the other symbols of <span
class="math inline">\(x\)</span> encode the intersections between <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> We conclude that <span
class="math inline">\(x\)</span> has even length, which completes the
proof.
</dd>
</dl>
<p>We can test this parity condition in <span
class="math inline">\(O(n^2)\)</span> time by brute force, but in fact,
there is a simple linear-time algorithm. Given the Gauss code <span
class="math inline">\(X\)</span>, we can define a directed graph <span
class="math inline">\(G(X)\)</span>, which I’ll call the <em>Nagy
graph</em> of <span class="math inline">\(X\)</span>, as follows:</p>
<ul>
<li>The vertices of <span class="math inline">\(G(X)\)</span> correspond
to the <span class="math inline">\(n\)</span> distinct symbols in <span
class="math inline">\(X\)</span>.</li>
<li>The edges of <span class="math inline">\(G(x)\)</span> correspond to
(cyclic) substrings of <span class="math inline">\(X\)</span> with
length <span class="math inline">\(2\)</span>, alternately directed
forward and backward. That is, the Nagy graph contains a forward edge
<span class="math inline">\(x_i\to x_{i+1}\)</span> for every even index
<span class="math inline">\(i\)</span> and a backward edge and <span
class="math inline">\(x_{i+1}\to x_i\)</span> for every odd index <span
class="math inline">\(i\)</span>. For example, the Nagy graph of the
string <code>abcdefgchaigdjkhbifejk</code> contains the following edges:
<span class="math display">\[
  a\mathord\rightarrow b\mathord\leftarrow
  c\mathord\rightarrow d\mathord\leftarrow
  e\mathord\rightarrow f\mathord\leftarrow
  g\mathord\rightarrow c\mathord\leftarrow
  h\mathord\rightarrow a\mathord\leftarrow
  i\mathord\rightarrow g\mathord\leftarrow
  d\mathord\rightarrow j\mathord\leftarrow
  k\mathord\rightarrow h\mathord\leftarrow
  b\mathord\rightarrow i\mathord\leftarrow
  f\mathord\rightarrow e\mathord\leftarrow
  j\mathord\rightarrow k\mathord\leftarrow a
\]</span></li>
</ul>
<p>Let me emphasize (despite the figure below) that the Nagy graph of a
string is an <em>abstract graph</em>, which may or may not be
planar.</p>
<figure>
<img src="Fig/Gauss-code-alternating.png" style="width:35.0%"
alt="The Nagy graph of Gauss code abcdefgchaigdjkhbifejk; compare with Figure 6." />
<figcaption aria-hidden="true">The Nagy graph of Gauss code
<code>abcdefgchaigdjkhbifejk</code>; compare with Figure 6.</figcaption>
</figure>
<p>Now imagine a point moving around the Nagy graph <span
class="math inline">\(G(X)\)</span>, alternately traversing edges
forward and backward in the order they appear in <span
class="math inline">\(X\)</span>. Whenever the point passes through a
vertex of <span class="math inline">\(G(X)\)</span>, it either traverses
two inward edges <span class="math inline">\(u\mathord\rightarrow
v\mathord\leftarrow w\)</span> (one forward and one backward) or two
outward edges <span class="math inline">\(u\mathord\leftarrow
v\mathord\rightarrow w\)</span> (one backward and one forward). The
parity condition implies that if we leave any vertex <span
class="math inline">\(v\)</span> along a forward edge <span
class="math inline">\(v\mathord\to w\)</span>, we will next enter <span
class="math inline">\(v\)</span> along a backward edge <span
class="math inline">\(x\mathord\leftarrow v\)</span> and v vice versa.
In fact, these two conditions are equivalent.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>A Gauss code <span class="math inline">\(X\)</span> satisfies the
parity condition if and only if every vertex of its Nagy graph <span
class="math inline">\(G(X)\)</span> has in-degree 2 and out-degree <span
class="math inline">\(2\)</span>.</em>
</dd>
</dl>
<p>If a Gauss code does <em>not</em> satisfy the parity condition, then
its Nagy graph will contain at least one vertex with in-degree 0 and
out-degree 4, and an equal number of vertices with in-degree <span
class="math inline">\(4\)</span> and out-degree <span
class="math inline">\(0\)</span>.</p>
<p>We can easily construct the Nagy graph and check the degree of each
vertex in <span class="math inline">\(O(n)\)</span> time, where <span
class="math inline">\(X\)</span> is the length of the given Gauss code.
(There are simpler algorithms to check the parity condition in <span
class="math inline">\(O(n)\)</span> time, but we’ll need the Nagy graph
later, so we might as well build it now.)</p>
<p>Gauss also observed that the sequences <code>abcadcedbe</code> and
<code>abcabdecde</code> satisfy his parity condition but cannot be
realized by planar curves, so the parity condition is not sufficient.
Tait later gave a third example <code>abcadebdec</code>.</p>
<h2 data-number="7.4" id="dehns-non-crossing-condition"><span
class="header-section-number">7.4</span> Dehn’s non-crossing
condition</h2>
<p>About 100 years after Gauss, Dehn [1] described <em>das Gaussische
Problem der Trakte</em> and proposed an algorithm to solve it. Dehn
observed that smoothing every vertex of a curve <em>to keep the curve
connected</em> results in a simple closed curve that <em>touches</em>
itself at every vertex. The same closed curve <span
class="math inline">\(\gamma\)</span> can have several different
connected smoothings.</p>
<figure>
<img src="Fig/Gauss-code-curve-uncrossed.png" style="width:35.0%"
alt="A smoothed curve with Dehn code ahkjdchbcgibaifefgdejk" />
<figcaption aria-hidden="true">A smoothed curve with Dehn code
<code>ahkjdchbcgibaifefgdejk</code></figcaption>
</figure>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every connected smoothing of a planar curve <span
class="math inline">\(\gamma\)</span> is an Euler tour of the Nagy graph
<span class="math inline">\(G(X(\gamma))\)</span>, and vice versa.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Consider two consecutive edges <span class="math inline">\(u\mathord\to
v\mathord\to w\)</span> of <span class="math inline">\(\gamma\)</span>
(<em>not</em> edges of <span
class="math inline">\(G(X(\gamma))\)</span>). Imagine smoothing the
vertices of <span class="math inline">\(\gamma\)</span> one at a time.
Each smoothing reverses one of the subcurves from the smoothed vertex to
itself. The edges <span class="math inline">\(uv\)</span> and <span
class="math inline">\(vw\)</span> are reversed by all these same
smoothing <em>except</em> at their common vertex <span
class="math inline">\(x\)</span>. Thus, exactly one of the two subpaths
<span class="math inline">\(u\mathord\to v\)</span> or <span
class="math inline">\(v\mathord\to w\)</span> is revised in the final
Dehn smoothing. It follows that every Dehn smoothing of <span
class="math inline">\(\gamma\)</span> is an Euler tour of <span
class="math inline">\(G(X(\gamma))\)</span>.
</dd>
<dd>
<p>On the other hand, the edges incident to any vertex of <span
class="math inline">\(G(X(\gamma))\)</span> alternative in, out, in, out
in cyclic order. Thus, every Euler tour of <span
class="math inline">\(G(X(\gamma))\)</span> touches itself at every
vertex, but never crosses itself. It follows that every Euler tour of
<span class="math inline">\(G(X(\gamma))\)</span> is a connected
smoothing of <span class="math inline">\(\gamma\)</span>.</p>
</dd>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>A Gauss code <span class="math inline">\(X\)</span> is realized by a
planar curve if and only if its Nagy graph <span
class="math inline">\(G(X)\)</span> has a planar embedding in which at
least one (and therefore every) Euler tour is weakly simple.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
An Euler tour of a planar graph can cross itself only at vertices. If
<span class="math inline">\(X\)</span> is the Gauss code of a planar
curve <span class="math inline">\(\gamma\)</span>, the edges incident to
any vertex of <span class="math inline">\(G(X)\)</span>, embedded on top
of <span class="math inline">\(\gamma\)</span> in the obvious way,
alternate in-out-in-out in cyclic order, which makes a crossing at that
vertex impossible.
</dd>
<dd>
<p>On the other hand, suppose <span class="math inline">\(G(X)\)</span>
has a planar embedding with a weakly simple Euler tour. Then the edges
incident to each vertex in that embedding must alternate in-out-in-out
in cyclic order. The original Gauss code <span
class="math inline">\(X\)</span> defines an <em>undirected</em> Euler
tour <span class="math inline">\(U\)</span> of <span
class="math inline">\(G(X)\)</span>, which traverses edges of <span
class="math inline">\(G(X)\)</span> alternately forward and backward.
<span class="math inline">\(U\)</span> crosses itself at every vertex of
<span class="math inline">\(G(X)\)</span>. It follows immediately that
<span class="math inline">\(U\)</span> is a closed curve with Gauss code
<span class="math inline">\(X\)</span>.</p>
</dd>
</dl>
<h2 data-number="7.5" id="tree-onion-figures"><span
class="header-section-number">7.5</span> Tree-onion figures</h2>
<p>Dehn described a symbolic algorithm to test his non-crossing
condition in terms of the sequence of <em>self-touching</em> points in
order along the smoothed curve <span
class="math inline">\(\tilde\gamma\)</span>. Just like Gauss codes, this
sequence contains exactly two occurrences of every symbol. To
distinguish this sequence from the Gauss code of a curve, I’ll refer to
this new string as a <em>Dehn code</em>. We can similarly define the
<em>Dehn diagram</em> of <span
class="math inline">\(\tilde\gamma\)</span> as a cycle of <span
class="math inline">\(2n\)</span> vertices, corresponding to the labels
in the Dehn code, plus chords connecting identical labels.<a
href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>Dehn observed that the Dehn diagram of any connected smoothing <span
class="math inline">\(\tilde\gamma\)</span> of any planar curve <span
class="math inline">\(\gamma\)</span> is a <em>planar</em> graph; that
is, we can embed some of the chords of the diagram inside the circle and
the rest outside the circle, so that no pair of chords intersects.
Specifically, if we perturb <span
class="math inline">\(\tilde\gamma\)</span> slightly into a simple
curve, the neighborhood of each vertex either has connected intersection
with the interior of <span class="math inline">\(\tilde\gamma\)</span>
or connected intersection with the exterior of <span
class="math inline">\(\tilde\gamma\)</span>. These vertices correspond
to inner and outer chords, respectively.</p>
<figure>
<img src="Fig/outer-Gauss-diagram.png" style="width:40.0%"
alt="A planar Dehn diagram for the Dehn code ahkjdchbcgibaifefgdejk; compare with the previous figure!" />
<figcaption aria-hidden="true">A planar Dehn diagram for the Dehn code
<code>ahkjdchbcgibaifefgdejk</code>; compare with the previous
figure!</figcaption>
</figure>
<p>Dehn playfully referred to these planar diagrams as “Baum-Zwiebel
Figuren” [“tree-onion diagrams”] and their corresponding Gauss codes as
“Baum-Zwiebel Reihen” [“tree-onion strings”]. Tree onions, also known as
walking onions or Egyptian onions, are onion cultivars that grow
clusters of small bulbs at the top of the stem, where other
<em>Allium</em> species have flowers. The chords of a tree-onion figure
(loosely) resemble clusters of onion layers. Coincidentally(?), the dual
graph of the inner chords (or the outer chords) of any tree-onion figure
is a tree.<a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
<figure>
<img src="Fig/Dehn-BZ-Figur.png" style="width:30.0%"
alt="A tree-onion figure [Dehn 1936]" />
<figcaption aria-hidden="true">A tree-onion figure [Dehn
1936]</figcaption>
</figure>
<figure>
<img src="Fig/tree-onion-photo.jpg" style="width:40.0%"
alt="Tree onion bulblets. [Kurt Stüber 2004, CC BY-SA 3.0, via Wikimedia Commons]" />
<figcaption aria-hidden="true">Tree onion bulblets. [Kurt Stüber 2004,
<a href="http://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA
3.0</a>, via <a
href="https://commons.wikimedia.org/wiki/File:Allium_fistulosum_bulbifera0.jpg">Wikimedia
Commons</a>]</figcaption>
</figure>
<figure>
<img src="Fig/childs-tree-onion.jpg" style="width:40.0%"
alt="Egyptian tree onion. From Child’s Rare Flowers, Vegetables &amp; Fruits (1894)" />
<figcaption aria-hidden="true">Egyptian tree onion. From <em>Child’s
Rare Flowers, Vegetables &amp; Fruits</em> (1894)</figcaption>
</figure>
<p>(Petersen [9] used similar diagrams in 1891 to study abstract regular
graphs. Consider a connected <span
class="math inline">\(4\)</span>-regular graph <span
class="math inline">\(G\)</span> with <span
class="math inline">\(n\)</span> vertices. Petersen defined a “stretched
graph” by representing any Euler tour of <span
class="math inline">\(G\)</span> as a cycle of length <span
class="math inline">\(2n\)</span>, with additional edges connecting the
two occurrence of each vertex of <span class="math inline">\(G\)</span>.
If we alternately color the edges this cycle red and blue, every vertex
of <span class="math inline">\(G\)</span> is incident to two edges of
each color. Thus, every <span class="math inline">\(4\)</span>-regular
graph can be decomposed into two 2-factors. Applying Petersen’s
construction to any curve, as an Euler tour of its image graph, recovers
the forward and backward cycles in the curve’s Nagy graph.)</p>
<figure>
<img src="Fig/Petersen-diagram.png" style="width:50.0%"
alt="Petersen’s diagram of an Euler tour (Petersen 1891)" />
<figcaption aria-hidden="true">Petersen’s diagram of an Euler tour
(Petersen 1891)</figcaption>
</figure>
<h2 data-number="7.6" id="bipartite-interlacement"><span
class="header-section-number">7.6</span> Bipartite interlacement</h2>
<p>Read and Rosenstiehl [6] observed that Dehn’s planarity condition can
verified efficiently by constructing yet another graph, called the
<em>interlacement graph</em> of the Dehn code. The interlacement graph
has <span class="math inline">\(n\)</span> vertices, one for each
symbol, and an edge between any two symbols <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> whose appearances are interlaced <span
class="math inline">\(x\dots y \dots x\dots y\)</span> in the Dehn code.
Partitioning the chords of a Dehn diagram into pairwise disjoint inner
and outer chords is equivalent to partitioning the vertices of the
interlacement graph into two independent sets. In other words, a Dehn
diagram is planar if and only if its interlacement graph is
bipartite.</p>
<figure>
<img src="Fig/interleave-graph.png" style="width:40.0%"
alt="The bipartite interlacement graph for the Dehn code ahkjdchbcgibaifefgdejk" />
<figcaption aria-hidden="true">The bipartite interlacement graph for the
Dehn code <code>ahkjdchbcgibaifefgdejk</code></figcaption>
</figure>
<h2 data-number="7.7" id="recrossing"><span
class="header-section-number">7.7</span> Recrossing</h2>
<p>To complete his algorithm, Dehn observed that we can transform the
Dehn diagram of any Euler tour of <span
class="math inline">\(G(X)\)</span> into a 4-regular graph by replacing
each chord with a pair of crossing chords with a crossing, as shown
below. Assuming the interlacement graph of the Dehn code is bipartite,
the corresponding Dehn diagram is planar, so this recrossing process
yields a single closed curve consistent with our original Gauss code
<span class="math inline">\(X\)</span>.</p>
<figure>
<img src="Fig/Dehn-recross.png" style="width:25.0%"
alt="Building a closed curve from a tree-onion-diagram (Dehn 1936)" />
<figcaption aria-hidden="true">Building a closed curve from a
tree-onion-diagram (Dehn 1936)</figcaption>
</figure>
<figure>
<img src="Fig/Dehn-Gauss-retangle.png" style="width:65.0%"
alt="A planar curve consistent with the original Gauss code abcdefgchaigdjkhbifejk" />
<figcaption aria-hidden="true">A planar curve consistent with the
original Gauss code <code>abcdefgchaigdjkhbifejk</code></figcaption>
</figure>
<p>Putting all the pieces together, we conclude:</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>A Gauss code <span class="math inline">\(X\)</span> can be realized
by a planar closed curve if and only if at least one (and therefore
every) Euler tour of <span class="math inline">\(G(X)\)</span> has a
bipartite interlacement graph.</em>
</dd>
</dl>
<h2 data-number="7.8" id="algorithm-summary"><span
class="header-section-number">7.8</span> Algorithm summary</h2>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Given a Gauss code <span class="math inline">\(X\)</span> of length
<span class="math inline">\(2n\)</span>, we can either construct a
planar curve consistent with <span class="math inline">\(X\)</span> or
correctly report that no such curve exists, in <span
class="math inline">\(O(n^2)\)</span> time.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
The algorithm proceeds as follows:
</dd>
<dd>
<ol type="1">
<li>Construct the Nagy graph <span class="math inline">\(G(X)\)</span>
of <span class="math inline">\(X\)</span>. This can be done in <span
class="math inline">\(O(n)\)</span> time by brute force. If any vertex
of <span class="math inline">\(G(X)\)</span> has no outgoing edges, halt
and report that <span class="math inline">\(X\)</span> is not
realizable. Otherwise, <span class="math inline">\(G(X)\)</span> is
Eulerian, and thus <span class="math inline">\(X\)</span> satisfies
Gauss’s parity condition.</li>
</ol>
</dd>
<dd>
<ol start="2" type="1">
<li>Compute any Euler tour of <span class="math inline">\(G(X)\)</span>.
This can be done in <span class="math inline">\(O(n)\)</span> time using
the well-known algorithm of Hierholzer (not Euler!).</li>
</ol>
</dd>
<dd>
<ol start="3" type="1">
<li>Construct the Dehn code <span
class="math inline">\(\tilde{X}\)</span> of this Euler tour. This can be
done in <span class="math inline">\(O(n)\)</span> time by brute
force.</li>
</ol>
</dd>
<dd>
<ol start="4" type="1">
<li>Construct the interlacement graph <span
class="math inline">\(I(\tilde{X})\)</span> of <span
class="math inline">\(\tilde{X}\)</span>. This can be done in <span
class="math inline">\(O(n^2)\)</span> time by brute force.</li>
</ol>
</dd>
<dd>
<ol start="5" type="1">
<li>Verify that the interlacement graph is bipartite. The interlacement
graph has <span class="math inline">\(n\)</span> vertices and at most
<span class="math inline">\(O(n^2)\)</span> edges, so we can verify
bipartiteness in <span class="math inline">\(O(n^2)\)</span> time uysing
whatever-first search. If the interlacement graph is not bipartite, halt
and report that <span class="math inline">\(X\)</span> is not
realizable.</li>
</ol>
</dd>
<dd>
<ol start="6" type="1">
<li>Build a tree-onion figure for <span
class="math inline">\(\tilde{X}\)</span> from any partition of nodes in
the interlacement graph. This can be done in <span
class="math inline">\(O(n)\)</span> time by brute force.</li>
</ol>
</dd>
<dd>
<ol start="7" type="1">
<li>Transform the plane Dehn diagram into a 4-regular plane graph by
replacing each chord with a pair of crossing chords, as shown in Figures
13 and 14. This can be done in <span class="math inline">\(O(n)\)</span>
time by brute force; the result is a closed curve consistent with our
original Gauss code <span class="math inline">\(X\)</span>.</li>
</ol>
</dd>
</dl>
<figure>
<img src="Fig/Gauss-code-algorithm-examples.png" style="width:100.0%"
alt="Two examples of Dehn’s Gauss-code algorithm in action" />
<figcaption aria-hidden="true">Two examples of Dehn’s Gauss-code
algorithm in action</figcaption>
</figure>
<h2 data-number="7.9" id="faster-faster"><span
class="header-section-number">7.9</span> Faster! Faster!</h2>
<p>There are several linear-time algorithms to test the interlacement
condition <em>without</em> explicitly constructing the interlacement
graph, but we’re out of time.</p>
<h2 data-number="7.10" id="dotsand-the-aptly-named-yadda-yadda-2"><span
class="header-section-number">7.10</span> <span
class="math inline">\(\dots\)</span>and the Aptly Named Yadda Yadda</h2>
<ul>
<li>Tait-Dowker-Thistlethwaite codes</li>
<li>Pile of twin stacks algorithm</li>
<li>Left-right graph planarity test</li>
</ul>
<h2 data-number="7.11" id="references-5"><span
class="header-section-number">7.11</span> References</h2>
<ol type="1">
<li><p>Max Dehn. <a href="https://doi.org/10.1007/BF02401740">Über
kombinatorishe Topologie</a>. <em>Acta Math.</em> 67:123–168,
1936.</p></li>
<li><p>Clifford H. Dowker and Morwen B. Thistlethwaite. <a
href="https://doi.org/10.1016/0166-8641(83)90004-4">Classification of
knot projections</a>. <em>Topology Appl.</em> 16(1):19–31,
1983.</p></li>
<li><p>Hubert de Fraysseix and Patrice Ossona de Mendez. <a
href="https://doi.org/10.1007/3-540-63938-1_65">A short proof of a Gauss
problem</a>. <em>Proc. 5th Int. Symp. Graph Drawing</em>, 230–235, 1997.
Lecture Notes Comput. Sci. 1353, Springer.</p></li>
<li><p>Carl Friedrich Gauß. Nachlass. I. Zur Geometria situs.
<em>Werke</em>, vol. 8, 271–281, 1900. Teubner. Originally written
between 1823 and 1840.</p></li>
<li><p>Carl Hierholzer. <a
href="https://doi.org/10.1007/BF01442866">Über die Möglichkeit, einen
Linienzug Ohne Wiederholung und ohne Unterbrech nung zu umfahren.</a>
<em>Math. Ann.</em> 6:30–32, 1873.</p></li>
<li><p>Louis H. Kauffman. <a
href="https://doi.org/10.1142/S0129055X93000231">Gauss codes, quantum
groups and ribbon Hopf algebras</a>. <em>Rev. Math, Phys.</em>
5(4):735–773, 1993.</p></li>
<li><p>Louis H. Kauffman. <a
href="https://doi.org/10.1006/eujc.1999.0314">Virtual knot theory</a>.
<em>Europ. J. Combin.</em> 20(7):663–691, 1999. arXiv:<a
href="https://arxiv.org/abs/math/9811028">math/9811028</a>.</p></li>
<li><p>Julius v. Sz. Nagy. <a
href="https://doi.org/10.1007/BF01475475">Über ein topologisches Problem
von Gauß</a>. <em>Math. Z.</em> 26(1):579–592, 1927.</p></li>
<li><p>Julius Petersen. <a href="https://doi.org/10.1007/BF02392606">Die
Theorie der regulären graphs.</a> <em>Acta Math.</em> 15:193–220, 1891.
Yes, really, “graphs” not “Graphen”.</p></li>
<li><p>Hans Rademacher and Otto Toeplitz. On closed self-intersecting
curves. <em>The Enjoyment of Mathematics: Selections from Mathematics
for the Amateur</em>, chapter 10, 61–66, 1990. Dover Publ. Originally
published by Princeton Univ. Press, 1957.</p></li>
<li><p>Ronald C. Read and Pierre Rosenstiehl. On the Gauss crossing
problem. <em>Combinatorics</em>, 843–876, 1976. Colloq. Math. Soc. János
Bolyai 18, North-Holland. Modern description of Dehn’s solution to the
Gauss code problem.</p></li>
<li><p>Pierre Rosenstiehl and Robert E. Tarjan. <a
href="https://doi.org/10.1016/0196-6774(84)90018-X">Gauss codes, planar
Hamiltonian graphs, and stack-sortable permutations</a>. <em>J.
Algorithms</em> 5(3):375–390, 1984. Linear-time implementation of Dehn’s
solution to the Gauss code problem.</p></li>
<li><p>Peter Guthrie Tait. <a
href="https://babel.hathitrust.org/cgi/pt?id=njp.32101074834365&amp;seq=199">On
knots I.</a> <em>Trans. Royal Soc. Edinburgh</em> 28(1):145–190,
1876–7.</p></li>
</ol>
<h1 data-number="8" id="curve-homotopy-and-curve-invariantsalpha"><span
class="header-section-number">8</span> Curve homotopy and curve
invariants<span class="math inline">\(^\alpha\)</span></h1>
<p><strong><em>Caveat Lector: This note is still pretty
sketchy!</em></strong></p>
<p>In an earlier lecture we argued that any generic curve in the plane
can be continuously deformed into any other by a finite sequence of
homotopy moves. But our earlier argument was unsatisfying for a number
of reasons. First, I deliberately glossed over several details; while I
claim that these details are ultimately mechanical, <em>you</em> have no
reason to believe my assessment, or even that I’ve worked out the
details at all. (I <em>have</em> worked out the details, but my mere
claim shouldn’t be enough to convince you. Proof by Old Tenured White
Dude is not a proof at all.) Second, the proof is nonconstructive.
Third, the proof gives us no idea <em>how many</em> homotopy moves are
required.</p>
<h2 data-number="8.1" id="steinitzs-contraction-algorithm"><span
class="header-section-number">8.1</span> Steinitz’s contraction
algorithm</h2>
<p>The following constructive algorithm for contracting a generic curve
via homotopy moves is implicit in Steinitz’s 1916 proof of the seminal
theorem that bears his name: A graph <span
class="math inline">\(G\)</span> is the 1-skeleton of a
three-dimensional convex polyhedron if and only if <span
class="math inline">\(G\)</span> is planar and 3-connected. (I’ll
explain the connection between this algorithm and Steinitz’s theorem
later in the course.)</p>
<p>We first define some useful substructures of non-simple generic
curves. A <em>loop</em> in a curve <span
class="math inline">\(\gamma\)</span> is a simple subpath of <span
class="math inline">\(\gamma\)</span> that starts and ends at the same
vertex. A <em>spindle</em> is a pair of simple, interior-disjoint
subpaths of <span class="math inline">\(\gamma\)</span> with the same
distinct endpoints. A <em>vertex</em> of a spindle is an endpoint of the
subpaths of <span class="math inline">\(\gamma\)</span> that defines it.
A spindle is <em>convex</em> if its interior contains exactly one corner
of each vertex. A spindle is <em>irreducible</em> if its interior does
not contain the interior of another bigon; easy case analysis implies
that every irreducible spindle is convex. A <em>monogon</em> is a face
whose boundary is a loop; a <em>bigon</em> is a face whose boundary is a
(necessarily convex) spindle.</p>
<figure>
<img src="Fig/loops+spindles.png" style="width:70.0%"
alt="Non-minimal loops and spindles; only the first loop and spindle are “convex”." />
<figcaption aria-hidden="true">Non-minimal loops and spindles; only the
first loop and spindle are “convex”.</figcaption>
</figure>
<dl>
<dt><strong>Lemma (Steinitz):</strong></dt>
<dd>
<em>Let <span class="math inline">\(\gamma\)</span> be a non-simple
curve with no monogons. There is at least one irreducible spindle in
<span class="math inline">\(\gamma\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(x\)</span> be the first vertex
encountered twice when traversing <span
class="math inline">\(\gamma\)</span> from an arbitrary basepoint; the
subpath of <span class="math inline">\(\gamma\)</span> between the two
occurrences of <span class="math inline">\(x\)</span> is a loop. Thus,
<span class="math inline">\(\gamma\)</span> contains at least one loop.
Let <span class="math inline">\(\ell\)</span> be the loop with the
fewest faces in its interior, breaking ties arbitrarily.
</dd>
<dd>
<p>We call any maximal subpath of <span
class="math inline">\(\gamma\)</span> in the interior of <span
class="math inline">\(\ell\)</span> a <em>strand</em>. There must be at
least one strand, since otherwise <span
class="math inline">\(\ell\)</span> would be a monogon. The minimality
of <span class="math inline">\(\ell\)</span> implies that each strand is
a <em>simple</em> path. Each strand in <span
class="math inline">\(\ell\)</span> forms a convex spindle with some
subpath of <span class="math inline">\(\ell\)</span>; thus, <span
class="math inline">\(\gamma\)</span> contains at least one spindle. Any
spindle with the fewest faces in its interior is irreducible.</p>
</dd>
</dl>
<figure>
<img src="Fig/Steinitz-Spindel.png" style="width:35.0%"
alt="An irreducible spindle with six boundary triangles (Steinitz and Rademacher 1934)." />
<figcaption aria-hidden="true">An irreducible spindle with six boundary
triangles (Steinitz and Rademacher 1934).</figcaption>
</figure>
<dl>
<dt><strong>Lemma (Steinitz):</strong></dt>
<dd>
<em>Let <span class="math inline">\(\gamma\)</span> be a non-simple
curve with no monogons, and let <span
class="math inline">\(\sigma\)</span> be any irreducible spindle in
<span class="math inline">\(\gamma\)</span>. Either <span
class="math inline">\(\sigma\)</span> is a bigon, or there is a
triangular face in the interior of <span
class="math inline">\(\sigma\)</span> that shares an edge with <span
class="math inline">\(\sigma\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Again, any maximal subpath of <span
class="math inline">\(\gamma\)</span> in the interior of <span
class="math inline">\(\sigma\)</span> a <em>strand</em>; there must be
at least one strand, since otherwise <span
class="math inline">\(\sigma\)</span> is a bigon. Irreducibility implies
that the strands satisfy three conditions:
</dd>
<dd>
<ul>
<li>Every strand is simple. (Otherwise a strand would contain a loop,
and therefore either a monogon or a smaller spindle.)</li>
</ul>
</dd>
<dd>
<ul>
<li>Every strand has one endpoint on each subpath defining <span
class="math inline">\(\sigma\)</span>. (Otherwise, that strand would
form a smaller spindle with one side of <span
class="math inline">\(\sigma\)</span>.)</li>
</ul>
</dd>
<dd>
<ul>
<li>Every pair of strands intersects at most once. (Otherwise, some pair
of strands would define a smaller spindle.)</li>
</ul>
</dd>
<dd>
<p>Now there are two cases to consider. If no pair of strands
intersects, the faces at both vertices are triangles, each sharing
<em>two</em> edges with <span class="math inline">\(\sigma\)</span>.
Otherwise, imagine continuously sweeping a curve through the interior of
<span class="math inline">\(\sigma\)</span> from one boundary subpath to
the other, and let <span class="math inline">\(x\)</span> be the first
interior vertex that this curve sweeps over. The two strands that
intersect at <span class="math inline">\(x\)</span> form a triangular
face with one of the boundary curves of <span
class="math inline">\(\sigma\)</span>.</p>
</dd>
</dl>
<p>With these two lemmas in hand, we can now describe Steinitz’s
algorithm. Let <span class="math inline">\(\gamma\)</span> be any
generic curve with <span class="math inline">\(n\)</span> vertices. If
<span class="math inline">\(n=0\)</span>, the curve is simple and there
is nothing to do. If <span class="math inline">\(\gamma\)</span>
contains a loop, remove it with a single <span
class="math inline">\(1\to0\)</span> move and recursively simplify the
remaining curve. Otherwise, let <span
class="math inline">\(\sigma\)</span> be any irreducible spindle. We
empty <span class="math inline">\(\sigma\)</span> by repeatedly
performing <span class="math inline">\(3\to3\)</span> moves, each time
moving a triangular face from the interior of <span
class="math inline">\(\sigma\)</span> to the exterior. Once <span
class="math inline">\(\sigma\)</span> becomes a bigon, we remove it with
a single <span class="math inline">\(2 \to 0\)</span> move, and then
recursively simplify the remaining curve.</p>
<figure>
<img src="Fig/Steinitz-moves.png" style="width:100.0%"
alt="Extracting a triangle from a spindle (Steinitz Rademacher 1934)." />
<figcaption aria-hidden="true">Extracting a triangle from a spindle
(Steinitz Rademacher 1934).</figcaption>
</figure>
<p>In the worst case, the algorithm uses <span
class="math inline">\(O(n)\)</span> moves to empty and remove each
irreducible spindle. Each phase of the algorithm removes either one or
two vertices. Thus, the algorithm runs through <span
class="math inline">\(\Theta(n)\)</span> phases, each with <span
class="math inline">\(O(n)\)</span> moves, so it makes <span
class="math inline">\(O(n^2)\)</span> moves altogether. This analysis is
tight; Steinitz’s algorithm requires <span
class="math inline">\(\Omega(n^2)\)</span> moves in the worst case.</p>
<p>This is not the fastest contraction algorithm known; in 2016,
Hsien-Chih Chang and I described an algorithm to contract any planar
curve Hsien using only <span class="math inline">\(O(n^{3/2})\)</span>
homotopy moves; we also proved a matching <span
class="math inline">\(\Omega(n^{3/2})\)</span> worst-case upper bound.
However, unlike Steinitz’s algorithm, our faster algorithm sometimes
uses <span class="math inline">\(0\to2\)</span> moves. In 2022, Santiago
Aranguri, Hsien-Chih Chang, and Dylan Fridman finally proved that any
planar curve can be contracted using a sequence of <span
class="math inline">\(O(n^{3/2})\)</span> homotopy moves that never
increases the number of vertices; the sequence includes only <span
class="math inline">\(1\mathord\to 0\)</span>, <span
class="math inline">\(2\mathord\to 0\)</span>, and <span
class="math inline">\(3\mathord\to3\)</span> moves.</p>
<h2 data-number="8.2" id="rotation-number"><span
class="header-section-number">8.2</span> Rotation number</h2>
<p>Definition: winding number oof the derivative around the origin.
Always an integer. For simple curves, either <span
class="math inline">\(+1\)</span> or <span
class="math inline">\(-1\)</span>; equal to the winding number around
any interior point.</p>
<p>For polygons, equal to sum of exterior angles. (Studied by Meister in
the 1700s, and arguably by Bradwardine in the 1300s.)</p>
<p>Classify points with rightward tangents as <em>happy</em> or
<em>sad</em>; rotation number = #happy <span
class="math inline">\(-\)</span> #sad. [Gauss, possibly Meister]</p>
<p>Gauss: Also equal to sum of rotation numbers of Seifert circles.</p>
<p>But our usual representation doesn’t give us access to tangents or
curvature; indeed, generic curves need not have well-defined tangents.
Instead we use a combinatorial formula known to Gauss in terms of the
<em>writhe</em> of the curve. The writhe is defined as the sum over all
vertices of the sign of the <em>first</em> crossing at that vertex; we
emphasize that writhe is a function of both the curve and the basepoint.
<span class="math display">\[
    \textsf{writhe}(\gamma) = \sum_x \textsf{sgn}(x)
\]</span> To state Gauss’s formula succinctly, we also need to extend
the definition of winding number to points on the curve. We define the
winding number along an edge of the image graph as the average of the
winding numbers of its two incident faces; this is always a
half-integer. Similarly, we define the winding number of a curve around
one of its vertices as the average of the winding numbers of the four
faces incident to that vertex; this is always an integer. (Two of those
four faces may be the same face.) We specifically define <span
class="math inline">\(\textsf{wind}_0(\gamma)\)</span> to be the winding
number of <span class="math inline">\(\gamma\)</span> around its
basepoint.</p>
<dl>
<dt><strong>Lemma (Gauss):</strong></dt>
<dd>
<span class="math inline">\(\textsf{rot}(\gamma) = 2 \cdot
\textsf{wind}_0(\gamma) + \textsf{writhe}(\gamma)\)</span>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Moving the basepoint through a positive crossing changes it into a
negative crossing (so the writhe decreases by <span
class="math inline">\(2\)</span>), but it also increases the winding
number around the basepoint by <span class="math inline">\(1\)</span>.
(So without loss of generality, we could assume that the basepoint is on
the outer face and therefore <span
class="math inline">\(\textsf{wind}_0(\gamma)= \pm 1/2\)</span>, but
this won’t be necessary.)
</dd>
<dd>
<p>Any continuous deformation of the curve that does not change the
number of vertices can only create and destroy happy and sad points in
matched pairs. (Deforming the curve also deforms its derivative, and the
deformation of the derivative that avoids the origin can only create or
destroy crossings with the positive <span
class="math inline">\(x\)</span>-axis in matched positive-negative
pairs. Think in terms of homotopy moves!) So rotation number is an
<em>isotopy</em> invariant.</p>
</dd>
<dd>
<p>Now we argue by induction over any sequence of homotopy moves that
leads to a simple cycle. We assume the basepoint is far away from
whatever move we’re analyzing, so <span
class="math inline">\(\textsf{wind}_0(\gamma)\)</span> doesn’t
change.</p>
</dd>
<dd>
<ul>
<li><span class="math inline">\(0\mathord\to 1\)</span>: If the deleted
vertex is positive, the loop is oriented counterclockwise, so the move
decreases both the rotation number and the writhe by <span
class="math inline">\(1\)</span>. Similarly, deleting a negative vertex
increases both rotation number and writhe by <span
class="math inline">\(1\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li><span class="math inline">\(2\mathord\to 0\)</span>: The two
vertices have opposite signs, so the writhe doesn’t change. But the
number of happy and sad points doesn’t change either, so the rotation
number doesn’t change.</li>
</ul>
</dd>
<dd>
<ul>
<li><span class="math inline">\(3\mathord\to 3\)</span>: Nothing in the
formula changes.</li>
</ul>
</dd>
<dd>
<p>Finally, we observe that the formula is trivially correct when the
curve is simple.</p>
</dd>
</dl>
<p><em>Would it be easier to argue by induction on the number of
vertices via oriented smoothing? By induction we have <span
class="math inline">\(\textsf{rot}(\gamma) = \textsf{rot}(\gamma^-) +
\textsf{rot}(\gamma^+) = 2 \cdot \textsf{wind}_0(\gamma^-) +
\textsf{writhe}(\gamma^-) + 2 \cdot \textsf{wind}_0(\gamma^+) +
\textsf{writhe}(\gamma+)\)</span>. The smoothed vertex vanishes, but it
becomes the basepoint of one of the two constituent curves. The number
of crossings between the two constituent curves <span
class="math inline">\(\gamma^-\)</span> and <span
class="math inline">\(\gamma^+\)</span> is even, with exactly half
positive and half negative. So we need to relate <span
class="math inline">\(\textsf{wind}_0(\gamma^+)\)</span> to the sign of
the smoothed vertex.</em></p>
<h2 data-number="8.3" id="regular-homotopy"><span
class="header-section-number">8.3</span> Regular homotopy</h2>
<p>No <span class="math inline">\(1\mathord\to 0\)</span> or <span
class="math inline">\(0\mathord\to 1\)</span> moves. So rotation number
never changes.</p>
<p>Nowik’s algorithm: Without loss of generality the basepoint is on the
outer face. Repeat the following until the curve consists of empty
loops:</p>
<ul>
<li>Find a simple loop.</li>
<li>Empty the loop (two moves per interior vertex, plus one move for
each remaining interior strand)</li>
<li>Move the loop close to the basepoint</li>
<li>Boy’s trick: Cancel two adjacent loops on opposite sides.</li>
</ul>
<p>When these iterations end, either all loops are inside or all loops
are outside. We can deform one canonical curve to the other using a
linear number of moves. Altogether, the algorithm requires <span
class="math inline">\(O(n^2)\)</span> moves to canonize a curve with
<span class="math inline">\(n\)</span> vertices.</p>
<p>it follows that rotation number is a complete regular homotopy
invariant (just like winding number around a point is a homotopy
invariant in the once-punctured plane).</p>
<h2 data-number="8.4" id="strangeness"><span
class="header-section-number">8.4</span> Strangeness</h2>
<p><em>(Cite Arnold, Aicardi, Polyak, inter alia)</em></p>
<p><span class="math display">\[
    \textsf{strange}(\gamma) = \textsf{wind}_0^2(\gamma) - \frac{1}{4} +
\sum_x \textsf{sgn}(x) \cdot \textsf{wind}(\gamma, x)
\]</span></p>
<p>Basepoint independence: moving the basepoint across a positive vertex
<span class="math inline">\(x\)</span> with winding number <span
class="math inline">\(w\)</span> changes <span
class="math inline">\(x\)</span> to a negative vertex (decreasing the
sum by <span class="math inline">\(2w\)</span>), but increases <span
class="math inline">\(\textsf{wind}_0\)</span> from <span
class="math inline">\(w-1/2\)</span> to <span
class="math inline">\(w+1/2\)</span> (increasing <span
class="math inline">\(\textsf{wind}_0^2(\gamma)\)</span> by <span
class="math inline">\(2w\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Each <span class="math inline">\(3\to 3\)</span> move changes
strangeness by exactly <span class="math inline">\(1\)</span>. <span
class="math inline">\(2\to0\)</span> moves do not change
strangeness.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
case analysis
</dd>
</dl>
<p>Our outer-canonical curves have strangeness <span
class="math inline">\(0\)</span>, because each vertex has winding number
<span class="math inline">\(0\)</span>. So the strangeness of a curve is
a lower bound on the number of moves required to canonize it. A nested
counterclockwise loop with rotation number <span
class="math inline">\(r\)</span> has <span
class="math inline">\(r+1\)</span> positive vertices and strangeness
<span class="math inline">\(r(r + 1)/2\)</span>. So Nowik’s algorithm is
optimal (up to constant factors).</p>
<figure>
<img src="Fig/Meister-strange.png" style="width:50.0%"
alt="Curves with maximum and minimum strangeness (Meister 1769)" />
<figcaption aria-hidden="true">Curves with maximum and minimum
strangeness (Meister 1769)</figcaption>
</figure>
<h2 data-number="8.5" id="defect"><span
class="header-section-number">8.5</span> Defect</h2>
<p><span class="math display">\[
    \textsf{defect} (\gamma) = -2 \sum_{x\between y} \textsf{sgn}(x)
\cdot\textsf{sgn}(y)
\]</span></p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Homotopy moves change defect as follows: <span
class="math inline">\(1\to 0\)</span> moves do not change the defect.
Each <span class="math inline">\(2\to 0\)</span> move either decreases
the defect <span class="math inline">\(2\)</span> or leaves it
unchanged. Each <span class="math inline">\(3\to 3\)</span> move either
increases the defect by <span class="math inline">\(2\)</span> or
decreases the defect by <span class="math inline">\(2\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Case analysis.
</dd>
</dl>
<p>The <em>flat torus knot</em> <span
class="math inline">\(T(p,q)\)</span> is defined as <span
class="math display">\[
    T(p,q)(\theta) = \big(cos(q\theta)+2)cos(p\theta),
(cos(q\theta)+2)sin(p\theta) \big).
\]</span> This curve has exactly <span
class="math inline">\((p-1)q\)</span> vertices.</p>
<figure>
<img src="Fig/T78.png" style="width:30.0%"
alt="The flat torus knot T(7,8)." />
<figcaption aria-hidden="true">The flat torus knot <span
class="math inline">\(T(7,8)\)</span>.</figcaption>
</figure>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<span class="math inline">\(\textsf{defect}(T(p,p+1)) = 2\binom{p+1}{3}
= n^{3/2}/3 - O(n)\)</span>
</dd>
</dl>
<p>So indeed, there are <span class="math inline">\(n\)</span>-vertex
curves that require <span class="math inline">\(\Omega(n^{3/2})\)</span>
homotopy moves to simplify, so Hsien-Chih Chang’s and my algorithm is
worst-case optimal.</p>
<h2 data-number="8.6" id="aptly-yadda-yadda"><span
class="header-section-number">8.6</span> Aptly Yadda Yadda</h2>
<ul>
<li>Connection to Steinitz’s theorem via medial graphs</li>
<li>Connection to electrical reduction via <span
class="math inline">\(\Delta Y\)</span>-transformations</li>
<li>Hass and Scott’s lemma for curves on orientable surfaces</li>
<li>Monotone planar homotopy in <span
class="math inline">\(O(n^{3/2})\)</span> moves</li>
<li>Simplifying curves in the annulus or torus in <span
class="math inline">\(O(n^2)\)</span> moves</li>
<li><span class="math inline">\(\Omega(n^2)\)</span> lower bound for
annular curves via winding depth</li>
</ul>
<h1 data-number="9" id="planar-graphsbeta"><span
class="header-section-number">9</span> Planar Graphs<span
class="math inline">\(^\beta\)</span></h1>
<h2 data-number="9.1" id="abstract-graphs"><span
class="header-section-number">9.1</span> Abstract graphs</h2>
<p>A graph is an abstract combinatorial structure that models pairwise
relationships. You probably have a good intuitive idea what a graph is
already. Nevertheless, to avoid subtle but pervasive differences in
terminology, notation, and basic assumptions, I will carefully define
everything from scratch. In particular, we need a definition that allows
parallel edges and loops, so we can’t use the standard
combinatorialist’s definition as a pair of sets <span
class="math inline">\((V,E)\)</span>, and I don’t want to wander into
the notational quagmire of multisets. So here we go.</p>
<p>An <em>abstract graph</em> is a quadruple <span
class="math inline">\(G := (V, D, \textsf{rev}, \textsf{head})\)</span>,
where</p>
<ul>
<li><span class="math inline">\(V\)</span> is a non-empty set of
abstract objects called <em>vertices</em>;</li>
<li><span class="math inline">\(D\)</span> is a set of abstract objects
called <em>darts</em>;</li>
<li><span class="math inline">\(\textsf{rev}\)</span> is a permutation
of the darts <span class="math inline">\(D\)</span> such that <span
class="math inline">\(\textsf{rev}(\textsf{rev}(d)) = d \ne
\textsf{rev}(d)\)</span> for every dart <span class="math inline">\(d\in
D\)</span>;</li>
<li><span class="math inline">\(\textsf{head}\)</span> is a function
from the darts <span class="math inline">\(D\)</span> to the vertices
<span class="math inline">\(V\)</span>.</li>
</ul>
<p>Darts are also called <em>half-edges</em> or <em>arcs</em> or
<em>brins</em> (French for “strands”).</p>
<p>For any dart <span class="math inline">\(d\)</span>, we call the dart
<span class="math inline">\(\textsf{rev}(d)\)</span> the
<em>reversal</em> of <span class="math inline">\(d\)</span>, and we call
the vertex <span class="math inline">\(\textsf{head}(d)\)</span> the
<em>head</em> of <span class="math inline">\(d\)</span>. The
<em>tail</em> of a dart is the head of its reversal: <span
class="math inline">\(\textsf{tail}(d) :=
\textsf{head}(\textsf{rev}(d))\)</span>. The head and tail of a dart are
its <em>endpoints</em>. Intuitively, a dart is a directed path from its
tail to its head; in keeping with this intuition, we say that a dart
<span class="math inline">\(d\)</span> <em>leaves</em> its tail and
<em>enters</em> its head. I often write <span
class="math inline">\(u\mathord\to v\)</span> to denote a dart with tail
<span class="math inline">\(u\)</span> and head <span
class="math inline">\(v\)</span>, even (at the risk of confusing the
reader) when there is more than one such dart.</p>
<p>For any dart <span class="math inline">\(d\in D\)</span>, the
unordered pair <span class="math inline">\(|d| =
\{d,\textsf{rev}(d)\}\)</span> is called an <em>edge</em> of the graph.
We often write <span class="math inline">\(E\)</span> to denote the set
of edges of a graph. The constituent darts of an edge <span
class="math inline">\(e\)</span> are arbitrarily denoted <span
class="math inline">\(e^+\)</span> and <span
class="math inline">\(e^-\)</span>. The <em>endpoints</em> of an edge
<span class="math inline">\(e = \{ e^+, e^- \}\)</span> are the
endpoints (equivalently, just the heads) of its constituent darts.
Intuitively, each dart is an orientation of some edge from one of its
endpoints to the other.</p>
<p>A vertex <span class="math inline">\(v\)</span> and an edge <span
class="math inline">\(e\)</span> are <em>incident</em> if <span
class="math inline">\(v\)</span> is an endpoint of <span
class="math inline">\(e\)</span>; two vertices are <em>neighbors</em> if
they are endpoints of the same edge. We often write <span
class="math inline">\(uv\)</span> to denote an edge with endpoints <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>, even (at the risk of confusing the
reader) when there is more than one such edge.</p>
<p>A <em>loop</em> is an edge <span class="math inline">\(e\)</span>
with only one endpoint, that is, <span
class="math inline">\(\textsf{head}(e^+) = \textsf{tail}(e^+)\)</span>.
Two edges are <em>parallel</em> if they have the same endpoints. A graph
is <em>simple</em> if it has no loops or parallel edges, and
<em>non-simple</em> otherwise. Non-simple graphs are sometimes called
“generalized graphs” or “multigraphs”; I will just call them
“graphs”.</p>
<p>Let me repeat this louder for the kids in the back:
<strong><em>Graphs are not necessarily simple.</em></strong></p>
<p>The degree of a vertex <span class="math inline">\(v\)</span>,
denoted <span class="math inline">\(\deg_G(v)\)</span> (or just <span
class="math inline">\(\deg(v)\)</span> if the graph <span
class="math inline">\(G\)</span> is clear from context), is the number<a
href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> of darts whose head is <span
class="math inline">\(v\)</span>, or equivalently, the number of
incident edges plus the number of incident loops. A vertex is
<em>isolated</em> if it is not incident to any edge.</p>
<h2 data-number="9.2" id="data-structures"><span
class="header-section-number">9.2</span> Data structures</h2>
<p>Here is an equivalent definition that might be clearer to computer
scientists: <strong>A (finite) graph is whatever can be stored in a
standard graph data structure.</strong></p>
<p>The canonical textbook graph data structure is the <em>incidence
list</em>. (For simple graphs, the same data structure is more commonly
called an <em>adjacency list</em>.) The <span
class="math inline">\(n\)</span> vertices of the graph are represented
by distinct integers between <span class="math inline">\(1\)</span> and
<span class="math inline">\(n\)</span>. A standard incidence list
consists of an array indexed by the vertices; each array entry in the
array points to a linked list of the darts leaving the corresponding
vertex. (The order of darts in these linked lists is unimportant; we use
linked lists only because they support certain operations quickly.) The
record for each dart <span class="math inline">\(d\)</span> contains the
index of <span class="math inline">\(\textsf{head}(d)\)</span> and a
pointer to the record for <span
class="math inline">\(\textsf{rev}(d)\)</span>. Storing a graph with
<span class="math inline">\(n\)</span> vertices and <span
class="math inline">\(m\)</span> edges in an incidence list requires
<span class="math inline">\(O(n + m)\)</span> space.</p>
<p>If a graph is stored in an incidence list, we can insert a new edge
in <span class="math inline">\(O(1)\)</span> time, delete an edge in
<span class="math inline">\(O(1)\)</span> time (given a pointer to one
of its darts), and visit all the edges incident to any vertex <span
class="math inline">\(v\)</span> in <span
class="math inline">\(O(1)\)</span> time per edge, or <span
class="math inline">\(O(\deg(v))\)</span> time altogether. There are a
few standard operations that incidence lists do not support on <span
class="math inline">\(O(1)\)</span> time, the most glaring of which is
testing whether two vertices are neighbors. Surprisingly, however, most
efficient graph algorithms do not require this operation, and for those
few that do, we can replace the linked lists with hash tables.</p>
<figure>
<img src="Fig/incidence-list.png" style="width:70.0%"
alt="An incidence list, with the dart records for two edges emphasized. For clarity, most reversal pointers are omitted." />
<figcaption aria-hidden="true">An incidence list, with the dart records
for two edges emphasized. For clarity, most reversal pointers are
omitted.</figcaption>
</figure>
<p>More generally, “array” and “linked list” can be replaced by any
suitable data structures that allow random access and fast iteration,
respectively. A particularly simple and efficient implementation keeps
<em>all</em> data in standard arrays. For a graph with <span
class="math inline">\(n\)</span> vertices and <span
class="math inline">\(m\)</span> edges, we represent vertices by
integers between <span class="math inline">\(0\)</span> and <span
class="math inline">\(n-1\)</span>, edges by integers from <span
class="math inline">\(0\)</span> to <span
class="math inline">\(m-1\)</span>, and darts by integers between <span
class="math inline">\(0\)</span> and <span
class="math inline">\(2m-1\)</span>. Each edge <span
class="math inline">\(e\)</span> is composed of darts <span
class="math inline">\(e^- = 2e\)</span> and <span
class="math inline">\(e^+ = 2e+1\)</span>; thus, the reversal of any
dart <span class="math inline">\(d\)</span> is obtained by flipping its
least significant bit: <span class="math inline">\(d\oplus 1\)</span>.
The actual data structure consists of three arrays:</p>
<ul>
<li><span class="math inline">\(\textsf{first}[0..n-1]\)</span>, where
<span class="math inline">\(\textsf{first}[v]\)</span> is any dart
leaving vertex <span class="math inline">\(v\)</span>.</li>
<li><span class="math inline">\(\textsf{head}[0..2m-1]\)</span>, where
<span class="math inline">\(\textsf{head}[d]\)</span> is the head of
dart <span class="math inline">\(d\)</span>.</li>
<li><span class="math inline">\(\textsf{next}[0..2m-1]\)</span>, where
<span class="math inline">\(\textsf{next}[d]\)</span> is the successor
of <span class="math inline">\(d\)</span> in the list of darts leaving
<span class="math inline">\(\textsf{tail}(d)\)</span>.</li>
</ul>
<p>It is convenient to treat the list of darts leaving each vertex as a
<em>circular</em> list; then <span
class="math inline">\(\textsf{next}\)</span> stores a permutation of the
darts, each of whose cycles is the set of darts leaving a vertex. We may
also want to store a predecessor array <span
class="math inline">\(\textsf{prev}[0..2m-1]\)</span> that stores the
inverse of this permutation. We do not need a separate <span
class="math inline">\(\textsf{tail}\)</span> array, because <span
class="math inline">\(\textsf{tail}(d) = \textsf{head}[d \oplus
1]\)</span>.</p>
<figure>
<img src="Fig/incidence-array.png" style="width:95.0%"
alt="An incidence array representation of the same graph as Figure 1." />
<figcaption aria-hidden="true">An incidence array representation of the
same graph as Figure 1.</figcaption>
</figure>
<p>For algorithms that make frequent changes to the graph (adding and/or
deleting vertices and/or edges), we should use dynamic hash tables
instead of raw arrays. Finally, we can easily store algorithm-dependent
auxiliary data such as vertex coordinates, edge weights, distances, or
flow capacities in separate arrays (or hash tables) indexed by vertices,
edges, or darts, as appropriate.</p>
<h2 data-number="9.3" id="topological-graphs"><span
class="header-section-number">9.3</span> Topological graphs</h2>
<p>Graphs can also be formalized as topological structures rather than
purely combinatorial structures. Informally, a <em>topological
graph</em> consists of a set of distinct points called
<em>vertices</em>, together with a collection of vertex-to-vertex paths
called <em>edges</em>, which are disjoint and simple, except possibly at
their endpoints.</p>
<p>More formally, a topological graph <span
class="math inline">\(G^\top\)</span> is the quotient space of a set of
disjoint closed intervals, with respect to an equivalence relation over
the intervals’ endpoints. The projections of the intervals are the
<em>edges</em> of <span class="math inline">\(G^\top\)</span>; the
projections (or equivalence classes) of interval endpoints are the
<em>vertices</em> of <span class="math inline">\(G^\top\)</span>. Again,
for the kids in the back, topological graphs are not required to be
simple; they can contain loops and parallel edges.<a href="#fn15"
class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p>
<p>Mechanical definition-chasing implies that any topological graph
<span class="math inline">\(G^\top\)</span> can be described by a unique
abstract graph <span class="math inline">\(G\)</span>, For example, the
darts of <span class="math inline">\(G\)</span> are orientations of the
edges of <span class="math inline">\(G^\top\)</span>. Conversely, any
abstract graph describes a unique (up to homeomorphism) topological
graph <span class="math inline">\(G^\top\)</span>.<a href="#fn16"
class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<h2 data-number="9.4" id="planar-graphs-and-planar-maps"><span
class="header-section-number">9.4</span> Planar graphs and planar
maps</h2>
<p>A <em>planar embedding</em> of a graph <span
class="math inline">\(G\)</span> represents its vertices as distinct
points in the plane (typically <em>drawn</em> as small circles) and its
edges as simple interior-disjoint paths between their endpoints.
Equivalently, a planar embedding of <span
class="math inline">\(G\)</span> is a continuous injective function from
the corresponding topological graph <span
class="math inline">\(G^\top\)</span> into the plane. A graph is
<em>planar</em> it it has at least one planar embedding. Somewhat
confusingly, the image of a planar embedding of a planar graph is also
called a <em>plane graph</em>.</p>
<figure>
<img src="Fig/planar-graph.png" style="width:85.0%"
alt="A planar graph G and two planar embeddings of G." />
<figcaption aria-hidden="true">A planar graph <span
class="math inline">\(G\)</span> and two planar embeddings of <span
class="math inline">\(G\)</span>.</figcaption>
</figure>
<p>The components of the complement of the image of a planar embedding
are called the <em>faces</em> of the embedding. Assuming the embedded
graph is connected, the Jordan curve theorem implies that every bounded
face is homeomorphic to an open disk, and the unique unbounded face is
homeomorphic to the complement of a closed disk. For disconnected
graphs, at least one face is homeomorphic to an open disk with a finite
number of closed disks removed.</p>
<p>The faces on either side of an edge of a planar embedding are called
the <em>shores</em> of that edge. For any dart <span
class="math inline">\(d\)</span>, the face just to the left of the image
of <span class="math inline">\(d\)</span> in the embedding is the
<em>left shore</em> of <span class="math inline">\(d\)</span>, denoted
<span class="math inline">\(\textsf{left}(d)\)</span>; symmetrically,
the face just to the right is the <em>right shore</em> <span
class="math inline">\(\textsf{right}(d)\)</span>. The left and right
shores of a dart can be the same face. An edge <span
class="math inline">\(e\)</span> and a face <span
class="math inline">\(f\)</span> are <em>incident</em> if <span
class="math inline">\(f\)</span> is one of the shores of <span
class="math inline">\(e^+\)</span>; similarly, an vertex <span
class="math inline">\(v\)</span> and a face <span
class="math inline">\(f\)</span> are incident if <span
class="math inline">\(v\)</span> and <span
class="math inline">\(f\)</span> have a common incident edge. The
<em>degree</em> of a face <span class="math inline">\(f\)</span>,
denoted <span class="math inline">\(\deg_G(f)\)</span> (or just <span
class="math inline">\(\deg(f)\)</span> if <span
class="math inline">\(G\)</span> is clear from context), is the number
of darts whose right shore is <span
class="math inline">\(f\)</span>.</p>
<p>Let <span class="math inline">\(F\)</span> be the set of faces of a
planar embedding of a connected graph with vertices <span
class="math inline">\(V\)</span> and edges <span
class="math inline">\(E\)</span>. The decomposition of the plane into
vertices, edges, and faces, typically written as a triple <span
class="math inline">\((V,E,F)\)</span>, is called a <em>planar map</em>.
Trapezoidal decompositions and triangulations of polygons are both
examples of planar maps. A planar map is called a <em>triangulation</em>
if every face, including the outer face, has degree <span
class="math inline">\(3\)</span>. The underlying graph <span
class="math inline">\((V, E)\)</span> of a planar triangulation is
<em>not</em> necessarily simple.<a href="#fn17" class="footnote-ref"
id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
<figure>
<img src="Fig/nonsimple-triangulation.png" style="width:30.0%"
alt="A nonsimple planar triangulation." />
<figcaption aria-hidden="true">A nonsimple planar
triangulation.</figcaption>
</figure>
<h2 data-number="9.5" id="rotation-systems"><span
class="header-section-number">9.5</span> Rotation systems</h2>
<p>As usual in topology, we are not really interested in
<em>particular</em> embeddings or maps, but rather topological
equivalence classes of embeddings or maps. Two planar embeddings of the
same graph <span class="math inline">\(G\)</span> are considered
<em>equivalent</em> if there is an orientation-preserving homeomorphism
of the plane to itself that carries one embedding to the other, or
equivalently, if one embedding can be continuously deformed to the other
through a continuous family of embeddings. Fortunately, every
equivalence class of embeddings has a concrete combinatorial
representation, called a <em>rotation system</em>.</p>
<p>Recall that a <em>permutation</em> of a finite set <span
class="math inline">\(X\)</span> is a bijection <span
class="math inline">\(\pi\colon X \to X\)</span>. For any permutation
<span class="math inline">\(\pi\)</span> and any element <span
class="math inline">\(x\in X\)</span>, let <span
class="math inline">\(\pi^0(x) := x\)</span> and <span
class="math inline">\(\pi^k(x) := \pi(\pi^{k-1}(x))\)</span> for any
integer <span class="math inline">\(k &gt; 0\)</span>. The
<em>orbit</em> of an element <span class="math inline">\(x\)</span> is
the set <span class="math inline">\(\{\pi^k(x) \mid k\in\mathbb{N}\} =
\{x, \pi(x), \pi^2(x), \dots\}\)</span>. The restriction of <span
class="math inline">\(\pi\)</span> to any of its orbits is a cyclic
permutation; the infinite sequence <span
class="math inline">\(x,\pi(x),\pi^2(x),\dots\)</span> repeatedly cycles
through the elements of the orbit of <span
class="math inline">\(x\)</span>. Thus, the orbits of any two elements
of <span class="math inline">\(X\)</span> are either identical or
disjoint.</p>
<p>The <em>successor permutation</em> or an embedding of <span
class="math inline">\(G\)</span> is a permutation of the darts of <span
class="math inline">\(G\)</span>; specifically, the successor <span
class="math inline">\(\textsf{succ}(d)\)</span> of any dart <span
class="math inline">\(d\)</span> is the successor of <span
class="math inline">\(d\)</span> in the <em>clockwise</em> sequence of
darts entering <span class="math inline">\(\textsf{head}(d)\)</span>.<a
href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a></p>
<p>Finally, the <em>rotation system</em> of an embedding is a triple
<span class="math inline">\(\Sigma = (D, \textsf{rev},
\textsf{succ})\)</span>, where</p>
<ul>
<li><span class="math inline">\(D\)</span> is the set of darts,</li>
<li><span class="math inline">\(\textsf{rev}\)</span> is is the reversal
permutation of <span class="math inline">\(D\)</span>, and</li>
<li><span class="math inline">\(\textsf{succ}\)</span> is the successor
permutation of <span class="math inline">\(D\)</span>.</li>
</ul>
<p>More generally, a <em>rotation system</em> or <em>combinatorial
map</em> is any triple <span class="math inline">\((D, \textsf{rev},
\textsf{succ})\)</span> where <span class="math inline">\(D\)</span> is
a set, <span class="math inline">\(\textsf{rev}\)</span> is a
fixed-point-free involution of <span class="math inline">\(D\)</span>,
and <span class="math inline">\(\textsf{succ}\)</span> is another
permutation of <span class="math inline">\(D\)</span>. The
<em>vertices</em> of a combinatorial map are the orbits of <span
class="math inline">\(\textsf{succ}\)</span>, its <em>edges</em> are the
orbits of <span class="math inline">\(\textsf{rev}\)</span>, and its
<em>faces</em> are the orbits of <span
class="math inline">\(\textsf{rev}(\textsf{succ})\)</span>. The vertices
and edges define the <em>1-skeleton</em> or <em>underlying graph</em> of
<span class="math inline">\(\Sigma\)</span>.</p>
<p>In other words, a rotation system is (almost) an incidence list where
the order of darts in each list actually matters! The only annoying
discrepancy is that rotation systems order darts <em>into</em> each
vertex, while incidence lists order darts <em>out</em> of each vertex,
but we can easily translate between these two standards using the
identity <span class="math inline">\(\textsf{next}(d) =
\textsf{rev}(\textsf{succ}(\textsf{rev}(d)))\)</span>.</p>
<p>The of any connected graph embedding are also implicitly encoded in
its rotation system. Recall that <span
class="math inline">\(\textsf{rev}\)</span> is the reversal permutation
of the darts of a graph. For any dart <span
class="math inline">\(d\)</span>, the <em>dual successor</em> <span
class="math inline">\(\textsf{succ}^*(d):=
\textsf{rev}(\textsf{succ}(d))\)</span> is the next dart after <span
class="math inline">\(d\)</span> in <em>counterclockwise</em> order
around the boundary of <span
class="math inline">\(\textsf{left}(d)\)</span>.</p>
<figure>
<img src="Fig/planar-darts2.png" style="width:50.0%"
alt="The successor and dual successor of a dart in a planar map." />
<figcaption aria-hidden="true">The successor and dual successor of a
dart in a planar map.</figcaption>
</figure>
<figure>
<img src="Fig/planar-navigate.png" style="width:45.0%"
alt="Navigating around a dart. To simplify the figure, negation is used to indicate dart reveral." />
<figcaption aria-hidden="true">Navigating around a dart. To simplify the
figure, negation is used to indicate dart reveral.</figcaption>
</figure>
<h2 data-number="9.6" id="formalities-and-trivialities"><span
class="header-section-number">9.6</span> Formalities and
Trivialities</h2>
<p>Formally, rotation systems (and their equivalent incidence lists)
describe embeddings onto the <em>sphere</em> <span
class="math inline">\(S^2 = \{ (x,y,z) \mid x^2+y^2+z^2=1 \}\)</span>,
not onto the plane. Indeed, for many results about planar graphs, it is
actually more natural to consider spherical embeddings on the sphere
instead the plane. Fortunately, we can transfer embeddings back and
forth between the sphere and the plane using <em>stereographic
projection</em>.</p>
<p>Stereographic projection is the function <span
class="math inline">\(\textsf{st}\colon S^2\setminus(0,0,1) \to
\mathbb{R}^2\)</span> where <span
class="math inline">\(\textsf{st}(x,y,z) := \big(\! \frac{x}{1-z},
\frac{y}{1-z} \!\big)\)</span>. The projection <span
class="math inline">\(\textsf{st}(p)\)</span> of any point <span
class="math inline">\(p\in S^2\setminus(0,0,1)\)</span> is the
intersection of the line through <span class="math inline">\(p\)</span>
and the “north pole” <span class="math inline">\((0,0,1)\)</span> with
the <span class="math inline">\(xy\)</span>-plane. Points in the
northern hemisphere project outside the unit circle; points in the
southern hemisphere project inside the unit circle. Given any spherical
embedding, if we rotate the sphere so that the embedding avoids <span
class="math inline">\((0,0,1)\)</span>, stereographic projection gives
us a planar embedding; conversely, given any planar embedding, inverse
stereographic projection immediately gives us a spherical embedding.
Thus, a graph is planar if and only if it has an embedding on the
sphere.</p>
<figure>
<img src="Fig/stereographic.png" style="width:50.0%"
alt="Stereographic projection." />
<figcaption aria-hidden="true">Stereographic projection.</figcaption>
</figure>
<p>To fully specify an embedding on the plane using a rotation system,
we must somehow also indicate which face of the embedding is the
<em>outer face</em>, or equivalently, which face of the corresponding
spherical embedding contains the north pole. The outer face can be
chosen arbitrarily.</p>
<p>Most of the exposition in these notes implicitly considers only
embeddings of graphs with at least one edge. Exactly one map violates
this assumption, namely the <em>trivial map</em>, which has one vertex,
one face, and no edges. The trivial map is represented by the
<em>empty</em> rotation system <span class="math inline">\((\varnothing,
\varnothing, \varnothing)\)</span>.</p>
<figure>
<img src="Fig/trivial-map.png" style="width:15.0%"
alt="The trivial map of the sphere." />
<figcaption aria-hidden="true">The trivial map of the
sphere.</figcaption>
</figure>
<h2 data-number="9.7" id="caveat-lector"><span
class="header-section-number">9.7</span> Caveat Lector</h2>
<blockquote>
<p>“There are dinner jackets and dinner jackets. This is the
latter.”<br />
— Vesper Lynd [Eva Green], <em>Casino Royale</em> (2006)</p>
</blockquote>
<p>It is somewhat confusing standard practice to use the same symbol
<span class="math inline">\(G\)</span> (and the same word “graph”) to
simultaneously denote at least six formally different structures:</p>
<ul>
<li>an abstract planar graph <span
class="math inline">\(G\)</span>,</li>
<li>the corresponding topological graph <span
class="math inline">\(G^\top\)</span>,</li>
<li>an embedding of <span class="math inline">\(G^\top\)</span> into the
plane,<a href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a></li>
<li>the image of that embedding (which by definition is homeomorphic to
<span class="math inline">\(G^\top\)</span>),</li>
<li>the rotation system <span
class="math inline">\((D,\textsf{rev},\textsf{succ})\)</span> of that
embedding, and</li>
<li>the planar map <span class="math inline">\((V,E,F)\)</span> induced
by that embedding.</li>
</ul>
<p>Even when authors do distinguish between <em>graphs</em> and
<em>maps</em>, it is standard practice to conflate abstract graphs, the
corresponding topological graphs, and images of embeddings as “graphs”.
In particular, the image of a planar graph embedding is commonly called
a <em>plane graph</em>. Even the phrases “abstract graph” and
“topological graph” are non-standard; the standard names for these
objects are “graph” (spoken by a combinatorialist) and “graph” (spoken
by a topologist), respectively.<a href="#fn20" class="footnote-ref"
id="fnref20" role="doc-noteref"><sup>20</sup></a> It is also standard
practice to use the word “embedding” to mean <em>both</em> an injective
function from <span class="math inline">\(G^\top\)</span> to the plane
<em>and</em> the image of such a function, and to use the word “map” to
mean <em>both</em> the decomposition of the plane induced by an
embedding <em>and</em> the rotation system of that embedding.</p>
<p>I will <em>try</em> to carefully distinguish between these various
objects when the distinction matters, but there is a serious tension
here between formality and clarity, so I am very likely to slip
occasionally.</p>
<h2 data-number="9.8" id="duality"><span
class="header-section-number">9.8</span> Duality</h2>
<p>Recall that a combinatorial map is a triple <span
class="math inline">\(\Sigma = (D, \textsf{rev},
\textsf{succ})\)</span>, where <span class="math inline">\(D\)</span> is
a set of darts, is an involution of <span
class="math inline">\(D\)</span>, and is a permutation of <span
class="math inline">\(D\)</span>. For any such triple, the triple <span
class="math inline">\(\Sigma^* = (D, \textsf{rev},
\textsf{rev}\circ\textsf{succ})\)</span> is also a well-defined
combinatorial map, called the <em>dual map</em> of <span
class="math inline">\(\Sigma\)</span>.<a href="#fn21"
class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a></p>
<ul>
<li>The <em>vertices</em> of <span
class="math inline">\(\Sigma^*\)</span> are the orbits of <span
class="math inline">\(\textsf{rev}\circ\textsf{succ}\)</span>, which are
also the faces of <span class="math inline">\(\Sigma\)</span>.</li>
<li>The <em>edges</em> of <span class="math inline">\(\Sigma^*\)</span>
are the orbits of , which are also the edges of <span
class="math inline">\(\Sigma\)</span>.</li>
<li>The <em>faces</em> of <span class="math inline">\(\Sigma^*\)</span>
are the orbits of <span
class="math inline">\(\textsf{rev}\circ\textsf{rev}\circ\textsf{succ} =
\textsf{succ}\)</span>, which are also the vertices of <span
class="math inline">\(\Sigma\)</span>!</li>
</ul>
<p>In other words, each vertex <span class="math inline">\(v\)</span>,
edge <span class="math inline">\(e\)</span>, dart <span
class="math inline">\(d\)</span>, or face <span
class="math inline">\(f\)</span> of the original map <span
class="math inline">\(\Sigma\)</span> corresponds to—or more
evocatively, “is dual to”—or more formally,
<strong><em>IS</em></strong>—a face <span
class="math inline">\(v^*\)</span>, edge <span
class="math inline">\(e^*\)</span>, dart <span
class="math inline">\(d^*\)</span>, or vertex <span
class="math inline">\(f^*\)</span> of the dual map <span
class="math inline">\(\Sigma^*\)</span>, respectively.</p>
<p>The endpoints of any primal edge <span
class="math inline">\(e\)</span> are dual to the shores of the
corresponding dual edge <span class="math inline">\(e^*\)</span>, and
vice versa. Specifically, for any dart <span
class="math inline">\(d\)</span>, we have <span
class="math inline">\(\textsf{head}(d^*) = \textsf{left}(d)^*\)</span>
and <span class="math inline">\(\textsf{tail}(d^*) =
\textsf{right}(d)^*\)</span>. Intuitively, the dual of a dart is
obtained by rotating it a quarter-turn counterclockwise.</p>
<p>Duality is trivially an involution: <span
class="math inline">\((\Sigma^*)^* = \Sigma\)</span>, because <span
class="math inline">\(\textsf{rev}\circ\textsf{rev}\circ\textsf{succ} =
\textsf{succ}\)</span>. It immediately follows that for any dart <span
class="math inline">\(d\)</span>, we have <span
class="math inline">\(\textsf{left}(d^*) = \textsf{head}(d)^*\)</span>
and <span class="math inline">\(\textsf{right}(d^*) =
\textsf{tail}(d)^*\)</span>.</p>
<p>We can also directly define the dual of a <em>topological</em> map
<span class="math inline">\(\Sigma\)</span> as follows. Choose an
arbitrary point <span class="math inline">\(f^*\)</span> in the interior
of each face <span class="math inline">\(f\)</span> of <span
class="math inline">\(\Sigma\)</span>. Let <span
class="math inline">\(F^*\)</span> denote the collection of all such
points. For each edge <span class="math inline">\(e\)</span> of <span
class="math inline">\(\Sigma\)</span>, choose a simple path <span
class="math inline">\(e^*\)</span> between the chosen points in the
shores of <span class="math inline">\(e\)</span>, such that <span
class="math inline">\(e^*\)</span> intersects <span
class="math inline">\(e\)</span> once transversely and does not
intersect any other edge of <span class="math inline">\(\Sigma\)</span>.
Let <span class="math inline">\(E^*\)</span> denote the collection of
all such paths. These paths partition the plane into regions <span
class="math inline">\(V^*\)</span>, each of which contains a unique
vertex.<a href="#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a> The dual map <span
class="math inline">\(\Sigma^*\)</span> is the decomposition of the
plane into vertices <span class="math inline">\(F^*\)</span>, edges
<span class="math inline">\(E^*\)</span>, and faces <span
class="math inline">\(V^*\)</span>.</p>
<figure>
<img src="Fig/planar-duality.png" style="width:55.0%"
alt="A planar map and its dual; one dart and its dual are emphasized." />
<figcaption aria-hidden="true">A planar map and its dual; one dart and
its dual are emphasized.</figcaption>
</figure>
<figure>
<img src="Fig/derived-maps/primal+dual.png" style="width:75.0%"
alt="A portion of a planar map \Sigma, and the corresponding portion of the dual map \Sigma^*" />
<figcaption aria-hidden="true">A portion of a planar map <span
class="math inline">\(\Sigma\)</span>, and the corresponding portion of
the dual map <span class="math inline">\(\Sigma^*\)</span></figcaption>
</figure>
<p><strong><em>[[ add dual navigation figure ]]</em></strong></p>
<p>When <span class="math inline">\(G\)</span> is an <em>embedded</em>
graph, it is extremely common to define the <em>dual graph</em> <span
class="math inline">\(G^*\)</span> as the 1-skeleton of the dual map of
the embedding. This habit is a bit misleading, however; duality is a
correspondence between <em>maps</em> or <em>embeddings</em>, not between
abstract graphs. An abstract planar graph can have many non-isomorphic
planar embeddings, each of which defines a different “dual graph”.
Moreover, the dual of a <em>simple</em> embedded graph is not necessary
simple; any vertex of degree <span class="math inline">\(2\)</span> in
<span class="math inline">\(G\)</span> gives rise to parallel edges in
<span class="math inline">\(G^*\)</span>, and any bridge in <span
class="math inline">\(G\)</span> is dual to a loop in <span
class="math inline">\(G^*\)</span>. This is why we don’t want graphs to
be simple by definition!</p>
<figure>
<img src="Fig/two-embeddings.png" style="width:50.0%"
alt="Two planar embeddings of a simple planar graph, with non-simple, non-isomorphic dual graphs." />
<figcaption aria-hidden="true">Two planar embeddings of a simple planar
graph, with non-simple, non-isomorphic dual graphs.</figcaption>
</figure>
<h2 data-number="9.9" id="self-dual-data-structures"><span
class="header-section-number">9.9</span> Self-dual data structures</h2>
<p><strong><em>[[Duality is not a transformation; it’s just a
type-cast]]</em></strong></p>
<table>
<caption>A (partial) duality dictionary.</caption>
<colgroup>
<col style="width: 24%" />
<col style="width: 25%" />
<col style="width: 24%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">vertex <span
class="math inline">\(v\)</span></td>
<td style="text-align: center;">face <span
class="math inline">\(v^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{head}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{left}(d^*)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">dart <span
class="math inline">\(d\)</span></td>
<td style="text-align: center;">dart <span
class="math inline">\(d^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{tail}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{right}(d^*)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">edge <span
class="math inline">\(e\)</span></td>
<td style="text-align: center;">edge <span
class="math inline">\(e^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{left}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{head}(d^*)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">face <span
class="math inline">\(f\)</span></td>
<td style="text-align: center;">vertex <span
class="math inline">\(f^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{right}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{tail}(d^*)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(\textsf{succ}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\circ\textsf{succ}\)</span></td>
<td style="text-align: center;">clockwise</td>
<td style="text-align: center;">counterclockwise</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h2 data-number="9.10" id="endianity"><span
class="header-section-number">9.10</span> Endianity</h2>
<p>There are several apparently arbitrary choices to make in the
definitions of incidence lists, rotation systems, and duality. Should we
store cycles of darts with the same head or the same tail? Should darts
be ordered in clockwise or counterclockwise order around vertices? Or
around faces? Should <span
class="math inline">\(\textsf{head}(d^*)\)</span> be defined as <span
class="math inline">\(\textsf{left}(d)^*\)</span> or <span
class="math inline">\(\textsf{right}(d)^*\)</span>? Different standards
are used by different authors, by the same authors in different papers,
and sometimes even within the same paper.<a href="#fn23"
class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>
(Mea culpa!)</p>
<p>Let me attempt to justify, motivate, or at least provide mnemonics
for the specific choices I use in these notes. Some of these rules will
only make sense later.</p>
<ul>
<li>Dualizing a dart should look (and act?) like multiplying a complex
number by the imaginary unit <span class="math inline">\(i\)</span>: a
quarter turn <em>counterclockwise</em>. Thus, <span
class="math inline">\(\textsf{head}(d^*) = \textsf{left}(d)^*\)</span>
and <span class="math inline">\(\textsf{tail}(d^*) =
\textsf{right}(d)^*\)</span>.</li>
<li>Duality is an involution, dammit. Thus, <span
class="math inline">\(\textsf{left}(d^*) = \textsf{head}(d)^*\)</span>
and <span class="math inline">\(\textsf{right}(d^*) =
\textsf{tail}(d)^*\)</span>. It follows that primal and dual planes must
have opposite orientations!</li>
<li>Simple <em>counterclockwise</em> cycles have winding number <span
class="math inline">\(+1\)</span>. So the dual successor function should
order darts <em>counterclockwise</em> around their <em>left</em> shores.
Thus, the primal successor function should order darts
<em>clockwise</em> around their <em>heads</em>.</li>
<li>Derivatives measure how much a function <em>increases</em>, so <span
class="math inline">\(\delta\omega(d) = \omega(\textsf{head}(d)) -
\omega(\textsf{tail}(d))\)</span>. On the other hand, the directed
boundary of a face should be a counterclockwise cycle, so <span
class="math inline">\(\partial\alpha(d) = \alpha(\textsf{left}(d)) -
\alpha(\textsf{right}(d))\)</span>. Hey, look, consistency!</li>
</ul>
<p>This standard creates an annoying discrepancy between the
mathematical abstraction of a rotation system and its implementation as
an incidence list. Rotation systems order darts around their heads
because that makes the math cleaner, but incidence lists (typically)
order darts around their tails because that better fits our intuition
about searching graphs by following directed edges outward. Rather than
give up either useful intuition, we’ll rely on (and if necessary
implement) the identity <span class="math inline">\(\textsf{next}(d) =
\textsf{rev}(\textsf{succ}(\textsf{rev}(d)))\)</span>.</p>
<h2 data-number="9.11" id="other-derived-maps"><span
class="header-section-number">9.11</span> Other derived maps</h2>
<p>Let <span class="math inline">\(\Sigma = (V, E, F)\)</span> be an
arbitrary planar map. In addition to the dual map <span
class="math inline">\(\Sigma^*\)</span>, there are several other useful
maps that can be derived from <span
class="math inline">\(\Sigma\)</span> in terms of two local
features.</p>
<ul>
<li><p>A <em>flag</em> of <span class="math inline">\(\Sigma\)</span> is
a vertex-edge-face triple <span class="math inline">\((v,e,f)\)</span>
such that <span class="math inline">\(v\)</span> is an endpoint of <span
class="math inline">\(e\)</span> and <span
class="math inline">\(f\)</span> is a shore of <span
class="math inline">\(e\)</span>.
<!-- Every dart $d$ is naturally associated with two flags $(\textsf{head}(d), |d|, \textsf{left}(d))$ and $(\textsf{head}(d), |d|, \textsf{right}(d))$ with the same vertex and edge.  Similarly, every corner is naturally associated with two flags $(\textsf{head}(d), |d|, \textsf{left}(d))$ and $(\textsf{head}(d), |\textsf{succ}(d)|, \textsf{left}(d))$ with the same vertex and face. --></p></li>
<li><p>A <em>corner</em> of <span class="math inline">\(\Sigma\)</span>
is a pair of flags that share the same vertex and the same face.
Intuitively, a corner is an incidence between a vertex and a face, or if
you prefer, a pair of edges whose darts are consecutive around a vertex,
or around a face. (Formally, a corner is just a nickname for a dart; for
each dart <span class="math inline">\(d\)</span>, the corresponding
corner is the incidence between the vertex <span
class="math inline">\(\textsf{head}(d)\)</span> and the face <span
class="math inline">\(\textsf{left}(d)\)</span>, or equivalently,
between the vertex <span
class="math inline">\(\textsf{tail}(\textsf{succ}^*(d))\)</span> and the
face <span
class="math inline">\(\textsf{right}(\textsf{succ}(d))\)</span>.)</p></li>
</ul>
<p>The <em>medial map</em> <span class="math inline">\(\Sigma^\times =
(E, C, V\cup F)\)</span> is the map whose vertices correspond to the
edges of <span class="math inline">\(\Sigma\)</span>, whose edges
correspond to the corners of <span
class="math inline">\(\Sigma\)</span>, and whose faces correspond to
vertices and faces of <span class="math inline">\(\Sigma\)</span>. The
medial map of <span class="math inline">\(\Sigma\)</span> is the image
graph of a generic planar multicurve. Specifically, two vertices are
connected by an edge in <span
class="math inline">\(\Sigma^\times\)</span> if the corresponding edges
in <span class="math inline">\(\Sigma\)</span> are adjacent in cyclic
order around any vertex (or equivalently, around any face). Every map
<span class="math inline">\(\Sigma\)</span> and its dual <span
class="math inline">\(\Sigma^*\)</span> share the same medial map <span
class="math inline">\(\Sigma^\times\)</span>.</p>
<p>The dual of the medial map is called the <em>radial</em> map <span
class="math inline">\(\Sigma^\diamond = (V\cup F, C, E)\)</span>. The
radial map can be constructed from <span
class="math inline">\(\Sigma\)</span> by placing a new vertex in the
interior of each face <span class="math inline">\(f\)</span> of <span
class="math inline">\(\Sigma\)</span>, connecting each face-vertex <span
class="math inline">\(f\)</span> to each vertex incident to <span
class="math inline">\(f\)</span> (with the appropriate multiplicity),
and then erasing the original edges. Thus, each edge of <span
class="math inline">\(\Sigma\)</span> becomes a quadrilateral face of
<span class="math inline">\(\Sigma^\diamond\)</span>. Again, every map
<span class="math inline">\(\Sigma\)</span> and its dual <span
class="math inline">\(\Sigma^*\)</span> share the same radial map <span
class="math inline">\(\Sigma^\diamond\)</span>.</p>
<figure>
<img src="Fig/derived-maps/medial+radial.png" style="width:75.0%"
alt="Corresponding portions of the medial map \Sigma^\times and radial map \Sigma^\diamond of the planar map in Figure 8." />
<figcaption aria-hidden="true">Corresponding portions of the medial map
<span class="math inline">\(\Sigma^\times\)</span> and radial map <span
class="math inline">\(\Sigma^\diamond\)</span> of the planar map in
Figure 8.</figcaption>
</figure>
<p>The <em>band decomposition</em> or <em>ribbon decomposition</em> of
<span class="math inline">\(\Sigma\)</span> is a map <span
class="math inline">\(\Sigma^\square\)</span> whose vertices correspond
to the flags of <span class="math inline">\(\Sigma\)</span>. Two flags
define an edge in <span class="math inline">\(\Sigma^\square\)</span> if
they differ in exactly one component: the same vertex and edge but a
different face, the same vertex and face but a different edge, or the
sane edge and face bu a different vertex. Every vertex of <span
class="math inline">\(\Sigma^\square\)</span> has degree <span
class="math inline">\(3\)</span>. The faces of <span
class="math inline">\(\Sigma^\square\)</span> correspond to the
vertices, edges, and faces of <span
class="math inline">\(\Sigma\)</span>. Every map <span
class="math inline">\(\Sigma\)</span> and its dual <span
class="math inline">\(\Sigma^*\)</span> share the same band
decomposition <span class="math inline">\(\Sigma^\square\)</span>.</p>
<p>The dual of the band decomposition is the <em>barycentric
subdivision</em> <span class="math inline">\(\Sigma^+\)</span>. This map
can be constructed by adding a new vertex in the interior of each edge,
subdividing it into two edges, adding a new vertex in the interior of
every face, and finally connecting each face-vertex to its vertices and
edge midpoints. Thus, the vertices of <span
class="math inline">\(\Sigma^+\)</span> correspond to the vertices,
edges, and faces of <span class="math inline">\(\Sigma\)</span>, and the
faces of <span class="math inline">\(\Sigma^+\)</span> correspond to the
flags of <span class="math inline">\(\Sigma\)</span>. Every face of
<span class="math inline">\(\Sigma^+\)</span> is a triangle. Again,
every map <span class="math inline">\(\Sigma\)</span> and its dual <span
class="math inline">\(\Sigma^*\)</span> share the same barycentric
subdivision <span class="math inline">\(\Sigma^+\)</span>.</p>
<figure>
<img src="Fig/derived-maps/band+bary.png" style="width:75.0%"
alt="Corresponding portions of the band decomposition \Sigma^\square and the barycentric subdivision \Sigma^+ of the planar map in Figure 8." />
<figcaption aria-hidden="true">Corresponding portions of the band
decomposition <span class="math inline">\(\Sigma^\square\)</span> and
the barycentric subdivision <span
class="math inline">\(\Sigma^+\)</span> of the planar map in Figure
8.</figcaption>
</figure>
<p>These four derived maps are formally well-defined if and only only if
the original map <span class="math inline">\(\Sigma\)</span> has at
least one edge. It is sometimes convenient, for example in base cases of
inductive arguments, to informally extend the definitions to the trivial
map <span class="math inline">\(\bullet\)</span> as follows:</p>
<ul>
<li><p>The trivial medial map <span
class="math inline">\(\bullet^\times\)</span> and the trivial band
decomposition <span class="math inline">\(\bullet^\square\)</span> both
consist of a single closed curve on the sphere, with no vertices and two
faces, corresponding to the vertex and face of <span
class="math inline">\(\bullet\)</span>. I recommend thinking of this
object as the result of gluing two flat circular disks together around
their boundary.</p></li>
<li><p>The trivial radial map <span
class="math inline">\(\bullet^\diamond\)</span> and the trivial
barycentric subdivision <span class="math inline">\(\bullet^+\)</span>
both consist of a single “edge”, with no faces and two vertices, again
corresponding to the vertex and face of <span
class="math inline">\(\bullet\)</span>. I recommend thinking of this
object as an infinitely thin cylinder with its ends pinched to
points.</p></li>
</ul>
<p>But let me emphasize that these extensions are informal; the objects
I’ve just described are not maps at all!</p>
<h2 data-number="9.12" id="aptly-yadda-yadda-1"><span
class="header-section-number">9.12</span> Aptly Yadda Yadda</h2>
<ul>
<li>References!
<ul>
<li>planar graphs, duality, etc</li>
<li>combinatorial maps / rotation systems</li>
<li>map data structures (half-edge, winged-edge, quad-edge, gem,
etc.)</li>
<li>derived maps (Tait, Steinitz, Conway, etc.)</li>
</ul></li>
<li>Directed duality: Acyclic <span
class="math inline">\(\leftrightharpoons\)</span> strongly
connected</li>
<li>Whitney’s theorem: Every 3-connected planar graph has a unique
planar embedding</li>
</ul>
<h2 data-number="9.13" id="revision"><span
class="header-section-number">9.13</span> Revision?</h2>
<p>Consider using more mnemonic <span
class="math inline">\(\textsf{hnext}\)</span> instead of <span
class="math inline">\(\textsf{succ}\)</span>, and similar for other
nearby darts:</p>
<ul>
<li><span class="math inline">\(\textsf{hprev} =
\textsf{hnext}^{-1}\)</span></li>
<li><span class="math inline">\(\textsf{tnext} =
\textsf{rev}(\textsf{hnext}(\textsf{rev})))\)</span></li>
<li><span class="math inline">\(\textsf{tprev} = \textsf{tnext}^{-1} =
\textsf{rev}(\textsf{hprev}(\textsf{rev})))\)</span></li>
<li><span class="math inline">\(\textsf{lnext} =
\textsf{rev}(\textsf{hnext}) = \textsf{succ}^*\)</span></li>
<li><span class="math inline">\(\textsf{lprev} = \textsf{lnext}^{-1} =
\textsf{hprev}(\textsf{rev})\)</span></li>
<li><span class="math inline">\(\textsf{rnext} =
\textsf{rev}(\textsf{hprev})\)</span></li>
<li><span class="math inline">\(\textsf{rprev} = \textsf{rnext}^{-1} =
\textsf{hnext}(\textsf{rev})\)</span></li>
</ul>
<h1 data-number="10" id="tree-cotree-decompositionsbeta"><span
class="header-section-number">10</span> Tree-Cotree Decompositions<span
class="math inline">\(^\beta\)</span></h1>
<h2 data-number="10.1" id="important-graph-definitions-yawn"><span
class="header-section-number">10.1</span> Important graph definitions
(yawn)</h2>
<p>We need to establish definitions for a few important structures in
graphs. Most of these are likely already familiar; I recommend using
this list as later reference rather than reading it as text.
<strong><em>Move to end of previous note?</em></strong></p>
<dl>
<dt><strong>walk</strong>:</dt>
<dd>
A sequence <span class="math inline">\(\langle s, d_1, d_2, \dots, d_k,
t \rangle\)</span> where <span class="math inline">\(s\)</span> and
<span class="math inline">\(t\)</span> are vertices and each <span
class="math inline">\(d_i\)</span> is a dart, such that <span
class="math inline">\(\textsf{tail}(d_1) = s\)</span> and <span
class="math inline">\(\textsf{head}(d_1) = t\)</span> and <span
class="math inline">\(\textsf{head}(d_i) =
\textsf{tail}(d_{i+1})\)</span> for each index <span
class="math inline">\(i\)</span>
</dd>
<dt><strong>length of a walk</strong>:</dt>
<dd>
The number of darts in the walk. The walk <span
class="math inline">\(\langle s, d_1, \dots, d_k, t \rangle\)</span> has
length <span class="math inline">\(k\)</span>.
</dd>
<dt><strong>trivial walk</strong>:</dt>
<dd>
A walk <span class="math inline">\(\langle s, s \rangle\)</span> with
length <span class="math inline">\(0\)</span>.
</dd>
<dt><strong>closed walk</strong>:</dt>
<dd>
A walk <span class="math inline">\(\langle s, d_2, \dots, d_k, t
\rangle\)</span> such that <span class="math inline">\(s = t\)</span>.
</dd>
<dt><strong>open walk</strong>:</dt>
<dd>
A walk that is either trivial or not closed
</dd>
<dt><strong>walk from <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span></strong>:</dt>
<dd>
A walk with specified initial vertex <span
class="math inline">\(s\)</span> and final vertex <span
class="math inline">\(t\)</span>
</dd>
<dt><strong><span class="math inline">\(s\)</span> can reach <span
class="math inline">\(t\)</span></strong>:</dt>
<dd>
There is a walk from <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>. This is an equivalence relation.
</dd>
<dt><strong>component</strong>:</dt>
<dd>
An equivalence class for “can reach”
</dd>
<dt><strong>connected graph</strong>:</dt>
<dd>
A graph with exactly one component
</dd>
<dt><strong>simple walk</strong>:</dt>
<dd>
A walk <span class="math inline">\(\langle s, d_1, \dots, d_k, t
\rangle\)</span> such that each vertex is the head of at most one dart
<span class="math inline">\(d_i\)</span>.
</dd>
<dt><strong>path</strong>:</dt>
<dd>
A simple open walk, or the subgraph induced by a simple open walk
</dd>
<dt><strong>even subgraph</strong>:</dt>
<dd>
A subgraph in which every vertex has even degree.
</dd>
<dt><strong>cycle</strong>:</dt>
<dd>
A simple non-trivial closed walk, or the subgraph induced by such a
walk. A minimal non-empty even subgraph.
</dd>
<dt><strong>loop</strong>:</dt>
<dd>
A cycle with length <span class="math inline">\(1\)</span>, or an edge
whose endpoints coincide.
</dd>
<dt><strong>cut</strong>:</dt>
<dd>
A partition of the vertices <span class="math inline">\(V\)</span> into
two non-empty subsets <span class="math inline">\(S\)</span> and <span
class="math inline">\(V\setminus S\)</span>
</dd>
<dt><strong>edge cut</strong>:</dt>
<dd>
All edges with one endpoint in <span class="math inline">\(S\)</span>
and the other in <span class="math inline">\(V\setminus S\)</span>, for
some subset <span class="math inline">\(S\subseteq V\)</span>
</dd>
<dt><strong>bond</strong>:</dt>
<dd>
A minimal nonempty edge cut
</dd>
<dt><strong>bridge</strong>:</dt>
<dd>
An edge cut containing a single edge; that is, a single edge whose
deletion disconnects the graph
</dd>
<dt><strong>acyclic graph</strong>:</dt>
<dd>
A graph containing no cycles
</dd>
</dl>
<h2 data-number="10.2" id="deletion-and-contraction"><span
class="header-section-number">10.2</span> Deletion and Contraction</h2>
<p>Let’s begin by discussing two operations for modifying abstract
graphs. Let <span class="math inline">\(G\)</span> be an arbitrary
connected (but <em>not</em> necessarily planar) abstract graph with
<span class="math inline">\(n\)</span> vertices and <span
class="math inline">\(m\)</span> edges.</p>
<p><em>Deleting</em> an edge <span class="math inline">\(e\)</span> from
G yields a smaller graph <span class="math inline">\(G \setminus
e\)</span> with <span class="math inline">\(n\)</span> vertices and
<span class="math inline">\(m-1\)</span> edges. We also write <span
class="math inline">\(G \setminus v\)</span> to denote the graph
obtained from <span class="math inline">\(G\)</span> by deleting a
vertex <span class="math inline">\(v\)</span> and all its incident
edges. Deleting a bridge disconnects the graph.</p>
<p>Symmetrically, if <span class="math inline">\(e\)</span> is not a
loop, then <em>contracting</em> <span class="math inline">\(e\)</span>
merges the endpoints of <span class="math inline">\(e\)</span> into a
single vertex and destroys the edge, yielding a smaller graph <span
class="math inline">\(G \mathbin/ e\)</span> with <span
class="math inline">\(n - 1\)</span> vertices and <span
class="math inline">\(m-1\)</span> edges. Contracting a loop is simply
forbidden by definition. Contracting a loop is not (yet) defined. If
<span class="math inline">\(G\)</span> contains edges parallel to <span
class="math inline">\(e\)</span>, those edges survive in <span
class="math inline">\(G \mathbin/ e\)</span> as loops.</p>
<figure>
<img src="Fig/contract-delete.png" style="width:95.0%"
alt="Contraction and deletion." />
<figcaption aria-hidden="true">Contraction and deletion.</figcaption>
</figure>
<p>A <em>subgraph</em> of a graph <span class="math inline">\(G\)</span>
is another graph obtained from <span class="math inline">\(G\)</span> by
deleting edges and isolated vertices; a <em>proper</em> subgraph of
<span class="math inline">\(G\)</span> is any subgraph other than <span
class="math inline">\(G\)</span> itself. (We often equate subgraphs of
<span class="math inline">\(G\)</span> with subsets of the edges of
<span class="math inline">\(G\)</span>.) Deleting any subset of edges
<span class="math inline">\(E’ \subseteq E\)</span> <em>that does not
contain a bond</em> yields a connected proper subgraph <span
class="math inline">\(G \setminus E’\)</span>.</p>
<p>Symmetrically, contracting any subset of edges <span
class="math inline">\(E’ \subseteq E\)</span> <em>that does not contain
a cycle</em> yields a <em>proper minor</em> <span
class="math inline">\(G \mathbin/ E’\)</span>. A minor of <span
class="math inline">\(G\)</span> is any graph obtained from a subgraph
of <span class="math inline">\(G\)</span> by contracting edges; a
<em>proper</em> minor of <span class="math inline">\(G\)</span> is any
minor other than <span class="math inline">\(G\)</span> itself.</p>
<p>The inverse of deletion is called <em>insertion</em>, and the inverse
of contraction is called <em>expansion</em>. If <span
class="math inline">\(G\)</span> is a (proper) subgraph of another graph
<span class="math inline">\(H\)</span>, then <span
class="math inline">\(H\)</span> is a <em>(proper) supergraph</em> of
<span class="math inline">\(G\)</span>; similarly, if <span
class="math inline">\(G\)</span> is a (proper) minor of <span
class="math inline">\(H\)</span>, then <span
class="math inline">\(H\)</span> is a <em>(proper) major</em> of <span
class="math inline">\(G\)</span>.</p>
<h2 data-number="10.3" id="spanning-trees"><span
class="header-section-number">10.3</span> Spanning trees</h2>
<p>A <em>spanning tree</em> of a graph <span
class="math inline">\(G\)</span> is a connected, acyclic subgraph of
<span class="math inline">\(G\)</span> (more more succinctly, a
<em>subtree</em> of <span class="math inline">\(G\)</span>) that
includes every vertex of <span class="math inline">\(G\)</span>. We
leave the following lemma as an exercise for the reader.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(G\)</span> be a connected graph, and
let <span class="math inline">\(e\)</span> be an edge of <span
class="math inline">\(G\)</span>.</em>
</dd>
<dd>
<ul>
<li><em>If <span class="math inline">\(e\)</span> is a loop, then every
spanning tree of <span class="math inline">\(G\)</span> excludes <span
class="math inline">\(e\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>If <span class="math inline">\(e\)</span> is not a loop, then
for any spanning tree <span class="math inline">\(T\)</span> of <span
class="math inline">\(G\mathbin/e\)</span>, the subgraph <span
class="math inline">\(T\cup e\)</span> is a spanning tree of <span
class="math inline">\(G\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>If <span class="math inline">\(e\)</span> is a bridge, then
every spanning tree of <span class="math inline">\(G\)</span> includes
<span class="math inline">\(e\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>If <span class="math inline">\(e\)</span> is not a bridge, then
every spanning tree of <span class="math inline">\(G \setminus
e\)</span> is also a spanning tree of <span
class="math inline">\(G\)</span>.</em></li>
</ul>
</dd>
</dl>
<p>This lemma immediately suggests the following general strategy to
compute a spanning tree of any connected graph: For each edge <span
class="math inline">\(e\)</span>, either contract <span
class="math inline">\(e\)</span> or delete <span
class="math inline">\(e\)</span>. Loops must be deleted and bridges must
be contracted; otherwise, the decision to contract or delete is
arbitrary. (It is impossible for an edge to be both a bridge and a
loop!) The previous lemma implies by induction that the set of
contracted edges is a spanning tree of <span
class="math inline">\(G\)</span>, regardless of the order that edges are
visited, or which non-loop non-bridge edges are deleted or
contracted.</p>
<figure>
<img src="Fig/spanning-tree.png" style="width:95.0%"
alt="Building a spanning tree by contraction and deletion." />
<figcaption aria-hidden="true">Building a spanning tree by contraction
and deletion.</figcaption>
</figure>
<p>In practice, algorithms that compute spanning trees do not
<em>actually</em> contract or delete edges; rather, they simply label
the edges as either belonging to the spanning tree or not. In this
context, the previous lemma can be rewritten as follows:</p>
<dl>
<dt><strong>Spanning Tree Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(G\)</span> be a connected
graph.</em>
</dd>
<dd>
<ul>
<li><em>Each spanning tree of <span class="math inline">\(G\)</span>
excludes at least one edge from each cycle in <span
class="math inline">\(G\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>For every edge e of every cycle of <span
class="math inline">\(G\)</span>, there is a spanning tree of <span
class="math inline">\(G\)</span> that excludes <span
class="math inline">\(e\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>Every spanning tree of <span class="math inline">\(G\)</span>
includes at least one edge from each bond in <span
class="math inline">\(G\)</span>.</em></li>
</ul>
</dd>
<dd>
<ul>
<li><em>For every edge <span class="math inline">\(e\)</span> of every
bond of <span class="math inline">\(G\)</span>, there is a spanning tree
of <span class="math inline">\(G\)</span> that includes <span
class="math inline">\(e\)</span>.</em></li>
</ul>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>If the edges of a connected graph <span
class="math inline">\(G\)</span> are arbitrarily colored red or blue, so
that each cycle in <span class="math inline">\(G\)</span> has at least
one red edge and each bond in <span class="math inline">\(G\)</span> has
at least one blue edge, then the subgraph of blue edges is a spanning
tree of <span class="math inline">\(G\)</span>.</em>
</dd>
</dl>
<p>Given a connected graph with <span class="math inline">\(n\)</span>
vertices and <span class="math inline">\(m\)</span> edges, we can
compute a spanning tree in <span class="math inline">\(O(n+m)\)</span>
time using any number of graph traversal algorithms, the most common of
which are <em>depth-first search</em> and <em>breadth-first search</em>.
These algorithms can be seen as variants of the red-blue coloring
algorithm, where the order in which edges are colored (or equivalently,
the choice of edges to delete or contract) is determined on the fly as
the algorithm explores the graph.</p>
<h2 data-number="10.4"
id="deletion-and-contraction-in-planar-maps"><span
class="header-section-number">10.4</span> Deletion and Contraction in
Planar Maps</h2>
<p>Contraction and deletion play complementary roles in planar maps. For
example, contracting any (non-loop) edge identifies its two endpoints;
deleting any (non-bridge) edge merges its two shores. This resemblance
is not merely incidental; in fact, contraction and deletion are
<em>dual</em> operations. Contracting an edge in any map <span
class="math inline">\(\Sigma\)</span> is equivalent to deleting the
corresponding edge in <span class="math inline">\(\Sigma^*\)</span> and
vice versa.</p>
<p>Hopefully this duality is intuitively clear, but we can make it
formally trivial by describing how deletion and contraction are
<em>implemented</em> in planar maps. Let <span
class="math inline">\(\textsf{succ}\)</span> denote the successor
permutation of a planar map <span class="math inline">\(\Sigma\)</span>,
and let <span class="math inline">\(\textsf{succ}^* = \textsf{rev}\circ
\textsf{succ}\)</span> denote its dual successor permutation, which is
also the successor permutation of the dual map <span
class="math inline">\(\Sigma^*\)</span>. Fix an arbitrary edge <span
class="math inline">\(e\)</span> of <span
class="math inline">\(\Sigma\)</span>.</p>
<dl>
<dt><strong>Deletion:</strong></dt>
<dd>
Suppose <span class="math inline">\(e\)</span> is not a bridge. Then
<span class="math inline">\(\Sigma \setminus e\)</span> is a planar map
that contains every dart in <span class="math inline">\(\Sigma\)</span>
except <span class="math inline">\(e^+\)</span> and <span
class="math inline">\(e^-\)</span>. Let <span
class="math inline">\(\textsf{succ}\setminus e\)</span> and <span
class="math inline">\(\textsf{succ}^*\setminus e\)</span> denote the
induced primal and dual successor permutations of <span
class="math inline">\(\Sigma\setminus e\)</span>. Then for any dart
<span class="math inline">\(d\)</span> in <span
class="math inline">\(\Sigma\setminus e\)</span>, we have <span
class="math display">\[
(\textsf{succ}\setminus e)(d) = \begin{cases}
    \textsf{succ}(\textsf{succ}(\textsf{succ}(d)))
        &amp; \text{if $\textsf{succ}(d) \in e$ and
                    $\textsf{succ}(\textsf{succ}(d)) \in e$,}\\
    \textsf{succ}(\textsf{succ}(d))
        &amp; \text{if $\textsf{succ}(d) \in e$,}\\
    \textsf{succ}(d) &amp; \text{otherwise.}
\end{cases}
\]</span> The first case occurs when <span
class="math inline">\(e\)</span> is an empty loop based at the head of
<span class="math inline">\(d\)</span>. See the figure below. In other
words, to find the successor of <span class="math inline">\(d\)</span>
in <span class="math inline">\(\Sigma \setminus e\)</span>, we
repeatedly follow successor pointers until we reach a dart that is not
in the deleted edge <span class="math inline">\(e\)</span>.
</dd>
<dd>
<p>It follows that the dual successor permutation changes as follows:
<span class="math display">\[
(\textsf{succ}^*\setminus e)(d) = \begin{cases}
    \textsf{succ}^*(\textsf{succ}(\textsf{succ}(d)))
        &amp; \text{if $\textsf{succ}(d) \in e$ and
                    $\textsf{succ}(\textsf{succ}(d)) \in e$,}\\
    \textsf{succ}^*(\textsf{succ}(d))
        &amp; \text{if $\textsf{succ}(d) \in e$,}\\
    \textsf{succ}^*(d) &amp; \text{otherwise.}
\end{cases}
\]</span></p>
</dd>
</dl>
<figure>
<img src="Fig/delete-cases.png" style="width:45.0%"
alt="Deleting an edge: Default case and empty loop" />
<figcaption aria-hidden="true">Deleting an edge: Default case and empty
loop</figcaption>
</figure>
<dl>
<dt><strong>Contraction:</strong></dt>
<dd>
Suppose <span class="math inline">\(e\)</span> is not a loop. Then <span
class="math inline">\(\Sigma \mathbin/ e\)</span> is a planar map that
contains every dart in <span class="math inline">\(\Sigma\)</span>
except <span class="math inline">\(e^+\)</span> and <span
class="math inline">\(e^-\)</span>. Let <span
class="math inline">\(\textsf{succ} \mathbin/ e\)</span> and <span
class="math inline">\(\textsf{succ}^* \mathbin/ e\)</span> respectively
denote the induced primal and dual successor permutations of <span
class="math inline">\(\Sigma \mathbin/ e\)</span>. Then for any dart
<span class="math inline">\(d\)</span> of <span
class="math inline">\(\Sigma \mathbin/ e\)</span>, we have <span
class="math display">\[
(\textsf{succ}^*\mathbin/ e)(d) = \begin{cases}
    \textsf{succ}^*(\textsf{succ}^*(\textsf{succ}^*(d)))
        &amp; \text{if $\textsf{succ}^*(d) \in e$ and
                    $\textsf{succ}^*(\textsf{succ}^*(d)) \in e$,}\\
    \textsf{succ}^*(\textsf{succ}^*(d))
        &amp; \text{if $\textsf{succ}^*(d) \in e$,}\\
    \textsf{succ}^*(d) &amp; \text{otherwise.}
\end{cases}
\]</span> The first case occurs when one endpoint of <span
class="math inline">\(e\)</span> has degree <span
class="math inline">\(1\)</span> and the head of <span
class="math inline">\(d\)</span> is the other endpoint of <span
class="math inline">\(e\)</span>. See the figure below. In other words,
to find the <em>dual</em> successor of <span
class="math inline">\(d\)</span> in <span
class="math inline">\(\Sigma\mathbin/e\)</span>, we chase <em>dual</em>
successor pointers until we reach a dart that is not in the contracted
edge <span class="math inline">\(e\)</span>.
</dd>
<dd>
<p>It follows that the primal successor permutation changes as follows:
<span class="math display">\[
(\textsf{succ} \mathbin/ e)(d) = \begin{cases}
    \textsf{succ}(\textsf{succ}^*(\textsf{succ}^*(d)))
        &amp; \text{if $\textsf{succ}(d) \in e$ and
                    $\textsf{succ}^*(\textsf{succ}^*(d)) \in e$,}\\
    \textsf{succ}(\textsf{succ}^*(d))
        &amp; \text{if $\textsf{succ}(d) \in e$,}\\
    \textsf{succ}(d) &amp; \text{otherwise.}
\end{cases}
\]</span></p>
</dd>
</dl>
<figure>
<img src="Fig/contract-cases.png" style="width:45.0%"
alt="Contracting an edge: Default case and leaf" />
<figcaption aria-hidden="true">Contracting an edge: Default case and
leaf</figcaption>
</figure>
<p>Both of these formulas are trivially correct when we either delete or
contract the only edge in a one-edge map, because the resulting trivial
map has no darts. Assuming standard data structures, any edge can be
contracted or deleted in <span class="math inline">\(O(1)\)</span>
time.</p>
<p>The following lemma is now purely mechanical.</p>
<dl>
<dt><strong>Lemma (contraction <span
class="math inline">\(\leftrightharpoons\)</span>
deletion):</strong></dt>
<dd>
<em>Fix a planar map <span class="math inline">\(\Sigma\)</span>, and
let <span class="math inline">\(e\)</span> be any edge in <span
class="math inline">\(\Sigma\)</span>.</em>
</dd>
<dd>
<ol type="a">
<li><em>If <span class="math inline">\(e\)</span> is not a loop, then
<span class="math inline">\(e^*\)</span> is not a bridge and <span
class="math inline">\((\Sigma \mathbin/ e)^* = \Sigma^* \setminus
e^*\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol start="2" type="a">
<li><em>If <span class="math inline">\(e\)</span> is not a bridge, then
<span class="math inline">\(e^*\)</span> is not a loop and <span
class="math inline">\((\Sigma\setminus e)^* = \Sigma^* \mathbin/
e^*\)</span>.</em></li>
</ol>
</dd>
</dl>
<p>If we delete a bridge using the formulas above, the components of
<span class="math inline">\(G\setminus e\)</span> become embedded
independently, each on its own plane/sphere; instead of merging two
faces into one, the deletion breaks one face (on either side of the
deleted edge) into two. Symmetrically, if we contract a loop using the
formula above, instead of merging two vertices into one, we split the
single endpoint of the loop into two, splitting the graph into two
independent subgraphs, one “inside” the loop and the other
“outside”.</p>
<figure>
<img src="Fig/contract-delete-medial.png" style="width:95.0%"
alt="Contraction and deletion in a planar map \Sigma both induce smoothing in the medial map \Sigma^\times." />
<figcaption aria-hidden="true">Contraction and deletion in a planar map
<span class="math inline">\(\Sigma\)</span> both induce smoothing in the
medial map <span
class="math inline">\(\Sigma^\times\)</span>.</figcaption>
</figure>
<h2 data-number="10.5" id="tree-cotree-decompositions"><span
class="header-section-number">10.5</span> Tree-Cotree
Decompositions</h2>
<dl>
<dt><strong>Lemma (even subgraph <span
class="math inline">\(\leftrightharpoons\)</span> edge
cut):</strong></dt>
<dd>
<em>Fix a planar map <span class="math inline">\(\Sigma\)</span>. A
subset <span class="math inline">\(H\)</span> of the edges of <span
class="math inline">\(\Sigma\)</span> is an even subgraph if and only if
the corresponding subset <span class="math inline">\(H^*\)</span> of
edges in <span class="math inline">\(\Sigma^*\)</span> is an edge
cut.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(H\)</span> be an even subgraph of <span
class="math inline">\(\Sigma\)</span>. Let <span
class="math inline">\(C_1, C_2, \dots, C_k\)</span> be edge-disjoint
cycles in <span class="math inline">\(\Sigma\)</span> whose union is
<span class="math inline">\(H\)</span>. Color each vertex of <span
class="math inline">\(\Sigma^*\)</span> black if it lies in the interior
of an odd number of cycles <span class="math inline">\(C_i\)</span>, and
white otherwise. Then <span class="math inline">\(H\)</span> is the
subgraph of edges with one white shore and one black shore. It follows
that <span class="math inline">\(H^*\)</span> is the subgraph of dual
edges with one endpoint of each color; in other words, <span
class="math inline">\(H^*\)</span> is an edge cut in <span
class="math inline">\(\Sigma^*\)</span>.
</dd>
<dd>
<p>On the other hand, let <span class="math inline">\(H^*\)</span> is an
edge cut in <span class="math inline">\(\Sigma^*\)</span>. Then it is
possible to color the vertices of <span
class="math inline">\(\Sigma^*\)</span> black and white, so that <span
class="math inline">\(H^*\)</span> is the subset of edges with one white
endpoint and one black endpoint. The primal subgraph <span
class="math inline">\(H\)</span> contains precisely the edges of <span
class="math inline">\(\Sigma\)</span> with one white shore and one black
shore. Every vertex of <span class="math inline">\(\Sigma\)</span> is
incident to an even number of such edges. We conclude that <span
class="math inline">\(H\)</span> is an even subgraph of <span
class="math inline">\(\Sigma\)</span>.</p>
</dd>
<dt><strong>Corollary (cycle <span
class="math inline">\(\leftrightharpoons\)</span> bond):</strong></dt>
<dd>
<em>A subgraph <span class="math inline">\(H\)</span> of a planar map
<span class="math inline">\(\Sigma\)</span> is a cycle if and only if
the corresponding subgraph <span class="math inline">\(H^*\)</span> of
<span class="math inline">\(\Sigma^*\)</span> is a bond.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
A cycle is a minimal non-empty even subgraph; a bond is a minimal
non-empty edge cut.
</dd>
<dd>
<p>Equivalently, a cycle is a minimal subset of edges that cannot all be
contracted, and a bond is a minimal subset of edges that cannot all be
deleted.</p>
</dd>
<dt><strong>Corollary (spanning tree <span
class="math inline">\(\leftrightharpoons\)</span> spanning
cotree):</strong></dt>
<dd>
<em>Fix a planar map <span class="math inline">\(\Sigma = (V, E,
F)\)</span>, and let <span class="math inline">\(T \sqcup C\)</span> be
a partition of <span class="math inline">\(E\)</span>. Then <span
class="math inline">\(T\)</span> defines a spanning tree of <span
class="math inline">\(\Sigma\)</span> if and only if <span
class="math inline">\(C^* \subset E^*\)</span> defines a spanning tree
of <span class="math inline">\(\Sigma^*\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(T\)</span> be an arbitrary spanning tree
of <span class="math inline">\(G\)</span>, and let <span
class="math inline">\(C^* = E^*\setminus T^*\)</span> be the
complementary dual subgraph of <span
class="math inline">\(\Sigma^*\)</span>. The Spanning Tree Lemma implies
that every cycle of <span class="math inline">\(\Sigma\)</span> excludes
at least one edge in <span class="math inline">\(T\)</span>, and every
bond of <span class="math inline">\(\Sigma\)</span> contains at least
one edge in <span class="math inline">\(T\)</span>. Cycle-bond duality
implies that every bond of <span class="math inline">\(\Sigma^*\)</span>
contains at least one edge in <span class="math inline">\(C^*\)</span>,
and every cycle of <span class="math inline">\(\Sigma^*\)</span>
excludes at least one edge in <span class="math inline">\(C^*\)</span>.
We conclude that <span class="math inline">\(C^*\)</span> is a connected
acyclic spanning subgraph of <span
class="math inline">\(\Sigma^*\)</span>, or in other words, a spanning
tree of <span class="math inline">\(\Sigma^*\)</span>.
</dd>
</dl>
<figure>
<img src="Fig/planar-tree-cotree.png" style="width:25.0%"
alt="A tree-cotree decomposition of a planar map and its dual." />
<figcaption aria-hidden="true">A tree-cotree decomposition of a planar
map and its dual.</figcaption>
</figure>
<p>The partition <span class="math inline">\(T\sqcup C\)</span> of edges
of a planar map into primal and dual spanning trees is called a
<em>tree-cotree decomposition</em>. Notice that either the primal
spanning tree <span class="math inline">\(T\)</span> or the dual
spanning tree <span class="math inline">\(C^*\)</span> can be chosen
arbitrarily.</p>
<p>The duality between cycles and bonds was first proved by Hassler
Whitney. Whitney also proved the following converse result. An
<em>algebraic dual</em> of an abstract graph <span
class="math inline">\(G\)</span> is another abstract graph <span
class="math inline">\(G^*\)</span> with the same set of edges, such that
a subset of edges defines a cycle in <span
class="math inline">\(G\)</span> if and only if the same subset defines
a bond in <span class="math inline">\(G^*\)</span>.</p>
<p><strong>Theorem (Whitney (1932)):</strong> <em>A connected abstract
graph is planar if and only if it has an algebraic dual.</em></p>
<h2 data-number="10.6" id="eulers-formula"><span
class="header-section-number">10.6</span> Euler’s Formula</h2>
<p>Arguably the earliest fundamental result in combinatorial topology is
a simple formula first <em>published</em> by Leonhard Euler, but
described in full generality over a century earlier by René Descartes,
and described for the special case of Platonic solids by Francesco
Maurolico a century before Descartes. I’ll provide two short proofs
here, one directly inductive, the other relying on tree-cotree
decompositions.</p>
<dl>
<dt><strong>Euler’s Formula for Planar Maps.</strong></dt>
<dd>
<em>For any connected planar map with <span
class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces, we have <span
class="math inline">\(n-m+f = 2\)</span>.</em>
</dd>
<dt><strong>Proof (by induction):</strong></dt>
<dd>
Fix an arbitrary planar map <span class="math inline">\(\Sigma\)</span>
with <span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces. If <span
class="math inline">\(\Sigma\)</span> has no edges, it has one vertex
and one face. Otherwise, let <span class="math inline">\(e\)</span> be
any edge of<span class="math inline">\(\Sigma\)</span>; there are two
overlapping cases to consider.
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(e\)</span> is not a bridge, then
deleting <span class="math inline">\(e\)</span> yields a planar map
<span class="math inline">\(\Sigma\setminus e\)</span> with <span
class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m-1\)</span> edges, and <span
class="math inline">\(f-1\)</span> faces. The induction hypothesis
implies that <span class="math inline">\(n-(m-1)+(f-1) =
2\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(e\)</span> is not a loop, then
contracting <span class="math inline">\(e\)</span> yields a planar map
<span class="math inline">\(\Sigma\mathbin/e\)</span> with <span
class="math inline">\(n-1\)</span> vertices, <span
class="math inline">\(m-1\)</span> edges, and <span
class="math inline">\(f\)</span> faces. The induction hypothesis implies
that <span class="math inline">\((n-1)-(m-1)+f = 2\)</span>.</li>
</ul>
</dd>
<dd>
<p>In all cases, we conclude that <span
class="math inline">\(n-m+f=2\)</span>.</p>
</dd>
<dt><strong>Proof (von Staudt 1847):</strong></dt>
<dd>
Fix an arbitrary planar map <span class="math inline">\(\Sigma\)</span>
with <span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces. Let <span
class="math inline">\(T\)</span> be an arbitrary spanning tree of <span
class="math inline">\(\Sigma\)</span>. Because <span
class="math inline">\(T\)</span> has <span
class="math inline">\(n\)</span> vertices, it also has <span
class="math inline">\(n-1\)</span> edges. The complementary dual
subgraph <span class="math inline">\(C^* = (E\setminus T)^*\)</span> is
a spanning tree of <span class="math inline">\(\Sigma^*\)</span>.
Because <span class="math inline">\(C^*\)</span> has <span
class="math inline">\(f\)</span> vertices, it also has <span
class="math inline">\(f-1\)</span> edges. Every edge in <span
class="math inline">\(\Sigma\)</span> is either an edge of <span
class="math inline">\(T\)</span> or the dual of an edge in <span
class="math inline">\(C^*\)</span>, but not both. We conclude that <span
class="math inline">\(m = (n-1)+(f-1)\)</span>.
</dd>
</dl>
<p>There are many many other proofs of Euler’s formula. David Eppstein
has <a href="https://www.ics.uci.edu/~eppstein/junkyard/euler/">a web
page describing more than twenty of them</a>, but even David’s list is
incomplete. For example, we can leverage our earlier proof of Euler’s
formula for planar <em>curves</em>, after establishing a few additional
definitions.</p>
<p>Recall that the <em>medial map</em> <span
class="math inline">\(\Sigma^\times\)</span> of a planar map <span
class="math inline">\(\Sigma\)</span> is another planar map whose
vertices correspond to edges of <span
class="math inline">\(\Sigma\)</span>, whose edges correspond to corners
of <span class="math inline">\(\Sigma\)</span>, and whose faces
correspond to vertices and faces of <span
class="math inline">\(\Sigma\)</span>. Every medial map <span
class="math inline">\(\Sigma^\times\)</span> is either a simple cycle or
4-regular, and therefore is the image map of a connected planar
multicurve. (Steinitz used medial maps (“<span
class="math inline">\(\Theta\)</span>-Prozeß”) to reduce his eponymous
theorem about graphs of convex polyhedra to an argument about
curves.)</p>
<figure>
<img src="Fig/derived-maps/medial.png" style="width:40.0%"
alt="The medial map of a planar map." />
<figcaption aria-hidden="true">The medial map of a planar
map.</figcaption>
</figure>
<dl>
<dt><strong>Proof (via medial homotopy):</strong></dt>
<dd>
Fix an arbitrary planar map <span class="math inline">\(\Sigma\)</span>
with <span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces. The medial map <span
class="math inline">\(\Sigma^\times\)</span> is the image map of a
connected planar multicurve with <span class="math inline">\(2m\)</span>
vertices and <span class="math inline">\(n+f\)</span> faces. We already
proved by induction<a href="#fn24" class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a> that every connected planar
multicurve with <span class="math inline">\(N\)</span> vertices has
exactly <span class="math inline">\(N+2\)</span> faces. We conclude that
<span class="math inline">\(n+f = 2m+2\)</span>.
</dd>
</dl>
<h2 data-number="10.7" id="the-combinatorial-gauss-bonnet-theorem"><span
class="header-section-number">10.7</span> The Combinatorial Gauss-Bonnet
Theorem</h2>
<p>I’ll close this lecture by proving a powerful reformulation of
Euler’s formula.</p>
<p>Suppose we assign a value <span class="math inline">\(\angle
c\)</span> to each corner <span class="math inline">\(c\)</span> of a
planar map <span class="math inline">\(\Sigma\)</span>, called the
<em>exterior angle</em> at <span class="math inline">\(c\)</span>.
Intuitively, you should think of <span class="math inline">\(\angle
c\)</span> as the signed angle between the tangent vectors to two darts
<span class="math inline">\(d\)</span> and <span
class="math inline">\(\textsf{succ}^*(d)\)</span> at their common
endpoint <span class="math inline">\(\textsf{head}(d)\)</span>, but in
fact <span class="math inline">\(\angle c\)</span> can be any real (or
complex!) number. As usual, we measure angles in units of circles (or
“turns”), as the gods intended.</p>
<p>We can then define the <em>combinatorial curvature</em> of a face
<span class="math inline">\(f\)</span> or a vertex <span
class="math inline">\(v\)</span>, with respect to this angle assignment,
as follows: <span class="math display">\[
    \kappa(f) := 1 - \sum_{c\in f} \angle c
    \qquad\qquad
    \kappa(v) := 1 - \frac{1}{2} \deg(v) + \sum_{c\in v} \angle c
\]</span> Or more formally, equating corners with darts: <span
class="math display">\[
    \kappa(f) := 1 - \sum_{d \colon \textsf{left}(d) = f} \angle d
    \qquad\qquad
    \kappa(v) := 1 - \sum_{d \colon \textsf{head}(d) = v}
                            \left(\frac12 - \angle d\right)
\]</span></p>
<p>For example, suppose every edge of <span
class="math inline">\(\Sigma\)</span> is a line segment, and we actually
measure corner angles geometrically. Then every vertex has curvature
<span class="math inline">\(0\)</span> (because its interior corner
angles sum to one circle) and every <em>bounded</em> face of <span
class="math inline">\(\Sigma\)</span> has curvature <span
class="math inline">\(0\)</span> (because its total turning angle is
<span class="math inline">\(1\)</span>). However, the the <em>outer</em>
face is oriented clockwise instead of counterclockwise, so its total
turning angle is <span class="math inline">\(-1\)</span>, and thus its
curvature is <span class="math inline">\(2\)</span>. That <span
class="math inline">\(2\)</span> is actually the same as the <span
class="math inline">\(2\)</span> in Euler’s formula.</p>
<p>Alternatively, suppose <span class="math inline">\(\Sigma\)</span> is
actually embedded on the <em>unit sphere</em>, every edge is an arc of a
great circle, and angles are again measured geometrically (between
tangent vectors). Then every vertex of <span
class="math inline">\(\Sigma\)</span> has curvature zero, because
interior angles at any vertex sum to one circle, and a bit of spherical
trigonometry implies that every face of <span
class="math inline">\(\Sigma\)</span> has curvature equal to its area
divided by <span class="math inline">\(2\pi\)</span>. Because the unit
sphere has surface area <span class="math inline">\(4\pi\)</span>, the
sum of all the face curvatures is <span
class="math inline">\(2\)</span>. That <span
class="math inline">\(2\)</span> is actually the same as the <span
class="math inline">\(2\)</span> in Euler’s formula! (In fact, this is
how Lagrange actually proved Euler’s formula for the first time.)</p>
<dl>
<dt><strong>The Combinatorial Gauss-Bonnet Theorem:</strong></dt>
<dd>
<em>For any planar map <span class="math inline">\(\Sigma = (V, E,
F)\)</span> and for <strong>any</strong> assignment of angles to the
corners of <span class="math inline">\(\Sigma\)</span>, we have <span
class="math inline">\(\sum_{v \in V} \kappa(v) + \sum_{f \in F}
\kappa(f) = 2\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We immediately have <span class="math inline">\(\sum_f \kappa(f) = |F| -
\sum_c \angle c\)</span> and <span class="math inline">\(\sum_v
\kappa(f) = |V| - |E| + \sum_c \angle c\)</span>, which implies that
<span class="math inline">\(\sum_v \kappa(v) + \sum_f \kappa(f) = |V| -
|E| + |F| = 2\)</span> by Euler’s formula. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>As a final geometric example, suppose <span
class="math inline">\(\Sigma\)</span> is actually the complex of
vertices, edges, and faces of a three-dimensional convex polyhedron
(which is homeomorphic to a sphere), and again, angles are measured
geometrically. Each face of <span class="math inline">\(\Sigma\)</span>
is a convex planar polygon, and therefore has curvature zero. The
interior angles at each vertex of <span
class="math inline">\(\Sigma\)</span> sum to less than a full circle, so
every vertex has positive curvature. The Combinatorial Gauss-Bonnet
Theorem implies that the sum of the vertex curvatures is exactly <span
class="math inline">\(2\)</span>. In other words, the sum of the
<em>angle defects</em> at the vertices is two full circles, or eight
right angles.</p>
<h2 data-number="10.8" id="historical-digression"><span
class="header-section-number">10.8</span> Historical Digression</h2>
<p>Euler’s formula has a long and convoluted history, involving
unpublished and lost manuscripts, quack medicine, boat wrecks, priority
battles, bad translations, incorrect proofs, and philosophical arguments
over the natural of mathematical proof. At the risk of adding to the
thousands of gallons of ink, seat, and blood that have already been
spilled over this history, let me briefly mention a few highlights.</p>
<p>The first known statement of Euler’s formula is in an unpublished
manuscript <em>Compaginationes solidorum regularium</em> (Combinations
of regular solids) written by Francesco Maurolico between 1536 and
1537.</p>
<blockquote>
<p><em>Item manifestum est in unoquoque regularium solidorum, numerum
basium coniunctum cum numero cacuminum conflare numerum, qui binario
excedit numerum laterum.</em> [It is obvious that in each of the regular
solids, the number of bases (faces) combined with the number of peaks
(vertices) is a number that exceeds the number of sides (edges) by
2.]</p>
</blockquote>
<p>Maurolico only considered the five Platonic solids, for which the
formula follows by direct inspection.</p>
<p>René Descartes described the angle defect theorem for convex
polyhedra, and derived Euler’s formula from it, in his unpublished note
<em>Progymnasmata de solidorum elementis</em> [<em>Exercises in the
Elements of Solids</em>], written around 1630.</p>
<blockquote>
<p><em>Ponam semper pro numero angulorum solidorum <span
class="math inline">\(\alpha\)</span> &amp; pro numero facirum <span
class="math inline">\(\varphi\dots\)</span>. Numerus verorum angulorum
planorum est <span class="math inline">\(2\varphi - 2\alpha -
4\)</span>.</em> [I always write <span
class="math inline">\(\alpha\)</span> for the number of solid angles
(vertices) and <span class="math inline">\(\varphi\)</span> for the
number of faces<span class="math inline">\(\dots\)</span>. The total
number of plane angles (corners) is <span class="math inline">\(2\varphi
- 2\alpha - 4\)</span>.]</p>
</blockquote>
<p>It is a matter of surprisingly intense scholarly dispute whether
Descartes actually stated Euler’s formula, and therefore deserves to
share credit with Euler, or only came close, and therefore does not.
Descartes did not express his formula using the syntax <span
class="math inline">\(V-E+F=2\)</span>, but in my opinion, this is
entirely a matter of notational emphasis, not content or understanding.
Elsewhere in <em>Progymnasmata</em>, Descartes observed that the number
of plane angles is exactly twice the number of edges, and he used the
numbers of vertices, edges, and faces of the Platonic and several
Archimedean solids to derive formulas for corresponding figurate
numbers. Had Descartes actually published his <em>Progymnasmata</em>, I
believe even Euler (who exhibited surprise that the formula was not
already known) would have called it “Descartes’ formula”.</p>
<p>Descartes traveled to Sweden in 1649 at the invitation of
then-19-year-old Queen Christina. Due to his poor health, Descartes
normally slept late, but after a few months, the young queen required
Descartes to give her lessons in philosophy three days a week, lasting
five hours per day and beginning at 5am. Within a month, Descartes fell
ill. He refused the treatments offered by the Swedish doctors,
preferring his own French doctor’s prescription of tobacco-infused wine
to induce vomiting. The treatment proved ineffective, and Descartes
eventually died of pneumonia in February 1650.</p>
<p>After Descartes’ death, his possessions were shipped to his friend
Claude Clerselier in Paris; upon arrival, a box of manuscripts,
including the <em>Progymnasmata</em>, fell into the Seine and was not
recovered for three days. Clerselier rescued Descartes’ manuscripts, and
after carefully drying them, made them available to other scholars.</p>
<p>Gottfried Leibniz transcribed several of Descartes’ manuscripts,
including the <em>Progymnasmata</em>, during a trip to Paris in 1676,
most likely in an effort to collect evidence against recent charges by
English mathematicians that his results were merely elaborations of
Descartes’ ideas. (Isaac Newton charged Leibniz of plagiarizing his
calculus later that same year.) Descartes’ original manuscript was then
lost forever. Leibniz’s hand-written copy vanished into his archives
until 1859, when it was rediscovered by Louis Alexandre Foucher de
Careil in an uncatalogued pile of Leibniz’s papers.<a href="#fn25"
class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>
Foucher de Careil published Leibniz’s transcription , but his
re-transcription introduced several significant errors, rendering it
essentially useless. An accurate transcription of the finally appeared
in
1908.<!--, thanks to the combined efforts of several Cartesian and Leibnizian scholars \cite{a-dse-1908}.  The remarkable story is told in more detail by Federico \cite{f-dpsds-82}, Richeson \cite{r-eg-05}, and (with some creative embellishment) Aczel \cite{a-dsn-05}.--></p>
<p>Leonhard Euler stated both his eponymous formula and the angle defect
theorem for convex polyhedra, expressing surprise that neither was
previously known, in a letter to his friend and colleague Christian
Goldbach in 1750. Two years later, he proposed an inductive proof to the
St. Petersberg Academy of Sciences; unfortunately his proof was flawed.
Similarly flawed inductive proofs were published by Karsten in 1768, by
Meister in 1785, by L’Huillier in 1811, by Cauchy in 1813, and by
Grunert in 1827. One of Cauchy’s inductive arguments is presented in
numerous textbooks as the first correct proof of Euler’s formula, but
that claim is incorrect for at least three reasons: The argument is not
original to Cauchy; the argument is not a proof; and a correct proof was
already known.<a href="#fn26" class="footnote-ref" id="fnref26"
role="doc-noteref"><sup>26</sup></a></p>
<p>Cauchy argued as follows: Consider a simple planar map <span
class="math inline">\(\Sigma\)</span> whose bounded faces are all
triangles and whose outer face is a simple cycle. Let <span
class="math inline">\(f\)</span> be any face that has at least one edge
on the outer face. If <span class="math inline">\(f\)</span> shares one
edge with the outer face, then deleting that edge removes one edge and
one face. If <span class="math inline">\(f\)</span> shares two edges
with the outer face, then removing those two edges removes one vertex,
two edges, and one face. Finally, if all three edges of <span
class="math inline">\(f\)</span> are boundary edges, the map has only
one bounded face, so <span class="math inline">\(v=e=3\)</span> and
<span class="math inline">\(f=2\)</span>.</p>
<p>Unfortunately, Cauchy (and his predecessors) did not prove that one
can always choose a face <span class="math inline">\(f\)</span> so that
the outer boundary is still a simple cycle after <span
class="math inline">\(f\)</span> is removed. This fact is not hard to
prove using a second careful induction argument (which I’ll present in
the next lecture), but neither Euler, nor Karsten, nor Meister, nor
L’Huillier, nor Cauchy, nor Grunert offered such a proof. Lakatos
noticed this lacuna in Cauchy’s argument and proposed a proof, but his
proposed proof was flawed. Most modern presentations of “Cauchy’s”
“proof”—including Wikipedia’s—either ignore this subtlety entirely, or
merely <em>state</em> that <span class="math inline">\(f\)</span> must
be chosen carefully without proving that is always possible.</p>
<p>The first <em>correct</em> proof of Euler’s formula was given by
Legendre in 1794. Legendre projects the vertices and edges of the
polyhedron onto the unit sphere from an arbitrary interior point, and
then applies the already well-known fact that a spherical triangle with
interior angles <span class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span>, and <span
class="math inline">\(\gamma\)</span> has area <span
class="math inline">\(\alpha+\beta+\gamma-\pi\)</span>. Suppose the
original polyhedron has <span class="math inline">\(n\)</span> vertices
and <span class="math inline">\(f\)</span> facets, all triangles. The
angles at each vertex of the resulting spherical triangulation sum to
exactly <span class="math inline">\(2\pi\)</span>; thus, the total area
of all <span class="math inline">\(f\)</span> spherical triangles is
<span class="math inline">\(2\pi n - \pi f\)</span>. We immediately
conclude that <span class="math inline">\(f = 2n-4\)</span>, because the
surface area of the unit sphere is <span
class="math inline">\(4\pi\)</span>. The proof for more general
polyhedra follows by triangulating the faces.
<!-- Essentially the same proof was later given by Hirsch in 1807, and   l’Huillier described a similar proof based on Euclidean angles in 1811. --></p>
<p>The first correct <em>combinatorial</em> proof of Euler’s formula is
Von Staudt’s 1847 tree-cotree proof. Von Staudt’s actual argument is
remarkably concise, despite being written in mid-19th-century academic
German, especially in comparison to the earlier inductive arguments:</p>
<blockquote>
<p><em>Wenn nämlich der Körper <span class="math inline">\(E\)</span>
Eckpünkte hat, so sind <span class="math inline">\(E-1\)</span> Kanten,
von welchen die erste zwei Eckpunkte unter sich, die zweite einen
derselben mit einem dritten, die dritte einen der drei vorigen mit einem
vierten u.s.w. verbindet, hinreichend um von jedem Eckpunkte auf jeden
andern übergehen zu können. Da nun in einem solchen Systeme von Kanten
keine geschlossene Linie enthalten ist, jede der übrigen (noch freien)
Kanten aber mit zwei oder mehrern Kanten des Systems eine geschlossene
Linie bildet, so sind die übrigen Kanten hinreichend aber auch alle
erforderlich, um durch sie von jeder der <span
class="math inline">\(F\)</span> Flächen des Korpers auf jede andere
übergehen zu können, woraus man scldiessen kann, dass die Anzahl der
übrigen Kanten <span class="math inline">\(F-1\)</span>, mithin die
Anzahl aller Kanten <span class="math inline">\(E+F-2\)</span> und
demnach <span class="math inline">\(E+F=K+2\)</span> sey.</em></p>
</blockquote>
<blockquote>
<p>[When a body has <span class="math inline">\(n\)</span> vertices,
then <span class="math inline">\(n-1\)</span> edges are sufficient—the
first connecting two vertices, the second connecting one of those with a
third, the third connecting one of the three rpevious vertices with a
fourth, and so on—to be able to go from any vertex to any other. Such a
system of edges does not contain a closed line, but each of the
remaining edges forms a closed line with two or more edges of the
system, so the remaining edges are sufficient, but also necessary, to be
able to go through them from any of the <span
class="math inline">\(f\)</span> faces of the body to any other. It
follows that the number of remaining edges if <span
class="math inline">\(f-1\)</span>; hence the number of all edges is
<span class="math inline">\(n+f-2\)</span>, and therefore <span
class="math inline">\(n+f=m+2\)</span>.]</p>
</blockquote>
<blockquote>
<p>[More loosely: When a body has <span class="math inline">\(n\)</span>
vertices, we can find <span class="math inline">\(n-1\)</span> edges
that define a spanning tree <span class="math inline">\(T\)</span>.
Cutting the surface along every edge in <span
class="math inline">\(T\)</span> leaves the surface connected, but
additionally cutting any other edge disconnects the surface, so that
edges not in <span class="math inline">\(T\)</span> are just enough to
keep the faces of the body connected. It follows that the number of
remaining edges if <span class="math inline">\(f-1\)</span>, so the
total number of edges is <span
class="math inline">\(n+f-2\)</span>.]</p>
</blockquote>
<p>All of these proofs were intended to prove Euler’s formula <em>for
convex polyhedra</em>, although Cauchy’s proof starts by projecting the
polyhedron to a <em>straight-line</em> planar map. The first proofs that
directly consider planar maps are due to Cayley and Listing, both
published in 1861.
<!-- In fact, both Cayley and Listing allowed their graphs to include isolated closed “edges” with no vertices, and Listing considered much more general “acyclodic spatial complexes” constructed by gluing disks to cycles in graphs.-->
Cayley’s argument is a prototype for our first inductive proof; he
observed that the quantity <span class="math inline">\(n-m+f\)</span>
does not change when one inserts a new vertex in the interior of an edge
or inserts a new edge in the interior of a face. Listing repeats (and
generalizes) Cauchy’s argument, using a global counting argument instead
of induction, but again assuming without proof the existence of a
shelling order. Both proofs implicitly assume the Jordan curve theorem,
so even ignoring shelling issues, they technically only apply to
<em>combinatorial</em> maps.</p>
<h2 data-number="10.9" id="aptly-named"><span
class="header-section-number">10.9</span> Aptly Named</h2>
<ul>
<li><p>Outerplanar graphs/maps</p></li>
<li><p>Easy consequences of Euler’s formula:</p>
<ul>
<li>Every simple planar graph has a vertex of degree at most <span
class="math inline">\(5\)</span>.</li>
<li>Every planar triangulation has <span
class="math inline">\(3n-6\)</span> edges and <span
class="math inline">\(2n-4\)</span> faces.</li>
<li>Every simple planar graph has at most <span
class="math inline">\(3n-6\)</span> edges.</li>
<li>Every simple planar bipartite graph has at most <span
class="math inline">\(2n-4\)</span> edges.</li>
<li>Every planar map has either a vertex or a face of degree at most
<span class="math inline">\(3\)</span>.</li>
<li><span class="math inline">\(K_{3,3}\)</span> and <span
class="math inline">\(K_5\)</span> are not planar.</li>
<li>There are only five Platonic solids.</li>
<li>Every loop-free planar graph is 6-colorable.</li>
<li>Every planar graph has an independent set of size <span
class="math inline">\(\Omega(n)\)</span> in which every vertex has
degree <span class="math inline">\(O(1)\)</span>.</li>
</ul></li>
<li><p>Minimum spanning trees:</p>
<ul>
<li>Tarjan’s red-blue meta-algorithm</li>
<li>Borůvka’s algorithm</li>
<li>Mareš’s algorithm, Matsui’s algorithm</li>
<li>minimum spanning tree <span
class="math inline">\(\leftrightharpoons\)</span> maximum spanning
cotree</li>
</ul></li>
<li><p>Equivalence of tree-cotree decompositions and tree-onion
figures</p></li>
<li><p>Random (but not uniform!) rooted planar maps via random
tree-onion figures</p></li>
</ul>
<h1 data-number="11" id="straight-line-planar-mapsbeta"><span
class="header-section-number">11</span> Straight-line Planar Maps<span
class="math inline">\(^\beta\)</span></h1>
<p>So far we have not assumed that planar embeddings are in any way
well-behaved geometrically; edges can be embedded as arbitrarily
pathological paths. It is not hard to prove using a compactness argument
(Similar to the simplicial approximation theorem for homotopy) that
every planar graph has a <em>piecewise-linear</em> planar embedding,
where every edge is embedded as a simple polygonal path.</p>
<p>But in fact, every <em>simple</em> planar graph has a
<em>straight-line</em> embedding, where every edge is represented by a
single straight line segment. More strongly, any planar
<em>embedding</em> is equivalent to (meaning it has the same rotation
system as) a straight-line embedding. This result was first proved
(indirectly) by Steinitz (1916), and then independently rediscovered by
Wagner (1936), [Cairns (1944)], Fáry (1948), Stein (1951), Stojaković
(1959), and Tutte (1960), so of course it’s usually called “Fáry’s
theorem”.</p>
<p>Non-simple planar graphs do not have straight-line embeddings; in any
such embedding, parallel edges would coincide and loops would degenerate
to points. But every planar map can be transformed into a simple map by
subdividing loops into cycles of length <span
class="math inline">\(3\)</span> and parallel edges into paths of length
<span class="math inline">\(2\)</span>. It (finally!) follows that any
generic planar curve with <span class="math inline">\(n\)</span>
vertices is equivalent to a planar <em>polygon</em> with at most <span
class="math inline">\(3n\)</span> vertices.</p>
<p>The existence of straight-line maps for simple planar graphs finally
gives us the converse of Euler’s theorem:.</p>
<ul>
<li>Every rotation system with <span class="math inline">\(n\)</span>
vertices, <span class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces is the rotation system of a
planar map <strong>if and only if</strong> <span
class="math inline">\(n-m+f = 2\)</span>.</li>
<li>A signed Gauss code with <span class="math inline">\(n\)</span>
symbols describes a planar curve <strong>if and only if</strong> it
induces <span class="math inline">\(n+2\)</span> faces.</li>
</ul>
<p>Moreover, all of the proofs described in this note are constructive;
in particular, they all imply linear-time algorithms to construct
straight-line embeddings from a given planar rotation system.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Given a planar rotation system for a planar graph <span
class="math inline">\(G\)</span> with <span
class="math inline">\(n\)</span> vertices and <span
class="math inline">\(m\)</span> edges, we can compute an equivalent
piecewise-linear embedding (or an equivalent straight-line embedding if
<span class="math inline">\(G\)</span> is simple) in <span
class="math inline">\(O(n+m)\)</span> time.</em>
</dd>
</dl>
<h2 data-number="11.1" id="simple-triangulations"><span
class="header-section-number">11.1</span> Simple triangulations</h2>
<p>Throughout this note, we’ll consider the special case of <em>simple
triangulations</em>: simple planar maps in which every face is bounded
by three edges.</p>
<dl>
<dt><strong>Triangulation Lemma (Fáry 1948):</strong></dt>
<dd>
<em>Every simple planar map can be extended to a simple triangulation by
adding edges between existing vertices.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix a simple planar map <span class="math inline">\(\Sigma\)</span> with
a non-triangular face <span class="math inline">\(f\)</span>, and let
<span class="math inline">\(w,x,y,z\)</span> be any four consecutive
vertices on the boundary of <span class="math inline">\(f\)</span>. I
claim that we can add at least one new edge <span
class="math inline">\(wy\)</span> or <span
class="math inline">\(xz\)</span> inside <span
class="math inline">\(f\)</span> without creating any parallel edges.
The lemma follows form this claim by induction on the quantity <span
class="math inline">\(\sum_f (\deg(f)-3)\)</span>.
</dd>
<dd>
<p>For ease of presentation, assume <span
class="math inline">\(f\)</span> is bounded. Suppose <span
class="math inline">\(\Sigma\)</span> contains an edge between <span
class="math inline">\(w\)</span> and <span
class="math inline">\(y\)</span>, necessarily outside <span
class="math inline">\(f\)</span>. The vertices <span
class="math inline">\(w\)</span> and <span
class="math inline">\(y\)</span> subdivide the boundary of <span
class="math inline">\(f\)</span> into two paths, one through <span
class="math inline">\(x\)</span> and the other through <span
class="math inline">\(z\)</span>. Adding the edge <span
class="math inline">\(wy\)</span> to those paths creates two cycles.
Without loss of generality, <span class="math inline">\(x\)</span> lies
in the interior of the cycle <span class="math inline">\(C\)</span> that
passes through <span class="math inline">\(z\)</span>; as shown in
Figure 1.</p>
</dd>
<dd>
<p>Now suppose for the sake of argument that <span
class="math inline">\(\Sigma\)</span> also contains an edge <span
class="math inline">\(xz\)</span>, again necessarily outside <span
class="math inline">\(f\)</span>. This edge passes through the exterior
of <span class="math inline">\(C\)</span> near <span
class="math inline">\(z\)</span>, but it also passes through the
interior of <span class="math inline">\(C\)</span> near <span
class="math inline">\(x\)</span>. So the Jordan Curve Theorem implies
that <span class="math inline">\(xz\)</span> intersects <span
class="math inline">\(C\)</span>, contradicting the definition of
embedding. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<figure>
<img src="Fig/face-diagonal.png" style="width:25.0%"
alt="Proof of the triangulation lemma." />
<figcaption aria-hidden="true">Proof of the triangulation
lemma.</figcaption>
</figure>
<p>To compute a straight-line map <span
class="math inline">\(\overline\Sigma\)</span> equivalent to an
arbitrary simple planar map <span class="math inline">\(\Sigma\)</span>,
it suffices to add edges to <span class="math inline">\(\Sigma\)</span>
to obtain a simple planar triangulation <span
class="math inline">\(T\)</span>, compute a straight-line map <span
class="math inline">\(\overline{T}\)</span> equivalent to <span
class="math inline">\(T\)</span>, and then delete the (straightened)
added edges.</p>
<p>In the following sections, I’ll describe three different
constructions of straight-line triangulations equivalent to a given
triangulation <span class="math inline">\(T\)</span>.</p>
<h2 data-number="11.2" id="inner-induction-hole-filling"><span
class="header-section-number">11.2</span> Inner Induction (Hole
Filling)</h2>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every simple planar triangulation with more than <span
class="math inline">\(3\)</span> vertices has an interior vertex with
degree at most <span class="math inline">\(5\)</span>.</em>
</dd>
</dl>
<!--
**Proof (Euler):**
: Let $T$ be a simple planar triangulation with $n>3$ vertices.  Every vertex of $T$ has degree at least $3$; otherwise, either $T$ is not simple or $T$ has a face with degree greater than $3$.  Euler’s formula implies that $T$ has exactly $3n-6$ edges, so the _average_ vertex degree is just less than $6$.  On the other hand, if $T$ has $k$ vertices with degree less than $6$, then $T$ has _at least_ $3n - 3k/2$ edges.  The inequality $3n-3k/2 \le 3n-6$  implies $k\ge 4$.  We conclude that $T$ has at least four vertices with degree less than $6$, at least one of which is an interior vertex. -->
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(T\)</span> be a simple planar
triangulation with <span class="math inline">\(n&gt;3\)</span> vertices.
Every vertex of <span class="math inline">\(T\)</span> has degree at
least <span class="math inline">\(3\)</span>; otherwise, either <span
class="math inline">\(T\)</span> is not simple or <span
class="math inline">\(T\)</span> has a face with degree greater than
<span class="math inline">\(3\)</span>. Assign angle <span
class="math inline">\(\angle c = 1/3\)</span> to every corner of <span
class="math inline">\(T\)</span>, so that every face <span
class="math inline">\(f\)</span> has discrete curvature <span
class="math inline">\(\kappa(f) = 0\)</span>. Then each vertex <span
class="math inline">\(v\)</span> has curvature <span
class="math inline">\(\kappa(v) = 1 - \deg(v)/6 \le 1/2\)</span>; in
particular, a vertex has positive curvature if and only if its degree is
at most <span class="math inline">\(5\)</span>. The combinatorial
Gauss-Bonnet theorem implies that <span class="math inline">\(\sum_v
\kappa(v) = 2\)</span>, so <span class="math inline">\(T\)</span> must
have at least four vertices with positive curvature. At least one of
these is an interior vertex.
</dd>
</dl>
<p>A simple polygon <span class="math inline">\(P\)</span> is
<em>star-shaped</em> if there is at least one interior point <span
class="math inline">\(q\)</span> such that for each vertex <span
class="math inline">\(p\)</span> of <span
class="math inline">\(P\)</span>, the segment <span
class="math inline">\(pq\)</span> does not cross any edge of <span
class="math inline">\(P\)</span>. The set of all such points <span
class="math inline">\(q\)</span> is called the <em>kernel</em> of <span
class="math inline">\(P\)</span>.</p>
<dl>
<dt><strong>Lemma (Cairns 1944, Stojaković 1959):</strong></dt>
<dd>
<em>Every simple polygon with at most <span
class="math inline">\(5\)</span> vertices is star-shaped.</em>
</dd>
<dt><strong>Proof (sketch):</strong></dt>
<dd>
Every convex polygon is trivially star-shaped. Every simple
quadrilateral has at most one reflex vertex; every simple pentagon has
at most two reflex vertices, which are either adjacent or not. In every
case, we can verify by exhaustive case analysis that the kernel is
non-empty; see the figure below.
</dd>
</dl>
<figure>
<img src="Fig/vertex-links.png" style="width:75.0%"
alt="Every simple polygon with at most five vertices is star-shaped" />
<figcaption aria-hidden="true">Every simple polygon with at most five
vertices is star-shaped</figcaption>
</figure>
<dl>
<dt><strong>Straight-Line Triangulation Theorem:</strong></dt>
<dd>
<em>Every simple planar triangulation is equivalent to a straight-line
triangulation.</em>
</dd>
<dt><strong>Proof (Stojaković 1959):</strong></dt>
<dd>
We argue by induction on the number of vertices. Let <span
class="math inline">\(T\)</span> be any simple planar triangulation. If
<span class="math inline">\(T\)</span> has only <span
class="math inline">\(3\)</span> vertices, then <span
class="math inline">\(T\)</span> is clearly equivalent to any
(geometric) triangle <span class="math inline">\(\overline{T}\)</span>.
So assume otherwise.
</dd>
<dd>
<p>Let <span class="math inline">\(v\)</span> be any interior vertex of
<span class="math inline">\(T\)</span> with degree at most <span
class="math inline">\(5\)</span>. Deleting <span
class="math inline">\(v\)</span> creates a face <span
class="math inline">\(f\)</span> with degree <span
class="math inline">\(\deg(v)\)</span>. We extend <span
class="math inline">\(T\setminus v\)</span> to a simple triangulation
<span class="math inline">\(T’\)</span> by adding <span
class="math inline">\(\deg(v)-3\)</span> diagonals inside <span
class="math inline">\(f\)</span>, following the Triangulation Lemma. The
induction hypothesis implies that <span
class="math inline">\(T’\)</span> is equivalent to a straight-line
triangulation <span class="math inline">\(\overline{T}’\)</span>.
Deleting the diagonals yields a simple planar map <span
class="math inline">\(\overline{T\setminus v}\)</span> equivalent to
<span class="math inline">\(T\setminus v\)</span>. The face <span
class="math inline">\(\overline{f}\)</span> of <span
class="math inline">\(\overline{T\setminus v}\)</span> corresponding to
<span class="math inline">\(f\)</span> is a simple polygon with <span
class="math inline">\(\deg(v)\le 5\)</span> vertices. Inserting a vertex
<span class="math inline">\(\overline{v}\)</span> in the kernel of <span
class="math inline">\(\overline{f}\)</span> and connecting <span
class="math inline">\(\overline{v}\)</span> to every vertex of <span
class="math inline">\(\overline{f}\)</span> yields a straight-line
triangulation <span class="math inline">\(\overline{T}\)</span>
equivalent to <span class="math inline">\(T\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<!-- ## Variations on a Theme

### Separating Triangles (Fáry)

Fáry avoids using the Triangulation Lemma in the induction step as follows:

**Proof (Fáry):**
: After removing _any_ interior vertex $v$, triangulate the resulting face $f$ by joining _any_ vertex $w$ to all others.  Equivalently, choose any two bounded faces $uvw$ and $vwx$ that share an edge $vw$, and contracting $vw$ to a new vertex $v’$.  This contraction creates parallel pairs of edges $uv’$ and $v’w$; delete one edge from each pair.

: If the resulting map $\Sigma’$ is not simple, the original triangulation $T$ has a nontrivial _separating triangle_ $tvw$.  Let $T^+$ be the subgraph of $T$ obtained by deleting all vertices inside $tvw$, and let $T^-$ be the subgraph obtained by deleting all vertices outside $tvw$.  We can recursively construct straight-line triangulations $\overline{T^+}$ and $\overline{T^-}$ equivalent to $T^+$ and $T^-$.  Affinely mapping $\overline{T^-}$ into face $\overline{tvw}$ of $\overline{T^+}$ gives us a straight-line triangulation $\overline{T}$ equivalent to $T$.

: Recursion inside the inner triangulation $T^-$ implies that it is always possible to choose an edge $vw$ whose contraction yields a simple triangulation.  So we can proceed as follows:

: Choose any interior vertex $v$.  Find a neighbor $w$ of $v$ that is adjacent to only two other neighbors of $v$.  Delete $v$ and connect $w$ to all of $v$’s other neighbors, to obtain a map $\Sigma’$.  Recursively compute a straight-line map $\overline\Sigma’$.  Delete the edges from $\overline{w}$ to the other neighbors of $v$; let $f$ be the resulting $\deg(v)$-gonal face.  The kernel of $f$ includes vertex $\overline{w}$ and therefore has nonempty intersection with the interior of $f$.  Add a point $\overline{v}$ in the interior of the kernel, and Bob’s your uncle!


## Convex Polyhedral Embeddings (Stein)

Stein actually proves a stronger claim, establishing necessary and sufficient conditions for embeddings with convex faces.  A planar map is _weakly convex_ if the boundary of each face, including the outer face, is a convex polygon, possibly with collinear edges.  In particular, every edge of a weakly convex map is a straight line segment.  Every weakly convex planar map satisfies two topological conditions:

- The boundary of every face is a simple cycle.
- The intersection of any two facial cycles is connected: either empty, a single vertex, or a simple path.

Any planar map satisfying these two conditions is called _weakly polyhedral_.

**Weakly Convex Embedding Theorem (Stein):** _For every weakly polyhedral planar embedding, there is an equivalent weakly convex polyhedral embedding._


**Proof [¡¡BROKEN!!]:**
: Let $\Sigma$ be a weakly polyhedral embedding.  If the underlying graph of $\Sigma$ is the complete graph $K_4$---the simplest graph with a polyhedral embedding---finding an equivalent convex embedding is straightforward, so assume otherwise.  There are two cases to consider:

: Suppose $\Sigma$ has a vertex $v$ with degree $2$.  Let $u$ and $w$ be the neighbors of $v$.  The contracted map $\Sigma / uv$ is still weakly polyhedral.  So  the induction hypothesis implies that there is a convex embedding $\overline{\Sigma'}$ equivalent to $\Sigma / uv$.  We can obtain a convex embedding $\overline{\Sigma}$ equivalent to $\Sigma$ by adding a vertex $\overline{v}$ on the edge $\overline{uw}$ in $\overline{\Sigma'}$.

: On the other hand, suppose every vertex in $\Sigma$ has degree at least $3$. I claim that there is an interior edge $e$ such that $\Sigma \setminus e$ is weakly polyhedral.

: Deleting any interior edge $e$ merges the faces $f$ and $g$ on either side of $e$  into a single face $f\cup g$.  Suppose this new face has disconnected intersection with some other face $h$; equivalently, the union $f\cup g\cup h$ is not simply connected.  Then there is a closed curve $\gamma$ that starts at an endpoint of $e$, then passes through $f$ to some vertex in $f \cap h$, then passes through $h$ to some vertex in $g\cap h$, and finally passes through $g$ back to its starting endpoint of $e$.  The interior of $\gamma$ contains at least one face of $\Sigma$.

: Deleting $uv$ merges the two shores of $u\mathord\to v$ into a new face $f$.  The the inductive hypothesis implies that there is an equivalent convex embedding $\overline{\Sigma \setminus uv}$.  We can obtain a convex embedding $\overline{\Sigma}$ equivalent to $\Sigma$ by adding the line segment $\overline{uv}$ through the convex face $\overline{f}$ in $\overline{\Sigma'}$.  $\qquad\square$


![Two weakly convex embeddings of the cube graph obtained by Stein's algorithm.](Fig/cube-convex){ width=40% }

With a bit more effort, Stein's argument can be extended to show that every _strictly_ polyhedral embedding (where two faces intersect in at most one edge) is equivalent to a _strictly_ convex embedding (where no two edges of any face are collinear).  But we'll see a more interesting proof of that fact in the next lecture.
-->
<h2 data-number="11.3" id="outer-induction-canonical-ordering"><span
class="header-section-number">11.3</span> Outer Induction (Canonical
Ordering)</h2>
<p>Here is a second inductive proof of the Straight-Line Triangulation
Theorem that does <em>not</em> rely on Euler’s formula, roughly
following an argument of de Fraysseix, Pach, and Pollack (1988). This
proof is close in spirit to early flawed inductive proofs of Euler’s
formula, including Euler’s own flawed proof.</p>
<p>We actually prove the following stronger claim: Let <span
class="math inline">\(\Sigma\)</span> be any simple planar map whose
interior faces are triangles and whose outer face is bounded by a simple
cycle of length <span class="math inline">\(h\ge 3\)</span>. Let <span
class="math inline">\(v_1, v_2, \dots, v_h\)</span> be the vertices of
the outer face of <span class="math inline">\(\Sigma\)</span> in
counterclockwise order. Let <span class="math inline">\(P\)</span> be
any convex polygon with vertices <span class="math inline">\(p_1, p_2,
\dots, p_h\)</span> in counterclockwise order. Then there is a
straight-line planar map <span
class="math inline">\(\overline{\Sigma}\)</span> that is equivalent to
<span class="math inline">\(\Sigma\)</span>, whose outer face is <span
class="math inline">\(P\)</span>, such that each outer vertex <span
class="math inline">\(v_i\)</span> corresponds to the polygon vertex
<span class="math inline">\(p_i\)</span>.</p>
<p>The proof proceeds by induction on the number of vertices of <span
class="math inline">\(\Sigma\)</span>. If <span
class="math inline">\(\Sigma\)</span> is a single triangle, the claim is
trivial, so assume otherwise. There are two nontrivial cases to
consider: Either <span class="math inline">\(v_1\)</span> and <span
class="math inline">\(v_{h-1}\)</span> are the only neighbors of <span
class="math inline">\(v_h\)</span> on the outer face, or <span
class="math inline">\(v_h\)</span> has another neighbor <span
class="math inline">\(v_j\)</span> on the outer face.</p>
<dl>
<dt><strong>Case 1: Only two neighbors on the outer face.</strong></dt>
<dd>
<p>In this case, we recursively compute a straight-line planar map
equivalent to <span class="math inline">\(\Sigma\setminus v_h\)</span>
and then embed the edges incident to <span
class="math inline">\(v_h\)</span> as line segments.</p>
</dd>
<dd>
<p>Specifically, let <span class="math inline">\(w_1, w_2, \dots,
w_d\)</span> be the neighbors of <span
class="math inline">\(v_h\)</span>, indexed in order around <span
class="math inline">\(v_h\)</span> so that <span
class="math inline">\(w_1 = v_{h-1}\)</span> and <span
class="math inline">\(w_d = v_1\)</span>. The vertices <span
class="math inline">\(w_2, \dots, w_{d-1}\)</span> all lie in the
complement of the outer face, and <span
class="math inline">\(\Sigma\)</span> contains the edge <span
class="math inline">\(w_i w_{i+1}\)</span> for every index <span
class="math inline">\(i\)</span>. It follows that the outer face of the
submap <span class="math inline">\(\Sigma’ = \Sigma\setminus
v_h\)</span> is bounded by a simple cycle with vertices <span
class="math inline">\(v_1, v_2, \dots, v_{h-1}=w_1, w_2, \dots,
w_d=v_1\)</span>. Every bounded face of <span
class="math inline">\(\Sigma’\)</span> is also a bounded face of <span
class="math inline">\(\Sigma\)</span> and thus has degree <span
class="math inline">\(3\)</span>.</p>
</dd>
<dd>
<p>Now let <span class="math inline">\(\alpha\)</span> be a convex arc
from <span class="math inline">\(p_1\)</span> to <span
class="math inline">\(p_{h-1}\)</span> inside the triangle <span
class="math inline">\(p_1 p_h p_{h-1}\)</span>. (For example, <span
class="math inline">\(\alpha\)</span> could be a circular arc tangent to
<span class="math inline">\(p_1 p_h\)</span> at <span
class="math inline">\(p_1\)</span> and tangent to <span
class="math inline">\(p_h p_{h-1}\)</span> at <span
class="math inline">\(p_{h-1}\)</span>.) Place <span
class="math inline">\(d\)</span> evenly spaced points <span
class="math inline">\(q_1, q_2, q_3, \dots, q_d\)</span> along <span
class="math inline">\(\alpha\)</span>, with <span
class="math inline">\(q_1 = p_{h-1}\)</span> and <span
class="math inline">\(q_d = p_1\)</span>. Finally, let <span
class="math inline">\(P&#39;\)</span> be the convex polygon obtained by
replacing the edges <span class="math inline">\(p_{h-1}p_h\)</span> and
<span class="math inline">\(p_hp_1\)</span> with the polygonal chain
<span class="math inline">\(q_1 q_2 \dots q_d\)</span>.</p>
</dd>
<dd>
<figure>
<img src="Fig/straight-embedding-1.png" style="width:45.0%"
alt="Case 1: Remove vertex v_h and recurse" />
<figcaption aria-hidden="true">Case 1: Remove vertex <span
class="math inline">\(v_h\)</span> and recurse</figcaption>
</figure>
</dd>
<dd>
<p>The inductive hypothesis implies that there is a straight-line
embedding <span class="math inline">\(\overline{\Sigma’}\)</span>
equivalent to <span class="math inline">\(\Sigma’\)</span> with outer
face <span class="math inline">\(P&#39;\)</span>, that maps each vertex
<span class="math inline">\(v_i\)</span> (with <span
class="math inline">\(i\ne h\)</span>) to the corresponding point <span
class="math inline">\(p_i\)</span> and each vertex <span
class="math inline">\(w_i\)</span> to the corresponding point <span
class="math inline">\(q_i\)</span>. Adding the edges <span
class="math inline">\(p_h q_i\)</span> gives us a straight-line map
<span class="math inline">\(\overline{\Sigma}\)</span> equivalent to
<span class="math inline">\(\Sigma\)</span> with outer face <span
class="math inline">\(P\)</span> and the required vertex
correspondences.</p>
</dd>
<dt><strong>Case 2: More than two neighbors on the outer
face.</strong></dt>
<dd>
<p>Now suppose <span class="math inline">\(v_h\)</span> is adjacent to
some vertex <span class="math inline">\(v_j\)</span> on the outer face
besides <span class="math inline">\(v_1\)</span> and <span
class="math inline">\(v_{h-1}\)</span>. In this case, we split <span
class="math inline">\(\Sigma\)</span> into two submaps along the edge
<span class="math inline">\(v_h v_j\)</span>, split the polygon <span
class="math inline">\(P\)</span> into two smaller polygons along the
diagonal <span class="math inline">\(p_hp_j\)</span>, and recursively
embed each fragment of <span class="math inline">\(\Sigma\)</span> into
the corresponding fragment of <span
class="math inline">\(P\)</span>.</p>
</dd>
<dd>
<p>Specifically, let <span class="math inline">\(\Sigma^\sharp\)</span>
be the submap of <span class="math inline">\(\Sigma\)</span> obtained by
deleting every vertex outside the simple cycle <span
class="math inline">\((v_h, v_1, v_2, \dots, v_j, v_h)\)</span>. (The
outside of this cycle is well-defined by the Jordan Curve Theorem.)
Similarly, let <span class="math inline">\(\Sigma^\flat\)</span> be the
submap of <span class="math inline">\(\Sigma\)</span> obtained by
deleting every vertex outside the simple cycle <span
class="math inline">\((v_h, v_j, v_{j-1}, \dots, v_{h-1}, v_h)\)</span>.
Both <span class="math inline">\(\Sigma^\flat\)</span> and <span
class="math inline">\(\Sigma^\sharp\)</span> satisfy the conditions of
our claim.</p>
</dd>
<dd>
<figure>
<img src="Fig/straight-embedding-2.png" style="width:45.0%"
alt="Case 2: Split along the diagonal and recurse twice" />
<figcaption aria-hidden="true">Case 2: Split along the diagonal and
recurse twice</figcaption>
</figure>
</dd>
<dd>
<p>The line segment <span class="math inline">\(p_hp_j\)</span>
partitions the polygon <span class="math inline">\(P\)</span> into two
smaller convex polygons <span class="math inline">\(P^\flat\)</span> and
<span class="math inline">\(P^\sharp\)</span>. The induction hypothesis
give us straight-line embeddings <span
class="math inline">\(\overline{\Sigma^\flat}\)</span> and <span
class="math inline">\(\overline{\Sigma^\sharp}\)</span>, respectively
equivalent to <span class="math inline">\(\Sigma^\flat\)</span> and
<span class="math inline">\(\Sigma^\sharp\)</span>, with respective
outer faces bounded by <span class="math inline">\(P^\flat\)</span> and
<span class="math inline">\(P^\sharp\)</span>, mapping each vertex <span
class="math inline">\(v_i\)</span> to the corresponding point <span
class="math inline">\(p_i\)</span>. In particular, in both straight-line
embeddings, the the line segment <span
class="math inline">\(p_hp_j\)</span> corresponds to the edge <span
class="math inline">\(v_hv_j\)</span>. Combining the straight-line
embeddings <span class="math inline">\(\overline{\Sigma^\flat}\)</span>
and <span class="math inline">\(\overline{\Sigma^\sharp}\)</span> along
<span class="math inline">\(p_hp_j\)</span> gives us the required
straight-line embedding <span
class="math inline">\(\overline{\Sigma}\)</span>.</p>
</dd>
</dl>
<p>The second case is actually redundant. A simple recursive argument,
similar to the proof that every polygon triangulation has two ears,
implies that there are at least two non-adjacent vertices on the outer
face with exactly two neighbors on the outer face. It follows that the
vertices of <span class="math inline">\(\Sigma\)</span> can be ordered
<span class="math inline">\(v_1, v_2, \dots, v_n\)</span>, so that after
deleting any prefix <span class="math inline">\(v_1, v_2, \dots,
v_i\)</span> where <span class="math inline">\(i\le n-3\)</span>, the
outer face of the remaining subgraph is bounded by a simple cycle, and
the next vertex <span class="math inline">\(v_{i+1}\)</span> lies on the
outer face. This sequence of vertices is called a <em>canonical
ordering</em> (or a <em>vertex-shelling order</em>) for <span
class="math inline">\(\Sigma\)</span></p>
<h2 data-number="11.4" id="schnyder-woods"><span
class="header-section-number">11.4</span> Schnyder Woods</h2>
<p>In 1989, Walter Schnyder discovered a significant refinement of the
previous proof, which implies that any <span
class="math inline">\(n\)</span>-vertex planar graph has a straight-line
embedding whose vertices lie on an <span
class="math inline">\((n-1)\times (n-1)\)</span> integer grid. Again, we
consider only simple planar <em>triangulations</em>, where all faces
have degree <span class="math inline">\(3\)</span>, including the outer
face.</p>
<p>Let <span class="math inline">\(T\)</span> be a simple planar
triangulation with <span class="math inline">\(n\)</span> vertices.
Schnyder defined two different ways to annotate features of <span
class="math inline">\(T\)</span> with the colors red, green, and blue.
The first of these is a <em>Schnyder coloring</em>, which colors the
interior corners subject to two conditions:</p>
<ul>
<li>The corners of each face are colored red, green, and blue in
counterclockwise order.</li>
<li>The corners around each internal vertex are colored red, then green,
then blue in counterclockwise order. In particular, each internal vertex
is incident to at least one corner of each color.</li>
</ul>
<figure>
<img src="Fig/Schnyder-coloring.png" style="width:40.0%"
alt="A Schnyder coloring of a simple triangulation" />
<figcaption aria-hidden="true">A Schnyder coloring of a simple
triangulation</figcaption>
</figure>
<p>A Schnyder coloring can be constructed in linear time as follows.
Color the outer vertices of <span class="math inline">\(T\)</span> red,
green, and blue in counterclockwise order. If <span
class="math inline">\(T\)</span> has a single bounded face, its three
corners inherit the colors of the incident vertices. Otherwise, choose
an arbitrary edge from a boundary vertex <span
class="math inline">\(u\)</span> to an interior vertex <span
class="math inline">\(v\)</span>. There are two cases to consider.</p>
<ul>
<li><p>Suppose <span class="math inline">\(v\)</span> has exactly two
common neighbors with <span class="math inline">\(u\)</span>. The
contraction <span class="math inline">\(T/uv\)</span> has two pairs of
parallel edges; deleting one edge in each pair yields a smaller
triangulation <span class="math inline">\(T’\)</span>. Recursively
compute a Schnyder coloring for <span class="math inline">\(T’\)</span>,
and transfer the corner colors back to <span
class="math inline">\(T\)</span>. Finally, there is only one way to
consistently color the faces of <span class="math inline">\(T\)</span>
on either side of <span class="math inline">\(uv\)</span>; specifically,
the corners incident to the boundary vertex <span
class="math inline">\(u\)</span> inherit <span
class="math inline">\(u\)</span>’s color.</p></li>
<li><p>If <span class="math inline">\(v\)</span> has at least three
common neighbors with <span class="math inline">\(u\)</span>, there must
be a triangle <span class="math inline">\(uvw\)</span> in <span
class="math inline">\(T\)</span> containing at least one vertex in its
interior. In this case, we recursively compute Schnyder colorings of the
subgraphs of <span class="math inline">\(G\)</span> inside <span
class="math inline">\(uvw\)</span> and outside <span
class="math inline">\(uvw\)</span>. In both recursive subproblems the
boundary vertex <span class="math inline">\(u\)</span> retains its
originally assigned color, so that the resulting Schnyder colorings are
compatible.</p></li>
</ul>
<p>In fact, the second case is unnecessary. By expanding the recursion
from the second case, we see that the entire construction is carried out
by a sequence of contractions; equivalently, an easy induction argument
implies that at least one edge from each boundary vertex can be
contracted immediately. The Schnyder coloring in the figure above was
computed by contacting the interior vertices toward the top (green)
vertex in the order indicated by the vertex labels.</p>
<figure>
<img src="Fig/Schnyder-contraction.png" style="width:55.0%"
alt="Recursively computing a Schnyder coloring" />
<figcaption aria-hidden="true">Recursively computing a Schnyder
coloring</figcaption>
</figure>
<p>The second annotation, called a <em>Schnyder wood</em>, assigns a
direction and a color to every internal edge of <span
class="math inline">\(T\)</span>. Every internal edge in <span
class="math inline">\(T\)</span> is incident to corners with all three
colors, with one color appearing twice at one endpoint. Schnyder orients
each internal edge <span class="math inline">\(e\)</span> toward the
endpoint with the same color twice, and assigns the repeated color to
the edge. The resulting coloring and orientation has the following
useful properties:</p>
<ul>
<li>Each boundary vertex has only incoming internal edges, all with the
same color as the vertex itself.</li>
<li>Every internal vertex has exactly one outgoing edge of each
color.</li>
<li>At every internal vertex, incident edges appear in counterclockwise
order as follows: one outgoing red, all incoming blue, one outgoing
green, all incoming red, one outgoing blue, all incoming green.</li>
</ul>
<figure>
<img src="Fig/Schnyder-wood.png" style="width:40.0%"
alt="The Schnyder wood constructed from the coloring in Figure 5" />
<figcaption aria-hidden="true">The Schnyder wood constructed from the
coloring in Figure 5</figcaption>
</figure>
<p>We can also construct Schnyder woods directly using a sequence of
edge contractions, just as we constructed Schnyder colorings. Expanding
an edge introduces one vertex and three edges; we orient the new edges
away from the new vertex, and assign them the only colors consistent
with the properties listed above. Conversely, <em>every</em> Schnyder
wood can be constructed using this algorithm, contracting toward any of
the outer vertices.</p>
<figure>
<img src="Fig/Schnyder-edge-contraction.png" style="width:55.0%"
alt="Recursively computing a Schnyder wood" />
<figcaption aria-hidden="true">Recursively computing a Schnyder
wood</figcaption>
</figure>
<p>Given any Schnyder wood, we can define an equivalent Schnyder
coloring as follows. For any interior corner, if the two edges are both
leaving the corner vertex, assign the third color to the corner;
otherwise, assign the color of the incoming edge(s) to the corner.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>In any Schnyder wood, the edges of each color induce a spanning tree
of the internal vertices, rooted at the boundary vertex with that
color.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Without loss of generality, assume the Schnyder wood is constructed by
repeatedly contracting to the green boundary vertex. Each interior
vertex has exactly one outgoing edge of each color, either leading to
another interior vertex or the boundary vertex of that color.
</dd>
<dd>
<p>Number the interior vertices by the order in which they are
contracted to the green boundary vertex, as shown in the figures. Label
the green boundary vertex <span class="math inline">\(0\)</span> and the
other two boundary vertices <span class="math inline">\(\infty\)</span>.
Call an edge <span class="math inline">\(v\mathord\to w\)</span>
<em>increasing</em> if the label of <span
class="math inline">\(w\)</span> is larger than the label of <span
class="math inline">\(w\)</span> and <em>decreasing</em> otherwise.
Every green edge is decreasing, and every red and blue edge is
increasing. Thus, none of the red, green, or blue subgraphs contains a
cycle; starting from any interior node, following edges of any fixed
color leads to the outer vertex of that color. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Hey, look, we have yet another proof of Euler’s formula!</p>
<dl>
<dt><strong>Euler’s formula:</strong></dt>
<dd>
<em>For any planar map with <span class="math inline">\(n\)</span>
vertices, <span class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces, we have <span
class="math inline">\(n-m+f=2\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
It suffices to prove the theorem for simple planar triangulations. If
<span class="math inline">\(\Sigma\)</span> is not a simple map, we can
make it simple by splitting each edge into a path of three edges, by
introducing two new vertices; the resulting simple graph has <span
class="math inline">\(n+2m\)</span> vertices, <span
class="math inline">\(3m\)</span> edges, and <span
class="math inline">\(f\)</span> faces. Similarly, if any face of <span
class="math inline">\(\Sigma\)</span> has degree greater than~<span
class="math inline">\(3\)</span>, it must contain a path between two
non-adjacent vertices; adding this path to the embedding yields a new
planar map with <span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m+1\)</span> edges, and <span
class="math inline">\(f+1\)</span> faces.
</dd>
<dd>
<p>Consider any Schnyder wood of a simple planar triangulation <span
class="math inline">\(T\)</span> with <span
class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces (including the outer face). The
edges of each color define a rooted tree with <span
class="math inline">\(n-2\)</span> vertices, and therefore <span
class="math inline">\(n-3\)</span> edges, and every interior
edgesbelongs to exactly one such tree. It immediately follows that <span
class="math inline">\(m = 3(n-3)+3 = 3n-6\)</span>. Finally, because
every face is a triangle, we have <span class="math inline">\(2m = 3f =
6n-12\)</span>, so <span class="math inline">\(f = 2n-4\)</span>. We
conclude that <span class="math inline">\(n-m+f = n - (3n-6) + (2n-4) =
2\)</span>. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="11.5" id="grid-embedding"><span
class="header-section-number">11.5</span> Grid embedding</h2>
<p>Now we assign integer coordinates to every interior vertex <span
class="math inline">\(v\)</span> as follows. There is a unique path of
red edges, a unique path of green edges, and a unique path of blue edges
from <span class="math inline">\(v\)</span> to the boundary. These three
paths partition the triangulation into three regions, which we color
red, green, and blue as shown below. Each region contains its clockwise
bounding path—for example, the green region includes the blue path,
including the blue boundary vertex—but not <span
class="math inline">\(v\)</span> itself.</p>
<p>For purposes of defining these regions when <span
class="math inline">\(v\)</span> is a boundary vertex, we orient the
boundary edges clockwise and color each edge according to its head.
Thus, if <span class="math inline">\(r,g,b\)</span> are the red, green,
and blue boundary vertices, the green region of <span
class="math inline">\(g\)</span> contains every vertex except <span
class="math inline">\(g\)</span> and <span
class="math inline">\(r\)</span>, the red region of <span
class="math inline">\(g\)</span> contains only <span
class="math inline">\(r\)</span>, and the blue region of <span
class="math inline">\(g\)</span> is empty.</p>
<p>For each vertex <span class="math inline">\(v\)</span>, let <span
class="math inline">\(r(v)\)</span>, <span
class="math inline">\(g(v)\)</span>, <span
class="math inline">\(b(v)\)</span> respectively denote the number of
vertices in the red, green, and blue regions of <span
class="math inline">\(v\)</span>. By definition, we have <span
class="math inline">\(r(v) + g(v) + b(v) = n-1\)</span> for every vertex
<span class="math inline">\(v\)</span>.</p>
<figure>
<img src="Fig/Schnyder-regions.png" style="width:45.0%"
alt="Schnyder regions for an interior vertex with coordinates (r,g,b) = (2,7,4)." />
<figcaption aria-hidden="true">Schnyder regions for an interior vertex
with coordinates <span class="math inline">\((r,g,b) =
(2,7,4)\)</span>.</figcaption>
</figure>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Schnyder’s coordinates <span class="math inline">\((r(v), g(v),
b(v))\)</span> satisfy the following conditions:</em>
</dd>
<dd>
<ol type="a">
<li><em>For every red edge <span class="math inline">\(v\mathord\to
w\)</span>, we have <span class="math inline">\(r(v) &lt; r(w)\)</span>
and <span class="math inline">\(g(v) \ge g(w)\)</span> and <span
class="math inline">\(b(v) &gt; b(w)\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol start="2" type="a">
<li><em>For every green edge <span class="math inline">\(v\mathord\to
w\)</span>, we have <span class="math inline">\(r(v) &gt; r(w)\)</span>
and <span class="math inline">\(g(v) &lt; g(w)\)</span> and <span
class="math inline">\(b(v) \ge b(w)\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol start="3" type="a">
<li><em>For every blue edge <span class="math inline">\(v\mathord\to
w\)</span>, we have <span class="math inline">\(r(v) \ge r(w)\)</span>
and <span class="math inline">\(g(v) &gt; g(w)\)</span> and <span
class="math inline">\(b(v) &lt; b(w)\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol start="4" type="a">
<li><em>For every triangle <span class="math inline">\({uvw}\)</span>
whose corners at <span class="math inline">\(u\)</span>, <span
class="math inline">\(v\)</span>, and <span
class="math inline">\(w\)</span> are respectively red, green, and blue,
we have <span class="math inline">\(r(u) \ge r(v) &gt; r(w)\)</span> and
<span class="math inline">\(g(v) \ge g(w) &gt; g(u)\)</span> and <span
class="math inline">\(b(w) \ge b(u) &gt; b(v)\)</span>.</em></li>
</ol>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix an arbitrary reference vertex <span
class="math inline">\(v\)</span>, Color <span
class="math inline">\(v\)</span> black, and color the other <span
class="math inline">\(n-1\)</span> vertices according to the region that
contains it. When we move the reference vertex from <span
class="math inline">\(v\)</span> to <span
class="math inline">\(w\)</span> along a green edge <span
class="math inline">\(v\mathord\to w\)</span>, <span
class="math inline">\(v\)</span> changes from black to green, <span
class="math inline">\(w\)</span> changes from red to black, every green
vertex remains green, and no vertex changes from red to blue or vice
versa. (Some red or blue vertices might become green, and the set of
blue vertices might remain unchanged.) Part (b) now follows immediately;
parts (a) and (c) follow from similar arguments.
</dd>
<dd>
<p>Finally, part (d) follows by straightforward case analysis. Up to a
choice of colors, there are only two cases to consider: either the edges
of <span class="math inline">\(uvw\)</span> have distinct colors (and
therefore define a directed cycle), or two of the three edges have the
same color (so the edges do not define a directed cycle). <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Any planar embedding of a simple planar graph with <span
class="math inline">\(n\)</span> vertices is equivalent to a
straight-line embedding with vertices on the <span
class="math inline">\((n-1)\times (n-1)\)</span> integer grid.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
As usual, it suffices to consider only simple triangulations. Let <span
class="math inline">\(T\)</span> be a simple planar triangulation with
<span class="math inline">\(n\)</span> vertices. Fix an arbitrary
Schnyder coloring of <span class="math inline">\(T\)</span>, and thus an
arbitrary Schnyder wood.
</dd>
<dd>
<p>Assign each vertex <span class="math inline">\(v\)</span> of <span
class="math inline">\(T\)</span> the integer coordinates <span
class="math inline">\((g(v), b(v))\)</span>. Let <span
class="math inline">\(uvw\)</span> be an arbitrary triangle whose
corners at <span class="math inline">\(u\)</span>, <span
class="math inline">\(v\)</span>, and <span
class="math inline">\(w\)</span> are respectively colored red, green,
and blue by the Schnyder coloring. The orientation of the new embedding
of <span class="math inline">\(uvw\)</span> is given by the sign of the
determinant <span class="math display">\[
\left|\begin{matrix}
    1 &amp; g(u) &amp; b(u) \\
    1 &amp; g(v) &amp; b(v) \\
    1 &amp; g(w) &amp; b(w)
\end{matrix}\right|
~=~
\big(g(v)-g(u)\big)\big(b(w)-b(u)\big) -
\big(g(w)-g(u)\big)\big(b(v)-b(u)\big).
\]</span> The previous lemma implies that this expression is positive,
which implies that the triangle is oriented counterclockwise. Because
every triangle is oriented consistently, no two triangles in the
embedding can overlap, and therefore no pair of edges can intersect.
(The signed area of the outer triangle is equal to the sum of the signed
areas of the interior triangles; if two triangles overlapped, the sum of
the areas of the interior triangles would be strictly larger than the
unsigned area of the outer triangle!) All vertex coordinates are
integers between <span class="math inline">\(0\)</span> and <span
class="math inline">\(n-2\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>The following figure shows the resulting embedding for our example
graph. Instead of embedding on the square grid, I’m using a grid of
equilateral triangles, assigning each vertex <span
class="math inline">\(v\)</span> <em>barycentric</em> coordinates <span
class="math inline">\((r(v), g(v), b(v))\)</span>.</p>
<figure>
<img src="Fig/Schnyder-grid.png" style="width:45.0%"
alt="Schnyder’s barycentric grid embedding." />
<figcaption aria-hidden="true">Schnyder’s barycentric grid
embedding.</figcaption>
</figure>
<h2 data-number="11.6" id="references-6"><span
class="header-section-number">11.6</span> References</h2>
<p>Eventually….</p>
<h2 data-number="11.7" id="not-appearing"><span
class="header-section-number">11.7</span> Not Appearing</h2>
<ul>
<li>Looser grid embedding from canonical ordering or Schnyder face
counts</li>
<li>Schnyder woods for more general planar graphs (Felsner et al.)</li>
<li>Weighted Schnyder embeddings</li>
<li>Morphing between equivalent straight-line embeddings (better via
Tutte)</li>
<li>Convex polyhedral embeddings (Stein, better via Tutte)</li>
<li>Steinitz’s theorem (better via Tutte)</li>
<li>Distributive lattice of 3-orientations (maybe later)</li>
<li>Koebe-Andreev circle packing (maybe later)</li>
</ul>
<h1 data-number="12" id="tuttes-spring-embedding-theorembeta"><span
class="header-section-number">12</span> Tutte’s Spring Embedding
Theorem<span class="math inline">\(^\beta\)</span></h1>
<p>In 1963, William Tutte published a paper ambitiously entitled “How to
Draw a Graph”. Let <span class="math inline">\(\Sigma\)</span> be any
planar embedding of any simple planar graph <span
class="math inline">\(G\)</span>.</p>
<ul>
<li>Nail the vertices of the outer face of <span
class="math inline">\(\Sigma\)</span> to the vertices of an arbitrary
strictly convex polygon <span class="math inline">\(P\)</span> in the
plane, in cyclic order.</li>
<li>Build the edges of <span class="math inline">\(G\)</span> out of
springs or rubber bands.</li>
<li>Let go!</li>
</ul>
<p>Tutte proved that if the input graph <span
class="math inline">\(G\)</span> is sufficiently well-connected, then
this physical system converges to a <em>strictly convex</em> planar
embedding of <span class="math inline">\(G\)</span>!</p>
<p>Let me state the parameters of the theorem more precisely, in
slightly more generality than Tutte did.<a href="#fn27"
class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> A
<em>Tutte drawing</em> of a planar graph <span
class="math inline">\(G\)</span> is described by a <em>position</em>
function <span class="math inline">\(p\colon V\to \mathbb{R}^2\)</span>
mapping the vertices to points in the plane, subject to the two
conditions:</p>
<ol type="1">
<li>The vertices of the outer face <span
class="math inline">\(f_\infty\)</span> of some planar embedding of
<span class="math inline">\(G\)</span> are mapped to the vertices of a
strictly convex polygon in cyclic order. In particular, the boundary of
<span class="math inline">\(F_\infty\)</span> must be a simple
cycle.</li>
<li>Each vertex <span class="math inline">\(v\)</span> that is not in
<span class="math inline">\(f_\infty\)</span> maps to a point in the
interior of the convex hull of its neighbors; that is, we have <span
class="math display">\[\sum_{u\mathord\to v} \lambda_{u\mathord\to v}
(p_v - p_u) = 0\]</span> for some positive real coefficients <span
class="math inline">\(\lambda_{u\mathord\to v}\)</span> on the darts
into <span class="math inline">\(v\)</span>.</li>
</ol>
<p>(I will use subscript notation <span
class="math inline">\(p_v\)</span> instead of function notation <span
class="math inline">\(p(v)\)</span> throughout this chapter.) The edges
of a Tutte drawing are line segments connecting their endpoints. Let me
emphasize that that the <em>definition</em> of a Tutte drawing does not
require mapping edges to <em>disjoint</em> segments, or even mapping
vertices to <em>distinct</em> points. Moreover, the dart coefficients
are not required to be symmetric; it is possible that <span
class="math inline">\(\lambda_{u\mathord\to v} \ne \lambda_{v\mathord\to
u}\)</span>.</p>
<p>A graph <span class="math inline">\(G\)</span> is
<em>3-connected</em> if we can delete any two vertices without
disconnecting the graph, or equivalently (by Menger’s theorem) if every
pair of vertices is connected by at least three vertex-disjoint
paths.</p>
<p>Finally, a planar embedding is <em>strictly convex</em> if the
boundary of every face of the embedding is a convex polygon, and no two
edges on any face boundary are collinear.</p>
<dl>
<dt><strong>Tutte’s spring-embedding theorem:</strong></dt>
<dd>
<em>Every Tutte drawing of a simple 3-connected planar graph <span
class="math inline">\(G\)</span> is a strictly convex straight-line
embedding.</em>
</dd>
</dl>
<p>It is not hard to see that 3-connectivity is required. If <span
class="math inline">\(G\)</span> has an articulation vertex <span
class="math inline">\(v\)</span>, that is, a vertex whose deleting
leaves a disconnected subgraph, then a Tutte drawing of <span
class="math inline">\(G\)</span> can map an entire component of <span
class="math inline">\(G\setminus v\)</span> to the point <span
class="math inline">\(p_v\)</span>. Similarly, if <span
class="math inline">\(G\)</span> has two vertices <span
class="math inline">\(v\)</span> and <span
class="math inline">\(v\)</span> such that <span
class="math inline">\(G\setminus \{u,v\}\)</span> is disconnected, a
Tutte drawing of <span class="math inline">\(G\)</span> can map an
entire component of <span class="math inline">\(G\setminus
\{u,v\}\)</span> to the line segment <span
class="math inline">\(p_up_v\)</span>. In both cases, the Tutte drawing
is not even an embedding, much less a strictly convex embedding.</p>
<h2 data-number="12.1" id="outer-face-is-outer"><span
class="header-section-number">12.1</span> Outer Face is Outer</h2>
<p>Whitney (1932) proved that every simple 3-connected graph <span
class="math inline">\(G\)</span> has a unique embedding on the sphere
(up to homeomorphism), or equivalently, a unique planar rotation system.
I will describe Whitney’s proof later in this note. Thus, in every
planar embedding of <span class="math inline">\(G\)</span>, the faces
are bounded by the same set of cycles; we can reasonably call these
cycles the <em>faces of <span class="math inline">\(G\)</span></em>.</p>
<p>The definition of a Tutte drawing requires choosing one of the faces
of <span class="math inline">\(G\)</span> to be the outer face <span
class="math inline">\(f_\infty\)</span>. We call the vertices of <span
class="math inline">\(f_\infty\)</span> <em>boundary</em> vertices, and
the remaining vertices of <span class="math inline">\(G\)</span>
<em>interior</em> vertices. Similarly, we call the edges of <span
class="math inline">\(f_\infty\)</span> <em>boundary</em> edges, and the
remaining edges of <span class="math inline">\(G\)</span>
<em>interior</em> edges. This terminology is justified by the following
observation:</p>
<dl>
<dt><strong>Outer face lemma:</strong></dt>
<dd>
<em>In every Tutte drawing of a simple 3-connected planar graph <span
class="math inline">\(G\)</span>, every interior vertex maps to a point
in the interior of the outer face. In particular, no interior vertex
maps to the same point as a boundary vertex.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We say that an interior vertex <span class="math inline">\(w\)</span>
<em>directly reaches</em> a boundary vertex <span
class="math inline">\(z\)</span>, or symmetrically that <span
class="math inline">\(z\)</span> is <em>directly reachable</em> from
<span class="math inline">\(w\)</span>, if there is a path from <span
class="math inline">\(w\)</span> to <span
class="math inline">\(z\)</span> using only interior edges.
3-connectivity implies that every interior vertex of <span
class="math inline">\(G\)</span> can directly reach at least three
boundary vertices of <span class="math inline">\(G\)</span>.
</dd>
<dd>
<p>We prove the lemma by applying Gaussian elimination to the system of
linear equations defined by condition (2). Linear system (2) expresses
the position <span class="math inline">\(p_v\)</span> of any vertex
<span class="math inline">\(v\)</span> as a strict convex combination of
the positions of its neighbors in <span
class="math inline">\(G\)</span>, that is, a weighted average where
every neighbor of <span class="math inline">\(v\)</span> has positive
weight. By pivoting on that row, we can remove the variables <span
class="math inline">\(p_v\)</span> from the system.</p>
</dd>
<dd>
<p>Such a pivot is equivalent to deleting vertex <span
class="math inline">\(v\)</span> from the graph and adding new edges
between the neighbors of <span class="math inline">\(v\)</span>, with
appropriate positive coefficients on their darts.<a href="#fn28"
class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a>
(Of course the resulting graph may not be planar.) Pivoting out one
interior vertex does not change which boundary vertices are directly
reachable from any other interior vertex. Thus, if we eliminate all but
one interior vertex <span class="math inline">\(w\)</span>, the
remaining constraint expresses <span class="math inline">\(w\)</span> as
a strict convex combination of at least three boundary vertices.</p>
</dd>
</dl>
<p>The same elimination argument implies that <em>every</em> assignment
of positive dart coefficients <span
class="math inline">\(\lambda_{u\mathord\to v} &gt; 0\)</span> defines a
<em>unique</em> Tutte drawing; the linear system containing the equation
<span class="math display">\[\sum_{u\mathord\to v} \lambda_{u\mathord\to
v} (p_v - p_u) = 0\]</span> for every interior vertex <span
class="math inline">\(v\)</span> always has full rank.</p>
<h2 data-number="12.2"
id="laplacian-linear-systems-and-energy-minimization"><span
class="header-section-number">12.2</span> Laplacian linear systems and
energy minimization</h2>
<p>Tutte’s original formulation required that every interior vertex lie
at the center of mass of its neighbors; this is equivalent to requiring
<span class="math inline">\(\lambda_{u\mathord\to v} = 1\)</span> for
every dart <span class="math inline">\(u\mathord\to v\)</span>.<a
href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a> More generally, the physical
interpretation in terms of springs corresponds to the special case where
dart coefficients are symmetric.</p>
<p>Suppose each edge <span class="math inline">\(uv\)</span> is to a
(first-order linear) spring with spring constant <span
class="math inline">\(\omega_{uv} = \lambda_{u\mathord\to v} =
\lambda_{v\mathord\to u}\)</span>. For any vertex placement <span
class="math inline">\(p \in (\mathbb{R}^2)^V\)</span>, the total
potential energy in the network of springs is <span
class="math display">\[
    \Phi(p) := \frac{1}{2} \sum_{u, v}
                    \omega_{uv} \| p_u - p_v \|^2.
\]</span> If we fix the positions of the outer vertices, <span
class="math inline">\(\Phi\)</span> becomes a strictly convex<a
href="#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a> function of the interior vertex
coordinates. If we let the interior vertex positions vary, the network
of springs will come to rest at a configuration with locally minimal
potential energy. The unique minimum of <span
class="math inline">\(\Phi\)</span> can be computed by setting the
gradient of <span class="math inline">\(\Phi\)</span> to the zero vector
and solving for the interior coordinates; thus we recover the original
linear constraints <span class="math display">\[
    \sum_v \omega_{uv} (p_u - p_v) = 0
\]</span> for every interior vertex <span
class="math inline">\(u\)</span>. The underlying matrix of this linear
system is called a weighted <em>Laplacian</em> matrix of <span
class="math inline">\(G\)</span>. This matrix is positive definite<a
href="#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a> and therefore non-singular, so a
unique equilibrium configuration always exists.</p>
<p>When the dart coefficients are not symmetric, this physical intuition
goes out the window; the linear system of balance equations is no longer
the gradient of a convex function. Nevertheless, as we’ve already
argued, any choice of positive coefficients <span
class="math inline">\(\lambda_{u\mathord\to v}\)</span> corresponds to a
unique straight-line drawing of <span class="math inline">\(G\)</span>.
None of the actual proof of Tutte’s theorem relies on any special
properties of the coefficients <span
class="math inline">\(\lambda_{u\mathord\to v}\)</span> other than
positivity.</p>
<p>Given the graph <span class="math inline">\(G\)</span>, the outer
convex polygon, and the dart coefficients, we can compute the
corresponding vertex positions in <span
class="math inline">\(O(n^3)\)</span> time via Gaussian elimination.
(There are faster algorithms to solve this linear system. In particular,
a numerically approximate solution can be computed in <span
class="math inline">\(O(n\log n)\)</span> time in theory, or in <span
class="math inline">\(O(n\,\text{poly}\!\log n)\)</span> time in
practice.)</p>
<h2 data-number="12.3" id="slicing-with-lines"><span
class="header-section-number">12.3</span> Slicing with Lines</h2>
<p>For the rest of this note, fix a simple 3-connected planar graph
<span class="math inline">\(G\)</span> and a Tutte drawing <span
class="math inline">\(p\)</span>. At the risk of confusing the reader, I
will generally not distinguish between features of the abstract graph
<span class="math inline">\(G\)</span> (vertices, edges, faces, cycles,
paths, and so on) and their images under the Tutte drawing (points, line
segments, polygons, polygonal chains, and so on). For example, an
<em>edge</em> of the Tutte drawing <span
class="math inline">\(p\)</span> is the (possibly degenerate) line
segment between the images of the endpoints of an edge of <span
class="math inline">\(H\)</span>, and a <em>face</em> of the Tutte
drawing <span class="math inline">\(p\)</span> is the (not necessarily
simple) polygon whose vertices are the images of the vertices of a face
of <span class="math inline">\(G\)</span> in cyclic order.</p>
<dl>
<dt><strong>Both sides lemma:</strong></dt>
<dd>
<em>For any interior vertex <span class="math inline">\(v\)</span> and
any line <span class="math inline">\(\ell\)</span> through <span
class="math inline">\(p_v\)</span>, either all neighbors of <span
class="math inline">\(v\)</span> lie on <span
class="math inline">\(\ell\)</span>, or <span
class="math inline">\(v\)</span> has neighbors on both sides of <span
class="math inline">\(\ell\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Suppose all of <span class="math inline">\(v\)</span>’s neighbors lie in
one closed halfplane bounded by <span
class="math inline">\(\ell\)</span>. Then the convex hull of <span
class="math inline">\(v\)</span>’s neighbors also lies in that
halfspace, which implies that <span class="math inline">\(v\)</span>
does not lie in the interior of that convex hull, contradicting the
definition of a Tutte drawing. <span
class="math inline">\(\qquad\square\)</span>
</dd>
<dt><strong>Halfplane lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(H\)</span> be any halfplane that
contains at least one vertex of <span class="math inline">\(G\)</span>.
The subgraph of <span class="math inline">\(G\)</span> induced by all
vertices in <span class="math inline">\(H\)</span> is connected.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Without loss of generality, assume that <span
class="math inline">\(H\)</span> is the halfplane above the <span
class="math inline">\(x\)</span>-axis. Let <span
class="math inline">\(t\)</span> be any vertex with maximum <span
class="math inline">\(y\)</span>-coordinate; the outer face lemma
implies that <span class="math inline">\(t\)</span> is a boundary
vertex. I claim that for any vertex <span class="math inline">\(u\in
H\)</span>, there is a directed path in <span
class="math inline">\(G\)</span> from <span
class="math inline">\(u\)</span> to <span
class="math inline">\(t\)</span>, where the <span
class="math inline">\(y\)</span>-coordinates never decrease. There are
two cases to consider:
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(t\)</span> and <span
class="math inline">\(u\)</span> have the same <span
class="math inline">\(y\)</span>-coordinate, the outer-face lemma
implies that either <span class="math inline">\(t=u\)</span> or <span
class="math inline">\(tu\)</span> is an edge of the outer face. In
either case the claim is trivial.</li>
</ul>
</dd>
<dd>
<ul>
<li>Otherwise, <span class="math inline">\(u\)</span> must lie below
<span class="math inline">\(t\)</span>. Let <span
class="math inline">\(U\)</span> be the set of all vertices reachable
from <span class="math inline">\(u\)</span> along horizontal edges of
<span class="math inline">\(G\)</span>. Because <span
class="math inline">\(G\)</span> is connected, some vertex <span
class="math inline">\(v\in U\)</span> has a neighbor that is not in
<span class="math inline">\(U\)</span>. The both-sides lemma implies
that <span class="math inline">\(v\)</span> has a neighbor <span
class="math inline">\(w\)</span> that has larger <span
class="math inline">\(y\)</span>-coordinate than <span
class="math inline">\(v\)</span>. The induction hypothesis implies that
there is a <span class="math inline">\(y\)</span>-monotone path in <span
class="math inline">\(G\)</span> from <span class="math inline">\(w
\mathord\leadsto t\)</span>. Thus, <span
class="math inline">\(u\mathord\leadsto v \mathord\to w \mathord\leadsto
t\)</span> is a <span class="math inline">\(y\)</span>-monotone path,
which proves the claim. <span
class="math inline">\(\qquad\square\)</span></li>
</ul>
</dd>
</dl>
<figure>
<img src="Fig/Tutte-halfplane.png" style="width:45.0%"
alt="The halfplane lemma." />
<figcaption aria-hidden="true">The halfplane lemma.</figcaption>
</figure>
<h2 data-number="12.4" id="no-degenerate-vertex-neighborhoods"><span
class="header-section-number">12.4</span> No Degenerate Vertex
Neighborhoods</h2>
<p>None of the previous lemmas actually require the planar graph <span
class="math inline">\(G\)</span> to be 3-connected. The main technical
challenge in proving Tutte’s theorem is showing that if <span
class="math inline">\(G\)</span> is 3-connected, then every Tutte
drawing of <span class="math inline">\(G\)</span> is non-degenerate. The
assumption of 3-connectivity is necessary<a href="#fn32"
class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a>—if <span
class="math inline">\(G\)</span> is 2-connected but not 3-connected,
then some subgraphs of <span class="math inline">\(G\)</span> can
degenerate to line segments in the Tutte drawing, and if <span
class="math inline">\(G\)</span> is connected but not 2-connected, some
subgraphs of <span class="math inline">\(G\)</span> <em>will</em>
degenerate to single points.</p>
<dl>
<dt><strong>Utility lemma:</strong></dt>
<dd>
<em>The complete bipartite graph <span
class="math inline">\(K_{3,3}\)</span> is not planar.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
<span class="math inline">\(K_{3,3}\)</span> has <span
class="math inline">\(n=6\)</span> vertices and <span
class="math inline">\(m=9\)</span> edges, so by Euler’s formula, any
planar embedding would have exactly <span class="math inline">\(2+m-n =
5\)</span> faces. On the other hand, because <span
class="math inline">\(K_{3,3}\)</span> is simple and bipartite, every
face in any planar embedding would have degree at least <span
class="math inline">\(4\)</span>. Thus, a planar embedding of <span
class="math inline">\(K_{3,3}\)</span> would imply <span
class="math inline">\(20 = 4f \le 2m = 18\)</span>, which is obviously
impossible.<span class="math inline">\(\qquad\square\)</span>
</dd>
<dt><strong>Nondegeneracy lemma:</strong></dt>
<dd>
<em>No vertex of <span class="math inline">\(G\)</span> is collinear
with all of its neighbors.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
By definition, no three boundary vertices are collinear, and thus no
boundary vertex is collinear with all of its neighbors.
</dd>
<dd>
<p>For the sake of argument, suppose some vertex <span
class="math inline">\(u\)</span> and all of its neighbors lies on a
common line <span class="math inline">\(\ell\)</span>, which without
loss of generality is horizontal. Let <span
class="math inline">\(V^+\)</span> and <span
class="math inline">\(V^-\)</span> be the subsets of vertices above and
below <span class="math inline">\(\ell\)</span>, respectively. Let <span
class="math inline">\(U\)</span> be the set of all vertices that are
reachable from <span class="math inline">\(u\)</span> and whose
neighbors all lie on <span class="math inline">\(\ell\)</span>. The
halfplane lemma implies that the induced subgraphs <span
class="math inline">\(G[V^+]\)</span> and <span
class="math inline">\(G[V^-]\)</span> are connected, and the induced
subgraph <span class="math inline">\(G[U]\)</span> is connected by
definition. Fix arbitrary vertices <span class="math inline">\(v^+\in
V^+\)</span> and <span class="math inline">\(v^-\in V^-\)</span>.</p>
</dd>
<dd>
<p>Finally, let <span class="math inline">\(W\)</span> denote the set of
all vertices that lie on line <span class="math inline">\(\ell\)</span>
and are adjacent to vertices in <span class="math inline">\(U\)</span>,
but are not in <span class="math inline">\(U\)</span> themselves. Every
vertex in <span class="math inline">\(W\)</span> has at least one
neighbor not in <span class="math inline">\(\ell\)</span>, so by the
both-sides lemma, every vertex in <span class="math inline">\(W\)</span>
has neighbors in both <span class="math inline">\(V^+\)</span> and <span
class="math inline">\(V^-\)</span>. Deleting the vertices in <span
class="math inline">\(W\)</span> disconnects <span
class="math inline">\(U\)</span> from the rest of the graph. Thus,
<strong>because <span class="math inline">\(G\)</span> is
3-connected</strong>, <span class="math inline">\(W\)</span> contains at
least three vertices <span class="math inline">\(w_1, w_2,
w_3\)</span>.</p>
</dd>
<dd>
<p>Now suppose we contract the induced subgraphs <span
class="math inline">\(G[V^+]\)</span>, <span
class="math inline">\(G[V^-]\)</span>, and <span
class="math inline">\(G[U]\)</span> to the vertices <span
class="math inline">\(v^+\)</span>, <span
class="math inline">\(v^-\)</span>, and <span
class="math inline">\(u\)</span>, respectively. The resulting minor of
<span class="math inline">\(G\)</span> contains the complete bipartite
graph <span class="math inline">\(\{v^+, v^-, u\}\times \{w_1, w_2,
w_3\} = K_{3,3}\)</span>. But this is impossible, <strong>because <span
class="math inline">\(G\)</span> is planar</strong> and therefore every
minor of <span class="math inline">\(G\)</span> is planar. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<figure>
<img src="Fig/Tutte-not-all-collinear.png" style="width:45.0%"
alt="A collinear vertex neighborhood implies a K_{3,3} minor." />
<figcaption aria-hidden="true">A collinear vertex neighborhood implies a
<span class="math inline">\(K_{3,3}\)</span> minor.</figcaption>
</figure>
<dl>
<dt><strong>Both sides redux:</strong></dt>
<dd>
<em>Every interior vertex <span class="math inline">\(v\)</span> has
neighbors on both sides of any line through <span
class="math inline">\(p_v\)</span>.</em>
</dd>
</dl>
<h2 data-number="12.5" id="no-degenerate-faces"><span
class="header-section-number">12.5</span> No Degenerate Faces</h2>
<p>It remains to prove that the faces of the Tutte drawing are
nondegenerate. First we need a combinatorial lemma, similar to Fáry’s
lemma that any simple planar map can be refined into a simple
triangulation.</p>
<dl>
<dt><strong>Geelen’s Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(uv\)</span> be any edge of <span
class="math inline">\(G\)</span>, let <span
class="math inline">\(f\)</span> and <span
class="math inline">\(f’\)</span> be the faces incident to <span
class="math inline">\(uv\)</span>, and let <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S’\)</span> be the vertices of these two faces
other than <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>. Let <span
class="math inline">\(P\)</span> be any path that starts at a vertex in
<span class="math inline">\(S\)</span> and ends at a vertex of <span
class="math inline">\(S’\)</span>. Then every path from <span
class="math inline">\(u\)</span> to <span
class="math inline">\(v\)</span> in <span
class="math inline">\(G\)</span> either consists of the edge <span
class="math inline">\(uv\)</span> or contains a vertex of <span
class="math inline">\(P\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix any planar embedding of <span class="math inline">\(G\)</span> (not
necessarily the Tutte drawing!) where <span
class="math inline">\(uv\)</span> is an interior edge. The faces
incident to <span class="math inline">\(uv\)</span> are disjoint disks
on either side of <span class="math inline">\(uv\)</span>. Let <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> be the endpoints of <span
class="math inline">\(P\)</span>. Let <span
class="math inline">\(P’\)</span> be a path from <span
class="math inline">\(l\)</span> to <span
class="math inline">\(r\)</span> through the union of the faces incident
to <span class="math inline">\(uv\)</span>, crossing the edge <span
class="math inline">\(uv\)</span> once. The closed curve <span
class="math inline">\(C = P + P’\)</span> separates <span
class="math inline">\(u\)</span> from <span
class="math inline">\(v\)</span>. Thus, by the Jordan curve theorem,
every path <span class="math inline">\(Q\)</span> from <span
class="math inline">\(u\)</span> to <span
class="math inline">\(v\)</span> crosses <span
class="math inline">\(C\)</span>, which implies that either <span
class="math inline">\(Q=uv\)</span> or <span
class="math inline">\(Q\)</span> contains a vertex of <span
class="math inline">\(P\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<figure>
<img src="Fig/geelen.png" style="width:30.0%" alt="Geelen’s lemma." />
<figcaption aria-hidden="true">Geelen’s lemma.</figcaption>
</figure>
<dl>
<dt><strong>Split Faces Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(uv\)</span> be any interior edge of
<span class="math inline">\(G\)</span>, let <span
class="math inline">\(f\)</span> and <span
class="math inline">\(f’\)</span> be the faces incident to <span
class="math inline">\(uv\)</span>, and let <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S’\)</span> be the vertices of these two faces
other than <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>. Finally, let <span
class="math inline">\(\ell\)</span> be any line through <span
class="math inline">\(p_u\)</span> and <span
class="math inline">\(p_v\)</span>. Then <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S’\)</span> lie on opposite sides of <span
class="math inline">\(\ell\)</span>; in particular, no vertex in <span
class="math inline">\(S\cup S’\)</span> lies on <span
class="math inline">\(\ell\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Without loss of generality, assume <span
class="math inline">\(\ell\)</span> is horizontal. For the sake of
argument, suppose both <span class="math inline">\(S\)</span> and <span
class="math inline">\(S’\)</span> contain vertices <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> that lie on or below <span
class="math inline">\(\ell\)</span>. If <span
class="math inline">\(s\)</span> lies on <span
class="math inline">\(\ell\)</span>, the nondegeneracy lemma implies
that <span class="math inline">\(s\)</span> has a neighbor <span
class="math inline">\(s’\)</span> strictly below <span
class="math inline">\(\ell\)</span>; otherwise, let <span
class="math inline">\(s’ = s\)</span>. Similarly, if <span
class="math inline">\(t\)</span> lies on <span
class="math inline">\(\ell\)</span>, the nondegeneracy lemma implies
that <span class="math inline">\(t\)</span> has a neighbor <span
class="math inline">\(t’\)</span> strictly below <span
class="math inline">\(\ell\)</span>; otherwise, let <span
class="math inline">\(t’ = t\)</span>. The halfspace lemma implies that
there is a path <span class="math inline">\(P’\)</span> in <span
class="math inline">\(G\)</span> from <span
class="math inline">\(s’\)</span> to <span
class="math inline">\(t’\)</span> that lies entirely below <span
class="math inline">\(\ell\)</span>. Let <span
class="math inline">\(P\)</span> be the path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> consisting of the edge <span
class="math inline">\(ss’\)</span> (if <span class="math inline">\(s\ne
s’\)</span>), the path <span class="math inline">\(P’\)</span>, and the
edge <span class="math inline">\(t’t\)</span> (if <span
class="math inline">\(t\ne t’\)</span>).
</dd>
<dd>
<p>The nondegeneracy lemma also implies that <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> have respective neighbors <span
class="math inline">\(u’\)</span> and <span
class="math inline">\(v’\)</span> strictly above <span
class="math inline">\(\ell\)</span>, and the halfspace lemma implies
that there is a path <span class="math inline">\(Q’\)</span> from <span
class="math inline">\(u’\)</span> to <span
class="math inline">\(v’\)</span> that lies strictly above <span
class="math inline">\(\ell\)</span>. Let <span
class="math inline">\(Q\)</span> be the path from <span
class="math inline">\(u\)</span> to <span
class="math inline">\(v\)</span> consisting of the edge <span
class="math inline">\(uu’\)</span>, the path <span
class="math inline">\(Q’\)</span>, and the edge <span
class="math inline">\(v’v\)</span>.</p>
</dd>
<dd>
<p>The edge <span class="math inline">\(uv\)</span> and the path <span
class="math inline">\(P\)</span> satisfy the conditions of Geelen’s
lemma. The path <span class="math inline">\(Q\)</span> clearly avoids
the edge <span class="math inline">\(uv\)</span>, so <span
class="math inline">\(Q\)</span> must cross <span
class="math inline">\(P\)</span>. But <span
class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span> lie on opposite sides of <span
class="math inline">\(\ell\)</span>. We have reached a contradiction,
completing the proof.<span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<figure>
<img src="Fig/split-faces.png" style="width:40.0%"
alt="The split faces lemma." />
<figcaption aria-hidden="true">The split faces lemma.</figcaption>
</figure>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>No edge of <span class="math inline">\(G\)</span> maps to a single
point.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Suppose <span class="math inline">\(p_u=p_v\)</span> for some edge <span
class="math inline">\(uv\)</span>. Let <span
class="math inline">\(\ell\)</span> be any line through <span
class="math inline">\(p_u=p_v\)</span> and some other vertex on a face
incident to <span class="math inline">\(uv\)</span>. We immediately have
a contradiction to the previous lemma. <span
class="math inline">\(\qquad\square\)</span>
</dd>
<dt><strong>Convexity lemma:</strong></dt>
<dd>
<em>Every face of <span class="math inline">\(G\)</span> maps to a
strictly convex polygon.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(f\)</span> be any face of <span
class="math inline">\(G\)</span>, let <span
class="math inline">\(uv\)</span> be any edge of <span
class="math inline">\(f\)</span>, and let <span
class="math inline">\(\ell\)</span> be the unique line containing <span
class="math inline">\(p_u\)</span> and <span
class="math inline">\(p_v\)</span>. If <span
class="math inline">\(uv\)</span> is a boundary edge, the outer face
lemma implies that every vertex of <span
class="math inline">\(f\)</span> except <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> lies strictly on one side of <span
class="math inline">\(\ell\)</span>. Similarly, if <span
class="math inline">\(uv\)</span> is an interior edge, the split faces
lemma implies that every vertex of <span
class="math inline">\(f\)</span> except <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> lies strictly on one side of <span
class="math inline">\(\ell\)</span>. In particular, no other vertex of
<span class="math inline">\(f\)</span> lies on the line <span
class="math inline">\(\ell\)</span>. It follows that <span
class="math inline">\(uv\)</span> is an edge of the convex hull of <span
class="math inline">\(f\)</span>. We conclude that <span
class="math inline">\(f\)</span> coincides with its convex hull. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>Now we are finally ready to prove the main theorem.</p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Call a point <em>generic</em> if it does not lie in the image of the
Tutte drawing. Consider any path from a generic point <span
class="math inline">\(p\)</span> out to infinity that does not pass
through any vertex in the drawing. The split faces lemma implies that
whenever the moving point crosses an edge <span
class="math inline">\(e\)</span>, it leaves one face and enters another.
When the moving point reaches infinity, it is only in the outer face.
Thus, every generic point lies in exactly one face.
</dd>
<dd>
<p>For the sake of argument, suppose two edges <span
class="math inline">\(uv\)</span> and <span
class="math inline">\(xy\)</span> intersect in the Tutte drawing. Then
any generic point near the intersection <span
class="math inline">\(uv\cap xy\)</span> must lie in two different
faces, which we just showed is impossible. We conclude that the Tutte
drawing is an embedding; in particular, every face is a simple polygon.
We already proved that every face in this embedding is strictly convex.
<span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="12.6" id="whitneys-uniqueness-theorem"><span
class="header-section-number">12.6</span> Whitney’s Uniqueness
Theorem</h2>
<p>Tutte’s theorem is as strong as possible in the following sense:
Every planar graph with a strictly convex embedding is 3-connected. This
observation follows from an earlier study of 3-connected planar graphs
by Hassler Whitney.</p>
<p>A planar map is <em>polyhedral</em> if (1) the boundary of every face
is a simple cycle, and (2) the intersection of any two facial cycles is
either empty, a single vertex, or a single edge. Every strictly convex
planar map is polyhedral.</p>
<p><strong>Lemma:</strong> <em>Every planar embedding of a 3-connected
planar graph is polyhedral.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Fix a planar embedding <span class="math inline">\(\Sigma\)</span> of
some graph <span class="math inline">\(G\)</span>.
</dd>
<dd>
<p>Suppose the boundary of some face <span
class="math inline">\(f\)</span> is not a simple cycle. The boundary of
<span class="math inline">\(f\)</span> must have a repeated vertex <span
class="math inline">\(v\)</span>. So the radial map <span
class="math inline">\(\Sigma^\diamond\)</span> contains a cycle of
length <span class="math inline">\(2\)</span> through <span
class="math inline">\(v\)</span> and <span
class="math inline">\(f\)</span>, which has at least one other vertex of
<span class="math inline">\(\Sigma\)</span> on either side. It follows
that <span class="math inline">\(G\setminus v\)</span> must be
disconnected.</p>
</dd>
<dd>
<p>Suppose two faces <span class="math inline">\(f\)</span> and <span
class="math inline">\(g\)</span> have two vertices <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> in common, but not the edge <span
class="math inline">\(uv\)</span>. Then the radial map <span
class="math inline">\(\Sigma^\diamond\)</span> contains a simple cycle
with vertices <span class="math inline">\(f, u, g, v\)</span>, which has
at least one other vertex of <span class="math inline">\(G\)</span> on
either side. It follows that <span class="math inline">\(G\setminus
\{u,v\}\)</span> is disconnected.</p>
</dd>
<dd>
<p>We conclude that if <span class="math inline">\(\Sigma\)</span> is
not polyhedral, then <span class="math inline">\(G\)</span> is not
3-connected. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>If a graph <span
class="math inline">\(G\)</span> has a polyhedral planar embedding, then
<span class="math inline">\(G\)</span> is 3-connected.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(G\)</span> be any graph that is not
3-connected, and let <span class="math inline">\(\Sigma\)</span> be any
planar embedding of <span class="math inline">\(G\)</span>. Again, there
are two cases to consider:
</dd>
<dd>
<ul>
<li>Suppose <span class="math inline">\(G\setminus v\)</span> is
disconnected, for some vertex <span class="math inline">\(v\)</span>.
Then the same face of <span class="math inline">\(\Sigma\)</span> must
be incident to <span class="math inline">\(v\)</span> twice.</li>
</ul>
</dd>
<dd>
<ul>
<li>Suppose <span class="math inline">\(G\setminus \{u,v\}\)</span> is
disconnected, for some vertices <span class="math inline">\(u\)</span>
and <span class="math inline">\(v\)</span>. We can assume without loss
of generality that <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> are not adjacent, since otherwise <span
class="math inline">\(G\setminus u\)</span> is already disconnected.
Then some pair of faces <span class="math inline">\(f\)</span> and <span
class="math inline">\(g\)</span> must have both <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> on their boundaries, but not the edge
<span class="math inline">\(uv\)</span>.</li>
</ul>
</dd>
<dd>
<p>In both cases, we conclude that <span
class="math inline">\(\Sigma\)</span> is not polyhedral. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>The dual <span
class="math inline">\(\Sigma^*\)</span> of any polyhedral planar map
<span class="math inline">\(\Sigma\)</span> is polyhedral.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Suppose <span class="math inline">\(\Sigma\)</span> has a face <span
class="math inline">\(f\)</span> whose boundary is not a simple cycle.
Then the boundary walk of <span class="math inline">\(f\)</span>
encounters some vertex <span class="math inline">\(v\)</span> more than
once; in other words, <span class="math inline">\(v\)</span> and <span
class="math inline">\(f\)</span> are incident more than once. Thus, in
the dual map <span class="math inline">\(\Sigma^*\)</span>, the dual
vertex <span class="math inline">\(f^*\)</span> and the dual face <span
class="math inline">\(v^*\)</span> are incident more than once, so the
boundary of <span class="math inline">\(v^*\)</span> is not a simple
cycle.
</dd>
<dd>
<p>On the other hand, suppose <span
class="math inline">\(\Sigma\)</span> has two faces <span
class="math inline">\(f\)</span> and <span
class="math inline">\(g\)</span> that share two vertices <span
class="math inline">\(v\)</span> and <span
class="math inline">\(w\)</span>, but there is no dart with endpoints
<span class="math inline">\(v\)</span> and <span
class="math inline">\(w\)</span> and shores <span
class="math inline">\(f\)</span> and <span
class="math inline">\(g\)</span>. It follows that the dual faces <span
class="math inline">\(v^*\)</span> and <span
class="math inline">\(w^*\)</span> in <span
class="math inline">\(\Sigma^*\)</span> share the dual vertices <span
class="math inline">\(f^*\)</span> and <span
class="math inline">\(g^*\)</span>, but there is no dart with endpoints
<span class="math inline">\(f^*\)</span> and <span
class="math inline">\(g^*\)</span> and shores <span
class="math inline">\(v^*\)</span> and <span
class="math inline">\(w^*\)</span>.</p>
</dd>
<dd>
<p>We conclude that if <span class="math inline">\(\Sigma\)</span> is
not polyhedral, then neither is <span
class="math inline">\(\Sigma^*\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Lemma (Whitney):</strong> <em>Every planar graph has at most
one polyhedral embedding.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be a polyhedral planar
embedding of some graph <span class="math inline">\(G\)</span> (which
must be planar and 3-connected by previous lemmas), and let <span
class="math inline">\(\Sigma&#39;\)</span> be any embedding of <span
class="math inline">\(G\)</span> that is not equivalent to <span
class="math inline">\(\Sigma\)</span>. Let <span
class="math inline">\(\textsf{succ}\)</span> and <span
class="math inline">\(\textsf{succ}&#39;\)</span> be the successor
permutations of <span class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(\Sigma&#39;\)</span>, respectively. Because <span
class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(\Sigma&#39;\)</span> are not equivalent, <span
class="math inline">\(\textsf{succ}&#39;\)</span> is not equal to either
<span class="math inline">\(\textsf{succ}\)</span> or <span
class="math inline">\(\textsf{succ}^{-1}\)</span>.
</dd>
<dd>
<p>First, suppose there is a dart <span class="math inline">\(d\)</span>
such that <span class="math inline">\(\textsf{succ}&#39;(d)\)</span> is
not equal to either <span
class="math inline">\(\textsf{succ}(d)\)</span> or <span
class="math inline">\(\textsf{succ}^{-1}(d)\)</span>. In other words,
suppose there is a vertex <span class="math inline">\(v =
\textsf{head}(d)\)</span> where the cyclic orders of darts into <span
class="math inline">\(v\)</span> in the two embeddings are different.
The darts <span class="math inline">\(d\)</span> and <span
class="math inline">\(\textsf{succ}&#39;(d)\)</span> split the cycle of
darts around <span class="math inline">\(v\)</span> into two non-empty
intervals; color the darts in one interval red and the other interval
blue. In particular, color <span
class="math inline">\(\textsf{succ}(d)\)</span> red and color <span
class="math inline">\(\textsf{succ}^{-1}(d)\)</span> blue. There must be
another dart <span class="math inline">\(d&#39;\)</span> that is red or
blue, whose successor <span
class="math inline">\(\textsf{succ}&#39;(d)\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span> is either blue or red,
respectively.</p>
</dd>
<dd>
<p>Let <span class="math inline">\(C\)</span> be the simple cycle in
<span class="math inline">\(G\)</span> that bounds face <span
class="math inline">\(f = \textsf{left}&#39;(d) =
\textsf{right}&#39;(\textsf{succ}&#39;(d))\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span>. (If the boundary of <span
class="math inline">\(f\)</span> is not a simple cycle, then <span
class="math inline">\(\Sigma&#39;\)</span> is not polyhedral and we are
done.) Similarly, let Let <span class="math inline">\(C&#39;\)</span> be
the cycle in <span class="math inline">\(G\)</span> that bounds <span
class="math inline">\(f&#39; = \textsf{left}&#39;(d&#39;) =
\textsf{right}&#39;(\textsf{succ}&#39;(d&#39;))\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span>. The images of <span
class="math inline">\(C\)</span> and <span
class="math inline">\(C&#39;\)</span> in the polyhedral embedding <span
class="math inline">\(\Sigma\)</span> cross each other at <span
class="math inline">\(v\)</span>, and therefore (by the Jordan curve
theorem) share at least one other vertex <span
class="math inline">\(w\)</span>. It follows that faces <span
class="math inline">\(f\)</span> and <span
class="math inline">\(f&#39;\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span> share vertices <span
class="math inline">\(v\)</span> and <span
class="math inline">\(w\)</span>, but do not share the edge <span
class="math inline">\(vw\)</span> (if that edge exists). We conclude
that <span class="math inline">\(\Sigma&#39;\)</span> is not
polyhedral.</p>
</dd>
<dd>
<figure>
<img src="Fig/polyhedral-cross-1.png" style="width:65.0%"
alt="If two embeddings disagree at a vertex, at least one embedding is not polyhedral" />
<figcaption aria-hidden="true">If two embeddings disagree at a vertex,
at least one embedding is not polyhedral</figcaption>
</figure>
</dd>
<dd>
<p>On the other hand, suppose are two darts <span
class="math inline">\(d\)</span> and <span
class="math inline">\(d&#39;\)</span> such that <span
class="math inline">\(\textsf{succ}&#39;(d) = \textsc{succ}(d)\)</span>
and <span class="math inline">\(\textsf{succ}&#39;(d&#39;)\)</span> or
<span class="math inline">\(\textsf{succ}^{-1}(d&#39;)\)</span>. In
other words, suppose the dart order around <span class="math inline">\(v
= \textsf{head}(d)\)</span> is the same in both embeddings, but the dart
order around <span class="math inline">\(w = \textsf{head}(d)\)</span>
is reversed from one embedding to the other. Without loss of generality,
<span class="math inline">\(v\)</span> and <span
class="math inline">\(w\)</span> are adjacent, and we can assume <span
class="math inline">\(d = v\mathord\to w\)</span> and <span
class="math inline">\(d&#39; = \textsf{rev}(d) = w\mathord\to
v\)</span>.</p>
</dd>
<dd>
<p>Let <span class="math inline">\(C\)</span> and <span
class="math inline">\(C&#39;\)</span> be the cycles in <span
class="math inline">\(G\)</span> that bound faces <span
class="math inline">\(f = \textsf{left}&#39;(d) =
\textsf{right}&#39;(d&#39;)\)</span> and <span
class="math inline">\(f&#39; = \textsf{left}&#39;(d&#39;) =
\textsf{right}&#39;(d)\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span>, respectively. After an
arbitrarily small perturbation, the images of <span
class="math inline">\(C\)</span> and <span
class="math inline">\(C&#39;\)</span> in the polyhedral embedding <span
class="math inline">\(\Sigma\)</span> cross each other at the midpoint
<span class="math inline">\(vw\)</span>, and therefore share at least
one other vertex <span class="math inline">\(x\)</span>. It follows that
the faces <span class="math inline">\(f\)</span> and <span
class="math inline">\(f&#39;\)</span> in <span
class="math inline">\(\Sigma&#39;\)</span> have disconnected
intersection, and therefore <span
class="math inline">\(\Sigma&#39;\)</span> is not polyhedral. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
<dd>
<figure>
<img src="Fig/polyhedral-cross-2.png" style="width:75.0%"
alt="If two embeddings disagree along an edge, at least one embedding is not polyhedral" />
<figcaption aria-hidden="true">If two embeddings disagree along an edge,
at least one embedding is not polyhedral</figcaption>
</figure>
</dd>
</dl>
<p>Together, the previous lemmas now imply Whitney’s unique-embedding
theorem.</p>
<p><strong>Theorem (Whitney):</strong> <em>Every 3-connected planar
graph has a unique planar embedding (up to homeomorphism), which is
polyhedral.</em></p>
<p>In light of Whitney’s observation, Tutte’s spring-embedding theorem
immediately implies the following corollary:</p>
<p><strong>Convex Embedding Theorem:</strong> <em>For every polyhedral
planar embedding, there is an equivalent strictly convex
embedding.</em></p>
<h2 data-number="12.7" id="not-appearing-1"><span
class="header-section-number">12.7</span> Not Appearing</h2>
<ul>
<li>Weakly convex faces and internal 3-connectivity</li>
<li>Directed version allowing zero dart weights via “strong
3-connectivity”</li>
<li>Colin de Verdière matrices and spherical spectral embeddings</li>
<li>More spectral graph algorithms!</li>
</ul>
<h1 data-number="13" id="maxwellcremona-correspondencebeta"><span
class="header-section-number">13</span> Maxwell–Cremona
Correspondence<span class="math inline">\(^\beta\)</span></h1>
<p>The idea of using graphs to model physical networks of springs or
ropes under tension does not originate with Tutte, but centuries
earlier.</p>
<p>In the late 1500s, the Dutch physicist Simon Stevin published an
influential book called <em>The Art of Weighing</em>. The 1605 reissue
of this book included a supplement where Stevin describes how to
calculate the forces imposed by a weight hanging from a tree of ropes.
In particular, Stevin correctly observes that as long as every vertex of
this tree has degree <span class="math inline">\(3\)</span>, there is a
unique force applied along each rope such that all forces balance
out.</p>
<figure>
<img src="Fig/Stevin-tree.png" style="width:30.0%"
alt="A weight hanging from a tree of ropes, from Stevin (1605)." />
<figcaption aria-hidden="true">A weight hanging from a tree of ropes,
from Stevin (1605).</figcaption>
</figure>
<p>More than a century later, the French engineer Pierre Varignon
described a method for visualising the forces acting on a planar tree of
ropes under tension. The network of ropes is sometimes called a
<em>funicular polygon</em>, from the Latin <em>funiculus</em> meaning
“small rope”, and the Greek <em>polygonos</em> meaning “many-angled”.
(It would be another 45 years before Meister redefined “polygon” to mean
a closed curve composed of line segments.</p>
<figure>
<img src="Fig/Varignon-diagram.png" style="width:35.0%"
alt="A force polygon (dotted) for a funicular polygon of ropes under tension, from Varignon (1725)." />
<figcaption aria-hidden="true">A force polygon (dotted) for a funicular
polygon of ropes under tension, from Varignon (1725).</figcaption>
</figure>
<p>Each edge in the funicular polygon is a line segment. We can
visualize the forces acting along these edges by drawing a <em>force
polygon</em> as follows. For each edge <span
class="math inline">\(e\)</span> in the funicular polygon, we draw a
line segment <span class="math inline">\(e^*\)</span> perpendicular<a
href="#fn33" class="footnote-ref" id="fnref33"
role="doc-noteref"><sup>33</sup></a> to <span
class="math inline">\(e\)</span> whose length is equal to the magnitude
of force being applied along <span class="math inline">\(e\)</span>. If
the system of ropes is in equilibrium, then the forces vectors into each
vertex of the funicular polygon sum to zero; equivalently, the
corresponding edges of the force polygon form a closed figure. In short,
the force polygon is the <em>dual graph</em> of the funicular polygon.
Outside the study of polyhedra (and especially <em>regular</em>
polyhedra), this may be the oldest example of planar-graph duality.<a
href="#fn34" class="footnote-ref" id="fnref34"
role="doc-noteref"><sup>34</sup></a></p>
<p>Finally, in the mid-1800s, famed Scottish physicist James Clark
Maxwell generalized Varignon’s force diagrams to arbitrarily complex
planar graphs. Maxwell’s analysis became a key technique in the new
field of <em>graphical statics</em> developed by William John Macquorn
Rankine, Carl Culmann, Luigi Cremona, and others. One of the early
successes of graphical statics was the world’s tallest man-made
structure (at the time), constructed in the 1880s to celebrate the
100-year anniversary of the French Revolution by Gustave Eiffel.</p>
<h2 data-number="13.1" id="dramatis-personae"><span
class="header-section-number">13.1</span> Dramatis Personae</h2>
<h3 data-number="13.1.1" id="graphs-and-frameworks"><span
class="header-section-number">13.1.1</span> Graphs and Frameworks</h3>
<p>Let <span class="math inline">\(G\)</span> be a simple 3-connected
planar graph. Recall from the previous lecture that <span
class="math inline">\(G\)</span> has a unique planar embedding (up to
homeomorphism) and therefore has a unique dual graph <span
class="math inline">\(G^*\)</span>, which is also simple, 3-connected,
and planar.</p>
<p>Let <span class="math inline">\(\langle uv | ab\rangle\)</span>
denote the unique dart <span class="math inline">\(d\)</span> in <span
class="math inline">\(G\)</span> with tail <span
class="math inline">\(u\)</span> and head <span
class="math inline">\(v\)</span>, whose dual dart <span
class="math inline">\(d^*\)</span> in <span
class="math inline">\(G^*\)</span> has tail <span
class="math inline">\(a\)</span> and head <span
class="math inline">\(b\)</span>. Thus, <span
class="math inline">\(\langle uv | ab \rangle^* = \langle ab | uv
\rangle\)</span> and <span class="math inline">\(\textsf{rev} \langle uv
| ab \rangle = \langle vu | ba \rangle\)</span>. Equivalently, <span
class="math inline">\(\langle uv | ab \rangle\)</span> has right shore
<span class="math inline">\(a^*\)</span> and left shore <span
class="math inline">\(b^*\)</span> in the unique planar embedding of
<span class="math inline">\(G\)</span>.</p>
<p>A <em>position function</em> for <span
class="math inline">\(G\)</span> is a function <span
class="math inline">\(p\colon V(G)\to\mathbb{R}^2\)</span>, or
equivalently a matrix <span class="math inline">\(p\in (\mathbb{R}^2)^n
= \mathbb{R}^{2\times n}\)</span>, such that <span
class="math inline">\(p(u)\ne p(v)\)</span> for every edge <span
class="math inline">\(uv\)</span>. For each edge <span
class="math inline">\(uv\)</span> of <span
class="math inline">\(G\)</span>, we abuse notation by writing <span
class="math inline">\(p(uv)\)</span> to denote the straight line segment
between <span class="math inline">\(p(u)\)</span> and <span
class="math inline">\(p(v)\)</span>. The pair <span
class="math inline">\((G, p)\)</span> is called a <em>planar
framework</em>. The <em>displacement</em> vector <span
class="math inline">\(\Delta(d)\)</span> of any dart <span
class="math inline">\(d = \langle uv | ab \rangle\)</span>, with respect
to a fixed position function <span class="math inline">\(p\)</span>, is
<span class="math inline">\(p(v) - p(u)\)</span>.</p>
<p>Let me emphasize that a planar framework <span
class="math inline">\((G,p)\)</span> is a straight-line <em>drawing</em>
of its underlying planar graph <span class="math inline">\(G\)</span>,
but it is not necessarily an <em>embedding</em>; images of distinct
edges may cross, overlap, or even coincide.</p>
<h3 data-number="13.1.2" id="stresses"><span
class="header-section-number">13.1.2</span> Stresses</h3>
<p>A <em>stress</em> is a function <span
class="math inline">\(\omega\colon E(G)\to\mathbb{R}\)</span>, or
equivalently, a vector <span class="math inline">\(\omega\in
\mathbb{R}^m\)</span>. A stress is <em>non-zero</em> if <span
class="math inline">\(\omega(e)\ne 0\)</span> for at least one edge
<span class="math inline">\(e\)</span>, and <em>strict</em> if <span
class="math inline">\(\omega(e)\ne 0\)</span> for every edge <span
class="math inline">\(e\)</span>. We frequently abuse notation by
defining <span class="math inline">\(\omega(uv)=0\)</span> when <span
class="math inline">\(uv\)</span> is not an edge. We also extend the
function <span class="math inline">\(\omega\)</span> to the darts of
<span class="math inline">\(G\)</span> by defining <span
class="math inline">\(\omega(\langle uv | ab \rangle) =
\omega(uv)\)</span>.</p>
<p>We can interpret each edge <span class="math inline">\(e\)</span> of
a planar framework as a (first-order linear) spring with spring constant
<span class="math inline">\(|\omega(e)|\)</span>, under tension if <span
class="math inline">\(\omega(e)&gt;0\)</span> and under compression if
<span class="math inline">\(\omega(e)&lt;0\)</span>. Hooke’s Law implies
that each edge <span class="math inline">\(uv\)</span> imparts a force
of <span class="math inline">\(\omega(uv) \cdot (p(v) - p(u)) =
\omega(uv)\cdot \Delta(u\mathord\to v)\)</span> to vertex <span
class="math inline">\(v\)</span>.</p>
<p>A stress <span class="math inline">\(\omega\)</span> is called an
<em>equilibrium</em> stress (or a <em>self-stress</em>) if the net force
on every vertex is zero; that is, for every vertex <span
class="math inline">\(v\)</span> we have <span class="math display">\[
\sum_u \omega(uv) \cdot (p(v) - p(u)) = \binom{0}{0}\]</span></p>
<p>Recall from the previous lecture that this linear system describes
the unique critical point of the potential energy function <span
class="math display">\[
    \Phi(p) := \frac{1}{2} \sum_{u, v}
                    \omega(uv) \cdot \| p(u) - p(v) \|^2.
\]</span> Because stress coefficients are allowed to be negative, this
unique critical point is no longer a local minimum, as it was in the
previous lecture.</p>
<h3 data-number="13.1.3" id="forms-and-discrete-integration"><span
class="header-section-number">13.1.3</span> 1-Forms and Discrete
Integration</h3>
<p>A <em>discrete 1-form</em> (or <em>1-cochain</em>, or <em>voltage
assignment</em>, or <em>pseudoflow</em>) on <span
class="math inline">\(G\)</span> is an anti-symmetric function <span
class="math inline">\(\phi\colon D(G) \to R\)</span> from the darts of
<span class="math inline">\(G\)</span> to some additive abelian group
<span class="math inline">\(R\)</span>, where anti-symmetry means <span
class="math inline">\(\phi(d) = -\phi(\textsf{rev}(d))\)</span> for
every dart <span class="math inline">\(d\)</span>. Here we consider only
1-chains over the vector spaces <span
class="math inline">\(\mathbb{R}\)</span> and <span
class="math inline">\(\mathbb{R}^2\)</span>. (Let me emphasize here that
a stress is not a 1-form!)</p>
<p>A 1-form is <em>exact</em> if the sum of the values of the darts in
any directed cycle is zero. Exact 1-forms are also called
<em>tensions</em>; they are also said to obey <em>Kirchhoff’s voltage
law</em>.<a href="#fn35" class="footnote-ref" id="fnref35"
role="doc-noteref"><sup>35</sup></a></p>
<p>A <em>vertex potential</em> (or <em>price function</em> or
<em>discrete <span class="math inline">\(0\)</span>-form</em>) is any
function <span class="math inline">\(\pi\colon V(G)\to R\)</span> over
the vertices of <span class="math inline">\(G\)</span>. The
<em>derivative</em> (or <em>coboundary</em>) <span
class="math inline">\(\delta\pi\)</span> of a <span
class="math inline">\(0\)</span>-form <span
class="math inline">\(\pi\)</span> is the 1-form <span
class="math inline">\(\delta\pi(u\mathord\to v) := \pi(v) -
\pi(u)\)</span>.</p>
<p><strong>Lemma:</strong> <em>A 1-form <span
class="math inline">\(\phi\)</span> is exact if and only if <span
class="math inline">\(\phi\)</span> is the derivative of a vertex
potential.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The derivative <span class="math inline">\(\delta\pi\)</span> of any
<span class="math inline">\(0\)</span>-form <span
class="math inline">\(\pi\)</span> is clearly exact. On the other hand,
given any exact <span class="math inline">\(1\)</span>-form <span
class="math inline">\(\phi\)</span>, we can arbitrarily fix the
potential <span class="math inline">\(\pi(o)\)</span> of an arbitrary
vertex <span class="math inline">\(o\)</span>, and then for any other
vertex define <span class="math inline">\(\pi(v)\)</span> by summing (or
“integrating”) <span class="math inline">\(\phi\)</span> along any path
from <span class="math inline">\(o\)</span> to <span
class="math inline">\(v\)</span>. Exactness of <span
class="math inline">\(\phi\)</span> implies that <span
class="math inline">\(\pi(v)\)</span> does not depend on which path we
choose to sum along. More generally, for any vertices <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span>, we can compute the potential
difference <span class="math inline">\(\pi(t)-\pi(s)\)</span> by
“integrating” <span class="math inline">\(\phi\)</span> along any <span
class="math inline">\(s\)</span>-to-<span
class="math inline">\(t\)</span> path.
</dd>
</dl>
<p>In particular, for any fixed planar framework <span
class="math inline">\((G, p)\)</span>, the <em>displacement</em>
function <span class="math inline">\(\Delta \colon D(G) \to
\mathbb{R}^2\)</span> defined by <span
class="math inline">\(\Delta(u\mathord\to v) = p(v) - p(u)\)</span> is
an exact 1-form.</p>
<p>A 1-form over a 3-connected planar graph (or more generally, any
surface map) is <em>closed</em> if the sum of the values of the darts in
any <em>face boundary</em> of <span class="math inline">\(G\)</span> sum
to zero. Exact 1-forms are also called <em>cocirculations</em>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(G\)</span> be an arbitrary
3-connected planar graph. A 1-form on <span
class="math inline">\(G\)</span> is closed <strong>if and only
if</strong> it is exact.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Every face boundary in <span class="math inline">\(G\)</span> is a
directed cycle by definition, so every exact 1-form is trivially closed
(even if the graph <span class="math inline">\(G\)</span> is not
planar). The Jordan curve theorem applied to any planar embedding of
<span class="math inline">\(G\)</span> implies that every directed cycle
in <span class="math inline">\(G\)</span> is a sum (or symmetric
difference) of directed face boundaries. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<h2 data-number="13.2" id="reciprocal-diagrams"><span
class="header-section-number">13.2</span> Reciprocal diagrams</h2>
<p>A <em>reciprocal diagram</em> for a planar framework <span
class="math inline">\((G, p)\)</span> is another planar framework <span
class="math inline">\((G^*, p^*)\)</span> such that <span
class="math inline">\(G^*\)</span> and <span
class="math inline">\(G\)</span> are dual and corresponding edges in
<span class="math inline">\(G\)</span> and <span
class="math inline">\(G^*\)</span> are mapped to orthogonal segments by
<span class="math inline">\(p\)</span> and <span
class="math inline">\(p^*\)</span>, respectively. Two reciprocal
diagrams are <em>equivalent</em> if one is a translation of the other.
For any vector <span class="math inline">\(v\in \mathbb{R}^2\)</span>,
let <span class="math inline">\(v^\perp\)</span> denote the result of
rotating <span class="math inline">\(v\)</span> a quarter turn
counterclockwise: <span class="math inline">\(\binom{x}{y}^\perp =
\binom{-y}{x}\)</span>.</p>
<dl>
<dt><strong>Theorem [Maxwell, Whiteley]:</strong></dt>
<dd>
<em>There is a bijection between equilibrium stresses <span
class="math inline">\(\omega\)</span> for <span
class="math inline">\((G, p)\)</span> and equivalence classes of
reciprocal diagrams <span class="math inline">\((G^*, p^*)\)</span>.
Moreover, the stress <span class="math inline">\(\omega^*(e) =
1/\omega(e)\)</span> is an equilibrium stress for every reciprocal
diagram <span class="math inline">\((G^*, p^*)\)</span>, and the
corresponding equivalence class of reciprocal diagrams of any <span
class="math inline">\((G^*, p^*)\)</span> contains <span
class="math inline">\((G,p)\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\omega\)</span> be any equilibrium
stress for <span class="math inline">\((G,p)\)</span>. Define a 1-form
<span class="math inline">\(\Delta^*\colon
D(G^*)\to\mathbb{R}^2\)</span>, which might be called the <em>dual
displacement function</em>, by setting <span class="math display">\[
\Delta^*(d^*)
:= \omega(d)\cdot \Delta(d)^\perp
\]</span> for every dart <span class="math inline">\(d\)</span> of <span
class="math inline">\(G\)</span>. For any face <span
class="math inline">\(v^*\)</span> of the dual graph <span
class="math inline">\(G^*\)</span>, equilibrium implies that <span
class="math display">\[\begin{aligned}
\sum_{d^* \colon v^* = \textsf{left}(d^*)} \Delta^*(d^*)
&amp;=
\sum_{d \colon v = \textsf{head}(d)} \omega(d)\cdot\Delta(d)^\perp
\\  &amp;=
\sum_{u} \omega(uv) \cdot \Delta(u\mathord\to v)^\perp
=
\binom{0}{0}^\perp
=
\binom{0}{0}.
\end{aligned}\]</span> Thus, the function <span
class="math inline">\(\Delta^*\)</span> is a closed 1-form in the dual
graph <span class="math inline">\(G^*\)</span>. , it follows that <span
class="math inline">\(\Delta^*\)</span> is an <em>exact</em> 1-form on
<span class="math inline">\(G^*\)</span>. Thus, there is a potential
function <span class="math inline">\(p^*\)</span> on the vertices of
<span class="math inline">\(G^*\)</span> such that <span
class="math inline">\(\Delta^*(a\mathord\to b) = p^*(b) -
p^*(a)\)</span> for all dual darts <span
class="math inline">\(a\mathord\to b\)</span>; moreover, <span
class="math inline">\(p^*\)</span> is unique up to translation. By
construction, the framework <span class="math inline">\((G^*,
p^*)\)</span> is a reciprocal diagram of <span
class="math inline">\((G,p)\)</span>.
</dd>
<dd>
<p>On the other hand, let <span class="math inline">\((G^*,
p^*)\)</span> be any reciprocal diagram for <span
class="math inline">\((G,p)\)</span>. For each dart <span
class="math inline">\(d = \langle uv | ab \rangle\)</span>, there is a
unique real number <span class="math inline">\(\omega(d)\)</span> such
that <span class="math display">\[
p^*(b) - p^*(a) = \omega(d) \cdot ( p(v) - p(u) )^\perp.
\]</span> Kirchoff’s voltage law in <span class="math inline">\((G^*,
p^*)\)</span> immediately implies that <span
class="math inline">\(\omega\)</span> is an equilibrium stress for <span
class="math inline">\((G, p)\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="13.3" id="polyhedral-lifts"><span
class="header-section-number">13.3</span> Polyhedral lifts</h2>
<p>A <em>lift</em> of a planar framework <span
class="math inline">\((G,p)\)</span> is another <em>height</em> function
<span class="math inline">\(z\colon V(G)\to\mathbb{R}\)</span>, or
equivalently, a vector <span class="math inline">\(z\in
\mathbb{R}^n\)</span>. The position and height functions define a
three-dimensional position function <span
class="math inline">\(\hat{p}\colon V(G)\to \mathbb{R}^3\)</span> by
concatenation: <span class="math inline">\(\hat{p}(v) = (x(v), y(v),
z(v))\)</span>, where <span class="math inline">\((x(v), y(v)) =
p(v)\)</span>. A lift of <span class="math inline">\((G,p)\)</span> is
<em>polyhedral</em> if, for each face <span
class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span>, the images <span
class="math inline">\(\hat{p}(v)\)</span> of all vertices <span
class="math inline">\(v\in f\)</span> are coplanar; a polyhedral lift is
<em>trivial</em> if all points <span
class="math inline">\(\hat{p}(v)\)</span> are coplanar. Finally, two
polyhedral lifts <span class="math inline">\(z\)</span> and <span
class="math inline">\(z’\)</span> are <em>equivalent</em> if their
difference a constant: <span class="math inline">\(z(u) - z’(u) = z(v) -
z’(v)\)</span> for all vertices <span class="math inline">\(u\)</span>
and <span class="math inline">\(v\)</span>. For example, every trivial
lift is equivalent to the zero lift <span class="math inline">\(h\equiv
0\)</span>.</p>
<dl>
<dt><strong>Theorem [Maxwell, Whiteley]:</strong></dt>
<dd>
<em>There is a bijection between reciprocal diagrams <span
class="math inline">\((G^*, p^*)\)</span> of <span
class="math inline">\((G,p)\)</span> and equivalence classes of
nontrivial polyhedral lifts of <span
class="math inline">\((G,p)\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
The <em>radial graph <span
class="math inline">\(G^\diamond\)</span></em> of <span
class="math inline">\(G\)</span> is a bipartite planar graph whose
vertices correspond to the vertices and faces of <span
class="math inline">\(G\)</span>, and whose edges correspond to
vertex-face incidences or <em>corners</em> of <span
class="math inline">\(G\)</span>. The radial graph <span
class="math inline">\(G^\diamond\)</span> inherits a unique planar
embedding from the unique embeddings of <span
class="math inline">\(G\)</span> and <span
class="math inline">\(G^*\)</span>. The faces of this embedding are
correspond to the edges of <span class="math inline">\(G\)</span>; in
particular, every face of <span
class="math inline">\(G^\diamond\)</span> has degree <span
class="math inline">\(4\)</span>.<a href="#fn36" class="footnote-ref"
id="fnref36" role="doc-noteref"><sup>36</sup></a>
</dd>
<dd>

</dd>
<dd>
<p>Let <span class="math inline">\(z\)</span> be any non-trivial
polyhedral lift of <span class="math inline">\((G,p)\)</span>. For each
face <span class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span>, let the equation <span
class="math inline">\(z = x^*(f)\cdot x + y^*(f)\cdot y -
z^*(f)\)</span> denote the plane supporting the lifted face <span
class="math inline">\(\hat{p}(f)\)</span>, and define <span
class="math inline">\(p^*(f) = (x^*(f), y^*(f))\)</span>. For every
corner <span class="math inline">\((v, f)\)</span> in <span
class="math inline">\(G\)</span> (or equivalently, every edge <span
class="math inline">\(vf\)</span> of the radial map <span
class="math inline">\(G^\diamond\)</span>) we immediately have <span
class="math display">\[
z(v) + z^*(f)
~=~ x^*(f)\cdot x(v) + y^*(f)\cdot y(v)
~=~ p(v) \cdot p^*(f)
\]</span> Thus, for every dart <span class="math inline">\(d = \langle
uv | ab \rangle\)</span> of <span class="math inline">\(G\)</span>, we
have four identities: <span class="math display">\[
\begin{aligned}
    p(u)\cdot p^*(a) &amp;= z(u) + z^*(a) \\
    p(u)\cdot p^*(b) &amp;= z(u) + z^*(b) \\
    p(v)\cdot p^*(a) &amp;= z(v) + z^*(a) \\
    p(v)\cdot p^*(b) &amp;= z(v) + z^*(b)
\end{aligned}
\]</span> It follows that <span
class="math inline">\((p(u)-p(v))\cdot(p^*(a)-p^*(b)) = 0\)</span>. We
conclude that each edge of <span class="math inline">\((G,p)\)</span> is
orthogonal to its dual edge in <span class="math inline">\((G^*,
p^*)\)</span>.</p>
</dd>
<dd>
<p>On the other hand, let <span class="math inline">\((G^*,
p^*)\)</span> be any reciprocal diagram for <span
class="math inline">\((G,p)\)</span>. For each face <span
class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span> we interpret the dual position vector
<span class="math inline">\(p^*(f)\)</span> as the gradient vector <span
class="math inline">\((x^*(f), y^*(f))\)</span> of the support plane of
the lifted face <span class="math inline">\(\hat{p}(f)\)</span>. We
simultaneously compute vertical offsets <span
class="math inline">\(z^*(f)\)</span> for those support planes and
heights <span class="math inline">\(z(v)\)</span> for the vertices to
obtain a consistent polyhedral lift.</p>
</dd>
<dd>
<p>We can assign values <span class="math inline">\(z(v)\)</span> and
<span class="math inline">\(z^*(f)\)</span> to the vertices <span
class="math inline">\(v\)</span> and faces <span
class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span> by integrating a closed <span
class="math inline">\(1\)</span>-form over the darts of the radial map
<span class="math inline">\(G^\diamond\)</span>. Specifically, we define
the 1-form <span class="math inline">\(\phi^\diamond\colon
D(G^\diamond)\to\mathbb{R}\)</span> by setting <span
class="math display">\[\phi^\diamond(f\mathord\to v) := p(v)\cdot
p^*(f),\]</span> and therefore <span
class="math display">\[\phi^\diamond(v\mathord\to f) = -p(v)\cdot
p^*(f),\]</span> for each vertex <span class="math inline">\(v\)</span>
and face <span class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span>. For each dart <span
class="math inline">\(d = \langle uv | ab \rangle\)</span> of <span
class="math inline">\(G\)</span>, reciprocality implies <span
class="math display">\[
\begin{aligned}
    \phi^\diamond(a\mathord\to v) + \phi^\diamond(v\mathord\to b)
&amp;{}
        + \phi^\diamond(b\mathord\to u) + \phi^\diamond(u\mathord\to a)
\\  &amp;=
    p(v)\cdot p^*(a) - p(v)\cdot p^*(b)
        + p(u)\cdot p^*(b) - p(u)\cdot p^*(a)
\\  &amp;=
    (p(v)-p(u)) \cdot (p^*(a) - p^*(b)) = 0.
\end{aligned}
\]</span> Thus, <span class="math inline">\(\phi^\diamond\)</span> is a
closed, and therefore exact, 1-form on the radial graph <span
class="math inline">\(G^\diamond\)</span>. It follows that there is a
0-form <span class="math inline">\(\pi^\diamond\colon V(G^\diamond)
\to\mathbb{R}\)</span>, unique up to translation, such that <span
class="math inline">\(\phi^\diamond(f\mathord\to v) = \pi^\diamond(v) -
\pi^\diamond(f)\)</span>. For each vertex <span
class="math inline">\(v\)</span> of <span
class="math inline">\(G\)</span>, define <span
class="math inline">\(z(v) := \pi^\diamond(v)\)</span>, and for each
face <span class="math inline">\(f\)</span> of <span
class="math inline">\(G\)</span>, define <span
class="math inline">\(z^*(f) := -\pi^\diamond(f)\)</span>. By
construction, for any corner <span class="math inline">\((v, f)\)</span>
of <span class="math inline">\(G\)</span>, we have <span
class="math display">\[
z(v) + z^*(f) = p(v)\cdot p^*(f)
\]</span> and therefore <span class="math display">\[
z(v) = x(v)\cdot x^*(f) + y(v)\cdot y^*(f) - z^*(f).
\]</span> Thus, the point <span class="math inline">\(\hat{p}(v) =
(x(v), y(v), z(v))\)</span> lies on the supporting plane of <span
class="math inline">\(\hat{p}(f)\)</span>, which has equation <span
class="math inline">\(z = x^*(f)\cdot f + y^*(f)\cdot y -
z^*(f)\)</span>. We conclude that the vertex heights <span
class="math inline">\(z(v)\)</span> and facet-plane offsets <span
class="math inline">\(z^*(f)\)</span> are consistent with a polyhedral
lift of <span class="math inline">\(G\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="13.4" id="a-non-obvious-example-the-anticube"><span
class="header-section-number">13.4</span> A Non-Obvious Example: The
“Anticube”</h2>
<p>Consider the planar framework <span class="math inline">\(\Gamma =
(G,p)\)</span> shown below left, whose underlying graph <span
class="math inline">\(G\)</span> is the standard cube graph, which is
planar and 3-connected. The six faces of the cube have vertices <span
class="math inline">\(1243\)</span>, <span
class="math inline">\(1276\)</span>, <span
class="math inline">\(2457\)</span>, <span
class="math inline">\(4365\)</span>, <span
class="math inline">\(3186\)</span>, and <span
class="math inline">\(5687\)</span>. (Short orthogonal edges have stress
coefficient <span class="math inline">\(6\)</span>; long orthogonal
edges have stress coefficient <span class="math inline">\(3\)</span>;
diagonal edges have stress coefficient <span
class="math inline">\(-4\)</span>.)</p>
<p>The resulting reciprocal framework <span
class="math inline">\(\Gamma^* = (G^*, p^*)\)</span> is shown on the
right, scaled down by a factor of <span
class="math inline">\(6\)</span>, along with its dual equilibrium
stress. (Dual vertices <span class="math inline">\(A\)</span> and <span
class="math inline">\(F\)</span> actually coincide, but are perturbed
apart to better illustrate the framework structure.) The dual graph
<span class="math inline">\(G^*\)</span> is the graph of the regular
octahedron. I computed this reciprocal framework by solving the system
of linear equations <span class="math inline">\(\Delta^*(a\mathord\to b)
= p^*(b) - p^*(a)\)</span>, one for each dual edge, for the dual
position vectors <span class="math inline">\(p^*(a)\)</span>.</p>
<figure>
<img src="Fig/anticube.png" style="width:80.0%"
alt="The anticube framework with an equilibrium stress, the radial map of the cube, and the corresponding reciprocal framework." />
<figcaption aria-hidden="true">The anticube framework with an
equilibrium stress, the radial map of the cube, and the corresponding
reciprocal framework.</figcaption>
</figure>
<!--
\begin{align*}
    P &= \begin{bmatrix}
        +1 & +2 \\
        -1 & +2 \\
        +1 & -2 \\
        -1 & -2 \\
        +2 & +1 \\
        -2 & +1 \\
        +2 & -1 \\
        -2 & -1
    \end{bmatrix}
    &
    L &= \begin{bmatrix}
        -5 & 6 & 3 & \cdot & \cdot & \cdot & \cdot & -4 \\ 
        6 & -5 & \cdot & 3 & \cdot & \cdot & -4 & \cdot \\
        3 & \cdot & -5 & 6 & \cdot & -4 & \cdot & \cdot \\
        \cdot & 3 & 6 & -5 & -4 & \cdot & \cdot & \cdot \\
        \cdot & \cdot & \cdot & -4 & -5 & 3 & 6 & \cdot \\ 
        \cdot & \cdot & -4 & \cdot & 3 & -5 & \cdot & 6 \\
        \cdot & -4 & \cdot & \cdot & 6 & \cdot & -5 & 3 \\
        -4 & \cdot & \cdot & \cdot & \cdot & 6 & 3 & -5 
    \end{bmatrix}
    &
    \ker L &= \begin{bmatrix}
        +1 & +2 & 1 \\
        -1 & +2 & 1 \\
        +1 & -2 & 1 \\
        -1 & -2 & 1 \\
        +2 & +1 & 1 \\
        -2 & +1 & 1 \\
        +2 & -1 & 1 \\
        -2 & -1 & 1
    \end{bmatrix}
\end{align*}
\begin{align*}
    \Delta &=
    \begin{bmatrix}
        -2 & 0 \\
        0 & -4 \\
        -3 & -3 \\
        0 & -4 \\
        +3 & -3 \\
        -2 & 0 \\
        -3 & 3 \\
        +3 & +3 \\
        -4 & 0 \\
        0 & -2 \\
        0 & -2 \\
        -4 & 0
    \end{bmatrix}
    ~
    \textcolor{Salmon}
    {\begin{matrix}
        \arc12 \\ \arc13 \\ \arc18 \\ \arc24 \\
        \arc27 \\ \arc34 \\ \arc36 \\ \arc45 \\
        \arc56 \\ \arc57 \\ \arc68 \\ \arc78
    \end{matrix}}
    \quad
    \textcolor{YellowGreen}
    {\begin{matrix}
        \fence{B}{A} \\ \fence{A}{C} \\ \fence{C}{B} \\ \fence{D}{A} \\
        \fence{B}{D} \\ \fence{A}{E} \\ \fence{E}{C} \\ \fence{D}{E} \\
        \fence{F}{E} \\ \fence{D}{F} \\ \fence{F}{C} \\ \fence{B}{F}
    \end{matrix}}
    &
    \Delta^* &=
    \begin{bmatrix}
        0 & -12  \\
        +12 & 0  \\
        -12 & +12 \\
        +12 & 0 \\
        -12 & -12 \\
        0 & -12 \\
        +12 & +12 \\
        +12 & -12 \\
        0 & -12 \\
        +12 & 0 \\
        +12 & 0 \\
        0 & -12
    \end{bmatrix}
    ~
    \textcolor{Salmon}
    {\begin{matrix}
        \fence12 \\ \fence13 \\ \fence18 \\ \fence24 \\
        \fence27 \\ \fence34 \\ \fence36 \\ \fence45 \\
        \fence56 \\ \fence57 \\ \fence68 \\ \fence78
    \end{matrix}}
    \quad
    \textcolor{YellowGreen}
    {\begin{matrix}
        \arc{B}{A} \\ \arc{A}{C} \\ \arc{C}{B} \\ \arc{D}{A} \\
        \arc{B}{D} \\ \arc{A}{E} \\ \arc{E}{C} \\ \arc{D}{E} \\
        \arc{F}{E} \\ \arc{D}{F} \\ \arc{F}{C} \\ \arc{B}{F}
    \end{matrix}}
\end{align*}
\begin{align*}
    [P, Z] &= \begin{bmatrix}[cc:c]
        +1 & +2 & 0 \\
        -1 & +2 & 0 \\
        +1 & -2 & 0 \\
        -1 & -2 & 0 \\
        +2 & +1 & 36 \\
        -2 & +1 & 36 \\
        +2 & -1 & 36 \\
        -2 & -1 & 36
    \end{bmatrix}
    \textcolor{Gray}    {\begin{matrix} 1\\2\\3\\4\\5\\6\\7\\8 \end{matrix}}
    &
    [P^*, Z^*] &= \begin{bmatrix}[cc:c]
        0 & 0 & 0 \\
        0 & +12 & 24 \\
        +12 & 0 & 12 \\
        -12 & 0 & 12 \\
        0 & -12 & 24 \\
        0 & 0 & 36
    \end{bmatrix}
    \textcolor{Gray}    {\begin{matrix} A\\B\\C\\D\\E\\F \end{matrix}}
    &   
    \phi^\diamond &= 
    \begin{bmatrix}
        0 \\ +24 \\ +12 \\ 
        0 \\ +24 \\ +12 \\
        0 \\ +12 \\ +24 \\
        0 \\ +12 \\ +24 \\\hdashline
        -24 \\ -12 \\ 0 \\
        -24 \\ -12 \\ 0 \\
        -12 \\ -24 \\ 0 \\
        -12 \\ -24 \\ 0
    \end{bmatrix}
    \textcolor{Gray}
    {\begin{matrix}
        \arc{1}{A} \\ \arc{1}{B} \\ \arc{1}{C} \\
        \arc{2}{A} \\ \arc{2}{B} \\ \arc{2}{D} \\
        \arc{3}{A} \\ \arc{3}{C} \\ \arc{3}{E} \\
        \arc{4}{A} \\ \arc{4}{D} \\ \arc{4}{E} \\\hdashline
        \arc{5}{D} \\ \arc{5}{E} \\ \arc{5}{F} \\
        \arc{6}{C} \\ \arc{6}{E} \\ \arc{6}{F} \\
        \arc{7}{B} \\ \arc{7}{D} \\ \arc{7}{F} \\
        \arc{8}{B} \\ \arc{8}{C} \\ \arc{8}{F}
    \end{matrix}}
\end{align*}
-->
<p>The next figure shows the polyhedral lift of the anticube
corresponding to the given equilibrium stress (scaled vertically by a
factor of <span class="math inline">\(9\)</span>). This polyhedron
appears to consist of two triangular prisms and a tetrahedron, but in
fact it is a self-intersecting embedding of the cube; the corners of the
central tetrahedron are not actually vertices of the polyhedron. Four of
the six cube faces are embedded as planar but self-intersecting
quadrilaterals; opposite pairs of these faces intersect each other.
Again, I computed this polyhedral lift by solving the system of linear
equations <span class="math inline">\(\phi^\diamond(f\mathord\to v) =
\pi^\diamond(v) - \pi^\diamond(f)\)</span>, one for each radial edge,
for the radial vertex potentials <span class="math inline">\(z(v) =
\pi^\diamond(v)\)</span> and <span class="math inline">\(z^*(f^*) =
\pi^\diamond(f)\)</span>.</p>
<figure>
<img src="Fig/anticube-lift.png" style="width:30.0%"
alt="The corresponding polyhedral lift of the anticube." />
<figcaption aria-hidden="true">The corresponding polyhedral lift of the
anticube.</figcaption>
</figure>
<h2 data-number="13.5" id="steinitzs-theorem"><span
class="header-section-number">13.5</span> Steinitz’s Theorem</h2>
<p><strong><em>[[Write this!]]</em></strong></p>
<p>For embedded planar frameworks, positive-stress bars lift to locally
convex edges, and negative-stress bars lift to locally concave edges. We
can solve for negative boundary stresses that turn any Tutte drawing
into an self-stressed planar framework. The Maxwell–Cremona lift of the
resulting framework is (the boundary of) a <em>convex polytope</em>.</p>
<p><strong>Steinitz’s Theorem:</strong> <em>Every 3-connected planar
graph is the 1-skeleton of am essentially unique convex polytope in
<span class="math inline">\(\mathbb{R}^3\)</span>.</em></p>
<p>(In fact, Steinitz only proved that every <em>polyhedral planar
map</em> is equivalent to the boundary map of a convex polytope.
Steinitz proved this theorem using a direct inductive construction via
the medial map. The equivalence of 3-connected planar graphs and
polyhedral embeddings was later proved by Whitney.)</p>
<p><strong><em>Positive interior stresses lift to convex edges; negative
interior stresses lift to concave edges.</em></strong></p>
<p><strong><em>We can’t actually solve for negative boundary stresses
for arbitrary outer faces, but we can for triangles. Every simple planar
map has either a face or a vertex of degree 3.</em></strong></p>
<h2 data-number="13.6" id="non-3-connected-frameworks"><span
class="header-section-number">13.6</span> Non-3-connected
Frameworks</h2>
<p>The definitions of planar framework and equilibrium stress do not
actually require the underlying graph to be planar and 3-connected. A
planar framework is a pair <span class="math inline">\((G,p)\)</span>
where <span class="math inline">\(G\)</span> is an
<strong><em>arbitrary</em></strong> graph and <span
class="math inline">\(p\colon V(G)\to\mathbb{R}^2\)</span> is a position
function for the vertices of <span class="math inline">\(G\)</span>. The
adjective “planar” refers to the target space of the position function
<span class="math inline">\(p\)</span>, not a the underlying graph of
the framework. Similarly, the definition of equilibrium stress has
nothing to do with the planarity or connectedness of the underlying
graph.</p>
<p>If the underlying graph <span class="math inline">\(G\)</span> of a
planar framework <span class="math inline">\((G,p)\)</span> is planar
but not 3-connected, we no longer have a bijection between equilibrium
stresses and equivalence classes of reciprocal diagrams. Instead, each
planar embedding of <span class="math inline">\(G\)</span> yields a
<em>different</em> bijection between equilibrium stresses and reciprocal
diagrams. In short, reciprocal diagrams are defined for <em>planar
embeddings</em>, not just for abstract graphs.</p>
<p>The following figure shows a planar framework whose underlying graph
two different planar embeddings, obtained by swapping the two “interior”
vertices; the shaded green polygons indicate one face of each embedding.
Each embedding yields a different reciprocal diagram for the same
equilibrium stress. (The arrows indicate the rotation system around the
vertex of the reciprocal diagram dual to the shaded green face in the
primal framework.)</p>
<figure>
<img src="Fig/MC-not-3-connected.png" style="width:95.0%"
alt="Two reciprocal frameworks for the same planar framework" />
<figcaption aria-hidden="true">Two reciprocal frameworks for the same
planar framework</figcaption>
</figure>
<p>Each embedding similarly yields a different polyhedral lift of the
framework <span class="math inline">\((G,p)\)</span>. One embedding is a
tetrahedron with a notch carved out of one edge; the other is a
self-intersecting polyhedron with convex faces that looks like two
tetrahedra sharing an edge.</p>
<h2 data-number="13.7" id="non-planar-frameworks"><span
class="header-section-number">13.7</span> Non-Planar Frameworks</h2>
<p>What about non-planar graphs? Every rotation system for a graph <span
class="math inline">\(G\)</span> yields a well-defined dual graph <span
class="math inline">\(G^*\)</span>. But if the rotation system for <span
class="math inline">\(G\)</span> does not define a planar map, we lose
the equivalence between <em>closed</em> and <em>exact</em> 1-forms in
the resulting dual graph <span class="math inline">\(G^*\)</span>. The
equilibrium stress at each vertex of <span
class="math inline">\(G\)</span> still defines (up to translation) a
planar polygon of forces for the corresponding face of <span
class="math inline">\(G^*\)</span>, but these polygons no longer
necessarily fit together consistently in the plane.</p>
<p>The final figures show two examples from Maxwell’s original papers.
The first figure shows a framework on the left that has <span
class="math inline">\(K_{3,3}\)</span> as a subgraph and is therefore
non-planar, together with an attempted reciprocal framework on the
right. The framework on the left has two edges <span
class="math inline">\(e\)</span> and <span
class="math inline">\(e&#39;\)</span> (respectively, <span
class="math inline">\(h\)</span> and <span
class="math inline">\(h&#39;\)</span>) that are dual to the same edge
<span class="math inline">\(E\)</span> (respectively <span
class="math inline">\(H\)</span>) in the original framework,
respectively. We can complete Maxwell’s construction by identifying
these edge pairs, but the resulting structure no longer embeds in the
plane; instead, we get a well-defined reciprocal framework in the
<em>flat torus</em>!</p>
<figure>
<img src="Fig/MC-nonplanar.png" style="width:60.0%"
alt="A non-planar planar framework with a toroidal reciprocal framework, from Maxwell (1864)" />
<figcaption aria-hidden="true">A non-planar planar framework with a
toroidal reciprocal framework, from Maxwell (1864)</figcaption>
</figure>
<p>On the other hand, sometimes we get lucky. The last figure shows a
planar framework <span class="math inline">\((G,p)\)</span> whose
underlying graph <span class="math inline">\(G\)</span> is again not
planar, but that has a natural embedding on the torus as a <span
class="math inline">\(4\times 4\)</span> toroidal grid. It’s fairly easy
to construct an equilibrium stress for this framework by assigning
positive stresses to one family of disjoint 4-cycles and negative
stresses to the other family of disjoint 4-cycles. Maxwell constructs a
reciprocal framework <span class="math inline">\((G^*, p^*)\)</span>
with respect to this toroidal embedding of <span
class="math inline">\(G\)</span> and such an equilibrium stress, and the
result is a proper planar framework!</p>
<figure>
<img src="Fig/MC-toroidal.png" style="width:60.0%"
alt="A toroidal planar framework with a planar reciprocal framework, from Maxwell (1870)" />
<figcaption aria-hidden="true">A toroidal planar framework with a planar
reciprocal framework, from Maxwell (1870)</figcaption>
</figure>
<h2 data-number="13.8" id="references-7"><span
class="header-section-number">13.8</span> References</h2>
<ol type="1">
<li><p>Henry Crapo and Walter Whiteley. <a
href="http://hdl.handle.net/2099/1091">Plane self stresses and projected
polyhedra I: The basic pattern</a>. <em>Topologie structurale /
Structural Topology</em> 20:55–77, 1993.</p></li>
<li><p>Henry Crapo and Walter Whiteley. <a
href="https://www.emis.de/journals/BAG/vol.35/no.2/">Spaces of stresses,
projections and parallel drawings for spherical polyhedra.</a>
<em>Beitr. Algebra Geom.</em> 35(2):259–281, 1994.</p></li>
<li><p>Luigi Cremona. <a
href="http://www.luigi-cremona.it/download/Scritti_matematici/1872_statica_grafica.pdf"><em>Le
figure reciproche nella statica grafica</em></a>. Tipografia di Giuseppe
Bernardoni, 1872. English translation in [4].</p></li>
<li><p>Luigi Cremona. <a
href="https://archive.org/details/graphicalstatic02cremgoog"><em>Graphical
Statics</em></a>. Oxford Univ. Press, 1890. English translation of [3]
by Thomas Hudson Beare.</p></li>
<li><p>Eduard J. Dijksterhuis, editor. <em>The Principal Works of Simon
Stevin, Volume I</em>. C. V. Swets &amp; Zeitlinger, 1955. English
translation by Carry Dikshoorn.</p></li>
<li><p>Peter Eades and Patrick Garvan. <a
href="https://doi.org/10.1007/BFb0021805">Drawing stressed planar graphs
in three dimensions</a>. <em>Proc. 2nd Symp. Graph Drawing</em>,
212–223, 1995. Lecture Notes Comput. Sci. 1027, Springer.</p></li>
<li><p>John E. Hopcroft and Peter J. Kahn. <a
href="https://doi.org/10.1007/BF01758769">A paradigm for robust
geometric algorithms</a>. <em>Algorithmica</em> 7(1–6):339–380,
1992.</p></li>
<li><p>James Clerk Maxwell. On reciprocal figures and diagrams of
forces. <em>Phil. Mag. (Ser. 4)</em> 27(182):250–261, 1864.</p></li>
<li><p>James Clerk Maxwell. On the application of the theory of
reciprocal polar figures to the construction of diagrams of forces.
<em>Engineer</em> 24:402, 1867. Reprinted in [109,
pp. 313–316].</p></li>
<li><p>James Clerk Maxwell. On reciprocal figures, frames, and diagrams
of forces. <em>Trans. Royal Soc. Edinburgh</em> 26(1):1–40,
1870.</p></li>
<li><p>James Clerk Maxwell. <em>The Scientific Letters and Papers of
James Clerk Maxwell. Volume 2: 1862–1873</em>. Cambridge Univ. Press,
2009.</p></li>
<li><p>Ares Ribó Mor, Günter Rote, and André Schulz. <a
href="https://doi.org/10.1007/s00454-010-9301-0">Small grid embeddings
of 3-polytopes</a>. <em>Discrete Comput. Geom.</em> 45(1):65–87,
2011.</p></li>
<li><p>Ernst Steinitz. <a
href="http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN360609767&amp;DMDID=dmdlog203">Polyeder
und Raumeinteilungen</a>. <em>Enzyklopädie der mathematischen
Wissenschaften mit Einschluss ihrer Anwendungen</em> III.AB(12):1–139,
1916.</p></li>
<li><p>Ernst Steinitz and Hans Rademacher. <em>Vorlesungen über die
Theorie der Polyeder: unter Einschluß der Elemente der Topologie</em>.
Grundlehren der mathematischen Wissenschaften 41. Springer-Verlag, 1934.
Reprinted 1976.</p></li>
<li><p>Simon Stevin. <em>Byvough der Weeghconst [Supplement to the Art
of Weighing]</em>. 1605. Reprinted and translated into English in [5,
pp. 525–607].</p></li>
<li><p>Pierre Varignon. <a
href="https://gallica.bnf.fr/ark:/12148/bpt6k5652714w.texteImage"><em>Nouvelle
mechanique ou statique, dont le projet fut donné en
M.DC.LXXVII</em></a>. Claude Jombert, Paris, 1725.</p></li>
<li><p>Walter Whiteley. <a href="http://hdl.handle.net/2099/989">Motion
and stresses of projected polyhedra</a>. <em>Topologie structurale /
Structural Topology</em> 7:13–38, 1982.</p></li>
</ol>
<h2 data-number="13.9" id="aptly-named-1"><span
class="header-section-number">13.9</span> Aptly Named</h2>
<ul>
<li>Homological constraints for planar reciprocal frameworks</li>
<li>Impossible figures (cohomology, linear programming)</li>
<li>Resolving force loads [Rote and Schulz]</li>
<li>Rigidity (via LP duality)</li>
</ul>
<h1 data-number="14" id="circle-packingvarnothing"><span
class="header-section-number">14</span> Circle Packing<span
class="math inline">\(^\varnothing\)</span></h1>
<h1 data-number="15" id="multiple-source-shortest-pathsalpha"><span
class="header-section-number">15</span> Multiple-Source Shortest
Paths<span class="math inline">\(^\alpha\)</span></h1>
<h2 data-number="15.1" id="problem-statement"><span
class="header-section-number">15.1</span> Problem Statement</h2>
<p>Let <span class="math inline">\(\Sigma = (V, E, F)\)</span> be a
planar map with outer face <span class="math inline">\(o\)</span>, where
each edge <span class="math inline">\(e\)</span> is assigned a
non-negative weight <span class="math inline">\(w(e)\)</span>.<a
href="#fn37" class="footnote-ref" id="fnref37"
role="doc-noteref"><sup>37</sup></a> Call any vertex incident to <span
class="math inline">\(o\)</span> a <em>boundary</em> vertex of <span
class="math inline">\(\Sigma\)</span>. The <em>multiple-source
shortest-path</em> problem asks for an implicit representation of the
shortest paths from <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>, for all boundary vertices <span
class="math inline">\(s\)</span> and all vertices <span
class="math inline">\(t\)</span>. An explicit representation of these
shortest paths, for example as a shortest-path tree rooted at every node
on the outer face, requires <span
class="math inline">\(\Omega(n^2)\)</span> space in the worst case.
Nevertheless, the multiple-source shortest-path problem can be solved in
only <span class="math inline">\(O(n\log n)\)</span> time, in any of the
following forms:</p>
<ul>
<li><p>Given a collection of <span class="math inline">\(k\)</span>
vertex pairs <span class="math inline">\((s_i, t_i)\)</span>, where each
<span class="math inline">\(s_i\)</span> is a boundary vertex, we can
report all <span class="math inline">\(k\)</span> shortest-path
distances <span class="math inline">\(\textsf{dist}(s_i, t_i)\)</span>
in <span class="math inline">\(O(n \log n + k\log n)\)</span>
time.</p></li>
<li><p>Assuming the outer face <span class="math inline">\(o\)</span>
has <span class="math inline">\(k\)</span> vertices, we can report the
<span class="math inline">\(O(k^2)\)</span> shortest-paths distances
between every pair of boundary vertices in <span
class="math inline">\(O(n\log n + k^2)\)</span> time.</p></li>
<li><p>We can preprocess <span class="math inline">\(\Sigma\)</span> in
<span class="math inline">\(O(n\log n)\)</span> time into a data
structure using <span class="math inline">\(O(n\log n)\)</span> space,
that can report the shortest-path distance from an arbitrary boundary
vertex to an arbitrary vertex in <span class="math inline">\(O(\log
n)\)</span> time.</p></li>
</ul>
<p>The multiple-source shortest-path problem was first posed and solved
by Philip Klein in 2005. Here I’m describing a variant of Klein’s
algorithm published by Sergio Cabello and Erin Chambers in 2007, which
more easily generalizes to graphs on non-planar surface maps. This
algorithm plays an essential role in several efficient algorithms for
planar maps and surface maps.</p>
<p>To ease presentation, I will make two simplifying assumptions about
the input graph:</p>
<ol type="1">
<li>The boundary of the outer face <span
class="math inline">\(o\)</span> is a simple cycle. This assumption can
be enforced if necessary by inserting additional edges with very large
weight.</li>
<li>For every vertex <span class="math inline">\(s\)</span> and every
vertex <span class="math inline">\(t\)</span>, there is
<strong><em>exactly one</em></strong> shortest path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>. (Thus, the algorithm I’ll describe
here cannot be used verbatim on unweighted graphs.) I’ll describe two
easy methods to enforce this assumption at the end of this note.</li>
</ol>
<h2 data-number="15.2" id="shortest-paths-and-slacks"><span
class="header-section-number">15.2</span> Shortest paths and slacks</h2>
<p>The MSSP algorithm relies on a characterization of shortest paths
developed by Lester Ford in the mid-1950s. Fix a <em>source</em> vertex
<span class="math inline">\(s\)</span>. For each vertex <span
class="math inline">\(v\)</span>, let <span
class="math inline">\(\textsf{dist}(v)\)</span> denote the shortest-path
distance from <span class="math inline">\(s\)</span> to <span
class="math inline">\(v\)</span>. Let <span
class="math inline">\(\textsf{pred}(v)\)</span> denote the predecessor
of vertex <span class="math inline">\(v\)</span> (if any) in the unique
shortest path from <span class="math inline">\(s\)</span> to <span
class="math inline">\(v\)</span>. Let <span
class="math inline">\(T_s\)</span> denote the tree of shortest paths
from <span class="math inline">\(s\)</span> to other vertices, defined
so that <span class="math inline">\(\textsf{pred}(v)\)</span> is the
parent of <span class="math inline">\(v\)</span> in <span
class="math inline">\(T_s\)</span>. Finally, define the <em>slack</em>
of each dart <span class="math inline">\(u\mathord\to v\)</span> as
<span class="math display">\[  
    \textsf{slack}(u\mathord\to v) :=
        \textsf{dist}(u) + w(u\mathord\to v) - \textsf{dist}(v)
\]</span> A dart whose slack is negative is called <em>tense</em>.</p>
<p>Ford’s generic single-source shortest path algorithm starts by
assigning <span class="math inline">\(\textsf{dist}(s) = 0\)</span> and
<em>tentatively</em> assigning <span
class="math inline">\(\textsf{dist}(v) = \infty\)</span> for every
vertex <span class="math inline">\(v\ne s\)</span>. Then as long as the
graph contains at least one tense dart, the algorithm <em>relaxes</em>
one tense dart <span class="math inline">\(u\mathord\to v\)</span> by
reassigning <span class="math inline">\(\textsf{dist}(v) \gets
\textsf{dist}(u) + w(u\mathord\to v)\)</span> and <span
class="math inline">\(\textsf{pred}(v) \gets u\)</span>. When no more
darts are tense, every value <span
class="math inline">\(\textsf{dist}(v)\)</span> is the correct
shortest-path distance, and the predecessor pointers define a correct
shortest-path tree <span class="math inline">\(T_s\)</span>.</p>
<dl>
<dt><strong>Lemma (Ford 1956):</strong></dt>
<dd>
<em>The following invariants hold for any shortest-path tree <span
class="math inline">\(T_s\)</span> in any edge-weighted graph <span
class="math inline">\(G\)</span>:</em>
</dd>
<dd>
<ol type="a">
<li><em>Every dart in <span class="math inline">\(G\)</span> has
non-negative slack.</em></li>
</ol>
</dd>
<dd>
<ol start="2" type="a">
<li><em>Every dart in a shortest path tree <span
class="math inline">\(T_s\)</span> (directed away from <span
class="math inline">\(s\)</span>) has slack zero.</em></li>
</ol>
</dd>
<dd>
<ol start="3" type="a">
<li><em>If shortest paths are unique, then every dart that is not in the
unique shortest-path tree <span class="math inline">\(T_s\)</span> has
positive slack.</em></li>
</ol>
</dd>
</dl>
<h2 data-number="15.3" id="compact-output"><span
class="header-section-number">15.3</span> Compact Output</h2>
<dl>
<dt><strong>Disk-tree Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(T\)</span> be any tree embedded on a
disk with boundary cycle <span class="math inline">\(B\)</span>; call
any vertex in <span class="math inline">\(T\cap B\)</span> a boundary
vertex. Let <span class="math inline">\(e\)</span> be any edge of <span
class="math inline">\(T\)</span>, and let <span
class="math inline">\(U\)</span> and <span
class="math inline">\(W\)</span> be the components of <span
class="math inline">\(T\setminus e\)</span>. Either <span
class="math inline">\(U\)</span> contains no vertices, or <span
class="math inline">\(U\)</span> contains every boundary vertex, or
boundary vertices in <span class="math inline">\(U\)</span> induce a
path in <span class="math inline">\(B\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be the planar map
induced by <span class="math inline">\(T \cup B\)</span>. Trivially,
<span class="math inline">\(T\)</span> is a spanning tree of <span
class="math inline">\(\Sigma\)</span>. The complementary dual spanning
tree <span class="math inline">\(C^*\)</span> of <span
class="math inline">\(\Sigma^*\)</span> is a star, with the outer face
of <span class="math inline">\(\Sigma\)</span> at the center and other
faces of <span class="math inline">\(\Sigma\)</span> at the leaves.
</dd>
<dd>
<p>The dual subgraph <span class="math inline">\(C^* / e^*\)</span>
contains a cycle <span class="math inline">\(\gamma\)</span> of length
<span class="math inline">\(2\)</span> that separates all vertices in
<span class="math inline">\(U\)</span> from all vertices in <span
class="math inline">\(W\)</span>. If <span
class="math inline">\(\gamma\)</span> does not intersect <span
class="math inline">\(B\)</span>, then <span
class="math inline">\(U\)</span> either contains every boundary vertex
or none. Otherwise, <span class="math inline">\(\gamma\)</span>
intersects <span class="math inline">\(B\)</span> exactly twice, so
<span class="math inline">\(U\)</span> contains an interval of boundary
vertices. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<figure>
<img src="Fig/disk-tree.png" style="width:75.0%"
alt="The disk-tree lemma." />
<figcaption aria-hidden="true">The disk-tree lemma.</figcaption>
</figure>
<p>Now suppose our original planar map <span
class="math inline">\(\Sigma\)</span> has <span
class="math inline">\(h\)</span> boundary vertices, indexed <span
class="math inline">\(s_0, s_1, s_2, \dots, s_{h-1}\)</span> in cyclic
order. For each index <span class="math inline">\(i\)</span>, let <span
class="math inline">\(T_i\)</span> denote the shortest-path tree rooted
at <span class="math inline">\(s_i\)</span>.</p>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Every directed edge <span class="math inline">\(x\mathord\to
y\)</span> is either in every shortest path tree <span
class="math inline">\(T_i\)</span>, in no shortest path tree <span
class="math inline">\(T_i\)</span>, or in an interval of shortest path
trees <span class="math inline">\(T_i, T_{i+1 \bmod h}, \dots, T_{i+j
\bmod h}\)</span></em>.
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(T\)</span> be the unique tree of
directed shortest paths <em>into</em> vertex <span
class="math inline">\(y\)</span>, and apply the disk-tree lemma to the
components of <span class="math inline">\(T - xy\)</span>. <span
class="math inline">\(\qquad\square\)</span>.
</dd>
</dl>
<p>It follows that we can encode all <span
class="math inline">\(k\)</span> shortest paths using only <span
class="math inline">\(O(n)\)</span> space, either by recording the first
and last trees <span class="math inline">\(T_i\)</span> that contain
each directed edge, or by recording the initial tree <span
class="math inline">\(T_1\)</span> followed by the differences <span
class="math inline">\(T_2\setminus T_1, T_3\setminus T_2\dots
T_h\setminus T_{h-1}\)</span>.</p>
<h2 data-number="15.4" id="parametric-shortest-paths"><span
class="header-section-number">15.4</span> Parametric Shortest Paths</h2>
<p><strong><em>[[Double- and triple-check directions for consistency:
Source vertex <span class="math inline">\(x\)</span> moves ccw around
boundary. Darts pivoting into <span
class="math inline">\(T_\lambda\)</span> point from new parent to child.
Dual dart <span class="math inline">\(d^*\)</span> is <span
class="math inline">\(\textsf{right}(d) \mathord\to
\textsf{left}(d)\)</span>. But left and right are reversed in the dual
plane!]]</em></strong></p>
<p>To solve the multiple-source shortest path problem, imagine moving
the source vertex <span class="math inline">\(s\)</span>
<em>continuously</em> around the outer face and maintaining the
shortest-path tree <span class="math inline">\(T_s\)</span> rooted at
<span class="math inline">\(s\)</span>. Although the shortest-path
<em>distances</em> vary continuously as <span
class="math inline">\(s\)</span> moves, the <em>structure</em> of the
shortest-path tree changes only at discrete events. (This approach is a
variant of the <em>parametric shortest-path</em> problem first proposed
by Karp and Orlin (1981).)</p>
<p>Now consider a single edge <span class="math inline">\(uv\)</span> on
the outer face. Suppose we have already computed the shortest-path tree
<span class="math inline">\(T_u\)</span> rooted at <span
class="math inline">\(u\)</span>, and we want to maintain the shortest
path tree <span class="math inline">\(T_s\)</span> as the source vertex
<span class="math inline">\(s\)</span> moves along <span
class="math inline">\(uv\)</span> from <span
class="math inline">\(u\)</span> to <span
class="math inline">\(v\)</span>. We insert <span
class="math inline">\(s\)</span> as a new vertex, partitioning <span
class="math inline">\(uv\)</span> into two edges <span
class="math inline">\(us\)</span> and <span
class="math inline">\(sv\)</span> with parametric weights <span
class="math display">\[
    w_\lambda(us) = \lambda \cdot w(uv)
    \qquad\text{and}\qquad
    w_\lambda(sv) = (1-\lambda) w(uv)
\]</span> Every other edge <span class="math inline">\(xy\)</span> has
constant parametric weight <span class="math inline">\(w_\lambda(xy) =
xy\)</span>. We then maintain the shortest-path tree <span
class="math inline">\(T_\lambda\)</span> rooted at <span
class="math inline">\(s\)</span>, with respect to the weight function
<span class="math inline">\(w_\lambda\)</span>, as the parameter <span
class="math inline">\(\lambda\)</span> increases continuously from <span
class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>. The initial shortest-path tree <span
class="math inline">\(T_0\)</span> is equal to <span
class="math inline">\(T_u\)</span>, and the final tree <span
class="math inline">\(T_1\)</span> is equal to <span
class="math inline">\(T_v\)</span>.</p>
<p>Fix a parameter value <span class="math inline">\(\lambda \in
[0,1]\)</span>. For any vertex <span class="math inline">\(x\)</span>,
let <span class="math inline">\(\textsf{dist}_\lambda(x)\)</span> denote
the shortest-path distance from <span class="math inline">\(s\)</span>
to <span class="math inline">\(x\)</span> with respect to the weight
function <span class="math inline">\(w_\lambda\)</span>. Similarly, for
any dart <span class="math inline">\(x\mathord\to y\)</span>, let <span
class="math display">\[
    \textsf{slack}_\lambda(x\mathord\to y) =
        \textsf{dist}_\lambda(x)
            + w_\lambda(x\mathord\to y)
            - \textsf{dist}_\lambda(y).
\]</span> Color each vertex <span class="math inline">\(x\)</span>
<em>red</em> if <span
class="math inline">\(\textsf{dist}_\lambda(x)\)</span> is an increasing
function of <span class="math inline">\(\lambda\)</span> (with
derivative <span class="math inline">\(1\)</span>), and <em>blue</em> if
<span class="math inline">\(\textsf{dist}_\lambda(x)\)</span> is an
decreasing function of <span class="math inline">\(\lambda\)</span>
(with derivative <span class="math inline">\(-1\)</span>). For generic
values of <span class="math inline">\(\lambda\)</span>, every vertex
except <span class="math inline">\(s\)</span> is either red or blue.
Finally, call a dart <span class="math inline">\(x\mathord\to y\)</span>
<em>active</em> if <span
class="math inline">\(\textsf{slack}_\lambda(x\mathord\to y)\)</span> is
a decreasing function of <span
class="math inline">\(\lambda\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>The following invariants hold for all <span
class="math inline">\(\lambda\in [0,1]\)</span>:</em>
</dd>
<dd>
<ol type="a">
<li><em>If <span class="math inline">\(s\mathord\to v \not\in
T_\lambda\)</span>, then every vertex except <span
class="math inline">\(s\)</span> is red, and the only active dart is
<span class="math inline">\(s\mathord\to v\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol type="a">
<li><em>If <span class="math inline">\(s\mathord\to u \not\in
T_\lambda\)</span>, then every vertex except <span
class="math inline">\(s\)</span> is blue, and there are no active
darts.</em></li>
</ol>
</dd>
<dd>
<ol type="a">
<li><em>Otherwise, every descendant of <span
class="math inline">\(u\)</span> is red, every descendant of <span
class="math inline">\(v\)</span> is blue, and <span
class="math inline">\(x\mathord\to y\)</span> is active if and only if
<span class="math inline">\(x\)</span> is blue and <span
class="math inline">\(y\)</span> is red.</em></li>
</ol>
</dd>
</dl>
<p>Without loss of generality, assume <span class="math inline">\(o =
\textsf{right}(u\mathord\to v)\)</span> is the outer face of <span
class="math inline">\(\Sigma\)</span>. Let <span class="math inline">\(p
= \textsf{left}(u\mathord\to v)\)</span> be the other face incident to
<span class="math inline">\(uv\)</span>. Let <span
class="math inline">\(C^*_\lambda = (E\setminus T_\lambda)^*\)</span>
denote the spanning tree of <span
class="math inline">\(\Sigma^*\)</span> complementary to <span
class="math inline">\(T_\lambda\)</span>. Finally, let <span
class="math inline">\(\pi_\lambda\)</span> denote the unique directed
path in <span class="math inline">\(C^*_\lambda\)</span> from <span
class="math inline">\(o^*\)</span> to <span
class="math inline">\(p^*\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>If <span class="math inline">\(T_\lambda\)</span> has both red and
blue vertices, then a dart is active if and only if its dual is in the
directed path <span class="math inline">\(\pi_\lambda\)</span>.</em>
</dd>
</dl>
<figure>
<img src="Fig/planar-shortest-pivot.png" style="width:75.0%"
alt="A single pivot in a planar shortest-path tree." />
<figcaption aria-hidden="true">A single pivot in a planar shortest-path
tree.</figcaption>
</figure>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>If <span class="math inline">\(T_\lambda\)</span> has both red and
blue vertices, the next dart to become tense (if any) is the dart with
minimum slack whose dual is in the directed path <span
class="math inline">\(\pi_\lambda\)</span>.</em>
</dd>
</dl>
<p>Thus, we can execute a single phase of the MSSP algorithm as follows.
Initially, we set <span class="math inline">\(s = u\)</span>. We
repeatedly find the tensest active dart <span class="math inline">\(d =
x\mathord\to y\)</span>, move <span class="math inline">\(s\)</span>
distance <span class="math inline">\(\textsf{slack}(d)/2\)</span> along
<span class="math inline">\(uv\)</span>, increase all red distances and
decrease all blue distances by <span
class="math inline">\(\textsf{slack}(d)/2\)</span>, decrease the slacks
of all active darts and increase the slacks of their reversals by <span
class="math inline">\(\textsf{slack}(d)\)</span>, and finally pivot
<span class="math inline">\(d\)</span> into the tree by assigning <span
class="math inline">\(\textsf{pred}(y) \gets x\)</span>. The loop ends
either when there are no more active darts, or when the source vertex
<span class="math inline">\(s\)</span> reaches <span
class="math inline">\(v\)</span>.</p>
<p>Each pivot changes at least one node <span
class="math inline">\(y\)</span> from red to blue, and no pivot changes
any node from blue to red. Thus, once a dart is pivoted into the
shortest-path tree, it is not pivoted out during that phase. Thus, the
darts that are pivoted into the tree are precisely the darts in <span
class="math inline">\(T_v \setminus T_u\)</span>. The disk-tree lemma
now immediately implies that the <em>total</em> number of pivots over
all phases is only linear.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>The MSSP algorithm performs a total of <span
class="math inline">\(O(n)\)</span> pivots.</em>
</dd>
</dl>
<h2 data-number="15.5" id="dynamic-forest-data-structures"><span
class="header-section-number">15.5</span> Dynamic Forest Data
Structures</h2>
<p>To achieve a running time of <span class="math inline">\(O(n\log
n)\)</span>, we need to perform each pivot quickly. We maintain both the
shortest-path tree <span class="math inline">\(T_\lambda\)</span> and
the complementary dual spanning tree <span
class="math inline">\(C^*_\lambda\)</span> in data <em>dynamic
forest</em> data structures that implicitly maintain dart values
(slacks) or vertex values (distances) under edge insertions, edge
deletions, and updates to the values in certain substructures.</p>
<p>We maintain the shortest path tree <span
class="math inline">\(T_\lambda\)</span> as a directed tree rooted at
<span class="math inline">\(s\)</span>, with <span
class="math inline">\(\textsf{dist}\)</span> values associated with each
vertex, in a data structure that supports the following operations:</p>
<ul>
<li><p><span class="math inline">\(\textsf{Cut}(x\mathord\to
y)\)</span>: Remove the edge <span class="math inline">\(x\mathord\to
y\)</span> from <span class="math inline">\(T_\lambda\)</span>, breaking
it into two rooted trees. The component containing <span
class="math inline">\(x\)</span> is still rooted at <span
class="math inline">\(s\)</span>; the other component is rooted at <span
class="math inline">\(y\)</span>.</p></li>
<li><p><span class="math inline">\(\textsf{Link}(x, y)\)</span>: Add a
directed edge from <span class="math inline">\(x\)</span> to <span
class="math inline">\(y\)</span>. This operation assumes that <span
class="math inline">\(y\)</span> a root. We always call <span
class="math inline">\(\textsf{Link}\)</span> immediately after <span
class="math inline">\(\textsf{Cut}\)</span> so that <span
class="math inline">\(T_\lambda\)</span> remains a single spanning
tree.</p></li>
<li><p><span class="math inline">\(\textsf{GetDist}(x)\)</span>: Return
the distance value associated with vertex <span
class="math inline">\(x\)</span>.</p></li>
<li><p><span class="math inline">\(\textsf{AddSubtreeDist}(x)\)</span>:
For every descendant <span class="math inline">\(y\)</span> of <span
class="math inline">\(x\)</span>, add <span
class="math inline">\(\Delta\)</span> to <span
class="math inline">\(\textsf{dist}(y)\)</span>.</p></li>
</ul>
<p>Similarly, we maintain the complementary dual spanning tree <span
class="math inline">\(C^*_\lambda\)</span> as an undirected unrooted
tree, with <span class="math inline">\(\textsf{slack}\)</span> values
associated with every dart, in a data structure that supports the
following operations.</p>
<ul>
<li><p><span class="math inline">\(\textsf{Cut}(xy)\)</span>: Remove the
edge <span class="math inline">\(xy\)</span> from <span
class="math inline">\(C^*_\lambda\)</span>, breaking it into two
trees.</p></li>
<li><p><span class="math inline">\(\textsf{Link}(x, y, \alpha,
\beta)\)</span>: Add the edge <span class="math inline">\(xy\)</span>
and assign <span class="math inline">\(\textsf{slack}(x\mathord\to y) =
\alpha\)</span> and <span
class="math inline">\(\textsf{slack}(y\mathord\to x) = \beta\)</span>.
We always call <span class="math inline">\(\textsf{Link}\)</span>
immediately after <span class="math inline">\(\textsf{Cut}\)</span> so
that <span class="math inline">\(C^*_\lambda\)</span> remains a single
dual spanning tree.</p></li>
<li><p><span class="math inline">\(\textsf{GetSlack}(x\mathord\to
y)\)</span>: Return the slack value associated with dart <span
class="math inline">\(x\mathord\to y\)</span>.</p></li>
<li><p><span class="math inline">\(\textsf{MinPathSlack}(\Delta, x,
y)\)</span>: Return the <span class="math inline">\(d\)</span> on the
directed path from <span class="math inline">\(x\)</span> to <span
class="math inline">\(y\)</span> such that <span
class="math inline">\(\textsf{slack}(d)\)</span> is minimized.</p></li>
<li><p><span class="math inline">\(\textsf{AddPathSlack}(\Delta, x,
y)\)</span>: For each dart <span class="math inline">\(d\)</span> on the
directed path from <span class="math inline">\(x\)</span> to <span
class="math inline">\(y\)</span>, add <span
class="math inline">\(\Delta\)</span> to <span
class="math inline">\(\textsf{slack}(d)\)</span> and subtract <span
class="math inline">\(\Delta\)</span> from <span
class="math inline">\(\textsf{slack}(\textsf{rev}(d))\)</span>.</p></li>
</ul>
<p>There are several dynamic-forest data structures that support the
operations we need in <span class="math inline">\(O(\log n)\)</span>
amortized time each; my favorite is Tarjan and Werneck’s
<em>self-adjusting top tree</em>. (Most of the others also have Tarjan’s
name on them.) A description of self-adjusting top trees (or the
<em>splay trees</em> they use under the hood) is unfortunately beyond
the scope of this note (or this course).</p>
<h2 data-number="15.6" id="the-pivoting-algorithm"><span
class="header-section-number">15.6</span> The Pivoting Algorithm</h2>
<p>With these data structures in hand, we can identify the tensest
active dart and perform the necessary updates to pivot it into <span
class="math inline">\(T_\lambda\)</span> in <span
class="math inline">\(O(\log n)\)</span> amortised time. The following
figure shows the algorithm to perform the next pivot, with all data
structure operations in place.</p>
<figure>
<img src="Fig/MSSP-pseudocode.png" style="width:80.0%"
alt="The MSSP pivoting algorithm." />
<figcaption aria-hidden="true">The MSSP pivoting algorithm.</figcaption>
</figure>
<p>As we already argued, the total number of pivots is <span
class="math inline">\(O(n)\)</span>, so the overall MSSP algorithm runs
in <span class="math inline">\(O(n\log n)\)</span> time, as claimed.</p>
<h2 data-number="15.7" id="applications"><span
class="header-section-number">15.7</span> Applications</h2>
<p>Computing all <span class="math inline">\(k^2\)</span>
boundary-to-boundary distances <span class="math inline">\(O((n +
k^2)\log n)\)</span> time is straightforward.</p>
<p><strong><em>[[More detail. Reduce time to <span
class="math inline">\(\boldsymbol{O(n\log n + k^2)}\)</span>. Say
anything at all about persistence?]]</em></strong></p>
<h2 data-number="15.8" id="enforcing-unique-shortest-paths"><span
class="header-section-number">15.8</span> Enforcing Unique Shortest
Paths</h2>
<p>So far our presentation has assumed that there is a <em>unique</em>
shortest path between any two vertices of <span
class="math inline">\(\Sigma\)</span>; in particular, for any source
vertex <span class="math inline">\(s\)</span>, there is a
<em>unique</em> shortest-path tree <span
class="math inline">\(T_s\)</span>. More subtly, we have also assumes
that there is always a unique tensest active dart. These assumption
obviously do not hold in general, but we can enforce them if necessary
using any of several standard <em>perturbation</em> techniques. I’ll
describe two such techniques here, but there are other
possibilities.</p>
<p>Standard perturbation methods either explicitly or implicitly define
a secondary weight <span class="math inline">\(w’(u\mathord\to
v)\)</span> for each each dart <span class="math inline">\(u\mathord\to
v\)</span> in <span class="math inline">\(\Sigma\)</span>. The
<em>perturbed weight</em> of a dart <span
class="math inline">\(d\)</span> is then defined as <span
class="math display">\[  
    \tilde{w}(d) :=
        w(d) + w’(d)\cdot \varepsilon
\]</span> for some sufficiently small real number <span
class="math inline">\(\varepsilon&gt;0\)</span>. Rather than computing a
particular value of <span class="math inline">\(\varepsilon\)</span>, we
consider the limiting behavior as <span
class="math inline">\(\varepsilon\)</span> approaches zero. Thus, we can
consider each perturbed weight <span
class="math inline">\(\tilde{w}(d)\)</span> to be an ordered pair or
vector <span class="math display">\[
    \tilde{w}(d) := ( w(d), w’(d) ).
\]</span> We compute lengths of paths by summing these vectors normally,
but we compare path lengths <em>lexicographically</em>. That is, we
consider one path <span class="math inline">\(\pi\)</span> to be shorter
than another path <span class="math inline">\(\pi’\)</span> if either of
the following conditions holds:</p>
<ol type="a">
<li><span class="math inline">\(w(\pi) &lt; w(\pi’)\)</span></li>
<li><span class="math inline">\(w(\pi) = w(\pi’)\)</span> and <span
class="math inline">\(w’(\pi) &lt; w’(\pi’)\)</span></li>
</ol>
<h3 data-number="15.8.1" id="random-perturbation"><span
class="header-section-number">15.8.1</span> Random Perturbation</h3>
<p>The simplest perturbation method chooses <em>random</em> secondary
weights for each edge. For example, if we choose each secondary weight
<span class="math inline">\(w’(e)\)</span> uniformly at random from the
real interval <span class="math inline">\([0,1]\)</span>, then the
lengths of all simple paths (indeed, the lengths of all finite walks)
are distinct with probability <span
class="math inline">\(1\)</span>.</p>
<p>Somewhat more realistically, the following lemma implies that we can
choose small random <em>integers</em> for the secondary weights.</p>
<p><strong>Isolation Lemma (Mulmuley, Vazirani, and Vazirani
1987):</strong> <em>Let <span class="math inline">\(\mathcal{F}\)</span>
be any family of subsets of <span class="math inline">\([n]\)</span>.
For each index <span class="math inline">\(i\in [n]\)</span>, let <span
class="math inline">\(w’(i)\)</span> be chosen independently and
uniformly at random from <span class="math inline">\([N]\)</span>.
Define the weight <span class="math inline">\(w’(S)\)</span> of any
subset <span class="math inline">\(S\subseteq[n]\)</span> as <span
class="math inline">\(w’(S) = \sum_{i\in S} w’(i)\)</span>. With
probability at least <span class="math inline">\(1-n/N\)</span>, the
minimum-weight set in <span class="math inline">\(\mathcal{F}\)</span>
is unique.</em></p>
<p><strong><em>[[Include the proof, which is relatively
straightforward]]</em></strong></p>
<p><strong>Corollary:</strong> <em>If each perturbation weight <span
class="math inline">\(w’(e)\)</span> is chosen independently and
uniformly at random from <span class="math inline">\([n^4]\)</span>,
then with probability <span class="math inline">\(1 - 1/O(n)\)</span>,
all shortest paths with respect to the perturbed weight function <span
class="math inline">\((w, w’)\)</span> are unique.</em></p>
<p>Let me emphasize that the Isolation Lemma <em>only</em> implies that
<em>shortest</em> paths are distinct; other pairs of paths may still
have equal length, even after perturbation.</p>
<p><strong><em>[[We also need unique tensest darts!!]]</em></strong></p>
<h3 data-number="15.8.2" id="cotree-perturbation"><span
class="header-section-number">15.8.2</span> Cotree Perturbation</h3>
<p>Let <span class="math inline">\(T\sqcup C\)</span> be a tree-cotree
decomposition of <span class="math inline">\(\Sigma\)</span>. Root the
dual spanning tree <span class="math inline">\(C^*\)</span> at the dual
of the outer face <span class="math inline">\(o^*\)</span>, and direct
all edges of <span class="math inline">\(C^*\)</span> away from the
root. We define the weight <span class="math inline">\(w’(d)\)</span> of
each dart <span class="math inline">\(d\)</span> of <span
class="math inline">\(\Sigma\)</span> as follows:</p>
<ul>
<li>If <span class="math inline">\(d^*\in C^*\)</span>, let <span
class="math inline">\(w’(d)\)</span> be the number of descendants of
<span class="math inline">\(\textsf{head}(d^*) =
\textsf{left}(d)^*\)</span> in <span
class="math inline">\(C^*\)</span>.</li>
<li>If <span class="math inline">\(\textsf{rev}(d^*)\in C^*\)</span>,
let <span class="math inline">\(w’(d) =
-w’(\textsf{rev}(d))\)</span>.</li>
<li>Otherwise, let <span class="math inline">\(w’(d) = 0\)</span>.</li>
</ul>
<p>Equivalently, for any dart <span class="math inline">\(d\not\in
T\)</span>, let <span class="math inline">\(\textsf{cycle}_T(d)\)</span>
be the unique directed cycle in <span class="math inline">\(T +
d\)</span>. Then <span class="math inline">\(w’(d)\)</span> is the
number of faces of <span class="math inline">\(\Sigma\)</span> inside
<span class="math inline">\(\textsf{cycle}_T(d)\)</span> if that cycle
is oriented counterclockwise, the negation of the number of interior
cycles if the cycle is clockwise, and zero if <span
class="math inline">\(d\)</span> is in <span
class="math inline">\(T\)</span>.</p>
<dl>
<dt><strong>Winding Lemma:</strong></dt>
<dd>
<em>For any closed walk <span class="math inline">\(W\)</span> in <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math inline">\(\sum_{d\in W} w’(d) = \sum_{f\in F}
\textsf{wind}(W, f)\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
This is essentially the shoelace algorithm. We can compute the winding
number of <span class="math inline">\(W\)</span> around <span
class="math inline">\(f\)</span> by traversing the path in <span
class="math inline">\(C^*\)</span> from <span
class="math inline">\(f^*\)</span> to <span
class="math inline">\(o^*\)</span> and counting crossings. We can write
<span class="math inline">\(W\)</span> as the sum of the fundamental
directed cycles determined by the non-tree edges of <span
class="math inline">\(W\)</span>.
<strong><em>[[Incomplete]]</em></strong>
</dd>
</dl>
<p>The previous lemma implies that although the secondary weights <span
class="math inline">\(w’\)</span> depend on the choice of tree-cotree
decomposition, the resulting shortest paths do not!</p>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>For any two paths <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> with the same endpoints, and any two
spanning trees <span class="math inline">\(T\)</span> and <span
class="math inline">\(T’\)</span>, we have <span
class="math inline">\(w’_T(\pi) &lt; w’_T(\pi’)\)</span> if and only if
<span class="math inline">\(w’_{T’}(\pi) &lt; w’_{T’}(\pi’)\)</span>.
Thus, shortest paths with respect to <span
class="math inline">\(w’_T\)</span> and <span
class="math inline">\(w’_{T’}\)</span> coincide.</em>
</dd>
</dl>
<p><strong><em>[[Figure!]]</em></strong></p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Cotree perturbation makes shortest paths unique.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> be two shortest paths from some
vertex <span class="math inline">\(s\)</span> to some other vertex <span
class="math inline">\(t\)</span>. By definition, we have <span
class="math inline">\(w(\pi) = w(\pi’)\)</span> and <span
class="math inline">\(w’(\pi) = w’(\pi’)\)</span>. The latter condition
implies that <span class="math inline">\(\sum_{f\in F}
\textsf{wind}(\pi-\pi’, f) = 0\)</span>. There are two cases to
consider.
</dd>
<dd>
<p>First, suppose <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> do not cross. Then the closed walk
<span class="math inline">\(\pi - \pi’\)</span> is a weakly simple
closed curve, which implies that the non-zero winding numbers <span
class="math inline">\(\textsf{wind}(\pi-\pi’, f)\)</span> are either all
<span class="math inline">\(1\)</span> or all <span
class="math inline">\(-1\)</span>. It follows that <span
class="math inline">\(\textsf{wind}(\pi-\pi’, f) = 0\)</span> for
<em>every</em> face <span class="math inline">\(f\)</span>, which is
only possible if <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> use the same subset of edges. In
other words, <span class="math inline">\(\pi = \pi’\)</span>.</p>
</dd>
<dd>
<p>Now suppose <span class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> cross at some vertex <span
class="math inline">\(x\)</span>. The prefixes <span
class="math inline">\(\alpha = \pi[s, x]\)</span> and <span
class="math inline">\(\alpha’ = \pi’[s, x]\)</span> must be shortest
paths, otherwise we could shorten one of <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span>. Similarly, the suffixes <span
class="math inline">\(\beta = \pi[x,t]\)</span> and <span
class="math inline">\(\beta’ = \pi’[x,t]\)</span> must be shortest
paths. The inductive hypothesis now implies that <span
class="math inline">\(\alpha = \alpha’\)</span> and <span
class="math inline">\(\beta = \beta’\)</span>. Again, we conclude that
<span class="math inline">\(\pi = \pi’\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong><em>[[We also need unique tensest darts!!]]</em></strong></p>
<h2 data-number="15.9" id="leftmost-shortest-paths"><span
class="header-section-number">15.9</span> Leftmost shortest paths</h2>
<p>In fact, we can implement cotree perturbation without explicit
secondary weights. Suppose <span class="math inline">\(\pi\)</span> and
<span class="math inline">\(\pi’\)</span> are two paths with the same
endpoints. We say that <span class="math inline">\(\pi\)</span> is
<em>to the left</em> of <span class="math inline">\(\pi’\)</span> if the
closed walk <span class="math inline">\(\pi-\pi’\)</span> winds
negatively (clockwise) around at least one face, but does not wind
positively (counterclockwise) around any face. If <span
class="math inline">\(\pi\)</span> is to the left of <span
class="math inline">\(\pi’\)</span>, we immediately have <span
class="math inline">\(w’(\pi) &lt; w’(\pi’)\)</span>.</p>
<p>It is not hard to show that for any two paths <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(\pi’\)</span> with the same endpoints, either one
path is the left of the other, or a third path is to the left of both of
them. Thus, shortest paths with respect to cotree perturbation are
always <em>leftmost</em> shortest paths.</p>
<p>We can simulate cotree perturbation by always breaking ties to the
left. In the MSSP algorithm, we always pivot the <em>leafmost</em>
tensest active dart.</p>
<p><strong><em>[[Need more details here]]</em></strong></p>
<h3 data-number="15.9.1" id="caveat-emptor"><span
class="header-section-number">15.9.1</span> Caveat Emptor!</h3>
<p>Cotree perturbation is attractive both because it is deterministic
and because it can often be implemented implicitly, but its asymmetry
can be a disadvantage. Unless shortest paths are already unique, cotree
perturbation yields shortest paths that are not symmetric, even when the
original graph is undirected. The reversal of the <em>leftmost</em>
shortest path from <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> is the <em>rightmost</em> shortest path
from <span class="math inline">\(t\)</span> to <span
class="math inline">\(u\)</span>. Thus, algorithms that rely on the
usual behavior of undirected shortest paths cannot automatically use
this technique.</p>
<p>As a simple example, consider the <em>non-crossing</em> shortest
paths problem. Given an undirected planar map <span
class="math inline">\(\Sigma\)</span> with weighted edges and several
pairs of vertices <span class="math inline">\((s_1, t_1), \dots, (s_k,
t_k)\)</span> on the outer face, we want to compute shortest paths
between each pair <span class="math inline">\(s_i\)</span> and <span
class="math inline">\(t_i\)</span> that are pairwise non-crossing. If
shortest paths in <span class="math inline">\(\Sigma\)</span> are
already unique, then it suffices to independently compute the shortest
path in <span class="math inline">\(\Sigma\)</span> from <span
class="math inline">\(s_i\)</span> to <span
class="math inline">\(t_i\)</span> for each index <span
class="math inline">\(i\)</span>. But suppose the terminals appear in
order <span class="math inline">\(s_1, t_1, s_2, t_2\)</span> on the
outer face, and we use cotree perturbation to <em>enforce</em>
uniqueness. Then the shortest path from <span
class="math inline">\(s_1\)</span> to <span
class="math inline">\(t_1\)</span> might cross the shortest path from
<span class="math inline">\(s_2\)</span> to <span
class="math inline">\(t_2\)</span>.</p>
<figure>
<img src="Fig/crossing-leftmost-paths.png" style="width:30.0%"
alt="Leftmost shortest paths in undirected planar graphs can cross" />
<figcaption aria-hidden="true">Leftmost shortest paths in undirected
planar graphs can cross</figcaption>
</figure>
<h2 data-number="15.10" id="references-8"><span
class="header-section-number">15.10</span> References</h2>
<ol type="1">
<li><p>Sergio Cabello and Erin W. Chambers. <a
href="https://dl.acm.org/doi/10.5555/1283383.1283394">Multiple source
shortest paths in a genus <span class="math inline">\(g\)</span>
graph</a>. <em>Proc. 18th Ann. ACM-SIAM Symp. Discrete Algorithms</em>,
89–97, 2007.</p></li>
<li><p>Sergio Cabello, Erin W. Chambers, and Jeff Erickson. <a
href="https://doi.org/10.1137/12086427">Multiple-source shortest paths
in embedded graphs</a>. <em>SIAM J. Comput.</em> 42(4):1542–1571, 2013.
arXiv:1202.0314.</p></li>
<li><p>David Eisenstat and Philip N. Klein. <a
href="http://doi.org/10.1145/2488608.2488702">Linear-time algorithms for
maxflow and multiple-source shortest paths in unit-weight planar
graphs</a>. <em>Proc. 45th Ann. ACM Symp. Theory Comput.</em>, 735–744,
2013.</p></li>
<li><p>Lester R. Ford. <a
href="http://www.rand.org/pubs/papers/P923.html">Network flow
theory</a>. Paper P-923, The RAND Corporation, Santa Monica, California,
August 14, 1956.</p></li>
<li><p>Richard M. Karp and James B. Orlin. <a
href="https://doi.org/10.1016/0166-218X(81)90026-3">Parametric shortest
path algorithms with an application to cyclic staffing</a>. <em>Discrete
Appl. Math.</em> 3:37–45, 1981.</p></li>
<li><p>Philip N. Klein. <a
href="https://dl.acm.org/doi/abs/10.5555/1070432.1070454">Multiple-source
shortest paths in planar graphs</a>. <em>Proc. 16th Ann. ACM-SIAM Symp.
Discrete Algorithms</em>, 146–155, 2005.</p></li>
<li><p>Yaowei Long and Seth Pettie. <a
href="http://doi.org/10.1137/1.9781611976465.149">Planar distance
oracles with better time-space tradeoffs</a>. <em>Proc. 32nd Ann.
ACM-SIAM Symp. Discrete Algorithms</em>, 2517–2537, 2021. arXiv:<a
href="https://arxiv.org/abs/2007.08585">2007.08585</a>.</p></li>
<li><p>Ketan Mulmuley, Umesh Vazirani, and Vijay Vazirani. <a
href="https://doi.org/10.1007/BF02579206">Matching is as easy as matrix
inversion</a>. <em>Combinatorica</em> 7:105–113, 1987.</p></li>
<li><p>Robert E. Tarjan and Renato F. Werneck. <a
href="https://dl.acm.org/doi/10.5555/1070432.1070547">Self-adjusting top
trees</a>. <em>Proc. 16th Ann. ACM-SIAM Symp. Discrete Algorithms</em>,
813–822, 2005.</p></li>
</ol>
<h2 data-number="15.11" id="sir-not-appearing"><span
class="header-section-number">15.11</span> Sir not appearing</h2>
<ul>
<li>Subtleties for directed graphs and/or graphs with negative edge
lengths.</li>
<li>Post-hoc distance and path queries via persistence</li>
<li>Klein’s leafmost pivot strategy</li>
<li>Unweighted MSSP in linear time [Eisenstat Klein]</li>
<li><span class="math inline">\(\Omega(n\log n)\)</span> lower bound
[Eisenstat Klein]</li>
<li>Space-time tradeoff for Klein’s algorithm (but <em>not</em> CCE)
using different dynamic-forest data structures: <span
class="math inline">\(O(kn^{1+1/k})\)</span> preprocessing time and
<span class="math inline">\(O(k\log\log n)\)</span> query time. [Long
Pettie 2021]</li>
</ul>
<h1 data-number="16"
id="multiple-source-shortest-paths-revisitedalpha"><span
class="header-section-number">16</span> Multiple-Source Shortest Paths,
Revisited<span class="math inline">\(^\alpha\)</span></h1>
<p>In a recent breakthrough, Das, Kipouridis, Probst Gutenberg, and
Wulff-Nilsen described an alternative algorithm that solves the planar
multiple-source shortest path problem using a relatively simple
divide-and-conquer strategy. Their algorithm theoretically runs in <span
class="math inline">\(O(n\log h)\)</span> time, where <span
class="math inline">\(h\)</span> is the number of vertices on the outer
face, which improves the <span class="math inline">\(O(n\log n)\)</span>
time of Klein’s algorithm when <span class="math inline">\(h\)</span> is
small. Moreover, this running time is worst-case optimal as a function
of both <span class="math inline">\(n\)</span> and <span
class="math inline">\(h\)</span>.</p>
<p>A better expression for the running time is <span
class="math inline">\(O(S(n)\log h)\)</span>, where <span
class="math inline">\(S(n)\)</span> is the time to compute a
single-source shortest path tree.</p>
<ul>
<li>If we use Dijkstra’s algorithm off the shelf, the running time is
<span class="math inline">\(O(n\log n \log h)\)</span>.</li>
<li>If we use the <span class="math inline">\(O(n\log\log
n)\)</span>-time algorithm that we will see in Lecture 15,<a
href="#fn38" class="footnote-ref" id="fnref38"
role="doc-noteref"><sup>38</sup></a> the running time is <span
class="math inline">\(O(n\log h\log\log n)\)</span>.</li>
<li>If we use the <span class="math inline">\(O(n)\)</span>-time
algorithm of Henzinger et al.,<a href="#fn39" class="footnote-ref"
id="fnref39" role="doc-noteref"><sup>39</sup></a> the running time is
the optimal <span class="math inline">\(O(n\log h)\)</span>.</li>
</ul>
<p>The new algorithm is simpler in the sense that it uses only black-box
shortest-path algorithms, completely avoiding complex dynamic forest
data structures that are inefficient in practice, at least for small
graphs.<a href="#fn40" class="footnote-ref" id="fnref40"
role="doc-noteref"><sup>40</sup></a> On the other hand, the new
algorithm requires a subtle divide-and-conquer algorithm with weighted
<span class="math inline">\(r\)</span>-divisions, which is <em>also</em>
inefficient in practice, to achieve its best possible running time <span
class="math inline">\(O(n\log h)\)</span>. On the gripping hand, Klein’s
algorithm has been observed to require a sublinear number of pivots for
many inputs, so the <span class="math inline">\(O(n\log n)\)</span> time
bound, while tight in the worst case, is usually conservative; whereas,
the <span class="math inline">\(O(n\log h)\)</span> time bound for the
new algorithm is tight for <em>all</em> inputs. It would be interesting
to experimentally compare Klein (or CCE) using linear-time dynamic trees
against the new algorithm using Dijkstra as a black box.</p>
<h2 data-number="16.1" id="problem-formulation"><span
class="header-section-number">16.1</span> Problem formulation</h2>
<p>It will be convenient to describe the inputs and outputs of the MSSP
problem slightly differently than in the previous lecture.</p>
<p>The input consists primarily of a <em>directed</em> planar map <span
class="math inline">\(\Sigma = (V, E, F)\)</span> with a distinguished
outer face <span class="math inline">\(o\)</span> and a non-negative
weight <span class="math inline">\(\ell(u\mathord\to v)\)</span> for
every directed edge/dart <span class="math inline">\(u\mathord\to
v\)</span>, which could be infinite (to indicate that a directed edge is
missing from the graph). The weights are not necessarily symmetric; we
allow <span class="math inline">\(\ell(u\mathord\to v) \ne
\ell(v\mathord\to u)\)</span>.</p>
<p>Let <span class="math inline">\(s_0, s_1, \dots, s_{h-1}\)</span> be
any subsequence of <span class="math inline">\(h\)</span> vertices in
counterclockwise order around the outer face, and let <span
class="math inline">\(S = \{s_0, s_1, \dots, s_{h-1}\}\)</span>. Our
goal is to compute an implicit representation of the shortest paths from
each source <span class="math inline">\(s_i\)</span> to every original
vertex of <span class="math inline">\(\Sigma\)</span>. See Figure 1.</p>
<p>For ease of presentation, I will make a few minor technical
assumptions:</p>
<ul>
<li>Every source vertex <span class="math inline">\(s_i\in S\)</span>
has out-degree <span class="math inline">\(1\)</span> and in-degree
<span class="math inline">\(0\)</span>. We can enforce this assumption
if necessary by adding a new artificial source vertex <span
class="math inline">\(s&#39;_i\)</span> and a single directed edge <span
class="math inline">\(s&#39;_i \mathord\to s_i\)</span> with weight
<span class="math inline">\(0\)</span>.</li>
<li><span class="math inline">\(\Sigma\)</span> is simple. We can
enforce this condition if necessary by resolving parallel edges and
deleting loops in <span class="math inline">\(O(n)\)</span> time using
hashing.<a href="#fn41" class="footnote-ref" id="fnref41"
role="doc-noteref"><sup>41</sup></a></li>
<li>The graph of <span class="math inline">\(\Sigma \setminus S\)</span>
is strongly connected. Thus, the shortest path tree rooted at each
source vertex <span class="math inline">\(s_i\)</span> includes every
non-source vertex. We can enforce this assumption if necessary by adding
new infinite-weight edges.</li>
<li>All shortest paths are unique. If necessary, we can enforce this
assumption either by randomly perturbing the edge weights or by choosing
leftmost shortest paths, just as in the previous lecture.</li>
</ul>
<figure>
<img src="Fig/planar-mssp-setup.png" style="width:30.0%"
alt="Setup for the recursive MSSP algorithm." />
<figcaption aria-hidden="true">Setup for the recursive MSSP
algorithm.</figcaption>
</figure>
<p>For any index <span class="math inline">\(j\)</span> and any vertex
<span class="math inline">\(v\)</span>, let <span
class="math inline">\(\mathit{path}_j(v)\)</span> denote the shortest
path in <span class="math inline">\(\Sigma\)</span> from <span
class="math inline">\(s_j\)</span> to <span
class="math inline">\(v\)</span>, let <span
class="math inline">\(\mathit{dist}_j(v)\)</span> denote the length of
this shortest path, and let <span
class="math inline">\(\mathit{pred}_j(v)\)</span> denote the predecessor
of <span class="math inline">\(v\)</span> in this shortest path.</p>
<p>The main recursive algorithm <span
class="math inline">\(\textsf{MSSP-Prep}\)</span> preprocesses the map
<span class="math inline">\(\Sigma\)</span> into a data structure that
implicitly encodes the single-source shortest path trees rooted at every
source <span class="math inline">\(s_j\)</span>. A separate query
algorithm <span class="math inline">\(\textsf{MSSP-Query}(s_j,
v)\)</span> returns <span
class="math inline">\(\mathit{dist}_j(v)\)</span>.</p>
<h2 data-number="16.2" id="overview"><span
class="header-section-number">16.2</span> Overview</h2>
<p>The preprocessing algorithm uses a divide-and conquer-strategy. The
input to each recursive call <span
class="math inline">\(\textsf{MSSP-Prep}(H, i, k)\)</span> consists of
the following:</p>
<ul>
<li>A planar map <span class="math inline">\(H\)</span>, which is a
simple weighted minor of the top-level input map <span
class="math inline">\(\Sigma\)</span>.</li>
<li>Two indices <span class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span>. To simplify presentation, we
implicitly assume that <span class="math inline">\(s_i, s_{i+1}, \dots,
s_k\)</span> are the only source vertices in <span
class="math inline">\(H\)</span>.</li>
</ul>
<p>For each index <span class="math inline">\(j\)</span>, let <span
class="math inline">\(T_j\)</span> denote the tree of shortest paths in
<span class="math inline">\(H\)</span> from <span
class="math inline">\(s_j\)</span> to every other vertex of <span
class="math inline">\(H\)</span>. The recursive call <span
class="math inline">\(\textsf{MSSP-Prep}(H, i, k)\)</span> computes an
implicit representation of all <span
class="math inline">\(k-i+1\)</span> shortest path trees <span
class="math inline">\(T_1, T_{i+1}, \dots, T_k\)</span>. The top-level
call is <span class="math inline">\(\textsf{MSSP-Prep}(\Sigma, 0,
h-1)\)</span>.</p>
<p><span class="math inline">\(\textsf{MSSP-Prep}\)</span> invokes a
subroutine <span class="math inline">\(\textsf{Filter}(H, i, k)\)</span>
that behaves as follows:</p>
<ul>
<li>Compute the shortest path trees <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span> rooted at <span
class="math inline">\(s_i\)</span> and <span
class="math inline">\(s_k\)</span>.</li>
<li>Identify directed edges that are shared by all shortest path trees
<span class="math inline">\(T_j\)</span> with <span
class="math inline">\(i\le j\le k\)</span>.</li>
<li>Contract shared edges and update nearby weights to maintain shortest
path distances.</li>
<li>Return the resulting contracted planar map.</li>
</ul>
<p>Finally, ignoring base cases for now, <span
class="math inline">\(\textsf{MSSP-Prep}(H,i,k)\)</span> has four
steps:</p>
<ul>
<li>Set <span class="math inline">\(H’ \gets \textsf{Filter}(H, i,
k)\)</span>.</li>
<li>Set <span class="math inline">\(j \gets \lfloor (i+k)/2
\rfloor\)</span>.</li>
<li>Recursively call <span class="math inline">\(\textsf{MSSP-Prep}(H’,
i, j)\)</span>.</li>
<li>Recursively call <span class="math inline">\(\textsf{MSSP-Prep}(H’,
j, k)\)</span>.</li>
</ul>
<p>Finally, <span
class="math inline">\(\textsf{MSSP-Prep}(H,i,k)\)</span> returns a
record storing the following information:</p>
<ul>
<li>the indices <span class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span></li>
<li>data about each vertex in <span class="math inline">\(H\)</span>
computed by <span class="math inline">\(\textsf{Filter}\)</span></li>
<li>pointers to the records returned by the recursive calls</li>
</ul>
<p>Said differently, <span
class="math inline">\(\textsf{MSSP-Prep}\)</span> returns a data
structure that mirrors its binary recursion tree; every record in this
data structure stores information computed by one invocation of <span
class="math inline">\(\textsf{Filter}\)</span>.</p>
<p>The time and space analysis of <span
class="math inline">\(\textsf{MSSP-Prep}\)</span> hinges on the
observation that the total size of all minors <span
class="math inline">\(H\)</span> at each level of the resulting
recursion tree is only <span class="math inline">\(O(n)\)</span>. The
depth of the recursion tree is <span class="math inline">\(O(\log
h)\)</span>, so the total size of the data structure is <span
class="math inline">\(O(n\log h)\)</span>. Similarly, aside from
recursive calls, the time for each subproblem with <span
class="math inline">\(m\)</span> vertices is <span
class="math inline">\(O(S(m))\)</span>, so the overall running time is
<span class="math inline">\(O(S(n)\log h)\)</span>.</p>
<p>Finally, the query algorithm recovers the shortest-path distance from
any source <span class="math inline">\(s_j\)</span> to any vertex <span
class="math inline">\(v\)</span> by traversing the recursion tree of
<span class="math inline">\(\textsf{MSSP-Prep}\)</span> in <span
class="math inline">\(O(\log h)\)</span> time.</p>
<p>In the rest of this note, I’ll consider each of the component
algorithms in more detail.</p>
<h2 data-number="16.3" id="properly-shared-edges"><span
class="header-section-number">16.3</span> Properly shared edges</h2>
<p>Now I’ll describe the filtering algorithm <span
class="math inline">\(\textsf{Filter}(H, i, k)\)</span> in more detail.
For any index <span class="math inline">\(j\)</span> and any vertex
<span class="math inline">\(v\)</span>, define the following:</p>
<ul>
<li><span class="math inline">\(T_j\)</span> is the shortest-path tree
in <span class="math inline">\(H\)</span> rooted at source vertex <span
class="math inline">\(s_j\)</span>.</li>
<li><span class="math inline">\(\mathit{dist}_j(v)\)</span> is the
shortest-path distance in <span class="math inline">\(H\)</span> from
<span class="math inline">\(s_j\)</span> to <span
class="math inline">\(v\)</span>.</li>
<li><span class="math inline">\(\mathit{pred}_j(v)\)</span> is the
predecessor of <span class="math inline">\(v\)</span> on the shortest
path in <span class="math inline">\(H\)</span> from <span
class="math inline">\(s_j\)</span> to <span
class="math inline">\(v\)</span>.</li>
</ul>
<p>Our filtering algorithm <span
class="math inline">\(\textsf{Filter}(H, i, k)\)</span> begins by
computing the distances <span
class="math inline">\(\mathit{dist}_i(v)\)</span> and <span
class="math inline">\(\mathit{dist}_k(v)\)</span> and predecessors <span
class="math inline">\(\mathit{pred}_i(v)\)</span> and <span
class="math inline">\(\mathit{pred}_k(v)\)</span> for every vertex <span
class="math inline">\(v\)</span>, using two invocations of your favorite
shortest-path algorithm. The algorithm also initializes two variables
for every vertex <span class="math inline">\(v\)</span>, which will
eventually be used by the query algorithm:</p>
<ul>
<li>A <em>representative</em> vertex <span
class="math inline">\(\mathit{rep}(v)\)</span>, initially equal to <span
class="math inline">\(v\)</span>.</li>
<li>A non-negative real <em>offset</em> <span
class="math inline">\(\mathit{off}(v)\)</span>, initially equal to <span
class="math inline">\(0\)</span>.</li>
</ul>
<p>Call any directed edge <span class="math inline">\(u \mathord\to
v\)</span> <em>properly shared</em> by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span> if it satisfies the following
recursive conditions:</p>
<ul>
<li><span class="math inline">\(\mathit{pred}_i(v) = \mathit{pred}_k(v)
= u\)</span>; in other words, <span class="math inline">\(u \mathord\to
v\)</span> is an edge in both <span class="math inline">\(T_i\)</span>
and <span class="math inline">\(T_k\)</span>.</li>
<li>If <span class="math inline">\(\mathit{pred}_i(u) =
\mathit{pred}_k(u)\)</span>, then the edge <span
class="math inline">\(\mathit{pred}_i(u)\mathord\to u\)</span> is
properly shared.</li>
<li>Otherwise, vertices <span
class="math inline">\(\mathit{pred}_i(u)\)</span>, <span
class="math inline">\(v\)</span>, <span
class="math inline">\(\mathit{pred}_k(u)\)</span> are ordered clockwise
around <span class="math inline">\(u\)</span>.</li>
</ul>
<p>We say that a properly shared edge <span class="math inline">\(u
\mathord\to v\)</span> is <em>exposed</em> if <span
class="math inline">\(\mathit{pred}_i(u) \ne
\mathit{pred}_k(u)\)</span>. For example, in Figure 2, both heavy black
edges on the left are properly shared, but only the lower edge is
exposed; the heavy black edges on the right are not properly shared.</p>
<figure>
<img src="Fig/planar-mssp-two-paths.png" style="width:60.0%"
alt="Shortest paths that share two edges. Left: Properly shared. Right: Improperly shared." />
<figcaption aria-hidden="true">Shortest paths that share two edges.
Left: Properly shared. Right: Improperly shared.</figcaption>
</figure>
<figure>
<img src="Fig/planar-mssp-two-trees.png" style="width:90.0%"
alt="Two shortest path trees with five properly shared edges, four of which are exposed." />
<figcaption aria-hidden="true">Two shortest path trees with five
properly shared edges, four of which are exposed.</figcaption>
</figure>
<p><strong>Lemma:</strong> <em>If <span
class="math inline">\(u\mathord\to v\)</span> is properly shared by
<span class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>, then <span
class="math inline">\(\mathit{pred}_j(v) = u\)</span> for all <span
class="math inline">\(i\le j\le k\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
First suppose <span class="math inline">\(u\mathord\to v\)</span> is
properly shared and exposed. Let <span
class="math inline">\(\gamma\)</span> be a simple closed curve obtained
by concatenating <span
class="math inline">\(\mathit{path}_k(u)\)</span>, the reversal of <span
class="math inline">\(\mathit{path}_i(u)\)</span>, and a simple path
from <span class="math inline">\(s_i\)</span> to <span
class="math inline">\(s_k\)</span> through the outer face. (The shaded
yellow region Figure 2 is the interior of <span
class="math inline">\(\gamma\)</span>.) Each source vertex <span
class="math inline">\(s_j\)</span> is inside <span
class="math inline">\(\gamma\)</span>, and <span
class="math inline">\(v\)</span> is outside <span
class="math inline">\(\gamma\)</span>. So the Jordan curve theorem
implies that <span class="math inline">\(\mathit{path}_j(v)\)</span>
must cross <span class="math inline">\(\gamma\)</span>. Uniqueness of
shortest paths implies that <span
class="math inline">\(\mathit{path}_j(v)\)</span> cannot cross either
<span class="math inline">\(\mathit{path}_i(v)\)</span> or <span
class="math inline">\(\mathit{path}_k(v)\)</span>. It follows that <span
class="math inline">\(\mathit{path}_j(v)\)</span> must contain <span
class="math inline">\(u\)</span>, and thus <span
class="math inline">\(\mathit{pred}_j(v) = u\)</span>.
</dd>
<dd>
<p>Now suppose <span class="math inline">\(u\mathord\to v\)</span> is
properly shared but not exposed. Let <span
class="math inline">\(p\)</span> be the first vertex on <span
class="math inline">\(\mathit{path}_i(v)\)</span> that is also in <span
class="math inline">\(\mathit{path}_k(v)\)</span>, and let <span
class="math inline">\(p\mathord\to q\)</span> be the first edge on the
shortest path from <span class="math inline">\(p\)</span> to <span
class="math inline">\(v\)</span> in <span
class="math inline">\(H\)</span>. Our recursive definitions imply that
<span class="math inline">\(p\mathord\to q\)</span> is properly shared
and exposed, so by the previous paragraph, for any index <span
class="math inline">\(j\)</span>, we have <span
class="math inline">\(\mathit{pred}_j(q) = p\)</span> for all <span
class="math inline">\(i\le j\le k\)</span>. It follows that <span
class="math inline">\(T_j\)</span> contains the entire shortest path
from <span class="math inline">\(p\)</span> to <span
class="math inline">\(v\)</span>, and in particular, the edge <span
class="math inline">\(u\mathord\to v\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>The converse of the previous lemma is not necessarily true; it is
possible for <span class="math inline">\(\mathit{pred}_j(v) = u\)</span>
for every index <span class="math inline">\(j\)</span> even though <span
class="math inline">\(u\mathord\to v\)</span> is not properly shared.
Consider the reversed shortest path tree <span
class="math inline">\(\overline{T}_v\)</span> rooted at <span
class="math inline">\(v\)</span>. Let <span
class="math inline">\(s_l\)</span> and <span
class="math inline">\(s_r\)</span> be the leftmost and rightmost source
vertices in the subtree of <span
class="math inline">\(\overline{T}_v\)</span> rooted at <span
class="math inline">\(u\)</span>. If this subtree contains
<em>every</em> source vertex <span class="math inline">\(s_j\)</span>,
then <span class="math inline">\(l = r+1 \bmod h\)</span>; intuitively,
the subtree wraps around <span class="math inline">\(u\mathord\to
v\)</span> and meets itself at the boundary. See Figure 4 for an
example. Edges of this form are <em>not</em> detected by the filtering
algorithm.</p>
<figure>
<img src="Fig/mssp-improper.png" style="width:30.0%"
alt="The black edge is shared by all shortest-path trees, but not properly shared by T_i and T_k." />
<figcaption aria-hidden="true">The black edge is shared by all
shortest-path trees, but not properly shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>.</figcaption>
</figure>
<p>Let <span class="math inline">\(m\)</span> denote the number of
vertices in <span class="math inline">\(H\)</span>. We can identify all
properly shared edges in <span class="math inline">\(H\)</span> in <span
class="math inline">\(O(m)\)</span> time using a preorder traversal of
either <span class="math inline">\(T_i\)</span> or <span
class="math inline">\(T_k\)</span>. In particular, we can find all
<em>exposed</em> edges leaving vertex <span
class="math inline">\(u\)</span> in <span
class="math inline">\(\deg(u)\)</span> time by visiting the darts into
<span class="math inline">\(u\)</span> in clockwise order—following the
successor permutation—from <span
class="math inline">\(\mathit{pred}_i(u)\mathord\to u\)</span> to <span
class="math inline">\(\mathit{pred}_k(u)\mathord\to u\)</span>.</p>
<h2 data-number="16.4" id="contraction"><span
class="header-section-number">16.4</span> Contraction</h2>
<p>The main work of the filtering algorithm is <em>contracting</em>
properly shared edges so that they need not be passed to recursive
subproblems. Intuitively, we contract the edge <span
class="math inline">\(u\mathord\to v\)</span> into its tail <span
class="math inline">\(u\)</span>, changing the tail of each directed
edge <span class="math inline">\(v\mathord\to w\)</span> from <span
class="math inline">\(v\)</span> to <span
class="math inline">\(u\)</span>. Here are the steps in detail:</p>
<ul>
<li>Set <span class="math inline">\(\mathit{rep}(v) \gets
u\)</span></li>
<li>Set <span class="math inline">\(\mathit{off}(v) \gets
\ell(u\mathord\to v)\)</span></li>
<li>For every edge <span class="math inline">\(w\mathord\to v\)</span>:
<ul>
<li>Set <span class="math inline">\(\ell(w\mathord\to v) \gets
\infty\)</span></li>
</ul></li>
<li>For every edge <span class="math inline">\(v\mathord\to w\)</span>:
<ul>
<li>Set <span class="math inline">\(\ell(v\mathord\to w) \gets
\mathit{off}(v) + \ell(v\mathord\to w)\)</span></li>
<li>If <span class="math inline">\(\mathit{pred}_i(w)=v\)</span>, set
<span class="math inline">\(\mathit{pred}_i(w)\gets u\)</span></li>
<li>If <span class="math inline">\(\mathit{pred}_k(w)=v\)</span>, set
<span class="math inline">\(\mathit{pred}_k(w)\gets u\)</span></li>
</ul></li>
<li>Contract <span class="math inline">\(uv\)</span> to <span
class="math inline">\(u\)</span></li>
</ul>
<p>The actual edge-contraction (in the second-to-last step) merges the
successor permutations of <span class="math inline">\(u\)</span> and
<span class="math inline">\(v\)</span> in <span
class="math inline">\(O(1)\)</span> time, as described in Lecture
10.</p>
<figure>
<img src="Fig/planar-mssp-contraction.png" style="width:65.0%"
alt="Contracting an exposed properly shared dart." />
<figcaption aria-hidden="true">Contracting an exposed properly shared
dart.</figcaption>
</figure>
<figure>
<img src="Fig/mssp-contract.png" style="width:60.0%"
alt="Edge weights before and after contraction and cleanup" />
<figcaption aria-hidden="true">Edge weights before and after contraction
and cleanup</figcaption>
</figure>
<p>If <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> have any common neighbors, contracting
<span class="math inline">\(v\)</span> into <span
class="math inline">\(u\)</span> creates parallel edges, which we must
resolve before passing the contracted map to <span
class="math inline">\(\textsf{MSSP-prep}\)</span>. After all properly
shared edges are contracted, we perform a global cleanup that identifies
and resolves all families of parallel edges. Specifically, for each pair
of neighboring vertices <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span> in the contracted map, we choose on
edge <span class="math inline">\(e\)</span> between <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>, change the dart weights of <span
class="math inline">\(e\)</span> to match the lightest darts <span
class="math inline">\(u\mathord\to v\)</span> and <span
class="math inline">\(v\mathord\to u\)</span>, and then delete all other
edges between <span class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>. If we use hashing to recognize and
collect parallel edges, the entire cleanup phase takes linear time.<a
href="#fn42" class="footnote-ref" id="fnref42"
role="doc-noteref"><sup>42</sup></a></p>
<p>Contracting <span class="math inline">\(u\mathord\to v\)</span>
preserves the shortest-path distance from every source <span
class="math inline">\(s_j\)</span> to every other vertex (except the
contracted vertex <span class="math inline">\(v\)</span>). Moreover, for
every source vertex <span class="math inline">\(s_j\)</span> and every
vertex <span class="math inline">\(w\)</span> in the original map <span
class="math inline">\(H\)</span> <em>including <span
class="math inline">\(v\)</span></em>, contraction also maintains the
following invariant, which allows us to recover shortest-path distances
during the query algorithm. Let <span
class="math inline">\(\mathit{dist}_j(w)\)</span> denote the
shortest-path distance from <span class="math inline">\(s_j\)</span> to
<span class="math inline">\(w\)</span> in the original map <span
class="math inline">\(H\)</span>, and let <span
class="math inline">\(\mathit{dist}’_j(w)\)</span> denote the
corresponding distance in the current contracted map.</p>
<p><strong>Key Invariant:</strong> <em>For every vertex <span
class="math inline">\(w\)</span> of <span
class="math inline">\(H\)</span> and for every index <span
class="math inline">\(j\)</span> such that <span
class="math inline">\(i\le j\le k\)</span>, we have <span
class="math inline">\(\mathit{dist}_j(w) =
\mathit{dist}’_j(\mathit{rep}(w)) + \mathit{off}(w)\)</span>.</em></p>
<p>When <span class="math inline">\(\textsf{Filter}\)</span> begins, we
have <span class="math inline">\(\mathit{dist}_j(w) =
\mathit{dist}’_j(w)\)</span> and <span
class="math inline">\(\mathit{rep}(w) = w\)</span> and <span
class="math inline">\(\mathit{off}(w)=0\)</span>, so the Key Invariant
holds trivially.</p>
<p>We contract properly shared edges in the same order they were
discovered, following a preorder traversal of <span
class="math inline">\(T_i\)</span>. This contraction order conveniently
guarantees that we only contract <em>exposed</em> edges; contracting one
exposed edge <span class="math inline">\(u \mathord\to v\)</span>
transforms each properly shared edge leaving <span
class="math inline">\(v\)</span> into an <em>exposed</em> properly
shared edge leaving <span class="math inline">\(u\)</span>. This
contraction order also guarantees that after contracting <span
class="math inline">\(u\mathord\to v\)</span>, no edge into <span
class="math inline">\(u\)</span> will ever be contracted. It follows
that we change the tail of each edge (and therefore the predecessors of
each vertex) at most once, and the Key Invariant is maintained. We
conclude:</p>
<p><strong>Lemma:</strong> <em><span
class="math inline">\(\textsf{Filter}(H, i, k)\)</span> identifies and
contracts all properly shared edges in <span
class="math inline">\(H\)</span> in <span class="math inline">\(O(S(m) +
m)\)</span> time, where <span class="math inline">\(m = |V(H)|\)</span>.
Moreover, after <span class="math inline">\(\textsf{Filter}(H, i,
k)\)</span> ends, the Key Invariant holds.</em></p>
<figure>
<img src="Fig/planar-mssp-recursion.png" style="width:90.0%"
alt="Contracting all properly shared directed edges and recursing." />
<figcaption aria-hidden="true">Contracting all properly shared directed
edges and recursing.</figcaption>
</figure>
<figure>
<img src="Fig/planar-mssp-recursion-tree.png" style="width:100.0%"
alt="Recursive subproblems after contraction become more and more birdlike." />
<figcaption aria-hidden="true">Recursive subproblems after contraction
become more and more birdlike.</figcaption>
</figure>
<h2 data-number="16.5" id="distance-queries"><span
class="header-section-number">16.5</span> Distance Queries</h2>
<p>Each call to <span
class="math inline">\(\textsf{Filter}(H,i,k)\)</span> creates a record
storing the following information:</p>
<ul>
<li>indices <span class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span></li>
<li>for each vertex <span class="math inline">\(v\)</span> of the input
map <span class="math inline">\(H\)</span>:<a href="#fn43"
class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a>
<ul>
<li>shortest-path distances <span
class="math inline">\(\mathit{dist}_i(v)\)</span> and <span
class="math inline">\(\mathit{dist}_k(v)\)</span></li>
<li>the representative vertex <span
class="math inline">\(\mathit{rep}(v)\)</span></li>
<li>the offset <span
class="math inline">\(\mathit{off}(v)\)</span>.</li>
</ul></li>
</ul>
<p>The recursive calls to <span
class="math inline">\(\textsf{MSSP-Prep}\)</span> assemble these records
into a binary tree, mirroring the tree of recursive calls, connected by
<span class="math inline">\(\mathit{left}\)</span> and <span
class="math inline">\(\mathit{right}\)</span> pointers.</p>
<p>The query algorithm <span
class="math inline">\(\textsf{MSSP-query}(\mathit{Rec},j,v)\)</span>
takes as input a recursive-call record <span
class="math inline">\(\mathit{Rec}\)</span>, a source index <span
class="math inline">\(j\)</span>, and a vertex <span
class="math inline">\(v\)</span>, satisfying two conditions:</p>
<ul>
<li><span class="math inline">\(\mathit{Rec}.i \le j\le
\mathit{Rec}.k\)</span></li>
<li><span class="math inline">\(v\)</span> is a vertex of the input map
<span class="math inline">\(H\)</span> to the recursive call to <span
class="math inline">\(\textsf{MSSP-Prep}\)</span> that created <span
class="math inline">\(\mathit{Rec}\)</span>.</li>
</ul>
<p>The output of <span
class="math inline">\(\textsf{MSSP-query}(\mathit{Rec},j,v)\)</span> is
the shortest-path distance from <span class="math inline">\(s_j\)</span>
to <span class="math inline">\(v\)</span> in <span
class="math inline">\(\Sigma\)</span>. The query algorithm follows
straightforwardly from the Key Invariant:</p>
<ul>
<li>if <span class="math inline">\(j=i\)</span>, return <span
class="math inline">\(\mathit{Rec}.\mathit{dist}_i[v]\)</span></li>
<li>else if <span class="math inline">\(j=k\)</span>, return <span
class="math inline">\(\mathit{Rec}.\mathit{dist}_k[v]\)</span></li>
<li>else if <span class="math inline">\(j \le
\mathit{Rec}.\mathit{left}.k\)</span>, return <span
class="math inline">\(\textsf{MSSP-query}(\mathit{Rec}.\mathit{left}, j,
\mathit{Rec}.\mathit{rep}[v]) +
\mathit{Rec}.\mathit{off}[v]\)</span></li>
<li>else return <span
class="math inline">\(\textsf{MSSP-query}(\mathit{Rec}.\mathit{righ}, j,
\mathit{Rec}.\mathit{rep}[v]) +
\mathit{Rec}\mathord.\mathit{off}[v]\)</span></li>
</ul>
<p>Because the recursion tree has depth <span
class="math inline">\(O(\log h)\)</span>, the query algorithm runs in
<span class="math inline">\(O(\log h)\)</span> time.</p>
<h2 data-number="16.6" id="space-and-time-analysis"><span
class="header-section-number">16.6</span> Space and Time Analysis</h2>
<p>It remains only to bound the size of our data structure and the
running time of <span class="math inline">\(\textsf{MSSP-Prep}\)</span>.
The key claim is that the total size of all input maps at any level of
the recursion tree is <span class="math inline">\(O(n)\)</span>.</p>
<p><strong>Contraction sharing lemma:</strong> <em>Contracting one
properly shared edge neither creates nor destroys other properly shared
edges.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Fix a map <span class="math inline">\(H\)</span> and source indices
<span class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span>. Let <span
class="math inline">\(u\mathord\to v\)</span> be an edge in <span
class="math inline">\(H\)</span> that is properly shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>. Let <span class="math inline">\(H’ =
H / u{\to}v\)</span>, with dart weights adjusted as described above, and
let <span class="math inline">\(T’_i\)</span> and <span
class="math inline">\(T’_k\)</span> denote the shortest path trees
rooted at <span class="math inline">\(s_i\)</span> and <span
class="math inline">\(s_k\)</span> in <span
class="math inline">\(H’\)</span>.
</dd>
<dd>
<p>First, because contraction preserves shortest paths, we can easily
verify that <span class="math inline">\(T’_i = T_i / u{\to}v\)</span>
and <span class="math inline">\(T’_k = T_k / u{\to}v\)</span>. It
follows that an edge in <span class="math inline">\(H\)</span> is shared
by <span class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span> if and only if the corresponding edge
in <span class="math inline">\(H’\)</span> is shared by <span
class="math inline">\(T’_i\)</span> and <span
class="math inline">\(T’_k\)</span>.</p>
</dd>
<dd>
<p>Now consider any edge <span class="math inline">\(x{\to}y \in T_i
\cap T_k\)</span> that is not <span
class="math inline">\(u{\to}v\)</span>. We must have <span
class="math inline">\(y\ne v\)</span>, because each vertex has only one
predecessor in any shortest-path tree. Let <span
class="math inline">\(w\)</span> be the first node on the shortest path
from <span class="math inline">\(s_i\)</span> to <span
class="math inline">\(x\)</span> in <span
class="math inline">\(H\)</span> that is also on the shortest path from
<span class="math inline">\(s_k\)</span> to <span
class="math inline">\(x\)</span>, so the entire shortest path from <span
class="math inline">\(w\)</span> to <span
class="math inline">\(y\)</span> is shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>. Consider three paths:</p>
</dd>
<dd>
<ul>
<li><span class="math inline">\(\alpha =\)</span> the shortest path from
<span class="math inline">\(s_i\)</span> to <span
class="math inline">\(w\)</span></li>
</ul>
</dd>
<dd>
<ul>
<li><span class="math inline">\(\beta =\)</span> the reverse of the
shortest path from <span class="math inline">\(w\)</span> to <span
class="math inline">\(y\)</span></li>
</ul>
</dd>
<dd>
<ul>
<li><span class="math inline">\(\gamma =\)</span> the shortest path from
<span class="math inline">\(s_k\)</span> to <span
class="math inline">\(w\)</span></li>
</ul>
</dd>
<dd>
<p>Then <span class="math inline">\(x{\to}y\)</span> is properly shared
if and only if (the last edges of) <span
class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span>, and <span
class="math inline">\(\gamma\)</span> are incident to <span
class="math inline">\(w\)</span> in clockwise order. The definition of
properly shared implies <span class="math inline">\(v=w\)</span>, so
<span class="math inline">\(w\)</span> is also a vertex in <span
class="math inline">\(H’\)</span>. Contracting <span
class="math inline">\(u{\to}v\)</span> might shorten one of the three
paths to <span class="math inline">\(w\)</span>, but it cannot change
their cyclic order around <span class="math inline">\(w\)</span>. We
conclude that <span class="math inline">\(x{\to}y\)</span> is properly
shared in <span class="math inline">\(H\)</span> if and only if <span
class="math inline">\(x{\to}y\)</span> (or <span
class="math inline">\(u{\to}y\)</span> if <span
class="math inline">\(x=v\)</span>) is properly shared in <span
class="math inline">\(H’\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>The contraction sharing lemma implies by induction that every call to
<span class="math inline">\(\textsf{Filter}(H, i, k)\)</span> outputs
the same contracted map as <span
class="math inline">\(\textsf{Filter}(\Sigma, i, k)\)</span>. In
particular, an edge <span class="math inline">\(u\mathord\to v\)</span>
in <span class="math inline">\(H\)</span> is properly shared by two
shortest-oath trees in <span class="math inline">\(H\)</span> if and
only if the corresponding edge in <span
class="math inline">\(\Sigma\)</span> (which may have a different tail
vertex) is properly shared by the corresponding trees in <span
class="math inline">\(\Sigma\)</span>. So from now on, “properly shared”
always implies “in the top level map <span
class="math inline">\(\Sigma\)</span>”.</p>
<p><strong>Corollary:</strong> <em>For all indices <span
class="math inline">\(i\le i’&lt;k’\le k\)</span>, if <span
class="math inline">\(u{\to}v\)</span> is properly shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>, then <span
class="math inline">\(u{\to}v\)</span> is properly shared by <span
class="math inline">\(T_{i’}\)</span> and <span
class="math inline">\(T_{k’}\)</span>.</em></p>
<p><strong>Corollary:</strong> <em>The vertices of <span
class="math inline">\(\textsf{Filter}(\Sigma, i, k)\)</span> are
precisely the vertices <span class="math inline">\(v\)</span> such that
no edge into <span class="math inline">\(v\)</span> is properly shared
by <span class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>.</em></p>
<p>Fix any vertex <span class="math inline">\(v\)</span> of <span
class="math inline">\(\Sigma\)</span>. We call an index <span
class="math inline">\(j\)</span> <em>interesting</em> if <span
class="math inline">\(\mathit{pred}_j(v)\mathord\to v\)</span> is
<em>not</em> properly shared by <span class="math inline">\(T_j\)</span>
and <span class="math inline">\(T_{j+1}\)</span>.</p>
<p><strong>Lemma:</strong> <em>Every vertex <span
class="math inline">\(v\)</span> of <span
class="math inline">\(\Sigma\)</span> has at most <span
class="math inline">\(\deg(v)\)</span> indices.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Equivalently, <span class="math inline">\(j\)</span> is interesting to
<span class="math inline">\(v\)</span> if either of the following
conditions holds:
</dd>
<dd>
<ul>
<li><span class="math inline">\(\mathit{pred}_j(v) \ne
\mathit{pred}_{j+1}(v)\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li><span class="math inline">\(\mathit{pred}_0(v) = \mathit{pred}_1(v)
= \cdots = \mathit{pred}_{h-1}(v) = u\)</span> and the paths <span
class="math inline">\(\mathit{path}_j(u)\)</span> and <span
class="math inline">\(\mathit{path}_{j+1}(u)\)</span> “wrap around”
<span class="math inline">\(u \mathord\to v\)</span>.</li>
</ul>
</dd>
<dd>
<p>The Disk-Tree Lemma implies that the first condition holds for at
most <span class="math inline">\(\deg(v)\)</span> indices <span
class="math inline">\(j\)</span>. If the first condition never holds
(that is, if <span class="math inline">\(\mathit{pred}_j(v)\)</span> is
the same for index <span class="math inline">\(j\)</span>), then the
second condition holds for exactly one index <span
class="math inline">\(j\)</span>; otherwise the second condition never
holds. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>Each vertex <span
class="math inline">\(v\)</span> appears in at most <span
class="math inline">\(2\deg(v)\)</span> subproblems at each level of the
recursion tree.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The children <span
class="math inline">\(\mathit{Rec}.\mathit{left}\)</span> and <span
class="math inline">\(\mathit{Rec}.\mathit{right}\)</span> of any
recursion record <span class="math inline">\(\mathit{Rec}\)</span> store
information about <span class="math inline">\(v\)</span> and if and only
if at least one index <span class="math inline">\(j\)</span> such that
<span class="math inline">\(\mathit{Rec}.i\le j\le
\mathit{Rec}.k\)</span> is interesting to <span
class="math inline">\(v\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Theorem:</strong> <em><span
class="math inline">\(\textsf{MSSP-Prep}(\Sigma, 0, h-1)\)</span> builds
a data structure of size <span class="math inline">\(O(n\log h)\)</span>
in <span class="math inline">\(O(S(n)\log h)\)</span> time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The total number of vertices in all subproblems at the same level of the
recursion tree is at most <span class="math inline">\(\sum_v 2\deg(v)
\le 4\cdot|E(\Sigma)| \le 4(3n-6) = 12n-24\)</span> by Euler’s formula,
since <span class="math inline">\(\Sigma\)</span> is a simple planar
map. Each recursion record uses <span
class="math inline">\(O(1)\)</span> space per vertex, so the total space
used at any level is <span class="math inline">\(O(n)\)</span>.
Similarly, the time spent in any subproblem is at most <span
class="math inline">\(O(S(n)/n)\)</span> per vertex, so the total time
spent in each level of the recursion tree is <span
class="math inline">\(O(S(n))\)</span>.
</dd>
<dd>
<p>Finally, the recursion tree has <span class="math inline">\(O(\log
h)\)</span> levels. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="16.7" id="references-9"><span
class="header-section-number">16.7</span> References</h2>
<ol type="1">
<li><p>Debarati Das, Evangelos Kipouridis, Maximilian Probst Gutenberg,
and Christian Wulff-Nilsen. <a
href="https://doi.org/10.1137/1.9781611977066.1">A simple algorithm for
multiple-source shortest paths in planar digraphs</a>. <em>Proc. 5th
Symp. Simplicity in Algorithms</em>, 1–11, 2022.</p></li>
<li><p>David Eisenstat. <a
href="https://cs.brown.edu/research/pubs/theses/phd/2014/eisenstat.pdf"><em>Toward
Practical Planar Graph Algorithms</em></a>. Ph.D. thesis, Comput. Sci.
Dept., Brown Univ., May 2014.</p></li>
<li><p>Jacob Holm, Giuseppe F. Italiano, Adam Karczmarz, Jakub Łącki,
Eva Rotenberg, and Piotr Sankowski. <a
href="http://doi.org/10.4230/LIPIcs.ESA.2017.50">Contracting a planar
graph efficiently</a>. <em>Proc. 25th Ann. Europ. Symp. Algorithms</em>,
50:1–50:15, 2017. Leibniz Int. Proc. Informatics 87, Schloss
Dagstuhl–Leibniz-Zentrum für Informatik. arXiv:<a
href="https://arxiv.org/abs/1706.10228">1706.10228</a>.</p></li>
<li><p>Frank Kammer and Johannes Meintrup. <a
href="http://doi.org/10.48550/ARXIV.2301.10564">Succinct planar encoding
with minor operations</a>. Preprint, January 2023. arXiv:<a
href="https://arxiv.org/abs/2301.10564">2301.10564</a>.</p></li>
<li><p>Robert E. Tarjan and Renato F. Werneck. <a
href="http://doi.org/10.1145/1498698.1594231">Dynamic trees in
practice</a>. <em>J. Exper. Algorithmics</em> 14:5:1–5:21,
2009.</p></li>
<li><p>Renato Werneck. <a
href="https://www.cs.princeton.edu/research/techreps/TR-750-06"><em>Design
and Analysis of Data Structures for Dynamic Trees</em></a>.
Ph.D. thesis, Dept. Comput. Sci., Princeton Univ., April 2006. Tech.
Rep. TR-750-06.</p></li>
</ol>
<h1 data-number="17" id="planar-separatorsbeta"><span
class="header-section-number">17</span> Planar Separators<span
class="math inline">\(^\beta\)</span></h1>
<p>Let <span class="math inline">\(\Sigma\)</span> be an arbitrary
planar map, with non-negative weights on its vertices, edges, and/or
faces that sum to <span class="math inline">\(W\)</span>. A simple cycle
<span class="math inline">\(C\)</span> in a planar map <span
class="math inline">\(\Sigma\)</span> is a <em>balanced cycle
separator</em> if the total weight of all vertices, edges, and faces on
either side of <span class="math inline">\(C\)</span> is at most <span
class="math inline">\(3W/4\)</span>. As long as each vertex, edge, or
face of <span class="math inline">\(\Sigma\)</span> has weight at most
<span class="math inline">\(W/4\)</span>, there is a balanced cycle
separator with at most <span class="math inline">\(O(\sqrt{n})\)</span>
vertices; moreover, we can compute such a cycle in <span
class="math inline">\(O(n)\)</span> time.</p>
<h2 data-number="17.1" id="tree-separators"><span
class="header-section-number">17.1</span> Tree separators</h2>
<p>Before we consider separators in planar graphs, let’s consider the
simpler case of trees. Here a balanced separator is a single edge that
splits the tree into two subtrees of roughly equal weight. Tree
separators were first studied by Camille Jordan</p>
<p>Let <span class="math inline">\(T = (V, E)\)</span> be an unrooted
tree in which every vertex has degree at most <span
class="math inline">\(3\)</span>. Intuitively, <span
class="math inline">\(T\)</span> is a “binary” tree, but without a root
and without a distinction between left and right children. (This
bounded-degree assumption is necessary.) Assign each vertex <span
class="math inline">\(v\)</span> a non-negative weight <span
class="math inline">\(w(v)\)</span> and let <span
class="math inline">\(W := \sum_v w(v)\)</span>.</p>
<dl>
<dt><strong>Tree-separator lemma:</strong></dt>
<dd>
<em>If every vertex has weight at most <span
class="math inline">\(W/4\)</span>, there is an edge <span
class="math inline">\(e\)</span> in <span
class="math inline">\(T\)</span> such that the total weight in either
component of <span class="math inline">\(T\setminus e\)</span> is at
most <span class="math inline">\(3W/4\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Pick an arbitrary leaf <span class="math inline">\(r\)</span> of <span
class="math inline">\(T\)</span> as the root, and direct all edges away
from <span class="math inline">\(r\)</span>, so every vertex in <span
class="math inline">\(T\)</span> has at most two children. By attaching
leaves with weight zero, we can assume without loss of generality that
every non-leaf vertex has exactly two children.
</dd>
<dd>
<p>For any vertex <span class="math inline">\(v\)</span>, let <span
class="math inline">\(W(v)\)</span> denote the total weight of <span
class="math inline">\(v\)</span> and its descendants; for example, <span
class="math inline">\(W(r) = W\)</span>. For any non-leaf vertex <span
class="math inline">\(v\)</span>, label its children <span
class="math inline">\(\textsf{heft}(v)\)</span> and <span
class="math inline">\(\textsf{lite}(v)\)</span> so that <span
class="math inline">\(W(\textsf{heft}(v)) \ge
W(\textsf{lite}(v))\)</span> (breaking ties arbitrarily).</p>
</dd>
<dd>
<p>Starting at the root <span class="math inline">\(r\)</span>, follow
pointers down to the first vertex <span class="math inline">\(x\)</span>
such that <span class="math inline">\(W(\textsf{heft}(x)) \le
W/4\)</span>. Then we immediately have <span class="math display">\[
\begin{aligned}
    W/4 &amp;&lt; W(x)
\\      &amp;= W(\textsf{heft}(x)) + W(\textsf{lite}(x)) + w(x)
\\      &amp;\le 2\cdot W(\textsf{heft}(x)) + w(x)
\\      &amp;\le 3W/4.
\end{aligned}
\]</span> Let <span class="math inline">\(e\)</span> be the edge between
<span class="math inline">\(x\)</span> and its parent. The two
components of <span class="math inline">\(T\setminus e\)</span> have
total weight <span class="math inline">\(W(x) \le 3W-4\)</span> and
<span class="math inline">\(W - W(x) &lt; 3W/4\)</span>. <span
class="math inline">\(\qquad\square\)</span>.</p>
</dd>
</dl>
<p>It’s easy to see that the upper bounds on vertex degree and vertex
weight are both necessary. This separator lemma has several variants;
I’ll mention just a few without proof:</p>
<dl>
<dt><strong>Unweighted tree-separator lemma:</strong></dt>
<dd>
<em>For any <span class="math inline">\(n\)</span>-vertex tree <span
class="math inline">\(T\)</span> with maximum degree <span
class="math inline">\(3\)</span>, there is an edge <span
class="math inline">\(e\)</span> such that the each component of <span
class="math inline">\(T\setminus e\)</span> has at most <span
class="math inline">\(2n/3\)</span> vertices.</em>
</dd>
<dt><strong>Edge-weight tree-separator lemma:</strong></dt>
<dd>
<em>For any tree <span class="math inline">\(T\)</span> with maximum
degree <span class="math inline">\(3\)</span> and any weights on the
<strong>edges</strong> of <span class="math inline">\(T\)</span> that
sum to <span class="math inline">\(W\)</span>, there is an edge <span
class="math inline">\(e\)</span> such that both components of <span
class="math inline">\(T\setminus e\)</span> have total edge weight at
most <span class="math inline">\(2W/3\)</span>.</em>
</dd>
<dt><strong>Vertex tree-separator lemma:</strong></dt>
<dd>
<em>For any tree <span class="math inline">\(T\)</span> and any weights
on the vertices of <span class="math inline">\(T\)</span> that sum to
<span class="math inline">\(W\)</span>, there is a
<strong>vertex</strong> <span class="math inline">\(v\)</span> such that
every component of <span class="math inline">\(T\setminus v\)</span> has
total weight at most <span class="math inline">\(W/2\)</span>.</em>
</dd>
</dl>
<h2 data-number="17.2" id="fundamental-cycle-separators"><span
class="header-section-number">17.2</span> Fundamental cycle
separators</h2>
<p>Now let <span class="math inline">\(\Sigma\)</span> be a planar
<em>triangulation</em>. Assign each face <span
class="math inline">\(f\)</span> a non-negative weight <span
class="math inline">\(w(f) \le W/4\)</span>, where <span
class="math inline">\(W := \sum_f w(f)\)</span>. (Again, the upper
bounds on face degree and face weight are both necessary.) A cycle <span
class="math inline">\(C\)</span> in <span
class="math inline">\(\Sigma\)</span> is a <em>balanced separator</em>
if the total weight on either side of <span
class="math inline">\(C\)</span> is at most <span
class="math inline">\(3W/4\)</span>.</p>
<p>Let <span class="math inline">\(T\)</span> be an arbitrary spanning
tree of <span class="math inline">\(\Sigma\)</span>. For any non-tree
edge <span class="math inline">\(e\)</span>, the <em>fundamental
cycle</em> <span class="math inline">\(\textsf{cycle}(T, e)\)</span> is
the unique cycle in <span class="math inline">\(T+e\)</span>, consisting
of <span class="math inline">\(e\)</span> and the unique path in <span
class="math inline">\(T\)</span> between the endpoints of <span
class="math inline">\(e\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>At least one fundamental cycle <span
class="math inline">\(\textsf{cycle}(T, e)\)</span> is a balanced
separator for <span class="math inline">\(\Sigma\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(C^*\)</span> be the spanning tree of
<span class="math inline">\(\Sigma^*\)</span> complementary to <span
class="math inline">\(T\)</span>. Because <span
class="math inline">\(\Sigma\)</span> is a triangulation, every vertex
of <span class="math inline">\(C^*\)</span> has degree at most <span
class="math inline">\(3\)</span>. Suppose each vertex of <span
class="math inline">\(C^*\)</span> inherits its weight from the
corresponding face of <span class="math inline">\(\Sigma\)</span>. The
tree-separator lemma implies that there is some edge <span
class="math inline">\(e\)</span> such that each component of <span
class="math inline">\(C^*\setminus e^*\)</span> has at most <span
class="math inline">\(3/4\)</span> the total weight of the vertices of
<span class="math inline">\(C^*\)</span>. It follows that <span
class="math inline">\(\textsf{cycle}(T, e)\)</span> is a balanced
separator. <span class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>We can extend this lemma to the setting where vertices and edges also
have weights, in addition to faces. Let <span
class="math inline">\(w\colon V\cup E\cup F \to \mathbb{R}_+\)</span> be
the given weight function. Define a new face-weight function <span
class="math inline">\(w’\colon F\to\mathbb{R}_+\)</span> by moving the
weight of each vertex and edge to some incident face.</p>
<p>Unfortunately, fundamental cycles can be quite long. For any
particular map <span class="math inline">\(\Sigma\)</span>, we can
minimize the maximum length of all fundamental cycles using a
<em>breadth-first search</em> tree from the correct root vertex as our
spanning tree <span class="math inline">\(T\)</span>, but in the worst
case, every <em>balanced</em> fundamental cycle separator has length
<span class="math inline">\(\Omega(n)\)</span>.</p>
<p>For most applications of balanced separators, breadth-first
fundamental cycles are usually the best choice <em>in practice</em>; see
the detailed experimental analysis by Fox-Epstein et al. [1].</p>
<h2 data-number="17.3" id="breadth-first-level-separators"><span
class="header-section-number">17.3</span> Breadth-first level
separators</h2>
<p>A second easy method for computing separators is to consider the
levels of a breadth-first search tree. For the moment, let’s assume that
the <em>vertices</em> of <span class="math inline">\(\Sigma\)</span> are
weighted. For each integer <span class="math inline">\(\ell\)</span>,
let <span class="math inline">\(V_\ell\)</span> denote the vertices
<span class="math inline">\(\ell\)</span> steps away from the root
vertex of <span class="math inline">\(T\)</span>. By computing a
weighted median, we can find a level <span
class="math inline">\(V_m\)</span> such that the total vertex weight in
any component of <span class="math inline">\(\Sigma\setminus
V_m\)</span> is at most <span class="math inline">\(W/2\)</span>.</p>
<p>There are two obvious problems with this separator construction. The
less serious problem is that the medial level <span
class="math inline">\(V_m\)</span> is not a cycle; it’s just a cloud of
vertices. Many applications of planar separators don’t actually require
<em>cycle</em> separators, but most of the applications we’ll see in
this class do. The more serious problem is size; in the worst case, the
set <span class="math inline">\(V_m\)</span> could contain a constant
fraction of the vertices.</p>
<p>When Richard Lipton and Robert Tarjan introduced planar separators in
1979, they did not consider cycle separators. Rather, they proved that
there is always a subset <span class="math inline">\(S\)</span> of <span
class="math inline">\(O(\sqrt{n})\)</span> vertices such that any
component of <span class="math inline">\(\Sigma\setminus S\)</span> has
at most <span class="math inline">\(2n/3\)</span> vertices. Lipton and
Tarjan’s construction combines fundamental cycle separators and
BFS-level separators. I will not describe their construction in detail,
partly because we really do need cycles, and partly because most of
their ideas show up in the next section.</p>
<h2 data-number="17.4" id="cycle-separators"><span
class="header-section-number">17.4</span> Cycle separators</h2>
<p>Gary Miller was the first to prove that small balanced cycle
separators exist, in 1986. The following refinement of Miller’s
algorithm is based on later proofs by Philip Klein, Shay Mozes, and
Christian Sommer (2013) and Sariel Har-Peled and Amir Nayyeri (2018).
Miller’s key idea was to generalize our notion of “level” from vertices
to faces.<a href="#fn44" class="footnote-ref" id="fnref44"
role="doc-noteref"><sup>44</sup></a></p>
<p>As in our earlier setup, Let <span
class="math inline">\(\Sigma\)</span> be a simple planar triangulation
with weighted faces, where no individual face weight is too large. Let
<span class="math inline">\(T_0\)</span> be a breadth-first search tree,
and suppose the fundamental cycle <span
class="math inline">\(\textsf{cycle}(T_0, xy)\)</span> is a balanced
separator. If this cycle has length <span
class="math inline">\(O(\sqrt{n})\)</span>, we are done, so assume
otherwise.</p>
<p>Let <span class="math inline">\(r\)</span> denote the least common
ancestor of <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>, and let <span
class="math inline">\(T\)</span> be a breadth-first search tree rooted
at <span class="math inline">\(r\)</span>. The cycle <span
class="math inline">\(\textsf{cycle}(T, xy) = \textsf{cycle}(T_0,
xy)\)</span> is still a balanced separator.</p>
<p>For any vertex <span class="math inline">\(v\)</span>, let <span
class="math inline">\(\textsf{level}(v)\)</span> denote the
breadth-first distance from <span class="math inline">\(r\)</span> to
<span class="math inline">\(v\)</span>. Without loss of generality,
assume <span class="math inline">\(\textsf{level}(x) \le
\textsf{level}(y)\)</span>. Then for any face <span
class="math inline">\(f\)</span>, let <span
class="math inline">\(\textsf{level}(f)\)</span> denote the maximum
level among the three vertices of <span
class="math inline">\(f\)</span>. A face at level <span
class="math inline">\(\ell\)</span> has vertices only at levels <span
class="math inline">\(\ell\)</span> and <span
class="math inline">\(\ell-1\)</span>. Let <span
class="math inline">\(o\)</span> denote the outer face of <span
class="math inline">\(\Sigma\)</span>, and without loss of generality,
assume that <span class="math inline">\(L = \textsf{level}(o) = \max_f
\textsf{level}(f)\)</span>.</p>
<p>For any integer <span class="math inline">\(\ell\)</span>, let <span
class="math inline">\(U_{\le\ell}\)</span> denote the union of all faces
with level at most <span class="math inline">\(\ell\)</span>, and let
<span class="math inline">\(C_\ell\)</span> be the outer boundary of
<span class="math inline">\(U_{\le\ell}\)</span>. Trivially <span
class="math inline">\(U_{\le 0} = \varnothing\)</span> and therefore
<span class="math inline">\(C_0 = \varnothing\)</span>. Similarly, fr
any <span class="math inline">\(\ell\ge L\)</span>, we have <span
class="math inline">\(U_{\le \ell} = \mathbb{R}^2\)</span> and therefore
<span class="math inline">\(C_\ell = \varnothing\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<ol type="a">
<li><em>Every vertex in <span class="math inline">\(C_\ell\)</span> has
level <span class="math inline">\(\ell\)</span>.</em></li>
</ol>
</dd>
<dd>
<ol start="2" type="a">
<li><em>Every non-empty subgraph <span
class="math inline">\(C_\ell\)</span> is a simple cycle.</em></li>
</ol>
</dd>
<dd>
<ol start="3" type="a">
<li><em>The cycles <span class="math inline">\(C_\ell\)</span> are
pairwise vertex-disjoint.</em></li>
</ol>
</dd>
<dd>
<ol start="4" type="a">
<li><em>The fundamental cycle <span
class="math inline">\(\textsf{cycle}(T, xy)\)</span> intersects <span
class="math inline">\(C_\ell\)</span> in at most two vertices</em></li>
</ol>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Part (a) follows directly from the definitions.
</dd>
<dd>
<p>By construction <span class="math inline">\(C_\ell\)</span> consists
of one or more simple cycles, any two of which share at most one vertex.
Let <span class="math inline">\(C\)</span> be the simple cycle in <span
class="math inline">\(C_\ell\)</span> that contains <span
class="math inline">\(r\)</span> in its interior. and let <span
class="math inline">\(v\)</span> be any vertex of <span
class="math inline">\(C_\ell\setminus C\)</span>. Let <span
class="math inline">\(u\)</span> be the second-to-last vertex on the
shortest path from <span class="math inline">\(r\)</span> to <span
class="math inline">\(v\)</span>. Vertex <span
class="math inline">\(u\)</span> has level <span
class="math inline">\(\ell-1\)</span> and therefore does not lie on
<span class="math inline">\(C\)</span>; moreover, because <span
class="math inline">\(v\not\in C\)</span>, vertex <span
class="math inline">\(u\)</span> cannot lie in the interior of <span
class="math inline">\(C\)</span>. The Jordan curve theorem implies that
the shortest path from <span class="math inline">\(u\)</span> to <span
class="math inline">\(r\)</span> crosses <span
class="math inline">\(C\)</span>, but this is impossible, because levels
decrease monotonically along that path. We conclude that <span
class="math inline">\(C_\ell = C\)</span>, proving part (b).</p>
</dd>
<dd>
<p>Part (c) follows immediately from part (a).</p>
</dd>
<dd>
<p>Finally, the vertices of <span
class="math inline">\(\textsf{cycle}(T, xy)\)</span> lie on two shortest
paths from <span class="math inline">\(r\)</span>, one to <span
class="math inline">\(x\)</span> and the other to <span
class="math inline">\(y\)</span>. Levels increase monotonically along
any shortest path from <span class="math inline">\(r\)</span>. Thus, by
part (a), the shortest paths from <span class="math inline">\(r\)</span>
to <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> each share at most one vertex with
<span class="math inline">\(C_\ell\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<figure>
<img src="Fig/separator-face-levels.png" style="width:95.0%"
alt="Depth contours in a plane triangulation. The starred vertex is the root r. Faces with even depth are shaded. Cycles C_\ell are black. Green cycles are other portions of the boundary of sublevel sets U_\ell." />
<figcaption aria-hidden="true">Depth contours in a plane triangulation.
The starred vertex is the root <span class="math inline">\(r\)</span>.
Faces with even depth are shaded. Cycles <span
class="math inline">\(C_\ell\)</span> are black. Green cycles are other
portions of the boundary of sublevel sets <span
class="math inline">\(U_\ell\)</span>.</figcaption>
</figure>
<p>Let <span class="math inline">\(m\)</span> be the largest integer
such that the total weight of all faces inside <span
class="math inline">\(C_m\)</span> is at most <span
class="math inline">\(W/2\)</span>. Then the total weight of the faces
<em>outside</em> <span class="math inline">\(C_{m+1}\)</span> is also at
most <span class="math inline">\(W/2\)</span>. If either of these cycles
is a balanced cycle separator of length <span
class="math inline">\(O(\sqrt{n})\)</span>, we are done, so assume
otherwise. We choose two level cycles <span
class="math inline">\(C^-\)</span> and <span
class="math inline">\(C^+\)</span> as follows.<a href="#fn45"
class="footnote-ref" id="fnref45"
role="doc-noteref"><sup>45</sup></a></p>
<ul>
<li><p>Consider the set of cycles <span
class="math inline">\(\mathcal{C}^- = \{C_\ell \mid m-\sqrt{n} &lt; \ell
\le m\}\)</span>. These <span class="math inline">\(\sqrt{n}\)</span>
cycles contain at most <span class="math inline">\(n\)</span> vertices,
and therefore some cycle <span class="math inline">\(C^-\)</span> in
this set must have length less than <span
class="math inline">\(\sqrt{n}\)</span>. By construction, the total
weight of all faces inside <span class="math inline">\(C^-\)</span> is
at most <span class="math inline">\(W/2\)</span>.</p></li>
<li><p>Similarly, consider the set <span
class="math inline">\(\mathcal{C}^+ = \{C_\ell \mid m &lt; \ell \le m +
\sqrt{n}\}\)</span>. These <span class="math inline">\(\sqrt{n}\)</span>
cycles contain at most <span class="math inline">\(n\)</span> vertices,
and therefore some cycle <span class="math inline">\(C^+\)</span> in
this set must have length less than <span
class="math inline">\(\sqrt{n}\)</span>. By construction, the total
weight of all faces outside <span class="math inline">\(C^+\)</span> is
at most <span class="math inline">\(W/2\)</span>.</p></li>
</ul>
<p>Let <span class="math inline">\(\pi_x\)</span> denote the portion of
the shortest path from <span class="math inline">\(r\)</span> to <span
class="math inline">\(x\)</span> with levels between <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span>, and define <span
class="math inline">\(\pi_y\)</span> similarly. By construction, each of
these paths has length at most <span
class="math inline">\(2\sqrt{n}\)</span>. Let <span
class="math inline">\(\Theta\)</span> denote the graph <span
class="math inline">\(C^- \cup C^+ \cup \pi_x \cup \pi_y\)</span>, as
shown in the figure below. This subgraph of <span
class="math inline">\(\Theta\)</span> has at most <span
class="math inline">\(4\sqrt{n}\)</span> vertices and edges. We label
the four faces of <span class="math inline">\(\Theta\)</span> as
follows:</p>
<ul>
<li><span class="math inline">\(A\)</span> is the interior of <span
class="math inline">\(C^-\)</span>.</li>
<li><span class="math inline">\(B\)</span> is the exterior of <span
class="math inline">\(C^+\)</span>.</li>
<li><span class="math inline">\(C\)</span> is the region between <span
class="math inline">\(C^+\)</span> and <span
class="math inline">\(C^-\)</span> and outside <span
class="math inline">\(\textsf{cycle}(T, xy)\)</span>.</li>
<li><span class="math inline">\(D\)</span> is the region between <span
class="math inline">\(C^+\)</span> and <span
class="math inline">\(C^-\)</span> and inside <span
class="math inline">\(\textsf{cycle}(T, xy)\)</span>.</li>
</ul>
<figure>
<img src="Fig/cycle-separator.png" style="width:30.0%"
alt="Regions in the cycle-separator algorithm." />
<figcaption aria-hidden="true">Regions in the cycle-separator
algorithm.</figcaption>
</figure>
<p>Let <span class="math inline">\(W(S)\)</span> denote the total weight
of the set of faces <span class="math inline">\(S\)</span>. By
construction we have <span class="math display">\[
    \begin{aligned}
        W(A) &amp; \le W/2, &amp;&amp;&amp;
        W(B) &amp; \le W/2, &amp;&amp;&amp;
        W(C) &amp; \le 3W/4, &amp;&amp;&amp;
        W(D) &amp; \le 3W/4.
    \end{aligned}
\]</span> At least one of these four regions contains total weight at
least <span class="math inline">\(W/4\)</span>; the boundary of that
region is a balanced cycle separator of length <span
class="math inline">\(O(\sqrt{n})\)</span>.</p>
<p>Most divide-and-conquer algorithms that use cycle separators do not
delete the separator vertices to obtain smaller subgraphs. Rather, the
algorithms <em>slice</em> the planar map along the cycle separator to
obtain smaller <em>maps</em>, called <em>pieces</em> of the original
map, one containing the faces inside the cycle and the other containing
the faces outside. Both pieces contain a copy of the <span
class="math inline">\(O(\sqrt{n})\)</span> vertices and edges of the
separator. Thus, the total size of all subproblems is larger at deeper
levels of the recursion tree, but because that increase is sublinear, we
can ignore it when solving the resulting divide-and-conquer
recurrences.</p>
<h2 data-number="17.5"
id="good-r-divisions-and-subdivision-hierarchies"><span
class="header-section-number">17.5</span> Good <span
class="math inline">\(r\)</span>-divisions and Subdivision
Hierarchies</h2>
<p>An <span class="math inline">\(r\)</span>-division is a decomposition
of a planar map into <span class="math inline">\(n/r\)</span>
<em>pieces</em>, each of which has <span
class="math inline">\(O(r)\)</span> vertices and <span
class="math inline">\(O(\sqrt{r})\)</span> boundary vertices (shared
with other pieces). An <span class="math inline">\(r\)</span>-division
is <em>good</em> if each piece is a disk with <span
class="math inline">\(O(1)\)</span> holes. For any <span
class="math inline">\(r\)</span>, we can construct a good <span
class="math inline">\(r\)</span>-division by recursively slicing the
input triangulation along balanced cycle separators. In fact, this
subdivision strategy computes a <em>subdivision hierarchy</em> that
includes good <span class="math inline">\(r\)</span>-divisions for
arbitrary values of <span class="math inline">\(r\)</span>.</p>
<p>In each recursive call, we are given a region <span
class="math inline">\(R\)</span>, which is a connected subcomplex of the
original triangulation <span class="math inline">\(\Sigma\)</span>. Any
face of the region <span class="math inline">\(R\)</span> that is not a
face of <span class="math inline">\(\Sigma\)</span> is called a
<em>hole</em>; any vertex of <span class="math inline">\(R\)</span> that
is incident to a hole is a <em>boundary vertex</em> of <span
class="math inline">\(R\)</span>. To split <span
class="math inline">\(R\)</span> into two smaller regions, we first
triangulate <span class="math inline">\(R\)</span> by inserting an
artificial vertex <span class="math inline">\(v_h\)</span> inside each
hole <span class="math inline">\(h\)</span>, along with artificial edges
connecting <span class="math inline">\(v_h\)</span> to each corner of
<span class="math inline">\(h\)</span>. We then compute a cycle
separator in the resulting triangulation <span
class="math inline">\(R’\)</span>, splitting it into two smaller
triangulated regions <span class="math inline">\(R’_0\)</span> and <span
class="math inline">\(R’_1\)</span>. Finally, we delete the artificial
vertices and edges from <span class="math inline">\(R’_0\)</span> and
<span class="math inline">\(R’_1\)</span> to get the final regions <span
class="math inline">\(R_0\)</span> and <span
class="math inline">\(R_1\)</span>.</p>
<figure>
<img src="Fig/recursive-decomposition.png" style="width:95.0%"
alt="A region with three holes, a cycle separator for the triangulated region, and the resulting smaller regions." />
<figcaption aria-hidden="true">A region with three holes, a cycle
separator for the triangulated region, and the resulting smaller
regions.</figcaption>
</figure>
<p>To simultaneously bound the number of vertices, the number of
boundary vertices, and the number of holes in the final regions, we
cycle through three different vertex weights at different levels of
recursion. Specifically, at recursion depth <span
class="math inline">\(l\)</span>, we weight the vertices as follows:</p>
<ul>
<li>If <span class="math inline">\(l\bmod 3 = 0\)</span>, we give
natural vertices weight <span class="math inline">\(1\)</span> and
artificial vertices weight <span class="math inline">\(0\)</span>, so
that the separator splits natural vertices evenly.</li>
<li>If <span class="math inline">\(l\bmod 3 = 1\)</span>, we give
boundary vertices weight <span class="math inline">\(1\)</span> and all
other vertices weight <span class="math inline">\(0\)</span>, so that
the separator splits boundary vertices evenly.</li>
<li>If <span class="math inline">\(l\bmod 3 = 2\)</span>, we give
artificial vertices weight <span class="math inline">\(1\)</span> and
natural vertices weight <span class="math inline">\(0\)</span>, so that
the separator splits holes evenly.</li>
</ul>
<p>Let <span class="math inline">\(T_r(n, b, h)\)</span> denote the time
to compute a good <span class="math inline">\(r\)</span>-division for a
region with <span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(b\)</span> boundary vertices, and <span
class="math inline">\(h\)</span> holes. Expanding out three levels of
recursion, we have <span class="math display">\[
    T_r(n, b, h)
    =
    O(n + h) + \sum_{i=1}^8 T_r(n_i, b_i, h_i),
\]</span> where <span class="math display">\[
    \begin{aligned}
        \sum_{i=1}^8 n_i &amp;\le n + O(\sqrt{n})
        &amp; \sum_{i=1}^8 b_i &amp;\le b + O(\sqrt{n})
        &amp; \sum_{i=1}^8 h_i &amp;\le h + O(1)
        \\
        \max_i n_i &amp;\le 3n/4 + O(\sqrt{n})
        &amp; \max_i b_i &amp;\le 3b/4 + O(\sqrt{n})
        &amp; \max_i h_i &amp;\le 3h/4 + O(1)
    \end{aligned}
\]</span> for suitable absolute big-Oh constants. The recursion stops
when the number of vertices in each piece is <span
class="math inline">\(O(r)\)</span>. Every leaf in the recursion tree
has depth at most <span class="math inline">\(O(\log (n/r))\)</span>,
and there are at most <span class="math inline">\(O(n/r)\)</span> such
leaves. One can prove by induction that in every recursive subproblem,
the number of boundary vertices is at most <span
class="math inline">\(O(\sqrt{r})\)</span> and the number of holes is at
most <span class="math inline">\(O(1)\)</span>, so we end with a good
<span class="math inline">\(r\)</span>-division. We perform <span
class="math inline">\(O(n)\)</span> work at every level of recursion, so
the overall running time of the algorithm is <span
class="math inline">\(T_r(n, 0, 0) = O(n \log(n/r))\)</span>. In
particular, if <span class="math inline">\(r = O(1)\)</span>, the entire
algorithm runs in <span class="math inline">\(O(n\log n)\)</span>
time.</p>
<p><strong>Theorem:</strong> <em>Given a planar triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices, we can compute a recursive
subdivision of <span class="math inline">\(\Sigma\)</span>, containing
good <span class="math inline">\(r\)</span>-divisions of <span
class="math inline">\(\Sigma\)</span> for every <span
class="math inline">\(r \ge r_0\)</span>, in <span
class="math inline">\(O(n \log (n/r_0))\)</span> time.</em></p>
<p><strong>Corollary:</strong> <em>Given a planar triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and an integer <span
class="math inline">\(r\)</span>, we can compute a good <span
class="math inline">\(r\)</span>-division of <span
class="math inline">\(\Sigma\)</span> in <span class="math inline">\(O(n
\log (n/r))\)</span> time.</em></p>
<p>Some applications of separators actually require a nested sequence of
good <span class="math inline">\(r\)</span>-divisions with exponentially
decreasing values of <span class="math inline">\(r\)</span>. For any
vector <span class="math inline">\(\vec{r} = (r_1, r_2, \dots,
r_t)\)</span> where <span class="math inline">\(r_i &lt;
r_{i-1}/\alpha\)</span> for some suitable constant <span
class="math inline">\(\alpha\)</span>, a <em>good <span
class="math inline">\(\vec{r}\)</span>-division</em> of a planar map
<span class="math inline">\(\Sigma\)</span> consists of a good <span
class="math inline">\(r_1\)</span>-division <span
class="math inline">\(\mathcal{R}_1\)</span> of <span
class="math inline">\(\Sigma\)</span> and (unless <span
class="math inline">\(t=1\)</span>) a good <span
class="math inline">\((r_2, \dots, r_t)\)</span>-division of each piece
of <span class="math inline">\(\mathcal{R}_1\)</span>. We can easily
extract a good <span class="math inline">\(\vec{r}\)</span>-division
from any good subdivision hierarchy in <span
class="math inline">\(O(n)\)</span> time.</p>
<p><strong>Corollary:</strong> <em>Given a planar triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices, and any exponentially
decreasing vector <span class="math inline">\(\vec{r} = (r_1, r_2,
\dots, r_t)\)</span>, we can construct a good <span
class="math inline">\(\vec{r}\)</span>-division of <span
class="math inline">\(\Sigma\)</span> in <span class="math inline">\(O(n
\log (n/r_t))\)</span> time.</em></p>
<h2 data-number="17.6" id="history"><span
class="header-section-number">17.6</span> History</h2>
<p>Greg Frederickson introduced <span
class="math inline">\(r\)</span>-divisions (based on non-cycle
separators) in 1989. The current definition of good <span
class="math inline">\(r\)</span>-division was proposed by Philip Klein
and Sairam Subramanian in 1998. The three-phase algorithm I’ve just
described was first proposed by Jittat Fakcharoenphol and Satish Rao in
2006, and extended to <span
class="math inline">\(\vec{r}\)</span>-divisions by Philip Klein, Shay
Mozes, and Christian Sommer in 2013.</p>
<p>This is not the fastest algorithm known for computing good <span
class="math inline">\(r\)</span>-divisions. A different algorithm for
constructing a good <span class="math inline">\(r\)</span>-division in
<span class="math inline">\(O(n\log r + O(n/\sqrt{r})\log n)\)</span>
time was described by Giuseppe Italiano, Yahav Nussbaum, Piotr
Sankowski, and Christian Wulff-Nilsen in 2011.</p>
<p>In 1996, Lyudmil Aleksandrov and Hristo Djidjev described an <span
class="math inline">\(O(n)\)</span>-time algorithm to construct <span
class="math inline">\(r\)</span>-divisions based on Lipton-Tarjan
separators, for any given <span class="math inline">\(r\)</span>. In
2013, Lars Arge, Freek van Walderveen, and Norbert Zeh described an
algorithm to construct a single <em>good</em> <span
class="math inline">\(r\)</span>-division in <span
class="math inline">\(O(n)\)</span> time. <strong><em>[[[How do these
algorithms work?]]]</em></strong></p>
<p>The first linear-time algorithm for building a subdivision
<em>hierarchy</em> containing <span
class="math inline">\(r\)</span>-divisions for every <span
class="math inline">\(r\)</span> was described by Michael Goodrich in
1996. Klein, Mozes, and Sommer described a similar algorithm to compute
a <em>good</em> subdivision hierarchy in <span
class="math inline">\(O(n)\)</span> time.<a href="#fn46"
class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a>
Both of these algorithms use dynamic forest data structures (to maintain
tree-cotree decompositions of the pieces, identify fundamental cycle
separators, compute least common ancestors, and compute the weight
enclosed by short cycles), along with several other data structures.</p>
<!--
These algorithms find each separator in the hierarchy in only $O(\sqrt{r}\log^2 r)$ time; the overall running time is dominated by the time to build the initial tree-cotree decomposition, compute levels for vertices or faces of the input triangulation, and initialize the data structures.
-->
<p>In the next lecture we’ll see how to use good <span
class="math inline">\(r\)</span>-divisions to compute shortest paths
quickly.</p>
<h2 data-number="17.7" id="references-10"><span
class="header-section-number">17.7</span> References</h2>
<ol type="1">
<li><p>Lyudmil Aleksandrov and Hristo Djidjev. <a
href="https://doi.org/10.1137/S0895480194272183">Linear algorithms for
partitioning embedded graphs of bounded genus</a>. <em>SIAM J. Discrete
Math.</em> 9(1):129–150, 1996.</p></li>
<li><p>Lars Arge, Freek van Walderveen, and Norbert Zeh. <a
href="http://doi.org/10.1137/1.9781611973105.65">Multiway simple cycle
separators and {I/O}-efficient algorithms for planar graphs</a>.
<em>Proc. 24th Ann. ACM-SIAM Symp. Discrete Algorithms</em>, 901–918,
2013. <!--
1. Sergio Cabello. [Many distances in planar graphs](https://dl.acm.org/doi/10.5555/1109557.1109691). _Proc. 17th Ann. ACM-SIAM Symp. Discrete Algorithms_, 1213–1220, 2006.

1. Sergio Cabello. [Many distances in planar graphs](https://10.1007/s00453-010-9459-0). _Algorithmica_ 62(1–2):361–381, 2010.
--></p></li>
<li><p>Jittat Fakcharoenphol and Satish Rao. <a
href="https://doi.org/10.1016/j.jcss.2005.05.007">Planar graphs,
negative weight edges, shortest paths, and near linear time</a>. <em>J.
Comput. Syst. Sci.</em> 72(5):868–889, 2006.</p></li>
<li><p>Eli Fox-Epstein, Shay Mozes, Phitchaya Mangpo Phothilimthana, and
Christian Sommer. <a href="https://doi.org/10.1145/2957318">Short and
simple cycle separators in planar graphs</a>. <em>ACM
J. Exp. Algorithmics</em> 21(1):2.2:1–2.2:24, 2016.</p></li>
<li><p>Greg N. Frederickson. <a
href="https://doi.org/10.1137/0216064">Fast algorithms for shortest
paths in planar graphs with applications</a>. <em>SIAM J. Comput.</em>
16(8):1004–1004, 1987.</p></li>
<li><p>Michael T. Goodrich. <a
href="https://doi.org/10.1006/jcss.1995.1076">Planar separators and
parallel polygon triangulation</a>. <em>J. Comput. Syst. Sci.</em>
51(3):374–389, 1995.</p></li>
<li><p>Sariel Har-Peled and Amir Nayyeri. <a
href="https://doi.org/10.48550/arXiv.1709.08122">A simple algorithm for
computing a cycle separator</a>. Preprint, September 2017.
arXiv:1709.08122.</p></li>
<li><p>Giuseppe F. Italiano, Yahav Nussbaum, Piotr Sankowski, and
Christian Wulff-Nilsen. <a
href="https://doi.org/10.1145/1993636.1993679">Improved algorithms for
min cut and max flow in undirected planar graphs</a>. <em>Proc. 43rd
Ann. ACM Symp. Theory Comput.</em>, 313–322, 2011.</p></li>
<li><p>Camille Jordan. <a href="http://eudml.org/doc/148084">Sur les
assemblages de lignes</a>. <em>J. Reine Angew. Math.</em> 70:185–190,
1869.</p></li>
<li><p>Philip N. Klein, Shay Mozes, and Christian Sommer. <a
href="https://doi.org/10.1145/2488608.2488672">Structured recursive
separator decompositions for planar graphs in linear time</a>. <em>Proc.
45th Ann. ACM Symp. Theory Comput.</em>, 505–514, 2013. arXiv:<a
href="https://arxiv.org/abs/1208.2223">1208.2223</a>.</p></li>
<li><p>Philip N. Klein and Sairam Subramanian. <a
href="https://doi.org/10.1007/PL00009223">A fully dynamic approximation
scheme for shortest paths in planar graphs</a>. <em>Algorithmica</em>
22(3):235–249, 1998.</p></li>
<li><p>Richard J. Lipton and Robert E. Tarjan. <a
href="https://doi.org/10.1137/0136016">A separator theorem for planar
graphs</a>. <em>SIAM J. Applied Math.</em> 36(2):177–189, 1979.</p></li>
<li><p>Richard J. Lipton and Robert Endre Tarjan. <a
href="https://doi.org/10.1137/0209046">Applications of a planar
separator theorem</a>. <em>SIAM J. Comput.</em> 9:615–627,
1980.</p></li>
<li><p>Gary L. Miller. <a
href="https://doi.org/10.1016/0022-0000(86)90030-9">Finding small simple
cycle separators for 2-connected planar graphs</a>. <em>J. Comput.
System Sci.</em> 32(3):265–279, 1986.</p></li>
</ol>
<h2 data-number="17.8" id="aptly-named-sir-not"><span
class="header-section-number">17.8</span> Aptly Named Sir Not</h2>
<ul>
<li>Cycle separators via Koebe-Andreev circle packing</li>
<li>Details of <span class="math inline">\(r\)</span> divisions (and
recursive <span class="math inline">\(r\)</span>-divisions) in <span
class="math inline">\(O(n)\)</span> time.</li>
</ul>
<h1 data-number="18" id="branch-decompositionsvarnothing"><span
class="header-section-number">18</span> Branch Decompositions<span
class="math inline">\(^\varnothing\)</span></h1>
<h2 data-number="18.1" id="branchwidth"><span
class="header-section-number">18.1</span> Branchwidth</h2>
<h2 data-number="18.2" id="treewidth"><span
class="header-section-number">18.2</span> Treewidth</h2>
<h2 data-number="18.3" id="width-versus-diameter"><span
class="header-section-number">18.3</span> Width versus diameter</h2>
<h2 data-number="18.4" id="local-approximation"><span
class="header-section-number">18.4</span> Local approximation</h2>
<h2 data-number="18.5" id="aptly-named-sir-not-1"><span
class="header-section-number">18.5</span> Aptly Named Sir Not</h2>
<h1 data-number="19" id="fast-shortest-paths-in-planar-graphsbeta"><span
class="header-section-number">19</span> Fast Shortest Paths in Planar
Graphs<span class="math inline">\(^\beta\)</span></h1>
<h2 data-number="19.1" id="dense-distance-graphs"><span
class="header-section-number">19.1</span> Dense Distance Graphs</h2>
<p>One of the most important applications of separators and <span
class="math inline">\(r\)</span>-divisions in planar graphs is faster
algorithms to computer shortest paths. Most of these faster algorithms
rely on an implicit representation of shortest-path distances called the
<em>dense distance graph</em>, first explicitly described by Jittat
Fakcharoenphol and Satish Rao in 2001, but already implicit in Lipton,
Rose, and Tarjan’s 1979 nested dissection algorithm, which we will
discuss shortly.</p>
<p>Let <span class="math inline">\(\Sigma\)</span> be a simple planar
map with weighted darts; for now we’ll assume that all edge weights are
non-negative. If necessary, add infinite-weight edges so that <span
class="math inline">\(\Sigma\)</span> is a simple triangulation. Recall
that a <em>good <span class="math inline">\(r\)</span>-division</em> of
<span class="math inline">\(\Sigma\)</span> is a subdivision of <span
class="math inline">\(\Sigma\)</span> into <span
class="math inline">\(O(n/r)\)</span> <em>pieces</em> <span
class="math inline">\(R_1, R_2, \dots\)</span> satisfying three
conditions:</p>
<ul>
<li>Each piece has <span class="math inline">\(O(r)\)</span>
vertices.</li>
<li>Each piece has <span class="math inline">\(O(\sqrt{r})\)</span>
boundary vertices (that is, vertices that are shared with other
pieces).</li>
<li>Each piece has <span class="math inline">\(O(1)\)</span>
<em>holes</em> (faces of the piece that are not faces of <span
class="math inline">\(\Sigma\)</span>).</li>
</ul>
<p>Fix a good <span class="math inline">\(r\)</span>-division <span
class="math inline">\(\mathcal{R}\)</span>. For each piece <span
class="math inline">\(R_i \in \mathcal{R}\)</span>, let <span
class="math inline">\(X_i\)</span> be a complete directed graph over the
boundary vertices of <span class="math inline">\(R_i\)</span>, where
each dart <span class="math inline">\(u{\to} v\)</span> is weighted by
the shortest-path distance in <span class="math inline">\(R_i\)</span>
from its tail <span class="math inline">\(u\)</span> to its head <span
class="math inline">\(v\)</span>. The dense distance graph is the union
of these <span class="math inline">\(O(n/r)\)</span> weighted cliques.
Altogether, the dense distance graph has <span class="math inline">\(n’
= O(n/\sqrt{r})\)</span> vertices—only the boundary vertices of the
pieces of the <span class="math inline">\(r\)</span>-division—and <span
class="math inline">\(m’ = O(n)\)</span> weighted darts.</p>
<p>Assuming all dart weights are non-negative, we can compute all <span
class="math inline">\(O(r)\)</span> boundary-to-boundary shortest-path
distances in each piece <span class="math inline">\(R_i\)</span> in
<span class="math inline">\(O(r\log r)\)</span> time, by running the
multiple-source shortest-path algorithm once for each hole in <span
class="math inline">\(R_i\)</span>, using Dijkstra’s algorithm to
compute the initial shortest-path tree. Thus, the overall time to
compute the dense-distance graph is <span class="math inline">\(O(n\log
r)\)</span>.</p>
<h2 data-number="19.2" id="beating-dijkstra"><span
class="header-section-number">19.2</span> Beating Dijkstra</h2>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Given any planar map <span class="math inline">\(\Sigma\)</span>
with non-negative lengths on its edges, we can compute the shortest path
from any vertex <span class="math inline">\(s\)</span> to every other
vertex of <span class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n\log\log n)\)</span> time.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We begin by triangulating <span class="math inline">\(\Sigma\)</span> in
<span class="math inline">\(O(n)\)</span> time, building a good <span
class="math inline">\(r\)</span>-division for the resulting
triangulation in <span class="math inline">\(O(n)\)</span> time, and
building the dense distance graph for the <span
class="math inline">\(r\)</span>-division in <span
class="math inline">\(O(n\log r)\)</span> time, for some parameter <span
class="math inline">\(r\)</span> to be determined. In the top-level
recursive call to build the good <span
class="math inline">\(r\)</span>-division, we artificially declare <span
class="math inline">\(s\)</span> to be a boundary vertex, so that it
survives as a vertex in the dense-distance graph.
</dd>
<dd>
<p>Next we compute the shortest-path distance from <span
class="math inline">\(s\)</span> to every boundary vertex of the <span
class="math inline">\(r\)</span>-division by running Dijkstra’s
algorithm in the dense distance graph. If we implement Dijkstra’s
algorithm using Fibonacci heaps, this step takes <span
class="math inline">\(O(n’\log n’ + m’) = O((n/\sqrt{r})\log n +
n)\)</span> time.</p>
</dd>
<dd>
<p>Finally, for each piece <span class="math inline">\(P\)</span>, we
attach an artificial course <span class="math inline">\(s’\)</span> to
each boundary vertex <span class="math inline">\(u\)</span> with an edge
with length <span class="math inline">\(\textsf{dist}(s,u)\)</span>, and
compute a shortest path tree in <span class="math inline">\(P\)</span>
from <span class="math inline">\(s’\)</span> using Dijkstra’s algorithm.
This step takes <span class="math inline">\(O(r\log r)\)</span> time per
piece, or <span class="math inline">\(O(n\log r)\)</span> time
overall.</p>
</dd>
<dd>
<p>The overall running time of our algorithm is <span
class="math inline">\(O(n\log r + (n/\sqrt{r})\log n)\)</span>. In
particular, if we set <span class="math inline">\(r = O(\log^2
n)\)</span>, the running time is <span class="math inline">\(O(n\log\log
n)\)</span>. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Let me reiterate that this analysis assumes that we are using the
<em>parametric</em> multiple-source shortest path algorithm to construct
the dense-distance graph. If we try to use the more recent
<em>contraction-based</em> MSSP algorithm of Das et al. instead, we end
up with two mutually recursive algorithms, one computing single-course
shortest paths, the other computing multiple-source shortest paths. The
running time of the resulting single-source shortest-path algorithm is
<span class="math inline">\(O(n\,\log\log n\, \log\log\log n\,
\log\log\log\log n\cdots)\)</span>.</p>
<p>The idea to use <span class="math inline">\(r\)</span>-divisions to
speed up planar shortest paths is due to Greg Frederickson, who
described an algorithm that runs in <span
class="math inline">\(O(n\sqrt{\log n})\)</span> time in 1987. Ten years
later, Monika Henzinger, Philip Klein, Satish Rao, and Sairam
Subramanian described an algorithm that runs in <span
class="math inline">\(O(n)\)</span> time. Both of these algorithms
predate both good <span class="math inline">\(r\)</span>-divisions and
Klein’s multiple-source shortest-path algorithm. Instead, these
algorithms are variants of Dijkstra’s algorithm that recursively relax
pieces of a carefully chosen recursive separator decomposition, instead
of relaxing individual edges. Unlike the <span
class="math inline">\(O(n\log\log n)\)</span> algorithm I’ve described
above, which relies on <em>good</em> <span
class="math inline">\(r\)</span>-divisions and planarity, the <span
class="math inline">\(O(n)\)</span>-time algorithm of Henzinger et
al. generalizes directly to any minor-closed family of graphs with
bounded vertex degrees; the bounded-degree restriction was later removed
by Tazari and Müller-Hannemann.</p>
<h2 data-number="19.3" id="beating-bellman-ford-nested-dissection"><span
class="header-section-number">19.3</span> Beating Bellman-Ford: Nested
Dissection</h2>
<p>Depending on which textbook you read, Dijkstra’s algorithm is either
no longer correct or no longer efficient when some darts of the input
graph have negative weight. In particular, if <span
class="math inline">\(\Sigma\)</span> contains negative darts, we can no
longer solve the multiple-source shortest-path problem in <span
class="math inline">\(O(n\log n)\)</span> time, because we don’t know
how compute the initial shortest-path trees that quickly.<a href="#fn47"
class="footnote-ref" id="fnref47"
role="doc-noteref"><sup>47</sup></a></p>
<p>The standard shortest-paths algorithm for graphs with negative edges
is <em>Bellman-Ford</em>, which runs in <span
class="math inline">\(O(mn)\)</span> time; in particular, for simple
planar graphs with <span class="math inline">\(n\)</span> vertices,
Bellman-Ford runs in <span class="math inline">\(O(n^2)\)</span> time.
But just as we beat Dijkstra’s algorithm, we can beat Bellman-Ford when
the underlying graph is planar.</p>
<p>The following <em>generalized nested dissection</em> algorithm,
proposed by Richard Lipton, Donald Rose, and Robert Tarjan in 1979, was
one of the earliest applications of planar separators. (The original
nested dissection algorithm, proposed by Alan George in 1973, applied
only to square grid graphs.) Although their algorithm was originally
designed for abstract planar <em>graphs</em> rather than planar
<em>maps</em>, the presentation and analysis are simpler if we use good
<span class="math inline">\(r\)</span>-divisions, which require a planar
embedding.</p>
<p>We are given a simple planar graph (sic) <span
class="math inline">\(G\)</span> with asymmetrically weighted darts,
where some of the darts weights may be negative, and a source vertex
<span class="math inline">\(s\)</span>. At a very high level, our
strategy is to delete one vertex of <span
class="math inline">\(G\)</span> using a <em>star-mesh
transformation</em>, compute shortest-path distances from <span
class="math inline">\(s\)</span> to every remaining vertex of <span
class="math inline">\(G\)</span>, and finally compute the shortest-path
distance from <span class="math inline">\(s\)</span> to <span
class="math inline">\(v\)</span>. A star-mesh transformation adds or
reweights edges between the neighbors of the deleted vertex <span
class="math inline">\(v\)</span> to restore shortest-path distances.
Specifically, if there is no edge <span
class="math inline">\(uw\)</span> between two neighbors <span
class="math inline">\(u\)</span> and <span
class="math inline">\(w\)</span>, we add one with dart weights <span
class="math display">\[
    \begin{aligned}
        \ell(u{\to}w) &amp;\gets \ell(u{\to}v) + \ell(v{\to}w)\\
        \ell(w{\to}u) &amp;\gets \ell(w{\to}v) + \ell(v{\to}u);
    \end{aligned}
\]</span> on the other hand, if edge <span
class="math inline">\(uw\)</span> already exists, we change its dart
weights as follows: <span class="math display">\[
    \begin{aligned}
        \ell(u{\to}w)
        &amp;\gets \min \big\{ \ell(u{\to}w),~
                            \ell(u{\to}v) + \ell(v{\to}w) \big\}
        \\
        \ell(w{\to}u)
        &amp;\gets \min\big\{ \ell(w{\to}u),~
                            \ell(w{\to}v) + \ell(v{\to}u) \big\}
    \end{aligned}
\]</span> These changes preserve shortest-path distances from any vertex
except <span class="math inline">\(v\)</span> to any other vertex except
<span class="math inline">\(v\)</span>.<a href="#fn48"
class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a>
With the appropriate graph data structures, deleting <span
class="math inline">\(v\)</span> takes <span
class="math inline">\(O(\deg(v)^2)\)</span> time.</p>
<p>After the Recursion Fairy computes distances from <span
class="math inline">\(s\)</span> to all other vertices, we can recover
the distance from <span class="math inline">\(s\)</span> to <span
class="math inline">\(v\)</span> by brute force in <span
class="math inline">\(O(\deg(v))\)</span> time: <span
class="math display">\[
    \textsf{dist}(v)
        \gets \min_{u{\to}v} \big\{\textsf{dist}(u) +
\ell(u{\to}v)\big\}
\]</span> In both running times, <span
class="math inline">\(\deg(v)\)</span> refers to the degree of <span
class="math inline">\(v\)</span> <em>when <span
class="math inline">\(v\)</span> is eliminated</em>, not in the original
graph <span class="math inline">\(G\)</span>. Different elimination
orders can lead to different vertex degrees and therefore different
running times. Star-mesh transformations do not preserve planarity, but
this elimination process works for <em>arbitrary</em> graphs.</p>
<p>Lipton, Rose, and Tarjan recursively construct an elimination order
for <em>planar</em> graphs as follows. Let <span
class="math inline">\(S\)</span> be a balanced separator that contains
the source vertex <span class="math inline">\(s\)</span>, and let <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> be a partition of the vertices <span
class="math inline">\(V\setminus S\)</span> so that there is no edge
directly from <span class="math inline">\(A\)</span> to <span
class="math inline">\(B\)</span>. We first recursively eliminate all
vertices in <span class="math inline">\(A\)</span>, then recursively
eliminate all vertices in <span class="math inline">\(B\)</span>, and
finally eliminate all vertices in <span class="math inline">\(S\)</span>
<em>except <span class="math inline">\(s\)</span></em> in arbitrary
order. Opening up the recursive calls, the algorithm construct a
complete separator hierarchy, and then eliminates vertices using a
postorder traversal of the decomposition tree.</p>
<p>If we only eliminate the interior vertices of each piece of a fixed
<span class="math inline">\(r\)</span>-division in this hierarchy, the
result is precisely the dense-distance graph defined by Fakcharoenphol
and Rao!</p>
<p>Suppose we build a <em>good</em> separator hierarchy using the
algorithm of Klein, Mozes, and Sommer. Let <span
class="math inline">\(T_\downarrow(r)\)</span> denote the worst-case
time to eliminate all <em>interior</em> vertices in a piece with <span
class="math inline">\(r\)</span> vertices, and let <span
class="math inline">\(T_\uparrow(r)\)</span> denote the time to compute
distances to the interior vertices in a piece with <span
class="math inline">\(r\)</span> vertices after distances to the
boundary vertices are known. The separation algorithm guarantees that
each piece of size <span class="math inline">\(r\)</span> has <span
class="math inline">\(O(\sqrt{r})\)</span> boundary vertices and a
separator of size <span class="math inline">\(O(\sqrt{r})\)</span>.
Thus, after recursively eliminating the interior vertices of the
subpieces, each interior vertex on the separator has degree <span
class="math inline">\(O(\sqrt{r})\)</span>. It follows that the
functions <span class="math inline">\(T_\downarrow\)</span> and <span
class="math inline">\(T_\uparrow\)</span> satisfy the recurrences <span
class="math display">\[
    \begin{aligned}
    T_\downarrow(r) &amp;= T_\downarrow(r_L) + T_\downarrow(r_R) +
O(r^{3/2})
    \\[0.5ex]
    T_\uparrow(r) &amp;= T_\uparrow(r_L) + T_\uparrow(r_R) + O(r)
    \end{aligned}
\]</span> where <span class="math inline">\(r_L + r_R &lt; r\)</span>
and <span class="math inline">\(\max\{r_L, r_R\} \le 3r/4\)</span>.<a
href="#fn49" class="footnote-ref" id="fnref49"
role="doc-noteref"><sup>49</sup></a> These recurrences solve to <span
class="math inline">\(T_\downarrow(r) = O(r^{3/2})\)</span> and <span
class="math inline">\(T_\uparrow(r) = O(r\log r)\)</span>.</p>
<p><strong>Theorem:</strong> <em>Given a planar graph <span
class="math inline">\(G\)</span> with weighted darts, some of which may
be negative, and a source vertex <span class="math inline">\(s\)</span>,
we can compute the shortest path from <span
class="math inline">\(s\)</span> to every other vertex of <span
class="math inline">\(G\)</span> in <span
class="math inline">\(O(n^{3/2})\)</span> time.</em></p>
<h2 data-number="19.4" id="aside-computing-spring-embeddings"><span
class="header-section-number">19.4</span> Aside: Computing Spring
Embeddings</h2>
<p>Almost exactly the same nested-dissection algorithm can be used to
solve any <span class="math inline">\(n\times n\)</span> system of
linear equations whose support matrix is the adjacency matrix of a
planar graph, in <span class="math inline">\(O(n^{3/2})\)</span> time.
The only differences are that we use stress coefficients instead of
lengths, addition instead of minimization, and multiplication instead of
addition.</p>
<p>In particular, we can compute Tutte spring embeddings in <span
class="math inline">\(O(n^{3/2})\)</span> time as follows. Recall that
the input consists of a planar graph <span
class="math inline">\(G\)</span>, where every dart <span
class="math inline">\(u{\to}v\)</span> has a positive weight <span
class="math inline">\(\lambda(u{\to}v)\)</span>. Without loss of
generality, suppose <span class="math inline">\(\sum_{x{\to}y}
\lambda(x{\to}y) = 1\)</span> for every vertex <span
class="math inline">\(y\)</span>. When we eliminate any vertex <span
class="math inline">\(v\)</span>, we adjust the stress coefficients
between neighbors of <span class="math inline">\(v\)</span> by setting
<span class="math display">\[
    \lambda(u{\to}w)
    \gets \lambda(u{\to}w) + \lambda(u{\to}v) \cdot \lambda(v{\to}w)
\]</span> for every pair of neighbors <span
class="math inline">\(u\)</span> and <span
class="math inline">\(w\)</span>, and setting <span
class="math inline">\(\lambda(v{\to}w) \gets 0\)</span> for every
neighbor <span class="math inline">\(w\)</span>. (These adjustments
preserve the invariant <span class="math inline">\(\sum_{x{\to}y}
\lambda(x{\to}y) = 1\)</span> at every vertex <span
class="math inline">\(y\)</span>.) On the way back up, we can recover
the position of vertex <span class="math inline">\(v\)</span> using the
equilibrium equation <span class="math display">\[
    p(v) \gets \sum_{u{\to}v} \lambda(u{\to}v)\cdot p(u).
\]</span> This elimination and recovery procedure is normally called
<em>Gaussian elimination</em>.<a href="#fn50" class="footnote-ref"
id="fnref50" role="doc-noteref"><sup>50</sup></a> Precisely the same
analysis as the previous theorem immediately implies:</p>
<p><strong>Theorem:</strong> <em>Given a planar graph <span
class="math inline">\(G\)</span> with positively weighted darts, with
one face identified with a convex polygon, we can compute the Tutte
embedding of <span class="math inline">\(G\)</span> in <span
class="math inline">\(O(n^{3/2})\)</span> time.</em></p>
<p>The running time of generalized nested dissection can be further
improved to <span class="math inline">\(O(n^{\omega/2})\)</span> using a
fast-matrix multiplication algorithm in place of eliminating separator
vertices. On the other hand, Lipton, Rose, and Tarjan’s algorithm cannot
solve <em>arbitrary</em> planar linear systems over arbitrary fields;
the underlying matrix must satisfy some subtle algebraic restrictions,
and the field must have characteristic zero (<span
class="math inline">\(\mathbb{Q}\)</span>, <span
class="math inline">\(\mathbb{R}\)</span>, or <span
class="math inline">\(\mathbb{C}\)</span>).<a href="#fn51"
class="footnote-ref" id="fnref51" role="doc-noteref"><sup>51</sup></a>
In 2010 Noga Alon and Raphael Yuster described a more complex variant
that avoids these restrictions.</p>
<h2 data-number="19.5" id="repricing"><span
class="header-section-number">19.5</span> Repricing</h2>
<p>More recent planar shortest-path algorithms improve Lipton, Rose, and
Tarjan’s <span class="math inline">\(O(n^{3/2})\)</span> time bound to
near-linear. One of the key components of these faster algorithms is a
standard <em>repricing</em> technique first<a href="#fn52"
class="footnote-ref" id="fnref52" role="doc-noteref"><sup>52</sup></a>
proposed independently for minimum-cost flows by Nobuaki Tomizawa in
1971, and Jack Edmonds and Richard Karp in 1972, but first applied
specifically to shortest paths by Donald Johnson in 1973.</p>
<p>Suppose each vertex <span class="math inline">\(v\)</span> has an
associate <em>price</em> <span class="math inline">\(\pi(v)\)</span>. We
can assign a new edge-length function <span
class="math inline">\(\ell’\)</span> as follows: <span
class="math display">\[
    \ell’(u\mathord\to v) := \pi(u) + \ell(u\mathord\to v) - \pi(v).
\]</span> Then for any path <span class="math inline">\(s\leadsto
t\)</span> in <span class="math inline">\(G\)</span>, we have a
telescoping sum <span class="math display">\[
    \ell’(s\leadsto t) := \pi(s) + \ell(s\leadsto t) - \pi(t).
\]</span> Because the length of every path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> changes by the same amount, the
shortest paths from <span class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> with respect to <span
class="math inline">\(\ell\)</span> and <span
class="math inline">\(\ell’\)</span> coincide! Thus, if we can find a
pricing function that makes all new edge lengths <span
class="math inline">\(\ell’(u\mathord\to v)\)</span> non-negative, we
can compute shortest-path distances with respect to <span
class="math inline">\(\ell’\)</span> using Dijkstra’s algorithm in <span
class="math inline">\(O(n\log n)\)</span> time, or its more efficient
planar replacement in <span class="math inline">\(O(n\log\log
n)\)</span> time, and then recover distances with respect to <span
class="math inline">\(\ell\)</span> as follows: <span
class="math display">\[
    \textsf{dist}(s, t) := \textsf{dist}’(s,t) - \pi(s) + \pi(t).
\]</span></p>
<p>For example, suppose <span class="math inline">\(\pi(v) =
\textsf{dist}(s, v)\)</span> for some fixed source vertex <span
class="math inline">\(s\)</span>, where <span
class="math inline">\(\textsf{dist}\)</span> denotes shortest-path
distance with respect to <span class="math inline">\(\ell\)</span>. Then
we have <span class="math display">\[
    \ell’(u\mathord\to v) := \textsf{dist}(s, u) + \ell(u\mathord\to v)
- \textsf{dist}(s, v).
\]</span> Ford’s formulation of shortest paths implies that the
expression on the right is non-negative. Thus, once we’ve computed
shortest paths from <em>one</em> source, we can efficiently compute
shortest paths from any other source in near-linear time.</p>
<h2 data-number="19.6" id="nested-dissection-revisited"><span
class="header-section-number">19.6</span> Nested Dissection
Revisited</h2>
<p>Now let’s consider a different shortest-path algorithm based on
nested dissection, based on a 1983 algorithm of Kurt Mehlhorn and Bernd
Schmidt, but with some optimizations proposed by later authors.</p>
<p>As before, we are given a simple <span
class="math inline">\(n\)</span>-vertex planar triangulation <span
class="math inline">\(\Sigma\)</span> with asymmetrically (and possibly
negatively) weighted darts and a source vertex <span
class="math inline">\(s\)</span>, and we want to compute the
shortest-path distance from <span class="math inline">\(s\)</span> to
every other vertex in <span class="math inline">\(\Sigma\)</span>. To
simplify presentation, I’ll assume that no cycle in <span
class="math inline">\(\Sigma\)</span> has negative total length, so that
shortest-path distances are well-defined.</p>
<p>I will use the notation <span
class="math inline">\(\textsf{dist}_P(X, Y)\)</span> to denote the set
of all shortest-path distances in subgraph <span
class="math inline">\(P\)</span> from vertices in <span
class="math inline">\(X\)</span> to vertices in <span
class="math inline">\(Y\)</span>; our goal is to compute <span
class="math inline">\(\textsf{dist}(s, \Sigma)\)</span>.</p>
<p>The algorithm starts by computing a balanced cycle separator <span
class="math inline">\(S\)</span> for <span
class="math inline">\(\Sigma\)</span>. Let <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> be the pieces of <span
class="math inline">\(\Sigma\)</span> obtained by slicing along <span
class="math inline">\(S\)</span>, and let <span
class="math inline">\(r\)</span> be any vertex in <span
class="math inline">\(S\)</span>. The algorithm has five stages.</p>
<ol type="1">
<li><p>Recursively compute <span
class="math inline">\(\textsf{dist}_A(r, A)\)</span> and <span
class="math inline">\(\textsf{dist}_B(r, B)\)</span>. How the Recursion
Fairy does this is none of your business.</p></li>
<li><p>Compute <span class="math inline">\(\textsf{dist}_A(S,
S)\)</span> and <span class="math inline">\(\textsf{dist}_B(S,
S)\)</span>. Because <span class="math inline">\(S\)</span> is a simple
cycle, we can compute all separator-to-separator distances within each
piece time using either of our multiple-source shortest-path algorithms.
There are <span class="math inline">\(O(n)\)</span> vertices in each
piece, and we want to compute <span class="math inline">\(k = |S|^2 =
O(n)\)</span> boundary-to-boundary distances within each piece, so our
MSSP algorithms run in <span class="math inline">\(O(n\log n + k\log n)
= O(n\log n)\)</span> time.<a href="#fn53" class="footnote-ref"
id="fnref53" role="doc-noteref"><sup>53</sup></a></p></li>
</ol>
<ol start="3" type="1">
<li><p>Compute <span class="math inline">\(\textsf{dist}_\Sigma(r,
S)\)</span>. Build a complete directed graph <span
class="math inline">\(\hat{S}\)</span> with vertices <span
class="math inline">\(S\)</span>, where each dart <span
class="math inline">\(u \mathord\to v\)</span> has length <span
class="math inline">\(\min \{ \textsf{dist}_A(u,v), \textsf{dist}_B(u,v)
\}\)</span>. The graph <span class="math inline">\(\hat{S}\)</span> has
<span class="math inline">\(O(\sqrt{n})\)</span> vertices and <span
class="math inline">\(O(n)\)</span> edges, so we can compute <span
class="math inline">\(\textsf{dist}_\Sigma(r, S) =
\textsf{dist}_{\hat{S}}(r, S)\)</span> using Bellman-Ford in <span
class="math inline">\(O(r^{3/2})\)</span> time.</p></li>
<li><p>Compute <span class="math inline">\(\textsf{dist}_\Sigma(r,
\Sigma)\)</span> using Johnson’s repricing trick. We construct a graph
<span class="math inline">\(H\)</span> from the disjoint union <span
class="math inline">\(A\sqcup B\)</span> as follows. First we add an
artificial source vertex <span class="math inline">\(\hat{r}\)</span>.
Then for each separator vertex <span class="math inline">\(v\in
S\)</span>, we add directed edges <span
class="math inline">\(\hat{r}\mathord\to v_A\)</span> and <span
class="math inline">\(\hat{r}\mathord\to v_B\)</span> to the copies of
<span class="math inline">\(v\)</span> in <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span>, both with length <span
class="math inline">\(\textsf{dist}_\Sigma(r, v)\)</span>, which we
computed in step 3. For any target vertex <span
class="math inline">\(t\)</span>, we have <span
class="math inline">\(\textsf{dist}_\Sigma(r, t) =
\textsf{dist}_H(\hat{r}, t)\)</span>. Now we define prices for the
vertices of <span class="math inline">\(H\)</span> using the distances
we computed in step 2: <span class="math display">\[
\pi(v) = \begin{cases}
     \textsf{dist}_A(r, v)   &amp; \text{if $v$ is a vertex of $A$} \\
     \textsf{dist}_B(r, v)   &amp; \text{if $v$ is a vertex of $B$} \\
     \infty                  &amp; \text{if $v = \hat{r}$.}
\end{cases}
\]</span> Here <span class="math inline">\(\infty\)</span> is a symbolic
placeholder for some sufficiently large value.<a href="#fn54"
class="footnote-ref" id="fnref54" role="doc-noteref"><sup>54</sup></a>
Straightforward calculation implies that all darts in <span
class="math inline">\(H\)</span> have non-negative repriced length.
<span class="math inline">\(H\)</span> is a planar graph with <span
class="math inline">\(O(n)\)</span> vertices and edges, so we can
compute shortest paths in <span class="math inline">\(H\)</span> in
<span class="math inline">\(O(n\log n)\)</span> time via Dijkstra’s
algorithm, or in <span class="math inline">\(O(n\log\log n)\)</span>
time using our faster algorithm based on <span
class="math inline">\(r\)</span>-divisions.<a href="#fn55"
class="footnote-ref" id="fnref55"
role="doc-noteref"><sup>55</sup></a></p></li>
</ol>
<ol start="5" type="1">
<li>Finally, compute <span class="math inline">\(\textsf{dist}_\Sigma(s,
\Sigma)\)</span> using Johnson’s repricing trick, this time using the
prices <span class="math inline">\(\pi(v) =
\textsf{dist}_\Sigma(r,v)\)</span>. Again, it is not hard to verify that
every dart in <span class="math inline">\(\Sigma\)</span> has
non-negative length after repricing. Thus, we can compute <span
class="math inline">\(\textsf{dist}_\Sigma(s,\Sigma)\)</span> in <span
class="math inline">\(O(n\log n)\)</span> time using Dijkstra’s
algorithm, or in <span class="math inline">\(O(n\log\log n)\)</span>
time using our faster algorithm based on <span
class="math inline">\(r\)</span>-divisions.</li>
</ol>
<figure>
<img src="Fig/planar-neg-shortest.png" style="width:95.0%"
alt="Computing planar shortest paths by nested dissection" />
<figcaption aria-hidden="true">Computing planar shortest paths by nested
dissection</figcaption>
</figure>
<p>The overall running time <span
class="math inline">\(O(n^{3/2})\)</span> is dominated by the
application of Bellman-Ford in stage 3. Any further improvements require
speeding up Bellman-Ford, which is exactly what we’re going to do
next!</p>
<h2 data-number="19.7" id="monge-arrays-and-smawk"><span
class="header-section-number">19.7</span> Monge arrays and SMAWK</h2>
<p>A two-dimensional array <span class="math inline">\(M\)</span> is
<em>Monge</em> if <span class="math display">\[
    M[i, j] + M[i’, j’] \le M[i, j’] + M[i’, j]
\]</span> for all array indices <span
class="math inline">\(i&lt;i’\)</span> and <span
class="math inline">\(j&lt;j’\)</span>. Monge arrays are named after the
French geometer and civil engineer Gaspard Monge, who described an
equivalent geometric condition in his 1781 <em>Mémoire sur la Théorie
des Déblais et des Remblais</em>. Monge observed that if <span
class="math inline">\(A, B, b, a\)</span> are the vertices of a convex
quadtrilateral in cyclic order, the triangle inequality implies that
<span class="math inline">\(|Aa| + |Bb| &lt; |Ab| + |aB|\)</span>.</p>
<figure>
<img src="Fig/monge.png" style="width:40.0%"
alt="Monge’s observation: Non-crossing paths are shorter" />
<figcaption aria-hidden="true">Monge’s observation: Non-crossing paths
are shorter</figcaption>
</figure>
<dl>
<dt><strong>Monge Structure Lemma:</strong></dt>
<dd>
<em>The following arrays are Monge:</em>
</dd>
<dd>
<ol type="a">
<li><em>Any array with constant rows.</em></li>
</ol>
</dd>
<dd>
<ol start="2" type="a">
<li><em>Any array with constant columns.</em></li>
</ol>
</dd>
<dd>
<ol start="3" type="a">
<li><em>Any array that is all 0s except for an upper-right rectangular
block of 1s.</em></li>
</ol>
</dd>
<dd>
<ol start="4" type="a">
<li><em>Any array that is all 0s except for an lower-left rectangular
block of 1s.</em></li>
</ol>
</dd>
<dd>
<ol start="5" type="a">
<li><em>Any positive multiple of any Monge array.</em></li>
</ol>
</dd>
<dd>
<ol start="6" type="a">
<li><em>The sum of any two Monge arrays.</em></li>
</ol>
</dd>
<dd>
<ol start="7" type="a">
<li><em>The transpose of any Monge array.</em></li>
</ol>
</dd>
</dl>
<p>In 1987, Alok Aggarwal, Maria Klawe, Shlomo Moran, Peter Shor, and
Robert Wilber described an elegant recursive algorithm that finds the
minimum element in every row of an <span class="math inline">\(n\times
n\)</span> Monge array in <span class="math inline">\(O(n)\)</span>
time, now usually called the <em>SMAWK</em> algorithm after the
suitably-permuted initials of its authors. In 1990, Maria Klawe and
Daniel Kleitman described an extension to the SMAWK algorithm that finds
row-minima in <em>partial</em> Monge matrices, where some entries are
undefined, but the Monge inequality holds whenever all four entries are
defined. Klawe and Kleitman’s algorithm runs in <span
class="math inline">\(O(n\,\alpha(n))\)</span> time, where <span
class="math inline">\(\alpha(n)\)</span> is the slowly-growing inverse
Ackermann function. Very recently, Timothy Chan described a randomized
algorithm that find all row-minima in a staircase-Monge matrix in <span
class="math inline">\(O(n)\)</span> expected time.</p>
<p>A description of these algorithms is beyond the scope of this class,
but you can find a complete description and analysis of the basic SMAWK
algorithm in my <a
href="https://courses.engr.illinois.edu/cs473/sp2020/notes/D-adv-dynprog.pdf">algorithms
lecture notes</a>.</p>
<h2 data-number="19.8"
id="planar-distance-matrices-are-almost-monge"><span
class="header-section-number">19.8</span> Planar distance matrices are
(almost) Monge</h2>
<p>In the same 2001 paper where they defined dense distance graphs,
Fakcharoenphol and Rao described how to use SMAWK to compute shortest
paths in planar maps more quickly.</p>
<p>Let <span class="math inline">\(\Sigma\)</span> be a planar map with
weighted edges. Let <span class="math inline">\(s_1, s_2, \dots,
s_k\)</span> be the sequence of vertices on the boundary of the outer
face of <span class="math inline">\(\Sigma\)</span>, in cyclic order.
(If the outer face boundary is not a simple cycle, the same vertex may
appear multiple times in this list.) Let <span
class="math inline">\(D\)</span> be the <span
class="math inline">\(k\times k\)</span> array where <span
class="math inline">\(D[i,j] = \textsf{dist}_\Sigma(s_i,
s_j)\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>The distance array <span class="math inline">\(D\)</span> can be
decomposed into two partial Monge matrices.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Fix four vertices <span class="math inline">\(u, v, w, x\)</span> in
cyclic order around the boundary of the outer face of <span
class="math inline">\(\Sigma\)</span>. The Jordan curve theorem implies
that the shortest paths from <span class="math inline">\(u\)</span> to
<span class="math inline">\(w\)</span> and from <span
class="math inline">\(v\)</span> to <span
class="math inline">\(x\)</span> must cross; let <span
class="math inline">\(z\)</span> be any vertex in the intersection of
these two shortest paths. The triangle inequality implies <span
class="math display">\[
\begin{aligned}
    \textsf{dist}(u, w) + \textsf{dist}(v, x)
    &amp; =
    (\textsf{dist}(u, z) + \textsf{dist}(z, w)) ~+~
    (\textsf{dist}(v, z) + \textsf{dist}(z, x)) \\
    &amp; =
    (\textsf{dist}(u, z) + \textsf{dist}(z, x)) ~+~
    (\textsf{dist}(v, z) + \textsf{dist}(z, w)) \\
    &amp; \le
    \hphantom{(\textsf{dist}(u, z) + {}}
    \textsf{dist}(u, x)\; ~+~ \;\textsf{dist}(v, w)
\end{aligned}
\]</span> (omitting subscript <span
class="math inline">\(\Sigma\)</span>’s everywhere).
</dd>
<dd>
<p>It follows that the Monge inequality <span class="math display">\[
M[i, j] + M[i’, j’] \le M[i, j’] + M[i’, j];
\]</span> holds for any indices <span class="math inline">\(i, i’, j,
j’\)</span> that appear in that cyclic order (possibly with ties) modulo
<span class="math inline">\(k\)</span>. In particular, the Monge
inequality holds whenever <span class="math inline">\(i\le i’\le j\le
j’\)</span>, which implies that the portion of <span
class="math inline">\(M\)</span> on or below the main diagonal is Monge.
Symmetrically, the portion of <span class="math inline">\(M\)</span> on
or above the main diagonal is Monge. These two partial Monge matrices
cover <span class="math inline">\(M\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Perhaps a better way to express this analysis is that the <span
class="math inline">\(k\times 2k\)</span> partial array defined by <span
class="math display">\[
    D[i,j] := \begin{cases}
        \textsf{dist}_G(s_i, s_{j \bmod k})
                &amp; \text{if $i\le j\le i+k$} \\
        \text{undefined}
                &amp; \text{otherwise}
    \end{cases}
\]</span> is a single partial Monge array.</p>
<figure>
<img src="Fig/partial-monge.png" style="width:70.0%"
alt="For any planar map, the array of boundary-to-boundary distances both splits into two partial Monge arrays (left) and unrolls into a single partial Monge array (right)" />
<figcaption aria-hidden="true">For any planar map, the array of
boundary-to-boundary distances both splits into two partial Monge arrays
(left) and unrolls into a single partial Monge array
(right)</figcaption>
</figure>
<h2 data-number="19.9" id="beating-nested-dissection"><span
class="header-section-number">19.9</span> Beating Nested Dissection</h2>
<p>Now recall that the third phase of our nested-dissection algorithm
computes the distances <span
class="math inline">\(\textsf{dist}_\Sigma(r, S)\)</span> by running
Bellman-Ford on a weighted directed clique <span
class="math inline">\(\hat{S}\)</span> over the vertices in <span
class="math inline">\(S\)</span>. Let <span class="math inline">\(s_1,
s_2, \dots, s_k\)</span> denote the vertices of the cycle separator
<span class="math inline">\(S\)</span>, in order around the cycle. It
will be more convenient to think of <span
class="math inline">\(\hat{S}\)</span> as the overlay of two directed
cliques <span class="math inline">\(\hat{S}_A\)</span> and <span
class="math inline">\(\hat{S}_B\)</span>, in which each edge <span
class="math inline">\(s_i\mathord\to s_j\)</span> has lengths <span
class="math inline">\(\ell_A(s_i\mathord\to s_j) = \textsf{dist}_A(s_i,
s_j)\)</span> and <span class="math inline">\(\ell_B(s_i\mathord\to s_j)
= \textsf{dist}_B(s_i, s_j)\)</span>, respectively.</p>
<p>The Bellman-Ford algorithm has the following simple structure. After
initializing <span class="math inline">\(\textsf{dist}[r] = 0\)</span>
and <span class="math inline">\(\textsf{dist}[v] = \infty\)</span> for
all <span class="math inline">\(v\ne r\)</span>, the algorithm
repeatedly identifies and then relaxes all tense edges in <span
class="math inline">\(\hat{S}\)</span>. The algorithm terminates after
<span class="math inline">\(O(k)\)</span> relaxation phases, where <span
class="math inline">\(k = O(\sqrt{n})\)</span> is the number of vertices
in <span class="math inline">\(S\)</span>.</p>
<p>Here is some pseudo-Python for a single relaxation phase:</p>
<pre><code>for i in range(k):
    for j in range(k):
        if dist[j] &lt; dist[i] + l[i,j]
            dist[j] = dist[i] + l[i,j]</code></pre>
<p>As written, this block of code runs in <span
class="math inline">\(O(k^2)\)</span> time. Because the order that we
scan the edges doesn’t matter, let’s first scan all edges in <span
class="math inline">\(\hat{S}_A\)</span> and then all edges in <span
class="math inline">\(\hat{S}_B\)</span>:</p>
<pre><code>for i in range(k):
    for j in range(k):
        if dist[j] &lt; dist[i] + lA[i,j]
            dist[j] = dist[i] + lA[i,j]
for i in range(k):
    for j in range(k):
        if dist[j] &lt; dist[i] + lB[i,j]
            dist[j] = dist[i] + lB[i,j]</code></pre>
<p>Now I’m going to do something a little weird to the first block of
code. For each vertex <span class="math inline">\(v\)</span>, I’ll first
figure out the minimum value of <code>dist[i] + lA[i,j]</code> and only
compare that minimum value to <code>dist[j]</code> at the end.</p>
<pre><code>for j in range(k):
    bestcost = math.inf
    for i in range(k):
        if dist[i] + lA[i,j] &lt; bestcost:
            best[j] = i
            bestcost = dist[i] + lA[i,j]
for j in range(k):
    if dist[j] &lt; bestcost:
        dist[j] = bestcost</code></pre>
<p>The first (outer) for-loop is choosing the minimum element in every
<em>column</em> of a <span class="math inline">\(k\times k\)</span>
matrix <span class="math inline">\(M\)</span>, where <span
class="math display">\[
    M[i,j] := \textsf{dist}(s_i) + \textsf{dist}_A(s_i, s_j)
\]</span> <span class="math inline">\(M\)</span> is the sum of a matrix
with constant columns (which is Monge) and the boundary-to-boundary
distance matrix in <span class="math inline">\(A\)</span>. Thus, <span
class="math inline">\(M\)</span> can be split into two partial Monge
arrays, and therefore so can its transpose. It follows that we can
compute <code>best[j]</code> (and therefore <code>dist[j]</code>) for
all <span class="math inline">\(j\)</span> in <span
class="math inline">\(O(k\alpha(k))\)</span> time using Klawe and
Kleitman’s algorithm, or in <span class="math inline">\(O(k)\)</span>
expected time using Chan’s algorithm.</p>
<p>The same modification relaxes every tense edge in <span
class="math inline">\(\hat{S}_B\)</span> in <span
class="math inline">\(O(k\alpha(k))\)</span> time, or <span
class="math inline">\(O(k)\)</span> expected time.</p>
<p>With this optimization in place, Bellman-Ford computes all
shortest-path distances <span
class="math inline">\(\textsf{dist}_\Sigma(r, S)\)</span> in <span
class="math inline">\(O(k) \cdot O(k\alpha(k)) = O(n\alpha(n))\)</span>
time, or in <span class="math inline">\(O(n)\)</span> expected time.
This accelerated version of Bellman-Ford is now commonly called
“FR-Bellman-Ford” after Fakcharoenphol and Rao, who described a similar
but slightly slower reduction to the original SMAWK algorithm.[^fr]</p>
<p>With all these improvements in place, we obtain a shortest-path
algorithm described by Philip Klein, Shay Mozes, and Oren Weimann in
2009.</p>
<ol type="1">
<li>Recursively compute <span class="math inline">\(\textsf{dist}_A(r,
A)\)</span> and <span class="math inline">\(\textsf{dist}_B(r,
B)\)</span></li>
<li>Compute <span class="math inline">\(\textsf{dist}_A(S,S)\)</span>
and <span class="math inline">\(\textsf{dist}_B(S,S)\)</span> using MSSP
in <span class="math inline">\(O(n\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,S)\)</span> using
FR-Bellman-Ford in <span class="math inline">\(O(n\alpha(n))\)</span>
time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(s,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
</ol>
<p>The overall running time satisfies the recurrence <span
class="math display">\[
    T(n) \le T(n_A) + T(n_B) ~+~ O(n\log n)
\]</span> where (after a suitable domain transformation) <span
class="math inline">\(n_A + n_B = n\)</span> and <span
class="math inline">\(\max\{n_A, n_B\} \le 3n/4\)</span>. We conclude
that the algorithm runs in <span class="math inline">\(O(n\log^2
n)\)</span> time; our invocation of MSSP in stage 2 is (just barely) the
bottleneck.</p>
<p>In 2010, Shay Mozes and Christian Wulff-Nilsen improved this
algorithm even further by using a good <span
class="math inline">\(r\)</span>-division at each level of recursion
(with <span class="math inline">\(r \approx n/\log n\)</span>) instead
of just one separator cycle; their improved algorithm runs in <span
class="math inline">\(O(n\log^2n /\log\log n)\)</span>. I will describe
their improvement at the end of the next lecture note.</p>
<h2 data-number="19.10" id="references-11"><span
class="header-section-number">19.10</span> References</h2>
<ol type="1">
<li><p>Alok Aggarwal, Maria M. Klawe, Shlomo Moran, Peter Shor, and
Robert Wilber. <a href="https://doi.org/10.1007/BF01840359">Geometric
applications of a matrix-searching algorithm</a>. <em>Algorithmica</em>
2(1–4):195–208, 1987. The SMAWK algorithm.</p></li>
<li><p>Noga Alon and Raphael Yuster. <a
href="https://doi.org/10.1109/FOCS.2010.28">Solving linear systems
through nested dissection</a>. <em>Proc. 51st IEEE Symp. Found. Comput.
Sci.</em>, 225–234, 2010.</p></li>
<li><p>Bernard A. Carré. <a
href="https://doi.org/10.1093/imamat/7.3.273">An algebra for network
routing problems</a>. <em>IMA J. Appl. Math.</em> 7(3):273–294,
1971.</p></li>
<li><p>Timothy M. Chan. <a
href="https://doi.org/10.1137/1.9781611976465.88">(Near-)linear-time
randomized algorithms for row minima in Monge partial matrices and
related problems</a>. <em>Proc. 32nd Ann. ACM-SIAM Symp. Discrete
Algorithms</em>, 1465–1482, 2021.</p></li>
<li><p>Jack Edmonds and Richard M. Karp. <a
href="https://doi.org/10.1145/321694.321699">Theoretical improvements in
algorithmic efficiency of network flow problems</a>. <em>J. Assoc.
Comput. Mach.</em> 19(2):248–264, 1972.</p></li>
<li><p>Jittat Fakcharoenphol and Satish Rao. <a
href="https://doi.org/10.1016/j.jcss.2005.05.007">Planar graphs,
negative weight edges, shortest paths, and near linear time</a>. <em>J.
Comput. Syst. Sci.</em> 72(5):868–889, 2006.</p></li>
<li><p>Greg N. Frederickson. <a
href="https://doi.org/10.1137/0216064">Fast algorithms for shortest
paths in planar graphs with applications</a>. <em>SIAM J. Comput.</em>
16(8):1004–1004, 1987.</p></li>
<li><p>Alan George. <a href="https://doi.org/10.1137/0710032">Nested
dissection of a regular finite element mesh</a>. <em>SIAM J. Numer.
Anal.</em> 10(2):345–363, 1973.</p></li>
<li><p>Monika R. Henzinger, Philip Klein, Satish Rao, and Sairam
Subramanian. <a href="https://doi.org/10.1006/jcss.1997.1493">Faster
shortest-path algorithms for planar graphs</a>. <em>J. Comput. Syst.
Sci.</em> 55(1):3–23, 1997.</p></li>
<li><p>Carl Gustav Jacob Jacobi. De aequationum differentialum systemate
non normali ad formam normalem revocando (Ex Ill. C. G. J. Jacobi
manuscriptis posthumis in medium protulit A. Clebsch). <em>C. G. J.
Jacobi’s gesammelte Werke, fünfter Band</em>, 485–513, 1890. Bruck und
Verlag von Georg Reimer. English translation in [8].</p></li>
<li><p>Carl Gustav Jacob Jacobi and François Ollivier (translator). <a
href="https://doi.org/10.1007/s00200-009-0088-2">The reduction to normal
form of a non-normal system of differential equations</a>. <em>Appl.
Algebra Eng. Commun. Comput.</em> 20(1):33–64, 2009. English translation
of [7].</p></li>
<li><p>Donald B. Johnson. <a
href="https://doi.org/10.1145/321992.321993">Efficient algorithms for
shortest paths in sparse networks</a>. <em>J. Assoc. Comput. Mach.</em>
24(1):1–13, 1977.</p></li>
<li><p>Maria M. Klawe and Daniel J. Kleitman. <a
href="https://doi.org/10.1137/0403009">An almost linear time algorithm
for generalized matrix searching</a>. <em>SIAM J. Discrete Math.</em>
3(1):81–97, 1990.</p></li>
<li><p>Philip Klein, Shay Mozes, and Oren Weimann. <a
href="https://doi.org/10.1145/1721837.1721846">Shortest paths in
directed planar graphs with negative lengths: A linear-space <span
class="math inline">\(O(n \log^2 n)\)</span>-time algorithm</a>. <em>ACM
Trans. Algorithms</em> 6(2):30:1–30:18, 2010.</p></li>
<li><p>Richard J. Lipton, Donald J. Rose, and Robert Endre Tarjan. <a
href="https://doi.org/10.1137/0716027">Generalized nested
dissection</a>. <em>SIAM J. Numer. Anal.</em> 16:346–358, 1979.</p></li>
<li><p>Kurt Mehlhorn and Bernd H. Schmidt. <a href="">A single shortest
path algorithm for graphs with separators</a>. <em>Proc. 4th Int. Conf.
Foundations of Computation Theory</em>, 302–309, 1983. Lecture Notes
Comput. Sci. 158, Springer.</p></li>
<li><p>Gaspard Monge. <a
href="https://gallica.bnf.fr/ark:/12148/bpt6k35800/f796">Mémoire sur la
théorie des déblais et des remblais</a>. <em>Histoire de l’Académie
royale des sciences</em> 666–705, 1781.</p></li>
<li><p>Shay Mozes and Christian Wulff-Nilsen. <a
href="https://doi.org/10.1007/978-3-642-15781-3_18">Shortest paths in
planar graphs with real lengths in <span class="math inline">\(O(n
\log^2 n/\log\log n)\)</span> time</a>. <em>Proc. 18th Ann. Europ. Symp.
Algorithms</em>, 206–217, 2010. Lecture Notes Comput. Sci. 6347,
Springer-Verlag. arXiv:<a
href="https://arxiv.org/abs/0911.4963">0911.4963</a>.</p></li>
<li><p>Siamak Tazari and Matthias Müller-Hannemann. <a
href="https://doi.org/10.1016/j.dam.2008.08.002">Shortest paths in
linear time on minor-closed graph classes, with an application to
Steiner tree approximation</a>. <em>Discrete Appl. Math.</em>
157(4):673–684, 2009.</p></li>
<li><p>Nobuaki Tomizawa. <a
href="https://doi.org/10.1002/net.3230010206">On some techniques useful
for solution of transportation network problems</a>. <em>Networks</em>
1:173–194, 1971.</p></li>
</ol>
<h2 data-number="19.11" id="aptly-named-sir-not-2"><span
class="header-section-number">19.11</span> Aptly Named Sir Not</h2>
<ul>
<li>Shortest paths in <span class="math inline">\(O(n)\)</span>
time.</li>
</ul>
<h1 data-number="20" id="minimum-cutsbeta"><span
class="header-section-number">20</span> Minimum Cuts<span
class="math inline">\(^\beta\)</span></h1>
<p>Let <span class="math inline">\(G\)</span> be an arbitrary graph, and
let <span class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> be two vertices of <span
class="math inline">\(G\)</span>. An <em><span class="math inline">\((s,
t)\)</span>-cut</em> (or more formally, an <span
class="math inline">\((s,t)\)</span>-edge-cut) is a subset <span
class="math inline">\(X\)</span> of the edges of <span
class="math inline">\(G\)</span> that intersects every path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> in <span
class="math inline">\(G\)</span>. A <em>minimum <span
class="math inline">\((s,t)\)</span>-cut</em> is an <span
class="math inline">\((s,t)\)</span>-cut of minimum size, or of minimum
total weight if the edges of <span class="math inline">\(G\)</span> are
weighted. (In this context, edge weights are normally called
<em>capacities</em>.)</p>
<p>The fastest method to compute minimum <span class="math inline">\((s,
t)\)</span>-cuts in <em>arbitrary</em> graphs is to compute a maximum
<span class="math inline">\((s, t)\)</span>-flow and then exploit the
classical proof of the maxflow-mincut theorem. In undirected
<em>planar</em> graphs, however, this dependency is reversed; the
fastest method to compute maximum flows actually computes minimum cuts
first.</p>
<h2 data-number="20.1" id="duality-shortest-essential-cycle"><span
class="header-section-number">20.1</span> Duality: Shortest essential
cycle</h2>
<p>Let <span class="math inline">\(\Sigma\)</span> be an undirected
planar <em>map</em>, each of whose edges <span
class="math inline">\(e\)</span> has a non-negative capacity <span
class="math inline">\(c(e)\)</span>, and let <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> be vertices of <span
class="math inline">\(\Sigma\)</span>. The first step in our fast
minimum-cut algorithm is to view the problem through the lens of
duality. It is helpful to think of the source vertex <span
class="math inline">\(s\)</span> and the target vertex <span
class="math inline">\(t\)</span> as <em>punctures</em> or
<em>obstacles</em> — points that are missing from the plane — and
similarly to think of the corresponding faces <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> as <em>holes</em> in the dual map
<span class="math inline">\(\Sigma^*\)</span>. In other words, we should
think of the dual map <span class="math inline">\(\Sigma^*\)</span> as a
decomposition of the <em>annulus</em> <span class="math inline">\(A =
\mathbb{R}^2 \setminus (s^*\cup t^*)\)</span> rather than a map on the
plane or a disk. Without loss of generality, assume that <span
class="math inline">\(t^*\)</span> is the outer face of <span
class="math inline">\(\Sigma^*\)</span>.</p>
<p>A simple cycle <span class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> is <em>essential</em> if it
satisfies any of the following equivalent conditions:</p>
<ul>
<li><span class="math inline">\(\gamma\)</span> separates <span
class="math inline">\(s^*\)</span> from <span
class="math inline">\(t^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> has winding number <span
class="math inline">\(\pm 1\)</span> around <span
class="math inline">\(s^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> is homotopic in <span
class="math inline">\(A\)</span> to the boundary of <span
class="math inline">\(s^*\)</span>.</li>
<li><span class="math inline">\(\gamma\)</span> is homotopic in <span
class="math inline">\(A\)</span> to the boundary of <span
class="math inline">\(t^*\)</span>.</li>
</ul>
<p>Each edge <span class="math inline">\(e^*\)</span> in the dual map
<span class="math inline">\(\Sigma^*\)</span> has a <em>cost</em> or
<em>length</em> <span class="math inline">\(c^*(e^*)\)</span> equal to
the capacity of the corresponding primal edge <span
class="math inline">\(e\)</span>. Whitney’s duality between simple
cycles in <span class="math inline">\(\Sigma\)</span> and and minimal
cuts (bonds) in <span class="math inline">\(\Sigma^*\)</span>
immediately implies the following:</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>A subset <span class="math inline">\(X\)</span> of edges is a
minimum <span class="math inline">\((s,t)\)</span>-cut in <span
class="math inline">\(\Sigma\)</span> if and only if the corresponding
set <span class="math inline">\(X^*\)</span> of dual edges is a
minimum-cost essential cycle in <span
class="math inline">\(\Sigma^*\)</span>.</em>
</dd>
</dl>
<figure>
<img src="Fig/mincut-primal-dual.png" style="width:90.0%"
alt="A minimum (s,t)-cut in a planar graph is dual to a shortest essential cycle in the annular dual map." />
<figcaption aria-hidden="true">A minimum <span
class="math inline">\((s,t)\)</span>-cut in a planar graph is dual to a
shortest essential cycle in the annular dual map.</figcaption>
</figure>
<h2 data-number="20.2" id="crossing-at-most-once"><span
class="header-section-number">20.2</span> Crossing at most once</h2>
<p>Now let <span class="math inline">\(\pi\)</span> be a shortest path
in <span class="math inline">\(\Sigma^*\)</span> from any vertex of
<span class="math inline">\(s^*\)</span> to any vertex of <span
class="math inline">\(t^*\)</span>. We can measure the winding number of
any directed cycle <span class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> by counting the number of times
<span class="math inline">\(\gamma\)</span> crosses <span
class="math inline">\(\pi\)</span> in either direction. We have to
define “crossing” carefully here, because <span
class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\pi\)</span> could share edges.</p>
<p>Suppose <span class="math inline">\(\pi = p_0\mathord\to
p_1\mathord\to \cdots \mathord\to p_k\)</span>, where <span
class="math inline">\(p_0\)</span> lies on <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(p_k\)</span> lies on <span
class="math inline">\(t^*\)</span>. To simplify the following
definition, we add two “ghost” darts <span
class="math inline">\(p_{-1}\mathord\to p_0\)</span> and <span
class="math inline">\(p_k\mathord\to p_{k+1}\)</span>, where <span
class="math inline">\(p_{-1}\)</span> lies inside <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(p_{k+1}\)</span> lies inside <span
class="math inline">\(t^*\)</span>. We say that a dart <span
class="math inline">\(q\mathord\to p_i\)</span> <em>enters <span
class="math inline">\(\pi\)</span> from the left</em> (resp. <em>from
the right</em>) if the darts <span
class="math inline">\(p_{i-1}\mathord\to p_i\)</span>, <span
class="math inline">\(q\mathord\to p_i\)</span>, and <span
class="math inline">\(p_{i+1}\mathord\to p_i\)</span> are ordered
clockwise (resp. counterclockwise) around <span
class="math inline">\(p_i\)</span>. Symmetrically, we say that a dart
<em>leaves <span class="math inline">\(\pi\)</span> to the left</em>
(resp. <em>to the right</em>) if its reversal enters <span
class="math inline">\(\pi\)</span> from the left (resp. from the right).
The same dart can leave <span class="math inline">\(\pi\)</span> to the
right and enter <span class="math inline">\(\pi\)</span> to the left, or
vice versa.</p>
<figure>
<img src="Fig/left-right.png" style="width:15.0%"
alt="Edges incident to both sides of \pi." />
<figcaption aria-hidden="true">Edges incident to both sides of <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<p>A <em>positive crossing</em> between <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(\gamma\)</span> is a subpath of <span
class="math inline">\(\gamma\)</span> that starts with a dart entering
<span class="math inline">\(\pi\)</span> from the right and ends with a
dart leaving <span class="math inline">\(\pi\)</span> to the left, and a
<em>negative crossing</em> is defined similarly. Intuitively, for
purposes of defining crossings, we are shifting the path <span
class="math inline">\(\pi\)</span> very slightly to the left, so that it
intersects the edges of <span class="math inline">\(\Sigma^*\)</span>
transversely. It follows that the winding number <span
class="math inline">\(\textsf{wind}(\gamma, s^*)\)</span> is the number
of darts in <span class="math inline">\(\gamma\)</span> that leave <span
class="math inline">\(\pi\)</span> to the left, minus the number of
darts in <span class="math inline">\(\gamma\)</span> that enter <span
class="math inline">\(\pi\)</span> from the left.</p>
<dl>
<dt><strong>Crossing Lemma [Itai and Shiloach (1979)]:</strong></dt>
<dd>
<em>The shortest essential cycle in <span
class="math inline">\(\Sigma^*\)</span> crosses <span
class="math inline">\(\pi\)</span> exactly once.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We follow the same intuition that we used for shortest homotopic paths
in the plane. Let <span class="math inline">\(\gamma\)</span> be any
essential cycle in <span class="math inline">\(\Sigma^*\)</span>,
directed so that <span class="math inline">\(\textsf{wind}(\gamma, s^*)
= 1\)</span>, that crosses <span class="math inline">\(\pi\)</span> more
than once. Then somewhere <span class="math inline">\(\gamma\)</span>
must have be a negative crossing followed immediately by a positive
crossing. It follows that <span class="math inline">\(\gamma\)</span>
has a subpath <span class="math inline">\(p_i\mathord\to
q\mathord\to\cdots\mathord\to r\mathord\to p_j\)</span>, where <span
class="math inline">\(p_i\mathord\to q\)</span> leaves <span
class="math inline">\(\pi\)</span> to the right, <span
class="math inline">\(r\mathord\to p_j\)</span> enters <span
class="math inline">\(\pi\)</span> from the right. Let <span
class="math inline">\(\gamma’\)</span> be the cycle obtained from <span
class="math inline">\(\gamma\)</span> by replacing this subpath with the
subpath of <span class="math inline">\(\pi\)</span> from <span
class="math inline">\(p_i\)</span> to <span
class="math inline">\(p_j\)</span>. Because <span
class="math inline">\(\pi\)</span> is a shortest path, <span
class="math inline">\(\gamma’\)</span> must be shorter than <span
class="math inline">\(\gamma\)</span>. We conclude that <span
class="math inline">\(\gamma’\)</span> is not the <em>shortest</em>
essential cycle in <span class="math inline">\(\Sigma^*\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<figure>
<img src="Fig/shortcut.png" style="width:13.0%"
alt="Any essential cycle that crosses \pi more than once can be shortened." />
<figcaption aria-hidden="true">Any essential cycle that crosses <span
class="math inline">\(\pi\)</span> more than once can be
shortened.</figcaption>
</figure>
<h2 data-number="20.3" id="slicing-along-a-path"><span
class="header-section-number">20.3</span> Slicing along a path</h2>
<p>Now let <span class="math inline">\(\Delta := \Sigma^*
\backslash\!\!\backslash \pi\)</span> denote the planar map obtained by
<em>slicing</em> the annular map <span
class="math inline">\(\Sigma^*\)</span> along path <span
class="math inline">\(\pi\)</span>. The slicing operation replaces <span
class="math inline">\(\pi\)</span> with two copies <span
class="math inline">\(\pi^+\)</span> and <span
class="math inline">\(\pi^-\)</span>. Then for every vertex <span
class="math inline">\(p_i\)</span> of <span
class="math inline">\(\pi\)</span>, all edges incident to <span
class="math inline">\(p_i\)</span> on the left are redirected to <span
class="math inline">\(p_i^+\)</span>, and all edges incident to <span
class="math inline">\(p_i\)</span> on the left are redirected to <span
class="math inline">\(p_i^-\)</span>. The channel between two two paths
<span class="math inline">\(\pi^+\)</span> and <span
class="math inline">\(\pi^-\)</span> joins <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> into a single outer face. Thus, we
should think of <span class="math inline">\(\Delta\)</span> as being
embedded on a disk. Every face of <span
class="math inline">\(\Sigma^*\)</span> except <span
class="math inline">\(s^*\)</span> and <span
class="math inline">\(t^*\)</span> appears as a face in <span
class="math inline">\(\Delta\)</span>.</p>
<figure>
<img src="Fig/slice-path.png" style="width:35.0%"
alt="Slicing along \pi." />
<figcaption aria-hidden="true">Slicing along <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<p>For any index <span class="math inline">\(i\)</span>, let <span
class="math inline">\(\sigma_i\)</span> denote the shortest path in
<span class="math inline">\(\Delta\)</span> from <span
class="math inline">\(p_i^+\)</span> to <span
class="math inline">\(p_i^-\)</span>. The shortest essential cycle <span
class="math inline">\(\gamma\)</span> in <span
class="math inline">\(\Sigma^*\)</span> appears in <span
class="math inline">\(\Delta\)</span> as one of the shortest paths <span
class="math inline">\(\sigma_i\)</span>. Thus, to compute the minimum
<span class="math inline">\((s,t)\)</span>-cut in our original planar
map <span class="math inline">\(\Sigma\)</span>, it suffices to compute
the length of <em>every</em> shortest path <span
class="math inline">\(\sigma_i\)</span> in <span
class="math inline">\(\Delta\)</span>.</p>
<figure>
<img src="Fig/mincut-dual-surgery.png" style="width:100.0%"
alt="Slicing along \pi transforms the shortest essential cycle into a shortest path between clones of some vertex of \pi." />
<figcaption aria-hidden="true">Slicing along <span
class="math inline">\(\pi\)</span> transforms the shortest essential
cycle into a shortest path between clones of some vertex of <span
class="math inline">\(\pi\)</span>.</figcaption>
</figure>
<h2 data-number="20.4" id="algorithms"><span
class="header-section-number">20.4</span> Algorithms</h2>
<p>The simplest way to compute these <span
class="math inline">\(k\)</span> shortest-path distances is to run
Dijkstra’s algorithm at each vertex <span
class="math inline">\(p_i^+\)</span>. Assuming <span
class="math inline">\(\pi\)</span> has <span
class="math inline">\(k\)</span> edges, so there are <span
class="math inline">\(k+1\)</span> terminal pairs <span
class="math inline">\(p_i^\pm\)</span>, this algorithm runs in <span
class="math inline">\(O(kn\log n)\)</span> time, which is <span
class="math inline">\(O(n^2\log n)\)</span> time in the worst case. We
can reduce the running time to <span class="math inline">\(O(kn\log\log
n)\)</span> using the faster shortest-path algorithm we described in the
previous lecture note, or even to <span
class="math inline">\(O(kn)\)</span> using a linear-time shortest-path
algorithm.</p>
<p>Alternatively, we can compute all <span
class="math inline">\(k\)</span> of these shortest paths using a
multiple-source shortest-paths algorithm. The parametric MSSP algorithms
of Klein and Cabello et al. both require <span
class="math inline">\(O(n\log n)\)</span> time, which is faster in the
worst case than <span class="math inline">\(O(kn)\)</span>, but slower
when <span class="math inline">\(k\)</span> is small. In particular,
even when <span class="math inline">\(k=2\)</span>, that algorithm could
require <span class="math inline">\(\Omega(n)\)</span> pivots. The more
recent recursive contraction algorithm runs in <span
class="math inline">\(O(n\log n\log k)\)</span> time if we use
Dijkstra’s algorithm to compute shortest paths, or in <span
class="math inline">\(O(n\log k)\)</span> time if we use a linear-time
shortest-path algorithm.</p>
<p>An older and simpler divide-and-conquer algorithm, proposed by John
Reif in 1983, exactly matches the recursive contraction MSSP algorithm.
Reif’s algorithm computes the median shortest path <span
class="math inline">\(\sigma_m\)</span>, where <span
class="math inline">\(m = \lfloor k/2 \rfloor\)</span>, and then
recurses in each component of the sliced map <span
class="math inline">\(\Delta \backslash\!\!\backslash \sigma_m\)</span>.
One of these components contains the terminal pairs <span
class="math inline">\(p_0^\pm, p_1^\pm, \dots, p^\pm_m\)</span>; the
other contains the terminal pairs <span class="math inline">\(p_m^\pm,
p_{m+1}^\pm, \dots, p_k^\pm\)</span>.</p>
<figure>
<img src="Fig/Reif-split.png" style="width:60.0%"
alt="Reif’s algorithm: Slice along the median shortest path and recurse." />
<figcaption aria-hidden="true">Reif’s algorithm: Slice along the median
shortest path and recurse.</figcaption>
</figure>
<p>Reif’s algorithm falls back on Dijkstra’s algorithm in two base
cases. First, if <span class="math inline">\(k\le 2\)</span>, we can
obviously compute each of the <span class="math inline">\(k\)</span>
shortest paths directly. A more subtle base case happens when the
“floor” and “ceiling” paths collide. Let <span
class="math inline">\(\alpha\)</span> denote the boundary path from
<span class="math inline">\(p_0^+\)</span> to <span
class="math inline">\(p_0^-\)</span>, and let <span
class="math inline">\(\beta\)</span> denote the boundary path from <span
class="math inline">\(p_k^+\)</span> to <span
class="math inline">\(p_k^-\)</span>. If <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> share a vertex <span
class="math inline">\(x\)</span>, then for every index <span
class="math inline">\(i\)</span> we have <span
class="math inline">\(\textsl{dist}(p_i^+, p_i^-) = \textsl{dist}(p_i^+,
x) + \textsl{dist}(x, p_i^-)\)</span>; thus, instead of recursing, we
can compute all <span class="math inline">\(k\)</span> shortest-path
distances by computing a single shortest-path tree rooted at <span
class="math inline">\(x\)</span>. (This second base case is not
necessary for the correctness of Reif’s algorithm, but it is necessary
for efficiency.)</p>
<figure>
<img src="Fig/Reif-collapse.png" style="width:30.0%"
alt="Base case of Reif’s algorithm." />
<figcaption aria-hidden="true">Base case of Reif’s
algorithm.</figcaption>
</figure>
<p>Let <span class="math inline">\(T(n,k)\)</span> denote the running
time of Reif’s algorithm, where <span class="math inline">\(k+1\)</span>
is the number of terminal pairs and <span
class="math inline">\(n\)</span> is the total number of vertices in the
map <span class="math inline">\(\Delta\)</span>. This function obeys the
recurrence <span class="math display">\[
    T(n,k) = T(n_1, \lfloor k/2 \lfloor) + T(n_1, \lceil k/2 \rceil) +
O(n\log n).
\]</span> where <span class="math inline">\(n_1\)</span> and <span
class="math inline">\(n_2\)</span> are the number of vertices in the two
components of <span class="math inline">\(\Delta
\backslash\!\!\backslash \sigma_m\)</span>. The second base case ensures
that each vertex and edge of <span class="math inline">\(\Delta\)</span>
appears in at most <span class="math inline">\(O(1)\)</span> subproblems
at any level of the recursion tree.<a href="#fn56" class="footnote-ref"
id="fnref56" role="doc-noteref"><sup>56</sup></a> Thus, the total work
at any level of recursion is <span class="math inline">\(O(n\log
n)\)</span>. The recursion tree has depth at most <span
class="math inline">\(O(\log k)\)</span>, so the overall algorithm runs
in <span class="math inline">\(O(n\log n\log k)\)</span> time.</p>
<p>If we use a linear-time shortest-path algorithm instead of Dijkstra,
the running time improves to <span class="math inline">\(O(n\log
k)\)</span>. This improvement was first described by Greg Frederickson
in 1987, as one of the earliest applications of <span
class="math inline">\(r\)</span>-divisions.</p>
<h2 data-number="20.5"
id="faster-shortest-paths-with-negative-lengths"><span
class="header-section-number">20.5</span> Faster Shortest Paths with
Negative Lengths</h2>
<p><strong><em>[[[This is still really sketchy!]]]</em></strong></p>
<p>In the previous lecture note, we described a 2009 algorithm by Klein,
Mozes, and Weimann to compute shortest paths in directed planar maps,
possibly with negative dart lengths, in <span
class="math inline">\(O(n\log^2 n)\)</span> time. In 2010, Shay Mozes
and Christian Wulff-Nilsen improved this algorithm even further by using
a good <span class="math inline">\(r\)</span>-division at each level of
recursion (with <span class="math inline">\(r \approx n/\log n\)</span>)
instead of just one separator cycle; their improved algorithm runs in
<span class="math inline">\(O(n\log^2n /\log\log n)\)</span>.</p>
<p>Recall the high-level description of the Klein-Mozes-Weimann
algorithm:</p>
<ol start="0" type="1">
<li>Split the map <span class="math inline">\(\Sigma\)</span> into two
smaller maps <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> along a single cycle separator <span
class="math inline">\(S\)</span>.</li>
<li>Recursively compute <span class="math inline">\(\textsf{dist}_A(r,
A)\)</span> and <span class="math inline">\(\textsf{dist}_B(r,
B)\)</span></li>
<li>Compute <span class="math inline">\(\textsf{dist}_A(S,S)\)</span>
and <span class="math inline">\(\textsf{dist}_B(S,S)\)</span> using MSSP
in <span class="math inline">\(O(n\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,S)\)</span> using
FR-Bellman-Ford in <span class="math inline">\(O(n\alpha(n))\)</span>
time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(r,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
<li>Compute <span
class="math inline">\(\textsf{dist}_\Sigma(s,\Sigma)\)</span> using
reweighting and <span class="math inline">\(r\)</span>-divisions in
<span class="math inline">\(O(n\log\log n)\)</span> time.</li>
</ol>
<p>Steps 1, 4, and 5 of Mozes and Wulff-Nilsen’s faster algorithm are
identical. In step 2, the only minor different is that we need to run
MSSP around the boundary of each hole of each piece, instead of just
once around the sole cycle separator. The total time for each piece is
<span class="math inline">\(O(r\log r)\)</span>, so the total time for
this step across the entire <span
class="math inline">\(r\)</span>-division is <span
class="math inline">\(O(n/r)\cdot O(r\log r) = O(n\log r)\)</span>.</p>
<p>The only major change to the algorithm is in step 3; we need to
modify FR-Bellman-Ford to deal with holes in each piece of the <span
class="math inline">\(r\)</span>-division.</p>
<p>In step 2, we compute all boundary-to-boundary distances within each
piece of the <span class="math inline">\(r\)</span>-division using MSSP.
Specifically, within each piece <span class="math inline">\(P\)</span>,
we run MSSP around each of the <span class="math inline">\(O(1)\)</span>
boundary cycles of <span class="math inline">\(P\)</span>. The total
time for each piece is <span class="math inline">\(O(r\log r)\)</span>,
so the total time for this step across the entire <span
class="math inline">\(r\)</span>-division is <span
class="math inline">\(O(n/r)\cdot O(r\log r) = O(n\log r)\)</span>.</p>
<p>Modifying step 3 is more interesting. Recall that a good <span
class="math inline">\(r\)</span>-division <span
class="math inline">\(\mathcal{R}\)</span> breaks <span
class="math inline">\(\Sigma\)</span> into <span
class="math inline">\(O(n/r)\)</span> pieces, each with <span
class="math inline">\(O(r)\)</span> vertices, <span
class="math inline">\(O(\sqrt{r})\)</span> boundary vertices, and <span
class="math inline">\(O(1)\)</span> holes; thus, overall, <span
class="math inline">\(\mathcal{R}\)</span> has <span
class="math inline">\(O(n/\sqrt{r})\)</span> boundary vertices,
organized into <span class="math inline">\(O(n/r)\)</span> cycles. We
construct a complete directed multigraph <span
class="math inline">\(\hat{R}\)</span> over the boundary vertices of the
<span class="math inline">\(r\)</span>-division, with an edge <span
class="math inline">\(u{\to}v\)</span> with weight <span
class="math inline">\(\textsf{dist}_P(u,v)\)</span> for every piece
<span class="math inline">\(P\)</span> containing both <span
class="math inline">\(u\)</span> and <span
class="math inline">\(v\)</span>.</p>
<p>Bellman-Ford computes shortest-path distances in <span
class="math inline">\(\hat{R}\)</span> in <span
class="math inline">\(O(n/\sqrt{r})\)</span> phases; in each phase, we
find and relax all tense edges. Our modification of FR-Bellman-Ford
breaks each relaxation phase into subphases:</p>
<pre><code>for each piece P:
   for each boundary cycle S of P:
       for each boundary cycle T of P:
           relax every edge within P from S to T</code></pre>
<p>We already described how to relax every edge in <span
class="math inline">\(P\)</span> from a boundary cycle <em>to
itself</em> in <span class="math inline">\(O(k\alpha(k))\)</span> time
(or <span class="math inline">\(O(k)\)</span> expected time). It remains
to show how to relax all edges from one boundary cycle <span
class="math inline">\(S\)</span> to a different boundary cycle <span
class="math inline">\(T\)</span>.</p>
<p>Without loss of generality, let’s assume that <span
class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span> are the only two boundary cycles in
<span class="math inline">\(P\)</span>; we’ll treat any other boundary
cycles as faces of <span class="math inline">\(P\)</span>. Thus, <span
class="math inline">\(P\)</span> is a map of an <em>annulus</em>. Let
<span class="math inline">\(s_1, s_2, \dots, s_k\)</span> and <span
class="math inline">\(t_1, t_2, \dots, t_l\)</span> denote the sequences
of vertices of <span class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span>, respectively.</p>
<p>Let <span class="math inline">\(\pi\)</span> be the shortest path in
<span class="math inline">\(P\)</span> from <span
class="math inline">\(s_1\)</span> to <span
class="math inline">\(t_1\)</span>, and let <span
class="math inline">\(\Delta = P \mathbin{\backslash\!\!\backslash}
\pi\)</span> be the map obtained by slicing <span
class="math inline">\(\Sigma\)</span> along the path <span
class="math inline">\(\pi\)</span>. As before, the slicing operation
duplicates the path <span class="math inline">\(\pi\)</span> and merges
the faces <span class="math inline">\(S\)</span> and <span
class="math inline">\(T\)</span> into a single outer face.</p>
<p>Let <span class="math inline">\(\Delta’\)</span> be a duplicate of
<span class="math inline">\(\Delta\)</span>, and let <span
class="math inline">\(\Delta^2\)</span> denote the map obtained by
gluing the “right” copy of <span class="math inline">\(\pi\)</span> in
<span class="math inline">\(\Delta\)</span> to the “left” copy of <span
class="math inline">\(\pi\)</span> in <span
class="math inline">\(\Delta’\)</span>.</p>
<p><strong>Lemma:</strong> <em>For all indices <span
class="math inline">\(i\)</span> and <span
class="math inline">\(j\)</span>, we have <span
class="math display">\[\textsf{dist}_P(s_i,t_j) = \min\big\{
\textsf{dist}_{\Delta^2}(s_i,t_j),~ \textsf{dist}_{\Delta^2}(s’_i,t_j),~
\textsf{dist}_{\Delta^2}(a_i,b’_j) \big\}\]</span>.</em></p>
<p><strong><em>[[[This is already claimed, but without proof, in the
next lecture note.]]]</em></strong></p>
<figure>
<img src="Fig/ddg-annulus-surgery.png" style="width:100.0%"
alt="Reducing the boundary-to-boundary distance array of an annulus to a Monge array; compare with Figure 5." />
<figcaption aria-hidden="true">Reducing the boundary-to-boundary
distance array of an annulus to a Monge array; compare with Figure
5.</figcaption>
</figure>
<p>The matrix of distances from the “top edge” of <span
class="math inline">\(\Delta^2\)</span> to the “bottom edge” of <span
class="math inline">\(\Delta^2\)</span> is Monge! So we can relax all
the edges from <span class="math inline">\(A\)</span> to <span
class="math inline">\(B\)</span> in <span
class="math inline">\(O(k+l)\)</span> time with one invocation of
SMAWK.</p>
<p>Suppose <span class="math inline">\(P\)</span> has <span
class="math inline">\(h = O(1)\)</span> holes, with <span
class="math inline">\(k_1, k_2, \dots, k_h\)</span> boundary vertices;
recall that <span class="math inline">\(k = \sum_i k_i =
O(\sqrt{r})\)</span>. Then the total time to relax all
boundary-to-boundary edges in <span class="math inline">\(P\)</span> is
<span class="math display">\[
    \sum_{i=1}^h O(k_i\alpha(k_i))
    +
    \sum_{i=1}^h \sum_{j=1}^h O(k_i + k_j)
    ~=~
    O(k\alpha(k) + kh)
    ~=~
    O(\sqrt{r}\,\alpha(r)).
\]</span> It follows that the time to relax <em>all</em> edges of <span
class="math inline">\(\mathcal{R}\)</span> is <span
class="math inline">\(O((n/\sqrt{r})\alpha(r)) = o(n)\)</span></p>
<h2 data-number="20.6" id="faster-minimum-cuts-fr-dijkstra"><span
class="header-section-number">20.6</span> Faster Minimum Cuts:
FR-Dijkstra</h2>
<p>Frederickson held the record for fastest planar minimum-cut algorithm
for almost two and a half decades; the record was finally broken in 2011
by two independent pairs of researchers, who ultimately published their
result jointly: Giuseppe Italiano, Yahav Nussbaum, Piotr Sankowski, and
Christian Wulff-Nilsen. Their <span class="math inline">\(O(n\log\log
n)\)</span>-time algorithm relies on an improvement to Dijkstra’s
algorithm in dense distance graphs, proposed by Jittat Fakcharoenphol
and Satish Rao in 2001, and now usually called <em>FR-Dijkstra</em>.</p>
<p>Recall from the previous lecture on shortest paths that we can
compute a dense distance graph for a nice <span
class="math inline">\(r\)</span>-division in <span
class="math inline">\(O(n\log r)\)</span> time. The dense distance graph
has <span class="math inline">\(O(n/\sqrt{r})\)</span> vertices—the
boundary vertices of the pieces of the <span
class="math inline">\(r\)</span>-division—and <span
class="math inline">\(O(n)\)</span> edges. So Dijkstra’s algorithm with
a Fibonacci heap runs in <span class="math inline">\(O(E + V\log V) =
O(n + (n/\sqrt{r})\log n)\)</span> time.</p>
<p>FR-Dijkstra removes the <span class="math inline">\(O(n)\)</span>
term from this running time. Specifically, within each piece of the
<span class="math inline">\(r\)</span>-division, the algorithm exploits
the Monge structure in the boundary-to-boundary distances to avoid
looking at every pair of boundary vertices. This is the same high-level
strategy that we previously used with FR-Bellman-Ford, but with one
significant difference: We do not know the relevant Monge arrays in
advance. Instead, portions of each Monge array are revealed each time
the Dijkstra wavefront touches the corresponding piece of the <span
class="math inline">\(r\)</span>-division.</p>
<p>I’ll discuss FR-Dijkstra in detail, along with the faster planar
minimum-cut algorithm, in the next lecture.</p>
<h2 data-number="20.7" id="references-12"><span
class="header-section-number">20.7</span> References</h2>
<ol type="1">
<li><p>Greg N. Frederickson. <a
href="https://doi.org/10.1137/0216064">Fast algorithms for shortest
paths in planar graphs with applications</a>. <em>SIAM J. Comput.</em>
16(8):1004–1004, 1987.</p></li>
<li><p>Alon Itai and Yossi Shiloach. <a
href="https://doi.org/10.1137/0208012">Maximum flow in planar
networks</a>. <em>SIAM J. Comput.</em> 8:135–150, 1979.</p></li>
<li><p>Giuseppe F. Italiano, Yahav Nussbaum, Piotr Sankowski, and
Christian Wulff-Nilsen. <a
href="https://doi.org/10.1145/1993636.1993679">Improved algorithms for
min cut and max flow in undirected planar graphs</a>. <em>Proc. 43rd
Ann. ACM Symp. Theory Comput.</em>, 313–322, 2011.</p></li>
<li><p>Shay Mozes and Christian Wulff-Nilsen. <a
href="https://doi.org/10.1007/978-3-642-15781-3_18">Shortest paths in
planar graphs with real lengths in <span class="math inline">\(O(n
\log^2 n/\log\log n)\)</span> time</a>. <em>Proc. 18th Ann. Europ. Symp.
Algorithms</em>, 206–217, 2010. Lecture Notes Comput. Sci. 6347,
Springer-Verlag. arXiv:<a
href="https://arxiv.org/abs/0911.4963">0911.4963</a>.</p></li>
<li><p>John Reif. <a href="https://doi.org/10.1137/0212005">Minimum
<span class="math inline">\(s\)</span>-<span
class="math inline">\(t\)</span> cut of a planar undirected network in
<span class="math inline">\(O(n\log^2 n)\)</span> time</a>. <em>SIAM J.
Comput.</em> 12(1):71–81, 1983.</p></li>
<li><p>Hassler Whitney. <a
href="https://doi.org/10.1090/S0002-9947-1932-1501641-2">Non-separable
and planar graphs</a>. <em>Trans. Amer. Math. Soc.</em> 34:339–362,
1932.</p></li>
<li><p>Hassler Whitney. <a
href="https://doi.org/10.4064/fm-21-1-73-84">Planar graphs</a>.
<em>Fund. Math.</em> 21:73–84, 1933.</p></li>
</ol>
<h2 data-number="20.8" id="aptly-named-sir-not-3"><span
class="header-section-number">20.8</span> Aptly Named Sir Not</h2>
<ul>
<li>Maximum cuts (or minimum cuts with negative capacities) [Hadlock
1975]</li>
<li>Deriving maximum flows from minimum cuts [Hassin Johnson 1985]</li>
<li><span class="math inline">\(O(n)\)</span> time for unweighted graphs
[Weihe 1997, Eisenstat Klein 2013, Balzotti Franciosa 2022]</li>
<li>Global minimum cuts (dual to shortest weighted cycle) [Łącki
Sankowski 2011]</li>
<li>Minimum cuts in directed planar graphs, via double cover [Janiga
Koubek 1992 but fixed, Erickson 2011, Fox 2013]</li>
<li>Faster directed planar minimum cuts [Mozes Nikolaev Nussbaum Weimann
SODA 2018]</li>
</ul>
<h1 data-number="21" id="faster-minimum-cuts-fr-dijkstraalpha"><span
class="header-section-number">21</span> Faster Minimum Cuts
(FR-Dijkstra)<span class="math inline">\(^\alpha\)</span></h1>
<h2 data-number="21.1" id="monge-heaps"><span
class="header-section-number">21.1</span> Monge Heaps</h2>
<p>Recall that a two-dimensional array <span
class="math inline">\(M\)</span> is <em>Monge</em> if the inequality
<span class="math inline">\(M[i,j] + M[i’,j’] \le M[i’,j] +
M[i,j’]\)</span> holds for all indices <span
class="math inline">\(i&lt;i’\)</span> and <span
class="math inline">\(j&lt;j’\)</span>. Any array where the columns are
constant is Monge, and the sum of any two Monge arrays is Monge.</p>
<p>Suppose we are given a <span class="math inline">\(k\times k\)</span>
Monge array <span class="math inline">\(D\)</span>, and we are
<em>promised</em> that there is a <span
class="math inline">\(k\)</span>-dimensional vector <span
class="math inline">\(c\)</span>. Then no matter what values <span
class="math inline">\(c\)</span> contains, the array <span
class="math inline">\(M\)</span> defined by <span
class="math inline">\(M[i,j] = D[i,j] + c[j]\)</span> is Monge.</p>
<p>A <em>Monge heap</em> is a data structure that allows us to extract
information from the array <span class="math inline">\(M\)</span> as the
coefficients of <span class="math inline">\(c\)</span> are revealed.
Specifically, a Monge heap supports the following three operations:</p>
<ul>
<li><span class="math inline">\(\textsf{Reveal}(j, x)\)</span>: Declare
that <span class="math inline">\(c[j] = x\)</span>, thereby revealing
the <span class="math inline">\(j\)</span>th column of <span
class="math inline">\(M\)</span>.</li>
<li><span class="math inline">\(\textsf{FindMin}()\)</span>: Return the
smallest visible element in <span class="math inline">\(M\)</span>. We
are guaranteed that this element is the smallest element in its row of
<span class="math inline">\(M\)</span>, not just the smallest
<em>visible</em> element of that row.</li>
<li><span class="math inline">\(\textsf{Hide}(i)\)</span>: Hide the row
<span class="math inline">\(i\)</span> of <span
class="math inline">\(M\)</span>, which must contain the smallest
visible element of <span class="math inline">\(M\)</span> (which is also
the smallest element of its row of <span
class="math inline">\(M\)</span>)</li>
</ul>
<p>Over the lifetime of the data structure, we will <span
class="math inline">\(\textsf{Reveal}\)</span> at most <span
class="math inline">\(k\)</span> columns and <span
class="math inline">\(\textsf{Hide}\)</span> at most <span
class="math inline">\(k\)</span> rows.</p>
<p>An element of <span class="math inline">\(M\)</span> is
<em>visible</em> if its column has been <span
class="math inline">\(\textsf{Reveal}\)</span>ed but its row has not
been <span class="math inline">\(\textsf{Hid}\)</span>d<span
class="math inline">\(\textsf{e}\)</span>n. We call an element of <span
class="math inline">\(M\)</span> <em>active</em> if it is the smallest
visible element in a visible row. Each visible column of <span
class="math inline">\(M\)</span> contains zero or more contiguous
intervals of <span class="math inline">\(M\)</span>, which we call
<em>active intervals</em>. Each active interval is specified by a triple
of indices <span class="math inline">\((j, i_{\min},
i_{\max})\)</span>.</p>
<figure>
<img src="Fig/Monge-heap.png" style="width:85.0%"
alt="Operations on a Monge heap, initially with four visible columns and no hidden rows." />
<figcaption aria-hidden="true">Operations on a Monge heap, initially
with four visible columns and no hidden rows.</figcaption>
</figure>
<p>A Monge heap consists of three component data structures (described
in more detail below):</p>
<ul>
<li>A priority queue storing all live intervals within the visible
columns of <span class="math inline">\(M\)</span></li>
<li>A balanced binary search tree storing the live intervals in
lexicographic order</li>
<li>A range-minimum query structure for each column of <span
class="math inline">\(D\)</span> (sic)</li>
</ul>
<p>These data structures support each <span
class="math inline">\(\textsf{Reveal}\)</span> in <span
class="math inline">\(O(\log k)\)</span> amortized time, <span
class="math inline">\(\textsf{FindMin}\)</span> in <span
class="math inline">\(O(1)\)</span> time, and <span
class="math inline">\(\textsf{Hide}\)</span> in <span
class="math inline">\(O(\log k)\)</span> time. Over the lifetime of the
data structure, we call each of these operations at most <span
class="math inline">\(k\)</span> times, thereby finding the minimum
elements in some subset of the rows of <span
class="math inline">\(M\)</span> in <span class="math inline">\(O(k\log
k)\)</span> time. (This is slower than the <span
class="math inline">\(O(k)\)</span> running time of SMAWK, but that
algorithm requires the entire array <span
class="math inline">\(M\)</span> to be visible from the beginning.)</p>
<h3 data-number="21.1.1" id="the-main-priority-queue"><span
class="header-section-number">21.1.1</span> The main priority queue</h3>
<p>At all times, the submatrix (or minor) of visible elements in <span
class="math inline">\(M\)</span> is Monge. This implies that the minimum
<em>visible</em> elements in the <em>visible</em> rows of <span
class="math inline">\(M\)</span> are <em>monotone</em>: The index of the
row minimum is a non-decreasing function of the row index. More
explicitly: For any indices <span class="math inline">\(i&lt;i’\)</span>
of visible rows, if <span class="math inline">\(M[i,j]\)</span> is the
minimum (visible) element of row <span class="math inline">\(i\)</span>,
and <span class="math inline">\(M[i’,j’]\)</span> is the minimum
(visible) element of row <span class="math inline">\(i’\)</span>, then
<span class="math inline">\(j\le j’\)</span>.</p>
<p>Thus, each visible column <span class="math inline">\(j\)</span> of
<span class="math inline">\(M\)</span> contains the smallest elements of
a interval of visible rows, which may be broken into smaller intervals
by hidden rows. Each <em>live interval</em> can be described by a triple
of indices <span class="math inline">\((j, i_{\min}, i_{\max})\)</span>,
indicating that <span class="math inline">\(M[i,j]\)</span> is the
minimum element in every row <span class="math inline">\(i\)</span> such
that <span class="math inline">\(i_{\min}\le i\le i_{\max}\)</span>, and
moreover none of those rows has been hidden. The live intervals
partition the visible rows of <span class="math inline">\(M\)</span>, so
there are at most <span class="math inline">\(k\)</span> of them at any
time.</p>
<p>We maintain the live intervals <span class="math inline">\((j,
i_{\min}, i_{\max})\)</span> in a priority queue, implemented as a
standard binary min-heap, where the priority of any interval is its
smallest element. In particular, the smallest visible element in <span
class="math inline">\(M\)</span> is the priority of the live interval at
the root of the heap, so we can support <span
class="math inline">\(\textsf{FindMin}\)</span> in <span
class="math inline">\(O(1)\)</span> time.</p>
<h3 data-number="21.1.2" id="range-minimum-queries"><span
class="header-section-number">21.1.2</span> Range-minimum queries</h3>
<p>The smallest element in any live interval <span
class="math inline">\((j, i_{\min}, i_{\max})\)</span> depends only on
the known Monge matrix <span class="math inline">\(D\)</span>. To
compute these minimum elements quickly, we preprocess each column <span
class="math inline">\(D[\cdot, j]\)</span> into a data structure that
supports <em>range-minimum queries</em> of the following form:</p>
<ul>
<li><span class="math inline">\(\textsf{RMQ}(j, i_{\min},
i_{\max})\)</span>: Return the index <span
class="math inline">\(i_{\min}\le i\le i_{\max}\)</span> that minimizes
<span class="math inline">\(D[i,j]\)</span>.</li>
</ul>
<p>The range-minimum data structure consists of a static balanced binary
search tree with <span class="math inline">\(k\)</span> leaves. The
<span class="math inline">\(i\)</span>th leaf stores <span
class="math inline">\(D[i,j]\)</span>, and every internal node stores
the minimum value of its two children, along with the index of the leaf
storing that value. This data structure is constructed once at the start
of the algorithm, in <span class="math inline">\(O(k)\)</span> time, and
it answers any range-minimum query in <span class="math inline">\(O(\log
k)\)</span> time.</p>
<p>Whenever we <span class="math inline">\(\textsf{Insert}\)</span> a
new live interval <span class="math inline">\((j, i_{\min},
i_{\max})\)</span> into the priority queue, we perform a range-minimum
query to determine the priority of that interval. Thus, the overall
<span class="math inline">\(\textsf{Insert}\)</span>ion time is <span
class="math inline">\(O(\log k)\)</span>. The other priority queue
operations <span class="math inline">\(\textsf{ExtractMin}\)</span> and
<span class="math inline">\(\textsf{Delete}\)</span> also take <span
class="math inline">\(O(\log k)\)</span> time.</p>
<h3 data-number="21.1.3" id="revealing-a-column"><span
class="header-section-number">21.1.3</span> Revealing a column</h3>
<p><span class="math inline">\(\textsf{Reveal}(j, x)\)</span> is
implemented in <span class="math inline">\(O(\log k)\)</span> amortized
time as follows:</p>
<ul>
<li><p>Find the live intervals <span class="math inline">\(I^- = (j^-,
i_{\min}^-, i_{\min}^-)\)</span> and <span class="math inline">\(I^+ =
(j^+, i_{\min}^+, i_{\min}^+)\)</span> immediately before and after
<span class="math inline">\((j, \cdot, \cdot)\)</span> in lexicographic
order, in <span class="math inline">\(O(\log k)\)</span> time, by
querying the balanced binary search tree.</p></li>
<li><p>While <span class="math inline">\(M[i_{\min}^-, j] &lt;
M[i_{\min}^-, j^-]\)</span>, replace <span
class="math inline">\(I^-\)</span> with its predecessor in lexicographic
order. Then binary search for the smallest index <span
class="math inline">\(i_{\min}\)</span> such that <span
class="math inline">\(M[i_{\min}, j] &lt; M[i_{\min},
j^-]\)</span>.</p></li>
<li><p>While <span class="math inline">\(M[i_{\min}^+, j] &lt;
M[i_{\min}^+, j^+]\)</span>, replace <span
class="math inline">\(I^+\)</span> with its successor in lexicographic
order. Then binary search for the smallest index <span
class="math inline">\(i_{\max}\)</span> such that <span
class="math inline">\(M[i_{\max}, j] &lt; M[i_{\min},
j^+]\)</span>.</p></li>
<li><p>Delete any live intervals <span class="math inline">\((j^\pm,
\cdot, \cdot)\)</span> that overlap <span class="math inline">\((j,
i_{\min}, i_{\max})\)</span> from the priority queue.</p></li>
<li><p>Insert the new live intervals <span class="math inline">\((j,
i_{\min}, i_{\max})\)</span>, <span class="math inline">\((j^-, \cdot,
i_{\min}-1)\)</span>, and <span class="math inline">\((j^+, i_{\max}+1,
\cdot)\)</span> into the priority queue.</p></li>
</ul>
<p>To obtain the claimed <span class="math inline">\(O(\log k)\)</span>
amortized time bound, we charge the time to delete any interval from the
priority queue to its earlier insertion. The requirement that we only
<span class="math inline">\(\textsf{Hide}\)</span> rows when their
minimum elements are visible implies that there is exactly one live
interval in the <span class="math inline">\(\textsf{Reveal}\)</span>ed
column.</p>
<h3 data-number="21.1.4" id="hiding-a-row"><span
class="header-section-number">21.1.4</span> Hiding a row</h3>
<p>Finally, <span class="math inline">\(\textsf{Hide}(i)\)</span> is
implemented in <span class="math inline">\(O(\log k)\)</span> time as
follows:</p>
<ul>
<li><p>Extract the live interval <span class="math inline">\((j,
i_{\min}, i_{\max})\)</span> from the root of the priority queue.
Because row <span class="math inline">\(i\)</span> contains the smallest
visible element in <span class="math inline">\(M\)</span>, that smallest
element is <span class="math inline">\(M[i,j]\)</span> and <span
class="math inline">\(i_{\min}\le i\le i_{\max}\)</span>.</p></li>
<li><p>Find the smallest element <span
class="math inline">\(M[i,j]\)</span> in that interval using a
range-minimum query.</p></li>
<li><p>Insert the live intervals <span class="math inline">\((j,
i_{\min}, i-1)\)</span> and <span class="math inline">\((j, i+1,
i_{\max})\)</span> into the priority queue.</p></li>
</ul>
<h2 data-number="21.2" id="monge-structure-of-nice-r-divisions"><span
class="header-section-number">21.2</span> Monge structure of nice <span
class="math inline">\(r\)</span>-divisions</h2>
<p>Suppose we are given a planar map <span
class="math inline">\(\Sigma\)</span> (called <span
class="math inline">\(\Delta\)</span> in the previous lecture) with
non-negatively weighted edges. Recall that a nice <span
class="math inline">\(r\)</span>-division partitions <span
class="math inline">\(S\)</span> into <span
class="math inline">\(O(n/r)\)</span> <em>pieces</em>, each with <span
class="math inline">\(O(r)\)</span> vertices and <span
class="math inline">\(O(\sqrt{r})\)</span> boundary vertices, and each
with the topology of a disk with <span
class="math inline">\(O(1)\)</span> holes.</p>
<p>Let <span class="math inline">\(D\)</span> denote the array of
boundary-to-boundary distances for a single piece <span
class="math inline">\(R\)</span> of this <span
class="math inline">\(r\)</span>-division. I claim that we can represent
<span class="math inline">\(D\)</span> using a small number of Monge
arrays. We need to consider two types of boundary-to-boundary distances,
depending on whether the two vertices lie on the same hole of <span
class="math inline">\(R\)</span> or on different holes.</p>
<p>First, consider two holes in <span class="math inline">\(R\)</span>,
with boundaries <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>. Think of <span
class="math inline">\(R\)</span> as a map on the annulus, with boundary
cycles <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>. Let <span
class="math inline">\(\pi\)</span> be the shortest path from any vertex
<span class="math inline">\(a_1 \in \alpha\)</span> to any vertex <span
class="math inline">\(b_1\in \beta\)</span>. For any vertices <span
class="math inline">\(a_i\in \alpha\)</span> and <span
class="math inline">\(b_j\in \beta\)</span>, the shortest path in <span
class="math inline">\(R\)</span> from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> either does not cross <span
class="math inline">\(\pi\)</span> at all, crosses <span
class="math inline">\(\pi\)</span> positively once, or crosses <span
class="math inline">\(\pi\)</span> negatively once. Let <span
class="math inline">\(\Delta = R\setminus\!\!\setminus \pi\)</span>, and
let <span class="math inline">\(\Delta^2\)</span> be the map obtained by
gluing two copies of <span class="math inline">\(\Delta\)</span>
together along <span class="math inline">\(\pi\)</span>, as shown in the
figure below. Then we have <span class="math display">\[
    \textsf{dist}_R(a_i, b_j) =
    \min\left\{
        \begin{gathered}
            \textsf{dist}_\Delta(a_i, b_j) \\[0.25ex]
            \textsf{dist}_{\Delta^2}(a_i^+, b_j^-) \\
            \textsf{dist}_{\Delta^2}(a_i^-, b_j^+)
        \end{gathered}
    \right\}
\]</span> where <span class="math inline">\(v^+\)</span> and <span
class="math inline">\(v^-\)</span> denote the two copies of vertex <span
class="math inline">\(v\)</span> in <span
class="math inline">\(\Delta^2\)</span>. Thus, the array <span
class="math inline">\(D(\alpha,\beta)\)</span> of pairwise distances
between vertices of <span class="math inline">\(\alpha\)</span> and
vertices of <span class="math inline">\(\beta\)</span> is the
element-wise minimum of three Monge arrays.</p>
<figure>
<img src="Fig/shortest-path-annulus.png" style="width:60.0%"
alt="Three types of boundary-to-boundary shortest paths in an annulus." />
<figcaption aria-hidden="true">Three types of boundary-to-boundary
shortest paths in an annulus.</figcaption>
</figure>
<p>Next consider a single hole in <span class="math inline">\(R\)</span>
with boundary <span class="math inline">\(\alpha\)</span>; by
construction <span class="math inline">\(\alpha\)</span> has at most
<span class="math inline">\(O(\sqrt{r})\)</span> vertices. As we saw two
lectures ago, the array <span class="math inline">\(D(\alpha)\)</span>
of pairwise distances in <span class="math inline">\(R\)</span> between
vertices in <span class="math inline">\(\alpha\)</span> is
<em>almost</em> Monge. Instead of splitting this array into
<em>partial</em> Monge arrays, we recursively partition it into <span
class="math inline">\(O(\sqrt{r})\)</span> square Monge subarrays.
Specifically, the upper right and lower left quadrants of <span
class="math inline">\(D(\alpha)\)</span> are both Monge, and we
recursively subdivide the lower left and upper right quadrants. Every
row or column of <span class="math inline">\(D(\alpha)\)</span>
intersects at most <span class="math inline">\(O(\log r)\)</span> of
these square subarrays. The total perimeter of these Monge arrays is
<span class="math inline">\(O(\sqrt{r} \log r)\)</span>.</p>
<figure>
<img src="Fig/quadtree-Monge.png" style="width:25.0%"
alt="Recursive partition of a circular Monge array into square Monge subarrays." />
<figcaption aria-hidden="true">Recursive partition of a circular Monge
array into square Monge subarrays.</figcaption>
</figure>
<p>Putting these two cases together, we can represent the
boundary-to-boundary distances within each piece <span
class="math inline">\(R\)</span> using <span
class="math inline">\(O(\sqrt{r})\)</span> Monge arrays, with total area
<span class="math inline">\(O(r)\)</span> and total perimeter <span
class="math inline">\(O(\sqrt{r}\log r)\)</span>. Altogether there are
<span class="math inline">\(O(n/\sqrt{r})\)</span> Monge arrays
associated with the entire <span
class="math inline">\(r\)</span>-division, with total area <span
class="math inline">\(O(n)\)</span> and total perimeter <span
class="math inline">\(O((n/\sqrt{r})\log r)\)</span>.</p>
<p>Finally, suppose we associate a Monge heap with every Monge array in
every piece of our <span class="math inline">\(r\)</span>-division. Then
the total number of <span class="math inline">\(\textsf{Reveal}\)</span>
and <span class="math inline">\(\textsf{Hide}\)</span> operations we can
perform is <span class="math inline">\(O((n/\sqrt{r})\log r)\)</span>,
and each of those operations takes <span class="math inline">\(O(\log
r)\)</span> amortized time. Thus, the total time spent constructing and
maintaining all Monge heaps, over their entire lifetimes, over the
entire <span class="math inline">\(r\)</span>-division, is <span
class="math inline">\(O((n/\sqrt{r}) \log^2 r)\)</span>.</p>
<h2 data-number="21.3" id="fr-dijkstra"><span
class="header-section-number">21.3</span> FR-Dijkstra</h2>
<p>Fakcharoenphol and Rao implement their improvement to Dijkstra’s
algorithm as follows. We begin by computing a nice <span
class="math inline">\(r\)</span>-division for <span
class="math inline">\(\Sigma\)</span> and the dense-distance graph for
that <span class="math inline">\(r\)</span>-division in <span
class="math inline">\(O(n\log r)\)</span> time, for some value of <span
class="math inline">\(r\)</span> to be determined later.</p>
<p>The query phase of FR-Dijkstra solves the single-source shortest path
problem in the dense distance graph: Given a boundary vertex <span
class="math inline">\(s\)</span> in our <span
class="math inline">\(r\)</span>-division, compute the shortest-path
distance to every other boundary vertex in the <span
class="math inline">\(r\)</span>-division. The algorithm mirrors the
Dijkstra’s algorithm, but using a nested collection of heaps instead of
a standard priority queue:</p>
<ul>
<li><p><span class="math inline">\(O(\sqrt{r})\)</span> Monge heaps for
each piece of the <span class="math inline">\(r\)</span>-division, once
for each Monge array in the decomposition described above.</p></li>
<li><p>A standard priority queue, called a <em>piece heap</em>, for each
piece of the <span class="math inline">\(r\)</span>-division, containing
the minimum elements of every Monge heap associated with that piece. We
automatically update the piece heap whenever the minimum element of a
Monge heap changes.</p></li>
<li><p>A standard priority queue, called the <em>global heap</em>,
containing the minimum elements of the piece heaps. We automatically
update the global heap whenever the minimum element of a piece heap
changes.</p></li>
</ul>
<p>To begin the algorithm, we initialize all the component heaps to
empty, call <span class="math inline">\(\textsf{Reveal}(s, 0)\)</span>
and <span class="math inline">\(\textsf{Hide}(s)\)</span> inside every
Monge heap containing the source vertex <span
class="math inline">\(s\)</span>. In alter iterations, whenever we
extract the next closest vertex <span class="math inline">\(v\)</span>
from the global priority queue, we call <span
class="math inline">\(\textsf{Reveal}(v, \textsf{dist}(v))\)</span> and
<span class="math inline">\(\textsf{Hide}(v)\)</span> in every Monge
heap containing vertex <span class="math inline">\(v\)</span>. By
induction, the vertex at the top of the global heap is always the
closest boundary vertex beyond the current Dijkstra wavefront.</p>
<p>The running time of the algorithm is dominated by the time spent
maintain the three different levels of heaps.</p>
<ul>
<li><p>As we argued above, the total time spent managing all Monge heaps
is <span class="math inline">\(O((n/\sqrt{r}) \log^2
r)\)</span>.</p></li>
<li><p>For each piece <span class="math inline">\(R\)</span>, we perform
<span class="math inline">\(O(\log r)\)</span> operations in <span
class="math inline">\(R\)</span>’s piece heap for each boundary vertex
of <span class="math inline">\(R\)</span>. Thus, the number of
piece-heap operations across the entire <span
class="math inline">\(r\)</span>-division is <span
class="math inline">\(O((n/\sqrt{r}) \log r)\)</span>; each piece-heap
operation takes <span class="math inline">\(O(\log r)\)</span>
time.</p></li>
<li><p>Finally, each iteration of Dijkstra’s algorithm removes one
vertex <span class="math inline">\(v\)</span> from the global heap and
performs at most one deletion and one inserti on for each piece
containing <span class="math inline">\(v\)</span>. Said differently, for
each piece <span class="math inline">\(R\)</span>, we perform <span
class="math inline">\(O(1)\)</span> global-heap operations for boundary
vertex of <span class="math inline">\(R\)</span>. So the total number of
global-heap operations is <span
class="math inline">\(O(n/\sqrt{r})\)</span>; each global-heap operation
takes <span class="math inline">\(O(\log n)\)</span> time.</p></li>
</ul>
<p>Thus, the overall running time of the query phase of FR-Dijkstra is
<span class="math inline">\(O((n/\sqrt{r})(\log^2r + \log n))\)</span>.
(The final <span class="math inline">\(\log n\)</span> term can be
eliminated with more effort.)</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>After <span class="math inline">\(O(n\log r)\)</span> preprocessing
time, we can compute the shortest-path distance between any two vertices
in a dense distance graph in <span
class="math inline">\(O((n/\sqrt{r})(\log^2r + \log n))\)</span>
time.</em>
</dd>
</dl>
<h2 data-number="21.4" id="back-to-minimum-cut"><span
class="header-section-number">21.4</span> Back to minimum cut</h2>
<p>In the previous lecture, we reduced computing minimum <span
class="math inline">\((s,t)\)</span>-cuts to the following problem.
Given a planar map <span class="math inline">\(\Sigma\)</span> with
non-negatively weighted weighted edges, and vertices <span
class="math inline">\(s_0, s_1, \dots, s_k, t_k, \dots, t_1,
t_0\)</span> in cyclic order on the outer face, compute the shortest
path distance <span class="math inline">\(\textsf{dist}(s_i,
t_i)\)</span> for every index <span class="math inline">\(i\)</span>.
Reif’s algorithm solves this problem in <span
class="math inline">\(O(n\log k)\)</span> time by computing the
<em>median</em> shortest path <span class="math inline">\(\pi_m\)</span>
from <span class="math inline">\(s_m\)</span> to <span
class="math inline">\(t_m\)</span>, where <span
class="math inline">\(m=\lfloor k/2 \rfloor\)</span>, and then recursing
on both sides of the sliced map <span class="math inline">\(\Sigma
\backslash\!\!\backslash \pi_m\)</span>.</p>
<p>The more efficient algorithm of Italiano et al. follows Reif’s
divide-and-conquer strategy, in three phases.</p>
<ul>
<li><p>In the <em>initialization</em> phase, we construct a nice <span
class="math inline">\(r\)</span>-division of <span
class="math inline">\(\Sigma\)</span>, construct its dense distance
graph by running MSSP in each piece, and initialize the range-minimum
trees needed to support FR-Dijkstra. This phase runs in <span
class="math inline">\(O(n\log r)\)</span> time.</p></li>
<li><p>Let <span class="math inline">\(\lambda = \lfloor \log_2 k
\rfloor\)</span>. In the <em>coarse</em> divide-and-conquer phase, we
compute shortest paths from <span
class="math inline">\(s_{i\lambda}\)</span> to <span
class="math inline">\(t_{i\lambda}\)</span> for all indices <span
class="math inline">\(0\le i\le \lfloor i/\lambda \rfloor\)</span>,
using Reif’s divide-and-conquer strategy, using FR-Dijkstra to compute
each shortest path.</p></li>
<li><p>Finally, in the <em>fine</em> divide-and-conquer phase, we run
Reif’s algorithm within each of the <span
class="math inline">\(O(k/\lambda)\)</span> slabs left by the previous
phase, using the linear-time shortest path algorithm to compute each
shortest path. Since each slab has only <span
class="math inline">\(\lambda = O(\log k)\)</span> terminal pairs on its
boundary, the total time for this phase is <span
class="math inline">\(O(n\log\log k)\)</span>.</p></li>
</ul>
<p>Crudely, the coarse divide-and-conquer phase stops after <span
class="math inline">\(O(\log(k/\lambda)) = O(\log n)\)</span> levels of
recursion, and the total time spent at each level is <span
class="math inline">\(O((n/\sqrt{r})(\log^2r + \log n))\)</span> time at
each level. It follows that the overall time for this phase is <span
class="math inline">\(O((n/\sqrt{r})(\log^2r + \log n)\log k) =
O((n/\sqrt{r})\log^3 n)\)</span>, and thus the overall running time of
the overall algorithm is <span class="math display">\[
    O\left(n\log r + \frac{n}{\sqrt{r}}\log^3 n + n\log \log k\right).
\]</span> Setting <span class="math inline">\(r = \log^6 n\)</span>
gives us a final running time of <span class="math inline">\(O(n\log\log
n)\)</span>. (With more effort, this time bound can be reduced to <span
class="math inline">\(O(n\log\log k)\)</span>.)</p>
<h3 data-number="21.4.1" id="technical-details"><span
class="header-section-number">21.4.1</span> Technical Details</h3>
<p>The previous high-level description and analysis overlooks several
technical details which are crucial for the efficiency of the algorithm.
Here I’ll give only a brief sketch of the most significant outstanding
issues and how to resolve them.</p>
<p>Arguably the most significant detail is that the pieces of the <span
class="math inline">\(r\)</span>-division do not respect the slab
boundaries. The the running time of the query phase of FR-Dijkstra
within any slab depends on the <em>total</em> size of all pieces that
intersect that slab, and a single piece could intersect several (or even
<em>all</em>) slabs at any level of recursion. To avoid blowing up the
running time, we must slice pieces (and their underlying collections of
Monge arrays) along the shortest paths we compute. <strong>This can be
done.</strong></p>
<p>Just as in Reif’s algorithm, we stop the course recursion early
whenever any vertex of the dense-distance graph appears on both the
“floor” and “ceiling” paths of a slab. All <span
class="math inline">\(s_i\)</span>-to-<span
class="math inline">\(t_i\)</span> distances through that slab will be
computed in <span class="math inline">\(O(n)\)</span> time in the fine
phase of the algorithm. If we ignore these <em>collapsed</em> slabs,
then at every level of recursion, each boundary vertex appears in at
most two slabs, so the sum over all sub-pieces of the number of boundary
nodes in that sub-piece is in fact <span
class="math inline">\(O(n/\sqrt{r})\)</span>.</p>
<p>Another important technical detail is that after the coarse phase
ends, we need to translate the shortest paths in the dense-distance
graph into explicit shortest paths in <span
class="math inline">\(\Sigma\)</span>. In particular, we need to
translate each boundary-to-boundary <em>distance</em> within a single
piece, as computed by MSSP, into an explicit boundary-to-boundary
<em>path</em>. If we record the execution of the MSSP algorithm as a
persistent data structure, we can extract the last edge of the shortest
path from any boundary node <span class="math inline">\(s\)</span> to
any internal node <span class="math inline">\(v\)</span> in <span
class="math inline">\(O(\log\log\deg(v))\)</span> time. Thus, a shortest
path consisting of <span class="math inline">\(\ell\)</span> edges can
be extracted in <span class="math inline">\(O(\ell\log\log n)\)</span>
time. If we assume (as Italiano et al. do) that</p>
<p>These <span class="math inline">\(O(k/\log k)\)</span> shortest paths
in <span class="math inline">\(\Sigma\)</span> can overlap; in the worst
case, the sum of their complexities is <span
class="math inline">\(\Omega(nk/\log k)\)</span>. The union of these
<span class="math inline">\(O(k/\log k)\)</span> shortest paths is a
forest <span class="math inline">\(F\)</span>; Italiano et al. describe
how to compute <span class="math inline">\(F\)</span> in <span
class="math inline">\(O(n\log\log n)\)</span> time.</p>
<p>Finally, at the beginning of the fine phase of the algorithm, suppose
the floor <span class="math inline">\(\alpha\)</span> and ceiling <span
class="math inline">\(\beta\)</span> of some slab coincide. We can
compute the endpoints <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> of the shared path <span
class="math inline">\(\alpha\cap\beta\)</span> by performing
least-common-ancestor queries in the forest <span
class="math inline">\(F\)</span>. Then every <span
class="math inline">\(s_i\)</span>-to-<span
class="math inline">\(t_i\)</span> shortest path in that slab consists
of the shortest path from <span class="math inline">\(s_i\)</span> to
<span class="math inline">\(x\)</span>, the unique path in <span
class="math inline">\(F\)</span> from <span
class="math inline">\(x\)</span> to <span
class="math inline">\(y\)</span>, and the shortest path from <span
class="math inline">\(y\)</span> to <span
class="math inline">\(t_i\)</span>. Thus, we can compute all <span
class="math inline">\(s_i\)</span>-to-<span
class="math inline">\(t_i\)</span> distances in that slab in linear
time, by computing shortest path trees at <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>.</p>
<h2 data-number="21.5" id="aptly-named-sir-not-4"><span
class="header-section-number">21.5</span> Aptly Named Sir Not</h2>
<ul>
<li>Faster global minimum cuts (dual to shortest weighted cycle)</li>
</ul>
<h1 data-number="22" id="distributive-flow-latticesvarnothing"><span
class="header-section-number">22</span> Distributive Flow Lattices<span
class="math inline">\(^\varnothing\)</span></h1>
<p><strong><em>Status: Unwritten</em></strong></p>
<h2 data-number="22.1" id="pseudoflows-and-circulations"><span
class="header-section-number">22.1</span> Pseudoflows and
Circulations</h2>
<p>Let <span class="math inline">\(\Sigma\)</span> be a planar map. A
<em>pseudoflow</em> in <span class="math inline">\(\Sigma\)</span> is an
antisymmetric function <span class="math inline">\(\phi\colon
D(\Sigma)\to \mathbb{R}\)</span> from the darts of <span
class="math inline">\(\Sigma\)</span> to the reals; here antisymmetry
means <span class="math inline">\(\phi(d) =
-\phi(\textsf{rev}(d))\)</span> for every dart <span
class="math inline">\(d\)</span>.<a href="#fn57" class="footnote-ref"
id="fnref57" role="doc-noteref"><sup>57</sup></a> Pseudoflows in <span
class="math inline">\(\Sigma\)</span> define a real vector space <span
class="math inline">\(C_1(\Sigma)\)</span>, unimaginatively called the
<em>chain space</em> of <span class="math inline">\(\Sigma\)</span>,
whose dimension is equal to the number of <em>edges</em> of <span
class="math inline">\(\Sigma\)</span>. If we arbitrarily fix a
<em>reference dart</em> <span class="math inline">\(e^+\)</span> for
every edge <span class="math inline">\(e\)</span>, then we can specify a
unique 1-chain by assigning arbitrary values to the reference darts.</p>
<p>A <em>circulation</em> is a pseudoflow that obeys <em>Kirchhoff’s
current law</em>: For every vertex <span
class="math inline">\(v\)</span>, the values assigned to darts into
<span class="math inline">\(v\)</span> sum to zero. (We previously
called circulations <em>closed discrete 1-forms</em>) More generally,
the <em>boundary</em> <span class="math inline">\(\partial\phi\)</span>
of any pseudoflow is the function <span
class="math inline">\(\partial\phi\colon V(\Sigma)\to\mathbb{R}\)</span>
defined by <span class="math display">\[\partial\phi(v) =
\sum_{u\mathord\to v} \phi(u\mathord\to v) = \sum_{d\colon
\textsf{head}(d)=v} \phi(v).\]</span> (At the risk of confusing the
reader, I will use the first summation notation even when <span
class="math inline">\(\Sigma\)</span> has parallel edges.)</p>
<p>Fix a tree-cotree decomposition <span
class="math inline">\((T,C)\)</span> of <span
class="math inline">\(\Sigma\)</span>. For any non-tree edge <span
class="math inline">\(e\in C\)</span>, the <em>fundamental cycle</em>
<span class="math inline">\(\textsf{cycle}_T(e^+)\)</span> is the
directed cycle consisting of the reference dart <span
class="math inline">\(e^+\)</span> and the directed path in <span
class="math inline">\(T\)</span> from <span
class="math inline">\(\textsf{head}(e^+)\)</span> to <span
class="math inline">\(\textsf{tail}(e^+)\)</span>.</p>
<p><strong>Lemma:</strong> <em>Fix an arbitrary planar map <span
class="math inline">\(\Sigma\)</span> and an arbitrary tree-cotree
decomposition <span class="math inline">\((T, C)\)</span> of <span
class="math inline">\(\Sigma\)</span>. Every circulation <span
class="math inline">\(\phi\)</span> in <span
class="math inline">\(\Sigma\)</span> satisfies the identity <span
class="math display">\[ \phi = \sum_{e\in C} \phi(e^+) \cdot
\textsf{cycle}_T(e^+) \]</span>.</em></p>
<h2 data-number="22.2" id="aptly-named-sir-not-5"><span
class="header-section-number">22.2</span> Aptly Named Sir Not</h2>
<h1 data-number="23" id="maximum-flowvarnothingalpha"><span
class="header-section-number">23</span> Maximum Flow<span
class="math inline">\(^{\varnothing/\alpha}\)</span></h1>
<figure>
<img src="Fig/HarrisRoss55-railflowcut.png" style="width:90.0%"
alt="Harris and Ross’s map of the Warsaw-Pact railway network." />
<figcaption aria-hidden="true">Harris and Ross’s map of the Warsaw-Pact
railway network.</figcaption>
</figure>
<h2 data-number="23.1" id="background"><span
class="header-section-number">23.1</span> Background</h2>
<p>Here I’ll provide a brief overview of standard definitions related to
the maximum flow problem. For a more thorough and gentler introduction,
see chapters 10 and 11 in my algorithms textbook.</p>
<h3 class="unnumbered"
id="pseudoflows-flows-and-circulations">Pseudoflows, flows, and
circulations</h3>
<p>Recall that a <em>pseudoflow</em> (or <em>1-chain</em>, or
<em>discrete 1-form</em>) in a graph <span
class="math inline">\(G\)</span> is any function <span
class="math inline">\(\phi \colon D(G) \to \mathbb{R}\)</span> on the
darts of <span class="math inline">\(G\)</span> that is antisymmetric,
meaning <span class="math inline">\(\phi(d) = -
\phi(\textsf{rev}(d))\)</span> for every dart <span
class="math inline">\(d\)</span>. Intuitively, the value <span
class="math inline">\(\phi(u{\to}v)\)</span> represents the rate of flow
of some divisible substance like water, train cars, or network packets
from <span class="math inline">\(u\)</span> to <span
class="math inline">\(v\)</span> along the undirected edge <span
class="math inline">\(uv\)</span>. In particular, a negative value
indicates that the substance is flowing backward from <span
class="math inline">\(v\)</span> to <span
class="math inline">\(u\)</span>.<a href="#fn58" class="footnote-ref"
id="fnref58" role="doc-noteref"><sup>58</sup></a></p>
<p>The <em>boundary</em> <span class="math inline">\(\partial\phi\colon
V(G)\to \mathbb{R}\)</span> of a pseudoflow <span
class="math inline">\(\phi\)</span> that intuitively describes the total
net flow into each vertex <span class="math inline">\(v\)</span>: <span
class="math display">\[
    \partial\phi(v) := \sum_u \phi(u{\to}v).
\]</span> A <em>circulation</em> is a pseudoflow <span
class="math inline">\(\phi\)</span> whose boundary <span
class="math inline">\(\partial\phi\)</span> is identically zero.
Intuitively, circulations are pseudoflows that respect conservation of
mass; any positive flow into <span class="math inline">\(v\)</span> must
be balanced by negative flow into <span class="math inline">\(v\)</span>
(that is, positive flow out of <span
class="math inline">\(v\)</span>).</p>
<p>For two fixed vertices <span class="math inline">\(s\)</span> and
<span class="math inline">\(t\)</span>, an <em><span
class="math inline">\((s,t)\)</span>-flow</em> is a pseudoflow <span
class="math inline">\(f\)</span> such that <span
class="math inline">\(\partial f(v) = 0\)</span> for all <span
class="math inline">\(v\)</span> except possibly <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span>. The <em>value</em> of an <span
class="math inline">\((s,t)\)</span>-flow <span
class="math inline">\(\phi\)</span> is the total net flow into <span
class="math inline">\(t\)</span> or out of <span
class="math inline">\(s\)</span>: <span class="math display">\[
    |\phi| := \partial \phi(t) = -\partial \phi(s).
\]</span> Intuitively, <span class="math inline">\((s,t)\)</span>-flows
model some substance being injected into a network of pipes at <span
class="math inline">\(s\)</span> and being extracted at <span
class="math inline">\(t\)</span>, with conservation at every other
vertex. Every circulation is an <span
class="math inline">\((s,t)\)</span>-flow with value <span
class="math inline">\(0\)</span>.</p>
<p><strong>Lemma:</strong> <em>For any two <span
class="math inline">\((s,t)\)</span>-flows <span
class="math inline">\(\phi\)</span> and <span
class="math inline">\(\psi\)</span> in the same graph <span
class="math inline">\(G\)</span> and any two real numbers <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>, the function <span
class="math inline">\(\alpha\phi + \beta\psi\)</span> is an <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G\)</span> with value <span
class="math inline">\(\alpha|\phi| + \beta|\psi|\)</span>. In
particular, if <span class="math inline">\(\phi\)</span> and <span
class="math inline">\(\psi\)</span> are circulations, then <span
class="math inline">\(\alpha\phi + \beta\psi\)</span> is also a
circulation. Thus, circulations and <span
class="math inline">\((s,t)\)</span>-flows in any graph <span
class="math inline">\(G\)</span> define vector spaces.</em></p>
<p>We can regard any directed cycle <span
class="math inline">\(\gamma\)</span> as a circulation: <span
class="math display">\[
    \gamma(d) = \begin{cases}
        1 &amp; \text{if $d \in \gamma$} \\
        -1 &amp; \text{if $\textsf{rev}(d) \in \gamma$} \\
        0 &amp; \text{otherwise}
    \end{cases}
\]</span> Similarly, we can regard any directed path <span
class="math inline">\(\pi\)</span> from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> as an <span
class="math inline">\((s,t)\)</span>-flow: <span class="math display">\[
    \pi(d) = \begin{cases}
        1 &amp; \text{if $d \in \pi$} \\
        -1 &amp; \text{if $\textsf{rev}(d) \in \pi$} \\
        0 &amp; \text{otherwise}
    \end{cases}
\]</span></p>
<p><strong>Lemma:</strong> <em>Every circulation is a weighted sum of
simple directed cycles. Every <span
class="math inline">\((s,t)\)</span>-flow is a weighted sum of simple
directed <span class="math inline">\((s,t)\)</span>-paths and simple
directed cycles.</em></p>
<h3 class="unnumbered" id="capacities-and-residual-graphs">Capacities
and residual graphs</h3>
<p>A <em>capacity</em> function for a graph <span
class="math inline">\(G\)</span> is any function <span
class="math inline">\(c\colon D(G)\to\mathbb{R}\)</span> from the darts
to the reals. Capacities are not necessary either symmetric,
antisymmetric, or non-negative. A <em>flow network</em> is a graph <span
class="math inline">\(G\)</span> together with a capacity function <span
class="math inline">\(c\)</span>.</p>
<p>A pseudoflow (or circulation or <span
class="math inline">\((s,t)\)</span>-flow) <span
class="math inline">\(\phi\)</span> is <em>feasible</em> with respect to
<span class="math inline">\(c\)</span> if and only if <span
class="math inline">\(\phi(d) \le c(d)\)</span> for every dart <span
class="math inline">\(d\)</span>. In particular, we allow the capacity
of a dart to be negative; a negative dart capacity is equivalent to a
positive <em>lower bound</em> on the amount of flow through the reversal
of the dart. The zero flow <span class="math inline">\(\phi\equiv
0\)</span> is feasible if and only if every dart has non-negative
capacity.</p>
<p>Given a graph <span class="math inline">\(G\)</span>, capacity
function <span class="math inline">\(c\)</span>, and two vertices <span
class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> as input, the maximum flow problem asks
for a feasible <span class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G\)</span> with the largest possible value.</p>
<p>Fix a graph <span class="math inline">\(G\)</span> and a capacity
function <span class="math inline">\(c\)</span>. Any pseudoflow <span
class="math inline">\(\phi\)</span> in <span
class="math inline">\(G\)</span> induces a <em>residual capacity</em>
function <span class="math inline">\(c_\phi\colon D(G)\to
\mathbb{R}\)</span>, defined simply as <span
class="math inline">\(c_\phi(d) = c(d) - \phi(d)\)</span>. A pseudoflow
<span class="math inline">\(\phi\)</span> is feasible if and only if
every dart has non-negative residual capacity. The <em>residual
graph</em> <span class="math inline">\(G_\phi\)</span> is just the
original graph <span class="math inline">\(G\)</span> but with the new
capacity function <span class="math inline">\(c_\phi\)</span>. A
<em>residual path</em> (respectively, <em>residual cycle</em>) is a
directed path (respectively, directed cycle) in <span
class="math inline">\(G_\phi\)</span> in which every dart has
<em>positive</em> residual capacity.</p>
<p>The standard textbook algorithm for maximum flows, proposed by Lester
Ford and Delbert Fulkerson in 1953, is the <em>augmenting path</em>
method. The method starts by finding an initial feasible <span
class="math inline">\((s,t)\)</span>-flow <span
class="math inline">\(\phi\)</span>; typically all capacities are
non-negative, so we can start with the zero flow <span
class="math inline">\(\phi\equiv 0\)</span>. Then we repeatedly
<em>augment</em> the flow <span class="math inline">\(\phi\)</span> by
<em>pushing</em> more flow along paths from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>. Specifically, at each iteration, we
find a residual path <span class="math inline">\(\pi\)</span> and
augment the flow by setting <span class="math inline">\(\phi’ \gets \phi
+ \min_{d\in\pi} c_\phi(d) \cdot \pi\)</span>; here I’m treating <span
class="math inline">\(\pi\)</span> both as a sequence of darts and as an
<span class="math inline">\((s,t)\)</span>-flow. Straightforward
definition-chasing implies that if the original flow <span
class="math inline">\(\phi\)</span> is feasible, then the augmented flow
<span class="math inline">\(\phi’\)</span> is also feasible. When <span
class="math inline">\(G_\phi\)</span> contains no more residual paths,
<span class="math inline">\(\phi\)</span> is a maximum <span
class="math inline">\((s,t)\)</span>-flow. More generally:</p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\phi\)</span> and <span
class="math inline">\(\phi’\)</span> be any (not necessarily feasible)
<span class="math inline">\((s,t)\)</span>-flows in <span
class="math inline">\(G\)</span>.</em></p>
<ol type="a">
<li><em><span class="math inline">\(\phi’\)</span> is a feasible <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G\)</span> if and only if <span
class="math inline">\(\phi’-\phi\)</span> is a feasible <span
class="math inline">\((s,t)\)</span>-flow in the residual graph <span
class="math inline">\(G_\phi\)</span>.</em></li>
<li><em>In particular, if <span class="math inline">\(|\phi| =
|\phi’|\)</span>, then <span class="math inline">\(\phi’\)</span> is a
feasible <span class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G\)</span> if and only if <span
class="math inline">\(\phi’-\phi\)</span> is a feasible
<strong>circulation</strong> in <span
class="math inline">\(G_\phi\)</span>.</em></li>
<li><em>In particular, <span class="math inline">\(\phi’\)</span> is a
<strong>maximum</strong> <span class="math inline">\((s,t)\)</span>-flow
in <span class="math inline">\(G\)</span> if and only if <span
class="math inline">\(\phi’-\phi\)</span> is a <strong>maximum</strong>
<span class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G_\phi\)</span>.</em></li>
</ol>
<h2 data-number="23.2" id="planar-circulations"><span
class="header-section-number">23.2</span> Planar Circulations</h2>
<p>Flows and circulations have particularly nice structure in planar
graphs, or more accurately, in planar <em>maps</em>.</p>
<p>Fix an arbitrary circulation <span
class="math inline">\(\phi\)</span> in an arbitrary planar map <span
class="math inline">\(\Sigma\)</span>, with a distinguished outer face
<span class="math inline">\(o\)</span>. The <em>winding number</em> of
<span class="math inline">\(\phi\)</span> around each face <span
class="math inline">\(f\)</span> of <span
class="math inline">\(\Sigma\)</span>, denoted <span
class="math inline">\(\textsf{wind}(\phi, f)\)</span> can be defined by
extending the definition of the Alexander numbering of a curve:</p>
<ul>
<li><span class="math inline">\(\textsf{wind}(\phi, o) = 0\)</span></li>
<li>For every dart <span class="math inline">\(d\)</span>, we have <span
class="math inline">\(\textsf{wind}(\phi, \textsf{left}(d)) = \phi(d) +
\textsf{wind}(\phi, \textsf{right}(d))\)</span>.</li>
</ul>
<p>Conservation at each vertex <span class="math inline">\(v\)</span>
implies that this st of constraints has a unique solution. Equivalently,
for any path (in fact, any <em>walk</em>) <span
class="math inline">\(\pi\)</span> in the dual map <span
class="math inline">\(\Sigma^*\)</span> from dual of the outer face
<span class="math inline">\(o^*\)</span> to the dual vertex <span
class="math inline">\(f^*\)</span>, we have <span
class="math display">\[
    \textsf{wind}(\phi, f) = \sum_{d^*\in\pi} \phi(d).
\]</span> The second definition is independent of the choice of dual
path <span class="math inline">\(\pi\)</span>, again by conservation. A
third equivalent definition uses the fact that <span
class="math inline">\(\phi\)</span> is a weighted sum of simple cycles:
<span class="math display">\[
    \phi = \sum_i \alpha_i\cdot \gamma_i
    \implies
    \textsf{wind}(\phi, f) = \sum_i \alpha_i\cdot
\textsf{wind}(\gamma_i, f);
\]</span> This definition is independent of the chosen decomposition of
<span class="math inline">\(\phi\)</span> into cycles <span
class="math inline">\(\gamma_1, \gamma_2, \dots\)</span>.</p>
<!--
**Lemma:**
_Fix a planar map $\Sigma$.  For any circulation $\phi$ in $\Sigma$, and any circulation $\theta$  in the dual map $\Sigma^*$, we have $\sum_d \phi(d) \cdot \theta(d^*) = 0$, where the sum is over the darts of $\Sigma$._

**Proof:**
: Because every circulation can be expressed as a sum of simple directed cycles, it suffices to consider a simple directed cycle $\gamma$ in $\Sigma$ and a simple directed cycle $\lambda$ in $\Sigma^*$.

: The Jordan curve theorem implies that these two cycles intersect an even number of times; specifically, the number of times that $\gamma$ crosses $\lambda$ from left to right is equal to the number of times $\gamma$ crosses $\lambda$ from right to left.  Every crossing is the intersection of an edge of $\Sigma$ with its dual edge in $\Sigma^*$.

: Consider an arbitrary dart $d$ in $\gamma$.  The dual dart $d^*$ is in $\theta$ if and only if $\gamma$ crosses $\theta$ from left to right at the point $d\cap d^*$.  Conversely, $\textsf{rev}(d^*) = \textsf{rev}(d)^* \in \theta$ if and only if $\gamma$ crosses $\theta$ from right to left at the point $d\cap d^*$.  Thus, each left-to-right crossing contributes $2$ to the sum $\sum_d \gamma(d) \cdot \lambda(d^*) = 0$ (one from the dart $d\in\gamma\cap\theta^*$ and one from its reversal), and each right-to-left crossing contributes $-2$. $\qquad\square$
-->
<p>Alexander numbering is an example of a <em>face potential</em> (or
<span class="math inline">\(2\)</span>-chain); more generally, a face
potential in <span class="math inline">\(\Sigma\)</span> is any function
<span class="math inline">\(\alpha\colon F(\Sigma)\to\mathbb{R}\)</span>
assigning a real number to each face of <span
class="math inline">\(\Sigma\)</span>. The <em>boundary</em> of a face
potential <span class="math inline">\(\alpha\)</span> is the circulation
<span class="math inline">\(\partial\alpha\colon D(\Sigma)\to
\mathbb{R}\)</span> defined by setting <span class="math display">\[
    \partial\alpha(d) = \alpha(\textsf{left}(d)) -
\alpha(\textsf{right}(d))
\]</span> for every dart <span class="math inline">\(d\)</span>. It
should be easy to verify that <span
class="math inline">\(\partial\alpha\)</span> is indeed a circulation.
Moreover, the boundary operator <span
class="math inline">\(\partial\)</span> is linear; for all face
potentials <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> and real numbers <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span>, we have <span
class="math inline">\(\partial(a\cdot\alpha + b\cdot\beta) =
a\cdot\partial\alpha + b\cdot\partial\beta\)</span>.</p>
<p>The following lemma is a natural generalization (and consequence) of
the Jordan Curve Theorem.</p>
<p><strong>Lemma:</strong> <em>Every circulation in a planar map is a
boundary circulation.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
For any circulation <span class="math inline">\(\phi\)</span>, routine
definition-chasing implies <span class="math inline">\(\phi = \partial
(\textsf{wind}(\phi))\)</span>. That is, <span
class="math inline">\(\phi = \partial\alpha\)</span>, where <span
class="math inline">\(\alpha(f) = \textsf{wind}(\alpha, f)\)</span> for
every face <span class="math inline">\(f\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Corollary:</strong> <em>The difference between any two <span
class="math inline">\((s,t)\)</span>-flows with the same value in the
same planar map <span class="math inline">\(\Sigma\)</span> is a
boundary circulation in <span
class="math inline">\(\Sigma\)</span>.</em></p>
<h2 data-number="23.3"
id="feasible-planar-circulations-and-shortest-paths"><span
class="header-section-number">23.3</span> Feasible Planar Circulations
and Shortest Paths</h2>
<p>Now suppose we endow our planar map <span
class="math inline">\(\Sigma\)</span> with a capacity function <span
class="math inline">\(c\colon D(\Sigma)\to\mathbb{R}\)</span>. Every
dart <span class="math inline">\(d^*\)</span> in the dual map <span
class="math inline">\(\Sigma^*\)</span> has a <em>cost</em> or
<em>length</em> <span class="math inline">\(c(d^*)\)</span> equal to the
capacity of the corresponding primal dart <span
class="math inline">\(d\)</span>; in short, we have <span
class="math inline">\(c(d^*) = c(d)\)</span>.</p>
<p><strong>Lemma [Venkatesan]:</strong> <em>Let <span
class="math inline">\(\Sigma\)</span> be any planar map, and let <span
class="math inline">\(c\colon D(\Sigma)\to\mathbb{R}\)</span> be any
capacity function for <span class="math inline">\(\Sigma\)</span>. There
is a feasible circulation in <span class="math inline">\(\Sigma\)</span>
if and only if the dual map <span
class="math inline">\(\Sigma^*\)</span> has no negative cycles.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
First, consider an arbitrary circulation <span
class="math inline">\(\phi\)</span> in <span
class="math inline">\(\Sigma\)</span> and an arbitrary cycle <span
class="math inline">\(\lambda^*\)</span> in the dual map <span
class="math inline">\(\Sigma^*\)</span> with negative total cost.
Without loss of generality, assume <span
class="math inline">\(\lambda^*\)</span> is simple and oriented
counterclockwise. Whitney’s duality theorem implies that the set <span
class="math inline">\(\lambda\)</span> of primal darts whose duals lie
in <span class="math inline">\(\lambda^*\)</span> define a <em>directed
edge cut</em>. Specifically, let <span class="math inline">\(A\)</span>
denote the vertices of <span class="math inline">\(\Sigma\)</span> whose
corresponding dual faces lie inside <span
class="math inline">\(\lambda^*\)</span>. Then <span
class="math inline">\(\lambda\)</span> is the set of all darts in <span
class="math inline">\(\Sigma\)</span> such that <span
class="math inline">\(\textsf{head}(d)\in A\)</span> and <span
class="math inline">\(\textsf{tail}(d) \not\in A\)</span>.
Straightforward calculation implies <span class="math display">\[
\begin{aligned}
    \sum_{d\in \lambda} \phi(d)
    &amp;=
    \sum_{\textsf{head}(d)\in A} \phi(d)
        &amp; \text{because $\phi(d) = -\phi(\textsf{rev}(d))$}
    \\ &amp;=
    \sum_{v\in A\vphantom{[}} ~ \sum_{\textsf{head}(d) = v} \phi(d)
    \\ &amp;=
    \sum_{v\in A} \partial\phi(v)
        &amp; \text{by definition of $\partial$}
    \\ &amp;=
    \sum_{v\in A} 0
        &amp; \text{because $\phi$ is a circulation}
    \\ &amp;= 0
    \\ &amp; &gt; \sum_{d\in \lambda} c(d).
\end{aligned}
\]</span> (In the first step, we are adding <span
class="math inline">\(\phi(d)\)</span> for all darts with both endpoints
in <span class="math inline">\(A\)</span>.) We conclude that <span
class="math inline">\(\phi(d) &gt; c(d)\)</span> for at least one dart
<span class="math inline">\(d\in\lambda\)</span>; in short, <span
class="math inline">\(\phi\)</span> is not feasible.
</dd>
<dd>
<p>On the other hand, suppose shortest-path distances are well-defined
in <span class="math inline">\(\Sigma^*\)</span>. For any dual vertex
<span class="math inline">\(p\)</span>, let <span
class="math inline">\(\textsf{dist}(p)\)</span> denote the shortest-path
distance from the outer face <span class="math inline">\(o\)</span> to
<span class="math inline">\(p\)</span>. We can interpret the function
<span class="math inline">\(\textsf{dist}\)</span> as a face potential
function for <span class="math inline">\(\Sigma\)</span>. I claim that
the boundary circulation <span
class="math inline">\(\partial\textsf{dist}\)</span> is feasible. For
any dart <span class="math inline">\(d\)</span>, we have <span
class="math display">\[
\phi(d)
~=~
\textsf{dist}(\textsf{left}(d)^*) - \textsf{dist}(\textsf{right}(d)^*)
\]</span> Now define the <em>slack</em> of every dart <span
class="math inline">\(d\)</span> as <span class="math display">\[
\begin{aligned}
    \textsf{slack}(d)
    &amp; := c(d) - \phi(d)
    \\
    &amp; =
    c(d) - \textsf{dist}(\textsf{left}(d)^*) +
\textsf{dist}(\textsf{right}(d)^*)
    \\
    &amp; =
    \textsf{dist}(\textsf{tail}(d^*)) + c(d^*) -
\textsf{dist}(\textsf{head}(d^*))
\end{aligned}
\]</span> The definition of shortest paths implies that <span
class="math inline">\(\textsf{slack}(d) \ge 0\)</span> for every dart
<span class="math inline">\(d\)</span>, and thus <span
class="math inline">\(\phi(d) \le c(d)\)</span> for every dart <span
class="math inline">\(d\)</span>. We conclude that <span
class="math inline">\(\phi\)</span> is feasible.</p>
</dd>
</dl>
<p><strong>Corollary:</strong> <em>Given a planar map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and arbitrary dart capacities,
we can compute either a feasible circulation in <span
class="math inline">\(\Sigma\)</span> or a negative-cost cycle in <span
class="math inline">\(\Sigma^*\)</span> in <span
class="math inline">\(O(n\log^2 n)\)</span> time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Run the shortest-path algorithm of Klein, Mozes, and Weimann, starting
at the vertex <span class="math inline">\(o^*\)</span> dual to the outer
face <span class="math inline">\(o\)</span>. If shortest-path distances
in <span class="math inline">\(\Sigma^*\)</span> are well-defined, set
<span class="math inline">\(\phi(d) = \textsf{dist}(\textsf{left}(d)^*)
- \textsf{dist}(\textsf{right}(d)^*)\)</span> for every dart <span
class="math inline">\(d\)</span>. Otherwise, the algorithm finds a
negative cycle in <span class="math inline">\(\Sigma^*\)</span>. In both
cases, the algorithm runs in <span class="math inline">\(O(n\log^2
n)\)</span> time.
</dd>
</dl>
<h2 data-number="23.4" id="our-first-planar-max-flow-algorithm"><span
class="header-section-number">23.4</span> Our First Planar Max-flow
Algorithm</h2>
<p>The previous lemma can also be used to find feasible <span
class="math inline">\((s,t)\)</span>-flows with particular values. Fix
two vertices <span class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span> in <span
class="math inline">\(G\)</span>.</p>
<p><strong>Corollary:</strong> <em>Let <span
class="math inline">\(\phi\)</span> be an arbitrary (not necessarily
feasible) <span class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(\Sigma\)</span>. There is a feasible <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(G\)</span> with value <span
class="math inline">\(|\phi|\)</span> if and only if the dual residual
map <span class="math inline">\(\Sigma^*_\phi\)</span> has no negative
cycles.</em></p>
<p><strong>Corollary:</strong> <em>Given a planar map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices, arbitrary dart capacities,
and a real number <span class="math inline">\(\lambda\)</span>, we can
either compute a feasible <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(\Sigma\)</span> with value <span
class="math inline">\(\lambda\)</span>, or correctly report that no such
flow exists, in <span class="math inline">\(O(n\log^2 n)\)</span>
time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\pi\)</span> be any path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> in <span
class="math inline">\(\Sigma\)</span> with value <span
class="math inline">\(\lambda\)</span>, and let <span
class="math inline">\(\phi\)</span> be the flow <span
class="math inline">\(\lambda\cdot\pi\)</span>. Then <span
class="math inline">\(\phi’\)</span> is a <em>feasible</em> <span
class="math inline">\((s,t)\)</span>-flow with value <span
class="math inline">\(\lambda\)</span> if and only if <span
class="math inline">\(\phi’-\phi\)</span> is a feasible circulation in
the residual map <span class="math inline">\(\Sigma_\phi\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Corollary:</strong> <em>Given a planar map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices, non-negative
<strong>integer</strong> dart capacities <span
class="math inline">\(c(d)\)</span>, we can compute a maximum <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n\log^2 n \log (nU))\)</span> time, where <span
class="math inline">\(U = \max_d c(d)\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Suppose every dart in <span class="math inline">\(\Sigma\)</span> has an
integer capacity between <span class="math inline">\(0\)</span> and
<span class="math inline">\(U\)</span>. Because all capacities are
non-negative, we know that the zero circulation is a feasible flow with
value <span class="math inline">\(0\)</span>, and the upper bound on
individual capacities implies that every feasible flow has value at most
<span class="math inline">\(nU\)</span>. If there is a feasible flow
with any value <span class="math inline">\(\lambda\)</span>, we can
scale it down to a feasible flow with any value smaller than <span
class="math inline">\(\lambda\)</span>. Finally, Ford and Fulkerson’s
augmenting-path algorithm implies by induction that the maximum flow in
a network with integer capacities has integer value. Thus, we can
compute a maximum flow in <span class="math inline">\(\Sigma\)</span> by
performing a binary search over the <span
class="math inline">\(nU\)</span> possible flow values, running the
<span class="math inline">\(O(n\log^2 n)\)</span>-time decision
algorithm at each iteration. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>I find this algorithm deeply unsatisfying, in part because it
requires integer capacities, but it does at least serve as a proof of
concept. Hassin and Johnson proved that for <em>undirected</em> planar
graphs, where every dart has the same capacity as its reversal, we can
compute a maximum <span class="math inline">\((s,t)\)</span>-flow by
first running Reif’s minimum-cut algorithm and then running Dijkstra’s
algorithm in a modified dual graph. Using Reif’s original algorithm,
this approach funds maximum flows in <span
class="math inline">\((n\log^2 n)\)</span> time; this running time can
be improved to <span class="math inline">\(O(n\log n)\)</span> using
either the linear-time shortest-path algorithm of Henzinger et al inside
Reif’s algorithm, or by replacing Reif’s algorithm with multiple-source
shortest paths.</p>
<p>Unfortunately, this approach does not extend to directed planar
graphs, because we do not have a similar divide-and-conquer minimum-cut
algorithm in that setting. In 1997, Karsten Weihe described an algorithm
to compute maximum flows in directed planar graphs in <span
class="math inline">\(O(n\log n)\)</span> time, generalizing his earlier
<span class="math inline">\(O(n)\)</span>-time algorithm for undirected
unit-capacity planar graphs. However, his algorithm assumes that every
dart in the input graph appears in at leas one simple path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>. Darts that do not satisfy this
criterion can be safely removed from the input graph, but an efficient
algorithm to find all such “useless” darts was only found in 2017, by
Jittat Fakcharoenphol, Bundit Laekhanukit, and Pattara Sukprasert.</p>
<p>Meanwhile, in 2006, Glencora Borradaile and Philip Klein discovered a
much cleaner algorithm to compute planar maximum flows in <span
class="math inline">\(O(n\log n)\)</span> time. In the rest of this
lecture note I will describe a reformulation of their algorithm that I
published in 2010.</p>
<h2 data-number="23.5" id="parametric-shortest-paths-1"><span
class="header-section-number">23.5</span> Parametric Shortest Paths</h2>
<p>We formulate the planar maximum-flow problem as a <em>parametric
shortest-path</em> problem, similar to our first multiple-source
shortest-path problem. Fix an arbitrary path <span
class="math inline">\(\pi\)</span> from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>. We are trying to find the largest
value <span class="math inline">\(\lambda\)</span> such that <span
class="math inline">\(\Sigma\)</span> supports and <span
class="math inline">\((s,t)\)</span>-flow with value <span
class="math inline">\(\lambda\)</span>. Equivalently, by the arguments
in the last two sections, we are looking for the largest value <span
class="math inline">\(\lambda\)</span> such that the dual residual map
<span class="math inline">\(\Sigma^*_{\lambda\cdot\pi}\)</span> does not
contain a negative cycle. The algorithm maintains a shortest-path tree
in the dual residual map <span
class="math inline">\(\Sigma^*_{\lambda\cdot\pi}\)</span> as the
parameter <span class="math inline">\(\lambda\)</span> continuously
increases from <span class="math inline">\(0\)</span>. At critical
values of <span class="math inline">\(\lambda\)</span>, darts <span
class="math inline">\(p{\to}q\)</span> in <span
class="math inline">\(\Sigma^*\)</span> become tense and pivot into the
shortest-path tree, replacing earlier darts <span
class="math inline">\(p’{\to}q\)</span>. The algorithm halts when a
pivot introduces a cycle into the shortest-path tree, which would become
negative if we increased <span class="math inline">\(\lambda\)</span>
any further. (That cycle is dual to the minimum cut!)</p>
<p>Again, we fix an arbitrary path <span
class="math inline">\(\pi\)</span> from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span>; we treat this path as a flow with
value <span class="math inline">\(1\)</span>: <span
class="math display">\[
    \pi(d) = \begin{cases}
        1 &amp; \text{if $d \in \pi$} \\
        -1 &amp; \text{if $\textsf{rev}(d) \in \pi$} \\
        0 &amp; \text{otherwise}
    \end{cases}
\]</span> We also fix a vertex <span class="math inline">\(o\)</span> in
the dual map <span class="math inline">\(\Sigma^*\)</span>. Let’s
establish some notation.</p>
<ul>
<li><span class="math inline">\(\Sigma_\lambda\)</span> is just
shorthand for the residual graph <span
class="math inline">\(\Sigma_{\lambda\cdot\pi}\)</span>.</li>
<li><span class="math inline">\(c(\lambda, d) = c(\lambda, d^*) = c(d) -
\lambda\cdot\pi(d)\)</span> is the capacity of <span
class="math inline">\(d\)</span> in the residual graph <span
class="math inline">\(\Sigma\)</span>, and therefore the cost of <span
class="math inline">\(d^*\)</span> in the dual residual map <span
class="math inline">\(\Sigma_\lambda^*\)</span>.</li>
<li><span class="math inline">\(T_\lambda\)</span> is the single-source
shortest-path rooted at <span class="math inline">\(o\)</span> in <span
class="math inline">\(\Sigma_\lambda^*\)</span>.</li>
<li><span class="math inline">\(\textsf{dist}(\lambda, p)\)</span> is
the shortest-path distance from <span class="math inline">\(o\)</span>
to <span class="math inline">\(p\)</span> in <span
class="math inline">\(\Sigma_\lambda^*\)</span>.</li>
<li><span class="math inline">\(\textsf{path}(\lambda, p)\)</span> is
the shortest path from <span class="math inline">\(o\)</span> to <span
class="math inline">\(p\)</span> in <span
class="math inline">\(\Sigma_\lambda^*\)</span>.</li>
<li><span class="math inline">\(\textsf{pred}(\lambda, p)\)</span> is
the second-to-last vertex of <span
class="math inline">\(\textsf{path}(\lambda, p)\)</span>.</li>
<li><span class="math inline">\(\textsf{slack}(\lambda, p{\to}q) =
\textsf{dist}(\lambda, p) + c(\lambda, p{\to}q) - \textsf{dist}(\lambda,
p)\)</span></li>
<li><span class="math inline">\(\textsf{cycle}(\lambda,
p{\to}q)\)</span> is the closed walk obtained by concatenating <span
class="math inline">\(\textsf{path}(\lambda, p)\)</span>, <span
class="math inline">\(p{\to}q\)</span>, and <span
class="math inline">\(\textsf{rev}(\textsf{path}(\lambda,q))\)</span>.</li>
<li>A dart <span class="math inline">\(d\)</span> of <span
class="math inline">\(\Sigma_\lambda\)</span> is <em>tense</em> if <span
class="math inline">\(\textsf{slack}(\lambda, d^*) = 0\)</span>.</li>
<li>An edge <span class="math inline">\(e\)</span> of <span
class="math inline">\(\Sigma_\lambda\)</span> is <em>loose</em> if
neither of its darts is tense.</li>
<li><span class="math inline">\(L_\lambda\)</span> is the subgraph of
all loose edges in <span
class="math inline">\(\Sigma_\lambda\)</span>.</li>
<li>A dart <span class="math inline">\(d\)</span> in <span
class="math inline">\(\Sigma_\lambda\)</span> is <em>active</em> if
<span class="math inline">\(\textsf{slack}(\lambda, d^*)\)</span> is
decreasing at <span class="math inline">\(\lambda\)</span>.</li>
<li><span class="math inline">\(LP_\lambda\)</span> is the set of all
active darts in <span
class="math inline">\(\Sigma_\lambda\)</span>.</li>
</ul>
<p>Except at critical values of <span
class="math inline">\(\lambda\)</span>, subgraph <span
class="math inline">\(L_\lambda\)</span> is a spanning tree of <span
class="math inline">\(\Sigma_\lambda\)</span>, and in fact <span
class="math inline">\((L_\lambda, T_\lambda)\)</span> is a tree-cotree
decomposition of <span class="math inline">\(\Sigma\)</span>.</p>
<p><strong>Lemma:</strong> <em><span
class="math inline">\(LP_\lambda\)</span> is the unique path from <span
class="math inline">\(s\)</span> to <span
class="math inline">\(t\)</span> in <span
class="math inline">\(L_\lambda\)</span>.</em></p>
<p><strong>Lemma:</strong> <em><span
class="math inline">\(LP_\lambda\)</span> is the set of all active darts
in <span class="math inline">\(\Sigma_\lambda\)</span>.</em></p>
<h2 data-number="23.6" id="active-darts"><span
class="header-section-number">23.6</span> Active Darts</h2>
<h2 data-number="23.7" id="fast-pivots"><span
class="header-section-number">23.7</span> Fast Pivots</h2>
<h2 data-number="23.8" id="universal-cover-analysis"><span
class="header-section-number">23.8</span> Universal Cover Analysis</h2>
<h2 data-number="23.9" id="references-13"><span
class="header-section-number">23.9</span> References</h2>
<ol type="1">
<li><p>Therese C. Biedl, Bronǎ Brejová, and Tomáš Vinař. <a
href="https://doi.org/10.1007/3-540-44612-5_15">Simplifying flow
networks</a>. <em>Proc. 25th Symp. Math. Found. Comput. Sci.</em>,
192–201, 2000. Lecture Notes Comput. Sci. 1893,
Springer-Verlag.</p></li>
<li><p>Glencora Borradaile and Anna Harutyunyan. <a
href="https://doi.org/10.1007/978-3-642-45278-9_36">Maximum st-flow in
directed planar graphs via shortest paths</a>. <em>Proc. 24th Int.
Workshop Combin. Algorithms</em>, 423–427, 2013. Lecture Notes Comput.
Sci. 8288, Springer. arXiv:<a
href="https://arxiv.org/abs/1305.5823">1305.5823</a>.</p></li>
<li><p>Glencora Borradaile and Philip Klein. <a
href="https://doi.org/10.1145/1502793.1502798">An <span
class="math inline">\(O(n\log n)\)</span> algorithm for maximum st-flow
in a directed planar graph</a>. <em>J. ACM</em> 56(2):1–9:1–30,
2009.</p></li>
<li><p>David Eppstein and Kevin A. Wortman. <a
href="https://doi.org/10.1007/978-3-642-03367-4_26">Optimal embedding
into star metrics</a>. <em>Proc. 11th Algorithms Data Struct. Symp.
(WADS)</em>, 290–301, 2009. Lecture Notes Comput. Sci. 5664, Springer.
Another application of parametric shortest paths.</p></li>
<li><p>Jeff Erickson. <a
href="https://doi.org/10.1137/1.9781611973075.65">Parametric shortest
paths and maximum flows in planar graphs</a>. <em>Proc. 21st Ann.
ACM-SIAM Symp. Discrete Algorithms</em>, 794–804, 2010.</p></li>
<li><p>Jittat Fakcharoenphol, Bundit Laekhanukit, and Pattara
Sukprasert. <a href="https://arxiv.org/abs/1702.04786">Finding all
useless arcs in directed planar graphs</a>. Preprint, May 2018. arXiv:<a
href="https://doi.org/10.48550/arXiv.1702.04786">1702.04786</a>.</p></li>
<li><p>Lester R. Ford and Delbert R. Fulkerson. <a
href="http://doi.org/10.4153/CJM-1956-045-5">Maximal flow through a
network</a>. <em>Canad. J. Math.</em> 8(399–404), 1956. First published
as <a href="https://www.rand.org/pubs/papers/P605.html">Research
Memorandum RM-1400</a>, The RAND Corporation, Santa Monica, California,
November 19, 1954.</p></li>
<li><p>Lester R. Ford and Delbert R. Fulkerson. <a
href="https://www.jstor.org/stable/j.ctt183q0b4"><em>Flows in
Networks</em></a>. Princeton University Press, 1962. First published as
<a href="https://www.rand.org/pubs/reports/R375.html">Research
Memorandum R-375-PR</a>, The RAND Corporation, Santa Monica, California,
August 1962.</p></li>
<li><p>Theodore E. Harris and Frank S. Ross. <a
href="https://apps.dtic.mil/sti/citations/AD0093458">Fundamentals of a
method for evaluating rail net capacities</a>. Research Memorandum
RM-1573, The RAND Corporation, Santa Monica, California, October 24,
1955. Declassified May 13, 1999.</p></li>
<li><p>Refael Hassin and Donald B. Johnson. <a
href="https://doi.org/10.1137/0214045">An <span
class="math inline">\(O(n \log^2 n)\)</span> algorithm for maximum flow
in undirected planar networks</a>. <em>SIAM J. Comput.</em>
14(3):612–624, 1985.</p></li>
<li><p>Samir Khuller, Joseph (Seffi) Naor, and Philip Klein. <a
href="https://doi.org/10.1137/0406038">The lattice structure of flow in
planar graphs</a>. <em>SIAM J. Discrete Math.</em> 477–490, 1993.
Removing clockwise residual cycles.</p></li>
<li><p>Karl Menger. <a href="http://doi.org/10.4064/fm-10-1-96-115">Zur
allgemeinen Kurventheorie</a>. <em>Fund. Math.</em> 10:96–115,
1927.</p></li>
<li><p>Shankar M. Venkatesan. <a
href="https://www.proquest.com/docview/303173800"><em>Algorithms for
network flows</em></a>. Ph.D. thesis, The Pennsylvania State University,
1983.</p></li>
<li><p>Karsten Weihe. <a
href="http://doi.org/10.1006/jagm.1996.0831">Edge-disjoint <span
class="math inline">\((s,t)\)</span>-paths in undirected planar graphs
in linear time</a>. <em>J. Algorithms</em> 23(1):121–138, 1997.</p></li>
<li><p>Karsten Weihe. <a
href="https://doi.org/10.1006/jcss.1997.1538">Maximum <span
class="math inline">\((s,t)\)</span>-flows in planar networks in <span
class="math inline">\(O(|V|\log|V|)\)</span> time</a>. <em>J. Comput.
Syst. Sci.</em> 55(3):454–476, 1997.</p></li>
</ol>
<h2 data-number="23.10" id="aptly-not"><span
class="header-section-number">23.10</span> Aptly Not</h2>
<h1 data-number="24" id="surface-mapsbeta"><span
class="header-section-number">24</span> Surface Maps<span
class="math inline">\(^\beta\)</span></h1>
<p>Recall that a <em>planar map</em> is the decomposition of the plane
(or by standard abuse of terminology, the sphere) induces by an
embedding of a graph in the plane. Any planar map can be represented by
a <em>rotation system</em> <span class="math inline">\(\Sigma = (D,
\textsf{rev}, \textsf{succ})\)</span> where <span
class="math inline">\(D\)</span> is the set of darts of the embedded
graph, <span class="math inline">\(\textsf{rev}\)</span> is the reversal
involution for those darts, and <span
class="math inline">\(\textsf{succ}\)</span> is a permutation of the
darts whose orbits describe the darts into each vertex of the embedded
graph in clockwise order. The orbits of the permutation <span
class="math inline">\(\textsf{rev}(\textsf{succ})\)</span> describe the
counterclockwise order of darts around the boundary of each face. A
rotation system with <span class="math inline">\(n\)</span> vertices,
<span class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces is <em>planar</em> if and only if
<span class="math inline">\(n-m+f = 2\)</span>.</p>
<p>But what if <span class="math inline">\(n-m+f \ne 2\)</span>? In that
case, <span class="math inline">\(\Sigma\)</span> represents a map on a
more complex surface.</p>
<h2 data-number="24.1"
id="surfaces-polygonal-schemata-and-cellular-embeddings"><span
class="header-section-number">24.1</span> Surfaces, Polygonal Schemata,
and Cellular Embeddings</h2>
<p>A <em>surface</em> (or <em>2-manifold</em>) is a (compact,
second-countable, Hausdorff) topological space that is <em>locally
homeomorphic</em> to the plane. That is, every point lies in an open
subset of the space that is homeomorphic to <span
class="math inline">\(\mathbb{R}^2\)</span>. (Later we will also
consider <em>surfaces with boundary</em>, spaces where every point lies
in an open neighborhood homeomorphic to either the plane or a closed
halfplane.)</p>
<p>The simplest method to construct surfaces is to glue disks together
along their boundary segments. A <em>polygonal schema</em> is a finite
set of polygons with labeled edges, where each label appears exactly
twice. We can construct a surface by identifying every pair of edges
with the same label; specifically, if the edges of each polygon are
oriented counterclockwise around its interior, we identify each edge
with the <em>reversal</em> of the other edge with the same label. The
vertices and edges of the polygons become the vertices and edges of a
graph; the interiors of the polygons become the faces of the resulting
embedding.</p>
<p>Formally, an (abstract) polygonal schema is a triple <span
class="math inline">\((D, \textsf{rev}, \textsf{succ}^*)\)</span>, where
<span class="math inline">\(D\)</span> is a set of darts (representing
the sides of the polygons), is an involution of those darts
(representing pairs of sides with matching labels), and <span
class="math inline">\(\textsf{succ}^*\)</span> is a permutation
describing the counterclockwise order of darts around each face/polygon.
Hopefully it’s clear that “abstract polygonal schema” is just a synonym
for “dual rotation system”.</p>
<p>To transform an abstract polygonal schema <span
class="math inline">\(\Pi\)</span> into a topological space, let <span
class="math inline">\(F\)</span> denote a set of disjoint closed disks
in the plane, one for each orbit of <span
class="math inline">\(\textsf{succ}^*\)</span>. For each orbit of length
<span class="math inline">\(d\)</span>, we subdivide the
counterclockwise boundary of the corresponding disk into <span
class="math inline">\(d\)</span> paths. We identify those paths with the
darts, so that <span class="math inline">\(\textsf{succ}^*(d)(0) =
d(1)\)</span> for every dart/path <span
class="math inline">\(d\)</span>. Then the space <span
class="math inline">\(\mathcal{S}(\Pi)\)</span> is the quotient space
<span class="math inline">\(\bigsqcup F / \sim\)</span>, where <span
class="math inline">\(d(t) \sim \textsf{rev}(d)(1-t)\)</span> for every
dart/path <span class="math inline">\(d\)</span> and <span
class="math inline">\(t\in[0,1]\)</span>. In other words, we identify
each dart with the reversal of its reversal! It is not hard to verify
that the space <span class="math inline">\(\mathcal{S}(\Pi)\)</span> is
always a 2-manifold; the vertices, edges, and faces constitute a map
<span class="math inline">\(\Sigma(\Pi)\)</span> of this surface.<a
href="#fn59" class="footnote-ref" id="fnref59"
role="doc-noteref"><sup>59</sup></a></p>
<p>Moving in the other direction, recall that an <em>embedding</em> of a
graph <span class="math inline">\(G = (V, \textsf{rev},
\textsf{head})\)</span> on a surface <span
class="math inline">\(\mathcal{S}\)</span> is a continuous injective
function from <span class="math inline">\(G\)</span> (as a topological
graph) into <span class="math inline">\(\mathcal{S}\)</span>. The
components of the complement of the image of the embedding are the
<em>faces</em> of the embedding. An embedding is <em>cellular</em> if
every face is homeomorphic to an open disk. The vertices, edges, and
faces of an embedding define a surface map if and only if the embedding
is cellular; in particular, the embedded graph must be connected.</p>
<h2 data-number="24.2" id="orientability"><span
class="header-section-number">24.2</span> Orientability</h2>
<p>Any discussion of rotation systems or polygonal schemata for surface
maps assumes <em>a priori</em> that the underlying surface is
<em>orientable</em>, meaning it is possible to consistently define
“clockwise” and “counterclockwise” everyone on the surface. As we’ll
prove in the next lecture, every orientable surface can be constructed
from the sphere by attaching one or more “handles”; the number of
handles is called the <em>genus</em> of the surface. More formally, the
genus of a surface <span class="math inline">\(\mathcal{S}\)</span> is
the maximum number of closed curves <span
class="math inline">\(\gamma_1, \dots, \gamma_g\)</span> in <span
class="math inline">\(\mathcal{S}\)</span> whose complement <span
class="math inline">\(\mathcal{S} \setminus (\gamma_1 \cup \cdots \cup
\gamma_g)\)</span> is connected.</p>
<p>However, not all 2-manifolds are orientable. The simplest example of
a non-orientable surface (with boundary) is the <em>Möbius band</em>,
which can be constructed from a strip of paper by gluing opposite ends
with a half-twist. More formally, the Möbius band is the quotient space
<span class="math inline">\([0,1]^2 / \sim\)</span> where <span
class="math inline">\((0, t) \sim (1, 1-t)\)</span> for all <span
class="math inline">\(t\in[0,1]\)</span>. In fact, Möbius bands are the
<em>only</em> obstruction to orientability; a surface is orientable if
and only if it does not contain (a subspace homeomorphic to) a Möbius
band.</p>
<p>In one of Lewis Carroll’s lesser-known works, one character explains
to another how to sew three square handkerchiefs into “Fortunatus’s
Purse” (so called because “Whatever is <em>inside</em> that Purse, is
<em>outside</em> it; and whatever is <em>outside</em> it, is
<em>inside</em> it. So you have all the wealth of the world in that
leetle Purse!”). His instructions can be interpreted as a signed
polygonal schema for a non-orientable surface map of genus 1.</p>
<figure>
<img src="Fig/fortunatus-purse.png" style="width:60.0%"
alt="Mein Herr’s instructions for sewing Fortunatus’s Purse. Sewing the first two squares along edges a and b yields a Möbius band; so does sewing the last two squares along f and d, or sewing the first and last square along c and e." />
<figcaption aria-hidden="true">Mein Herr’s instructions for sewing
Fortunatus’s Purse. Sewing the first two squares along edges <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> yields a Möbius band; so does sewing
the last two squares along <span class="math inline">\(f\)</span> and
<span class="math inline">\(d\)</span>, or sewing the first and last
square along <span class="math inline">\(c\)</span> and <span
class="math inline">\(e\)</span>.</figcaption>
</figure>
<figure>
<img src="Fig/fortunatus-purse-2.png" style="width:30.0%"
alt="Another signed polygonal schema for Fortunatus’s Purse." />
<figcaption aria-hidden="true">Another signed polygonal schema for
Fortunatus’s Purse.</figcaption>
</figure>
<p>We can’t represent non-orientable surface maps using rotation
systems, so we need a different combinatorial representation. It is
possible to define signed versions of both rotation systems and
polygonal schemata, but their navigation requires awkward bookkeeping
and case analysis. Instead we consider a more elegant but slightly more
verbose combinatorial representation that works for both orientable and
non-orientable surfaces.</p>
<h2 data-number="24.3" id="band-decompositions"><span
class="header-section-number">24.3</span> Band Decompositions</h2>
<p>Let <span class="math inline">\(\Sigma = (V, E, F)\)</span> be an
arbitrary map of some surface <span
class="math inline">\(\mathcal{S}\)</span>, which may or may not be
orientable. We construct a related surface map <span
class="math inline">\(\Sigma^\square\)</span>, called a <em>band
decomposition</em>, intuitively by shrinking each face of <span
class="math inline">\(\Sigma\)</span> slightly, expanding each vertex of
<span class="math inline">\(\Sigma\)</span> into a small closed disk,
and replacing each edge of <span class="math inline">\(\Sigma\)</span>
with a closed quadrilateral “band”.</p>
<ul>
<li>Each vertex of <span class="math inline">\(\Sigma^\square\)</span>
correspond to a <em>blade</em> in <span
class="math inline">\(\Sigma\)</span>, which is an edge with a chosen
direction (specifying its head) and an <em>independent</em> orientation
(specifying its “left” shore).</li>
<li>There are three types of edges in <span
class="math inline">\(\Sigma^\square\)</span>, corresponding to the
sides, corners, and darts of <span
class="math inline">\(\Sigma\)</span>.</li>
<li>There are three types of faces in <span
class="math inline">\(\Sigma^\square\)</span>, corresponding to the
vertices, edges, and faces of <span
class="math inline">\(\Sigma\)</span>.</li>
<li>Every vertex of <span class="math inline">\(\Sigma^\square\)</span>
is incident to exactly one edge and one face of each type.</li>
</ul>
<p>If a surface map <span class="math inline">\(\Sigma\)</span> has
<span class="math inline">\(n\)</span> vertices, <span
class="math inline">\(m\)</span> edges, and <span
class="math inline">\(f\)</span> faces, then its band decomposition
<span class="math inline">\(\Sigma^\square\)</span> has <span
class="math inline">\(4m\)</span> vertices, <span
class="math inline">\(6m\)</span> edges (<span
class="math inline">\(2m\)</span> of each type), and <span
class="math inline">\(n+m+f\)</span> faces.</p>
<figure>
<img src="Fig/derived-maps/band.png" style="width:40.0%"
alt="A band decomposition (black) of a surface map (white)." />
<figcaption aria-hidden="true">A band decomposition (black) of a surface
map (white).</figcaption>
</figure>
<p><strong>Lemma:</strong> <em>A surface map <span
class="math inline">\(\Sigma\)</span> is orientable if and only if the
graph of its band decomposition <span
class="math inline">\(\Sigma^\square\)</span> is bipartite.</em></p>
<h2 data-number="24.4" id="reflection-systems"><span
class="header-section-number">24.4</span> Reflection Systems</h2>
<p>Band decompositions immediately suggest the following combinatorial
representation of surface maps. A <em>reflection system</em>.<a
href="#fn60" class="footnote-ref" id="fnref60"
role="doc-noteref"><sup>60</sup></a> is a quadruple <span
class="math inline">\(\Xi = (\Phi, a, b, c)\)</span> with the following
components:</p>
<ul>
<li><span class="math inline">\(\Phi\)</span> is a finite set of
abstract objects called <em>blades</em> or <em>flags</em>.</li>
<li><span class="math inline">\(a\colon \Phi\to\Phi\)</span> is an
involution of <span class="math inline">\(\Phi\)</span>, whose orbits
are called <em>sides</em>.</li>
<li><span class="math inline">\(b\colon \Phi\to\Phi\)</span> is an
involution of <span class="math inline">\(\Phi\)</span>, whose orbits
are called <em>corners</em>.</li>
<li><span class="math inline">\(c\colon \Phi\to\Phi\)</span> is an
involution of <span class="math inline">\(\Phi\)</span>, whose orbits
are called <em>darts</em>.</li>
<li>The involutions <span class="math inline">\(a\)</span> and <span
class="math inline">\(c\)</span> commute, and their product <span
class="math inline">\(ac = ca\)</span> is an involution</li>
</ul>
<p>To simplify notation, I’ll use concatenation to denote compositions
of the involutions <span class="math inline">\(a\)</span>, <span
class="math inline">\(b\)</span>, and <span
class="math inline">\(c\)</span>; thus, for example, <span
class="math inline">\(ac\)</span> is shorthand for the permutation <span
class="math inline">\(a \circ c\)</span>, and <span
class="math inline">\(abc(\phi)\)</span> is shorthand for <span
class="math inline">\(a(b(c(\phi)))\)</span>.</p>
<p>Each blade in <span class="math inline">\(\Sigma\)</span> can be
associated with a triple <span class="math inline">\((v, e, f)\)</span>,
where <span class="math inline">\(e\)</span> is an edge of <span
class="math inline">\(\Sigma\)</span>, <span
class="math inline">\(v\)</span> is one of <span
class="math inline">\(e\)</span>’s endpoints, and <span
class="math inline">\(f\)</span> is one of <span
class="math inline">\(e\)</span>’s shores. Intuitively, each of the
involutions <span class="math inline">\(a\)</span>, <span
class="math inline">\(b\)</span>, <span
class="math inline">\(c\)</span>, changes one of the components of this
triple: <span class="math inline">\(a\)</span> changes the vertex (or
<em>apex</em>); <span class="math inline">\(b\)</span> changes the edge
(or <em>border</em>); <span class="math inline">\(c\)</span> changes the
face (of <em>chamber</em>). More formally, the orbits of the permutation
group <span class="math inline">\(\langle b,c \rangle\)</span> are the
<em>vertices</em> of the reflection system; the orbits of <span
class="math inline">\(\langle a,c \rangle\)</span> are its
<em>edges</em>; and the orbits of <span class="math inline">\(\langle
a,b \rangle\)</span> are its <em>faces</em>.</p>
<figure>
<img src="Fig/blade-operations.png" style="width:70.0%"
alt="Operations on blades in a reflection system." />
<figcaption aria-hidden="true">Operations on blades in a reflection
system.</figcaption>
</figure>
<p>Every reflection system represents a unique surface map with
corresponding blades, sides, corners, darts, vertices, edges, and faces.
(In particular, the trivial reflection system with <span
class="math inline">\(\Phi = \varnothing\)</span> represents the trivial
map.) Conversely, every surface map is represented by a <em>unique</em>
reflection system.</p>
<figure>
<img src="Fig/reflection-band.png" style="width:40.0%"
alt="Corresponding vertices and edges in the band decomposition." />
<figcaption aria-hidden="true">Corresponding vertices and edges in the
band decomposition.</figcaption>
</figure>
<p>Just as rotation systems are mathematical abstractions of incidence
lists, reflection systems can also be encoded as a simple data structure
for surface maps, which has one record for every blade <span
class="math inline">\(\phi\)</span>, each containing the index of its
head and pointers to its neighboring blades <span
class="math inline">\(a(\phi)\)</span>, <span
class="math inline">\(b(\phi)\)</span>, <span
class="math inline">\(c(\phi)\)</span>, along with an array indexed by
vertices pointing to an arbitrary blade into each vertex. (It may also
be convenient to store the index of each blade’s “left” shore, and a
face-indexed array pointing one blade for each face.)</p>
<p>A particularly simple implementation represents blades by integers
from <span class="math inline">\(0\)</span> to <span
class="math inline">\(4m-1\)</span>, such that for any blade <span
class="math inline">\(\phi\)</span>, the neighboring blades <span
class="math inline">\(a(\phi)\)</span> and <span
class="math inline">\(c(\phi)\)</span> are obtained by flipping the two
least significant bits, for example, by defining <span
class="math inline">\(a(\phi) = \phi\oplus 2\)</span> and <span
class="math inline">\(c(\phi) = \phi\oplus 1\)</span>. Thus, edge <span
class="math inline">\(e\)</span> consists of blades <span
class="math inline">\(4e, 4e+1, 4e+2, 4e+3\)</span>, and blade <span
class="math inline">\(\phi\)</span> belongs to edge <span
class="math inline">\(\lfloor \phi/4 \rfloor\)</span>. Then any static
surface map can be represented using five arrays:</p>
<ul>
<li><span class="math inline">\(\textsf{vany}[0\,..\,n]\)</span> storing
an arbitrary blade for each vertex;</li>
<li><span class="math inline">\(\textsf{fany}[0\,..\,f]\)</span> storing
an arbitrary blade for each face;</li>
<li><span class="math inline">\(\textsf{vert}[0\,..\,4m-1]\)</span>
storing the “head” vertex of each blade;</li>
<li><span class="math inline">\(\textsf{face}[0\,..\,4m-1]\)</span>
storing the “left” face of each blade;</li>
<li><span class="math inline">\(B[0\,..\,4m-1]\)</span> storing the
involution <span class="math inline">\(b\)</span>.</li>
</ul>
<p>Notice that <span class="math inline">\(\textsf{vert}(\phi) =
\textsf{vert}(c(\phi)) = \textsf{vert}(\phi\oplus 1)\)</span> and <span
class="math inline">\(\textsf{face}(\phi) = \textsf{face}(a(\phi)) =
\textsf{face}(\phi\oplus 2)\)</span>, so in principle, exactly half of
the <span class="math inline">\(\textsf{vert}\)</span> and <span
class="math inline">\(\textsf{face}\)</span> arrays are redundant.</p>
<figure>
<img src="Fig/fortunatus-purse-band.png" style="width:30.0%"
alt="A reflection system for Fortunatus’s Purse." />
<figcaption aria-hidden="true">A reflection system for Fortunatus’s
Purse.</figcaption>
</figure>
<h2 data-number="24.5" id="equivalence"><span
class="header-section-number">24.5</span> Equivalence</h2>
<p>Transforming a rotation system of a surface map into an equivalent
reflection system or vice versa (if the map is orientable) is
straightforward.</p>
<p>Let <span class="math inline">\(\Sigma = (D, \textsf{rev},
\textsf{succ})\)</span> be a rotation system. Then setting <span
class="math inline">\(\Phi := D\times \{-1, +1\}\)</span> and defining
the involutions as follows gives us an equivalent reflection system:
<span class="math display">\[
    \begin{aligned}
        a((d, +1)) &amp; := (\textsf{rev}(d), -1)
        &amp;
        a((d, -1)) &amp; := (\textsf{rev}(d), +1)
        \\
        b((d, +1)) &amp; := (\textsf{succ}(d), -1)
        &amp;
        b((d, -1)) &amp; := (\textsf{succ}^{-1}(d), +1)
        \\
        c((d, +1)) &amp; := (d, -1)
        &amp;
        c((d, -1)) &amp; := (d, +1)
    \end{aligned}
\]</span></p>
<p>Conversely, let <span class="math inline">\(\Xi = (\Phi, a, b,
c)\)</span> be an orientable reflection system. Because <span
class="math inline">\(\Xi\)</span> is orientable, we can partition <span
class="math inline">\(\Phi\)</span> into two subsets <span
class="math inline">\(\Phi^+\)</span> and <span
class="math inline">\(\Phi^-\)</span>, so that each of the involutions
<span class="math inline">\(a,b,c\)</span> is a bijection between the
two subsets. We can construct a rotation system equivalent to <span
class="math inline">\(\Xi\)</span> by setting <span
class="math inline">\(D := \Phi^+\)</span> and <span
class="math inline">\(\textsf{rev} := a\circ c\)</span> and <span
class="math inline">\(\textsf{succ} := b\circ c\)</span>.</p>
<h2 data-number="24.6" id="duality-1"><span
class="header-section-number">24.6</span> Duality</h2>
<p>Duality generalizes naturally from planar maps to surface maps. Two
surface maps <span class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(\Sigma^*\)</span> of the same underlying surface
are <em>duals</em> if (up to homeomorphism) each face of <span
class="math inline">\(\Sigma\)</span> contains exactly one vertex of
<span class="math inline">\(\Sigma^*\)</span>, each face of <span
class="math inline">\(\Sigma^*\)</span> contains exactly one vertex of
<span class="math inline">\(\Sigma\)</span>, and each edge of <span
class="math inline">\(\Sigma\)</span> crosses exactly one edge of <span
class="math inline">\(\Sigma^*\)</span>.</p>
<p>Just as in the planar setting, the dual of a rotation system <span
class="math inline">\(\Sigma = (D, \textsf{rev}, \textsf{succ})\)</span>
is obtained by replacing the successor permutation <span
class="math inline">\(\textsf{succ}\)</span> with <span
class="math inline">\(\textsf{succ}^* :=
\textsf{rev}(\textsf{succ})\)</span>; that is, <span
class="math inline">\(\Sigma^* = (D, \textsf{rev},
\textsf{rev}(\textsf{succ}))\)</span>. Thus, the darts in any
<em>orientable</em> surface map <span
class="math inline">\(\Sigma\)</span> are dual to (or more formally,
<em>are</em>) the darts in the dual map <span
class="math inline">\(\Sigma^*\)</span>.</p>
<p>Duality for reflection systems is similarly straightforward. Suppose
<span class="math inline">\(\Xi = (\Phi, a, b, c)\)</span> is the
reflection system for a surface map <span
class="math inline">\(\Sigma\)</span>; exchanging the involutions <span
class="math inline">\(a\)</span> and <span
class="math inline">\(c\)</span>, gives us the dual reflection system
<span class="math inline">\(\Xi^* = (\Phi, c, b, a)\)</span>, which is
the reflection system of its dual map <span
class="math inline">\(\Sigma^*\)</span>. (As a mnemonic device, we could
refer to the vertices, edges, and faces of the dual map <span
class="math inline">\(\Sigma^*\)</span> as <em>areas</em>,
<em>borders</em>, and <em>centroids</em>, respectively.) In this
representation, darts in a surface map are dual to (or more formally,
<em>are</em>) <em>sides</em> in its dual map, rather than darts.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every surface map <span class="math inline">\(\Sigma\)</span> and
its dual <span class="math inline">\(\Sigma^*\)</span> have the same
band decomposition: <span class="math inline">\(\Sigma^\square =
(\Sigma^*)^\square\)</span>.</em>
</dd>
</dl>
<p>For <em>orientable</em> surface maps, we have exactly the same
correspondences between features in primal and dual rotation systems as
we do for planar maps.</p>
<table>
<caption>A (partial) duality dictionary for rotation systems of
orientable surface maps</caption>
<colgroup>
<col style="width: 24%" />
<col style="width: 25%" />
<col style="width: 24%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">vertex <span
class="math inline">\(v\)</span></td>
<td style="text-align: center;">face <span
class="math inline">\(v^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{head}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{left}(d^*)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">dart <span
class="math inline">\(d\)</span></td>
<td style="text-align: center;">dart <span
class="math inline">\(d^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{tail}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{right}(d^*)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">edge <span
class="math inline">\(e\)</span></td>
<td style="text-align: center;">edge <span
class="math inline">\(e^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{left}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{head}(d^*)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">face <span
class="math inline">\(f\)</span></td>
<td style="text-align: center;">vertex <span
class="math inline">\(f^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{right}(d)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{tail}(d^*)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(\textsf{succ}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\circ\textsf{succ}\)</span></td>
<td style="text-align: center;">clockwise</td>
<td style="text-align: center;">counterclockwise</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{rev}\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>There is a similar but slightly more complex correspondence between
primal and dual <em>reflection</em> systems. In particular, the dual of
a <em>directed</em> map (where every edge has a preferred “head” vertex)
on a non-orientable surface is not another directed graph, but rather an
<em>sided</em> map (where every edge has a preferred <em>face</em>).</p>
<table>
<caption>A (partial) duality dictionary for reflection systems</caption>
<colgroup>
<col style="width: 24%" />
<col style="width: 25%" />
<col style="width: 24%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
<th style="text-align: center;">Primal <span
class="math inline">\(\Sigma\)</span></th>
<th style="text-align: center;">Dual <span
class="math inline">\(\Sigma^*\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">vertex <span
class="math inline">\(v\)</span></td>
<td style="text-align: center;">face <span
class="math inline">\(v^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(a\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(c\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">blade <span
class="math inline">\(\phi\)</span></td>
<td style="text-align: center;">blade <span
class="math inline">\(\phi^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(b\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(b\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">dart <span
class="math inline">\(d\)</span></td>
<td style="text-align: center;">side <span
class="math inline">\(d^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(c\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(a\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">side <span
class="math inline">\(\sigma\)</span></td>
<td style="text-align: center;">dart <span
class="math inline">\(\sigma^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{vert}(\phi)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{face}(\phi^*)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">edge <span
class="math inline">\(e\)</span></td>
<td style="text-align: center;">edge <span
class="math inline">\(e^*\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{face}(\phi)\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\textsf{vert}(\phi^*)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">face <span
class="math inline">\(f\)</span></td>
<td style="text-align: center;">vertex <span
class="math inline">\(f^*\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h2 data-number="24.7"
id="loops-and-isthmuses-deletion-and-contraction"><span
class="header-section-number">24.7</span> Loops and Isthmuses; Deletion
and Contraction</h2>
<p>Recall that a <em>loop</em> in a graph is an edge that is incident to
only one vertex, and a <em>bridge</em> is an edge whose deletion
disconnects the graph. An <em>isthmus</em> in a surface map is an edge
that is incident to only one face. As in planar maps, every bridge in a
surface map is also an isthmus. The Jordan curve theorem implies that
every isthmus in a <em>planar</em> map is also a bridge, but because the
Jordan curve theorem does not extend to maps on other surfaces, an an
isthmus in a surface map is <em>not</em> necessarily a bridge. Moreover,
unlike in planar graphs, the same edge in a surface map can be
<em>both</em> a loop <em>and</em> an isthmus.</p>
<p>Let <span class="math inline">\(\Sigma = (V, E, F)\)</span> be an
arbitrary surface map. Deleting any edge <span
class="math inline">\(e\)</span> that is not an isthmus yields a simpler
map <span class="math inline">\(\Sigma\setminus e\)</span> <em>of the
same surface</em> with the same vertices, one less edge, and with the
two faces on either side of <span class="math inline">\(e\)</span>
replaces with their union. Similarly, contracting any edge <span
class="math inline">\(e\)</span> that is not a loop yields a simpler map
<span class="math inline">\(\Sigma / e\)</span> <em>of the same
surface</em> with the endpoints of <span
class="math inline">\(e\)</span> merged into a single vertex, one less
edge, and the same number of faces.</p>
<p>Contraction and deletion modify the rotation system of an orientable
surface map exactly as they do in planar maps: <span
class="math display">\[
    (\textsf{succ}\setminus e)(d) = \begin{cases}
        \textsf{succ}(\textsf{succ}(\textsf{succ}(d)))
        \hphantom{^{**}}
            &amp; \text{if $\textsf{succ}(d) \in e$ and
                        $\textsf{succ}(\textsf{succ}(d)) \in e$,}\\
        \textsf{succ}(\textsf{succ}(d))
            &amp; \text{if $\textsf{succ}(d) \in e$,}\\
        \textsf{succ}(d) &amp; \text{otherwise.}
    \end{cases}
\]</span> <span class="math display">\[
    (\textsf{succ} \mathbin/ e)(d) = \begin{cases}
        \textsf{succ}(\textsf{succ}^*(\textsf{succ}^*(d)))
            &amp; \text{if $\textsf{succ}(d) \in e$ and
                        $\textsf{succ}^*(\textsf{succ}(d)) \in e$,}\\
        \textsf{succ}(\textsf{succ}^*(d))
            &amp; \text{if $\textsf{succ}(d) \in e$,}\\
        \textsf{succ}(d) &amp; \text{otherwise.}
    \end{cases}
\]</span> The first deletion case occurs when the deleted edge is an
empty loop; the first contraction case occurs when one endpoint of the
contracted edge is a <em>leaf</em> (has degree <span
class="math inline">\(1\)</span>).</p>
<p>Deletion and contraction can be similarly implemented in reflection
systems, even in non-orientable maps. If we equate <span
class="math inline">\(e\)</span> with the corresponding set of four
flags in <span class="math inline">\(\Phi\)</span>, then the reflection
systems <span class="math inline">\(\Xi\setminus e = (\Phi\setminus e,
a, b\setminus e, c)\)</span> and <span
class="math inline">\(\Xi\mathbin/ e = (\Phi\setminus e, a, b\mathbin/
e, c)\)</span>, which respectively represent the maps <span
class="math inline">\(\Sigma\setminus e\)</span> and <span
class="math inline">\(\Sigma\mathbin/ e\)</span>, can be defined as
follows, for all <span class="math inline">\(\phi \in \Phi\setminus
e\)</span>: <span class="math display">\[
    (b\setminus e)(\phi) :=
    \begin{cases}
        \mathit{b c b c b}(\phi)\quad{}
                    &amp; \text{if~ $b(\phi) \in e$
                            ~and~ $\mathit{b c b}(\phi) \in e$} \\
        \mathit{b c b}(\phi)
                    &amp; \text{if~ $b(\phi) \in e$} \\
        b(\phi)         &amp; \text{otherwise}
    \end{cases}
\]</span> <span class="math display">\[
    (b\mathbin/ e)(\phi) :=
    \begin{cases}
        \mathit{babab}(\phi)\quad{}
                    &amp; \text{if~ $b(\phi) \in e$
                        ~and~ $\mathit{bab}(\phi) \in e$} \\
        \mathit{bab}(\phi)
                    &amp; \text{if~ $b(\phi) \in e$} \\
        b(\phi) &amp; \text{otherwise}
    \end{cases}
\]</span> Again, the complicated first cases correspond to the only edge
incident to a vertex or an edge. We emphasize the involutions <span
class="math inline">\(a\)</span> and <span
class="math inline">\(c\)</span> from the original reflection system
<span class="math inline">\(\Xi\)</span> appear verbatim (except for
their smaller domains) in <span class="math inline">\(\Xi\setminus
e\)</span> and <span class="math inline">\(\Xi\mathbin/ e\)</span>.</p>
<figure>
<img src="Fig/band-delete-contract.png" style="width:80.0%"
alt="Typical contraction, expansion, deletion, and insertion in the band decomposition." />
<figcaption aria-hidden="true">Typical contraction, expansion, deletion,
and insertion in the band decomposition.</figcaption>
</figure>
<figure>
<img src="Fig/band-delete-loop.png" style="width:65.0%"
alt="Deleting or inserting an empty loop." />
<figcaption aria-hidden="true">Deleting or inserting an empty
loop.</figcaption>
</figure>
<figure>
<img src="Fig/band-contract-leaf.png" style="width:65.0%"
alt="Contracting or expanding a leaf." />
<figcaption aria-hidden="true">Contracting or expanding a
leaf.</figcaption>
</figure>
<figure>
<img src="Fig/band-delete-twist.png" style="width:65.0%"
alt="Deleting or contracting a twisted loop/isthmus." />
<figcaption aria-hidden="true">Deleting or contracting a twisted
loop/isthmus.</figcaption>
</figure>
<h2 data-number="24.8" id="references-14"><span
class="header-section-number">24.8</span> References</h2>
<ol type="1">
<li><p>Lewis Carroll. <a
href="https://www.gutenberg.org/ebooks/48795"><em>Sylvie and Bruno
Concluded</em></a>. Illustrated by Henry Furniss. Macmillan and Co.,
1893.</p></li>
<li><p>Sóstenes Lins. <a
href="http://doi.org/10.1016/0095-8956(82)90033-8">Graph-encoded
maps</a>. <em>J. Comb. Theory Ser. B</em> 32:171–181, 1982.</p></li>
</ol>
<h2 data-number="24.9" id="sir-not-appearing-1"><span
class="header-section-number">24.9</span> Sir Not Appearing</h2>
<ul>
<li>Henry Slade and the “Afghan Bands”</li>
</ul>
<figure>
<img src="Fig/MeinHerr.png" style="width:60.0%"
alt="Mein Herr explains to Lady Muriel how to sew Fortunatus’ Purse." />
<figcaption aria-hidden="true">Mein Herr explains to Lady Muriel how to
sew Fortunatus’ Purse.</figcaption>
</figure>
<h1 data-number="25" id="surface-classificationbeta"><span
class="header-section-number">25</span> Surface Classification<span
class="math inline">\(^\beta\)</span></h1>
<p>In this lecture, we will prove that up to homeomorphism, surfaces are
uniquely identified by two pieces of data: their <em>genus</em> and
their <em>orientability</em>.</p>
<ul>
<li><p>The <em>genus</em> of a surface <span
class="math inline">\(\mathcal{S}\)</span> is the maximum number of
simple disjoint cycles that can be deleted without disconnecting the
surface.</p></li>
<li><p>A surface <span class="math inline">\(\mathcal{S}\)</span> is
<em>orientable</em> if it does not contain a subspace homeomorphic to a
Möbius band.</p></li>
</ul>
<p>A difficult theorem of Kerékjártó (1923) and Rado (1925) states that
every compact 2-manifold is the underlying surface of some map.<a
href="#fn61" class="footnote-ref" id="fnref61"
role="doc-noteref"><sup>61</sup></a> In light of this result, it
suffices to consider an arbitrary surface <em>map</em> <span
class="math inline">\(\Sigma\)</span>, represented by a reflection
system, and argue that the underlying surface of <span
class="math inline">\(\Sigma\)</span> is determined by its genus and
orientability. By assumption all surface maps are connected.</p>
<p>For any vertex <span class="math inline">\(v\)</span>, edge <span
class="math inline">\(e\)</span>, or face <span
class="math inline">\(f\)</span> of <span
class="math inline">\(\Sigma\)</span>, let <span
class="math inline">\(v^\square\)</span>, <span
class="math inline">\(e^\square\)</span>, or <span
class="math inline">\(f^\square\)</span> denote the corresponding face
of the band decomposition <span
class="math inline">\(\Sigma^\square\)</span>.</p>
<h2 data-number="25.1"
id="tree-cotree-decompositions-and-systems-of-loops"><span
class="header-section-number">25.1</span> Tree-Cotree Decompositions and
Systems of Loops</h2>
<p>A <em>tree-cotree decomposition</em> of a surface map <span
class="math inline">\(\Sigma\)</span> is a partition of the edges <span
class="math inline">\(E = T\sqcup L\sqcup C\)</span>, where <span
class="math inline">\(T\)</span> is a spanning tree of <span
class="math inline">\(\Sigma\)</span>, <span
class="math inline">\(C^*\)</span> is a spanning tree of the dual map
<span class="math inline">\(\Sigma^*\)</span>, and <span
class="math inline">\(L = E\setminus (C\cup T)\)</span> is the set of
<em>leftover</em> edges.</p>
<p>Because <span class="math inline">\(\Sigma\)</span> is connected,
<span class="math inline">\(\Sigma\)</span> has a spanning tree <span
class="math inline">\(T\)</span>, and we can contract all edges in <span
class="math inline">\(T\)</span> to obtain a single-vertex map <span
class="math inline">\(\Sigma \mathbin/ T\)</span>. The dual map <span
class="math inline">\((\Sigma \mathbin/ T)^*\)</span> is also connected,
so it has a spanning tree <span class="math inline">\(C\)</span>; we can
delete the corresponding primal edges <span
class="math inline">\(C^*\)</span> to obtain a map <span
class="math inline">\(\Sigma \mathbin/ T \setminus C\)</span> that has
one vertex, one face, and zero or more edges. Thus, every surface map
has a tree-cotree decomposition.</p>
<p>When <span class="math inline">\(\Sigma\)</span> is a planar (or
spherical) map, every tree-cotree decomposition has <span
class="math inline">\(L = \varnothing\)</span>. Tree-cotree
decompositions were first studied for orientable surface maps by Norman
Biggs and for arbitrary surface maps by Bruce Richter and Herbert Shank;
however, David Eppstein was apparently the first to call the three-way
edge partition <span class="math inline">\((T,L,C)\)</span> a
“tree-cotree decomposition”.</p>
<p>We call any map with a single vertex and a single face a <em>system
of loops</em>. Trivially, every edge in a system of loops is both a loop
(incident to only one vertex) and an isthmus (incident to only one
face). Because contraction and deletion do not change the underlying
surface of a map, the Kerékjártó-Rado theorem implies that every surface
supports a system of loops. Thus, for purposes of proving the surface
classification theorem, we can assume without loss of generality that
<strong>the original map <span class="math inline">\(\Sigma\)</span> is
a system of loops.</strong></p>
<p>For any edge <span class="math inline">\(e\)</span> in a system of
loops, the union <span class="math inline">\(e^\square \cup
v^\square\)</span> is either a Möbius band or an annulus. If <span
class="math inline">\(e^\square \cup v^\square\)</span> is an Möbius
band, we call <span class="math inline">\(e\)</span> a
<em>one-sided</em> loop; otherwise, <span
class="math inline">\(e\)</span> is a <em>two-sided</em> loop.</p>
<h2 data-number="25.2" id="handles"><span
class="header-section-number">25.2</span> Handles</h2>
<p>A <em>handle</em> in a surface <span
class="math inline">\(\mathcal{S}\)</span> is an annulus <span
class="math inline">\(A\)</span> whose complement <span
class="math inline">\(\mathcal{S}\setminus A\)</span> is connected. The
Jordan curve theorem implies that the sphere has no handles, but this
theorem does not extend to other surfaces. To detach the handle, we
delete it from <span class="math inline">\(\mathcal{S}\)</span> and glue
disks to the two resulting boundary circles, as shown in the figure
below.</p>
<figure>
<img src="Fig/add-handle2.png" style="width:75.0%"
alt="Detaching or attaching a handle." />
<figcaption aria-hidden="true">Detaching or attaching a
handle.</figcaption>
</figure>
<p>Now suppose our system of loops <span
class="math inline">\(\Sigma\)</span> is orientable, or equivalently,
that every loop in <span class="math inline">\(\Sigma\)</span> is
two-sided. Let <span class="math inline">\(e\)</span> be any loop in
<span class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(v\)</span> be its only vertex. Then the band
decomposition <span class="math inline">\(\Sigma^\square\)</span>
contains a handle <span class="math inline">\(H_e\)</span>, composed of
<span class="math inline">\(e^\square\)</span> and the rectangle in
<span class="math inline">\(v^\square\)</span> connecting the four
vertices of <span class="math inline">\(e^\square\)</span>; see Figure 2
below.</p>
<p>The two endpoints of <span class="math inline">\(e\)</span> cannot be
adjacent around <span class="math inline">\(v\)</span>, because then
<span class="math inline">\(e\)</span> would be the boundary of an empty
loop on one side and another face on the other, contradicting the facet
that <span class="math inline">\(\Sigma\)</span> has only one face.</p>
<p>Normally, we are not allowed to contract loops, but for the sake of
argument, consider the map <span class="math inline">\(\Sigma \mathbin/
e\)</span> obtained by contracting <span
class="math inline">\(e\)</span> using the usual formula for contraction
in a reflection system. If <span class="math inline">\((\Phi, a, b,
c)\)</span> is a reflection system for <span
class="math inline">\(\Sigma\)</span>, then <span
class="math inline">\((\Phi\setminus e, a, b\mathbin/ e, c)\)</span> is
a reflection system for <span class="math inline">\(\Sigma \mathbin/
e\)</span>, where for any dart <span class="math inline">\(\phi \in
\Phi\setminus e\)</span>, <span class="math display">\[
    (b\mathbin/ e)(\phi) :=
    \begin{cases}
        \mathit{b a b a b}(\phi)\quad{}
                    &amp; \text{if~ $b(\phi) \in e$
                            ~and~ $\mathit{b c b}(\phi) \in e$} \\
        \mathit{b a b}(\phi)
                    &amp; \text{if~ $b(\phi) \in e$} \\
        b(\phi)         &amp; \text{otherwise}
    \end{cases}
\]</span> Combinatorially, contracting <span
class="math inline">\(e\)</span> splits its sole endpoint <span
class="math inline">\(v\)</span> of <span
class="math inline">\(e\)</span> into two vertices, each incident to the
darts that enter <span class="math inline">\(v\)</span> from one side or
the other of <span class="math inline">\(e\)</span>. (This
counterintuitive behavior is exactly why we normally forbid contracting
loops.) Topologically, the contraction detaches the handle <span
class="math inline">\(H_e\)</span>. The resulting map <span
class="math inline">\(\Sigma\mathbin/ e\)</span> has two vertices but
still only one face.</p>
<figure>
<img src="Fig/band-contract-2sided-loop.png" style="width:75.0%"
alt="Detaching a handle by contracting a two-sided loop." />
<figcaption aria-hidden="true">Detaching a handle by contracting a
two-sided loop.</figcaption>
</figure>
<p>Symmetrically, because <span class="math inline">\(e\)</span> is also
an isthmus, <em>deleting</em> <span class="math inline">\(e\)</span>
also detaches a handle in the band decomposition, this time consisting
of <span class="math inline">\(e^\square\)</span> and a rectangle inside
<span class="math inline">\(f^\square\)</span>. The resulting map <span
class="math inline">\(\Sigma\setminus e\)</span> has two faces but still
only one vertex.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every orientable surface can be reduced to a sphere by detaching
zero or more handles.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be any system of loops
on an orientable surface <span
class="math inline">\(\mathcal{S}\)</span>. If <span
class="math inline">\(\Sigma\)</span> has no edges, then <span
class="math inline">\(\mathcal{S}\)</span> is the sphere. Otherwise, let
<span class="math inline">\(e\)</span> be any loop in <span
class="math inline">\(\Sigma\)</span>. Contracting <span
class="math inline">\(e\)</span> detaches a handle from <span
class="math inline">\(\mathcal{S}\)</span> and leaves a map <span
class="math inline">\(\Sigma\mathbin/ e\)</span> with two vertices and
one face. <span class="math inline">\(\Sigma\mathbin/ e\)</span> must
contain an edge <span class="math inline">\(e’\)</span> between its two
vertices; otherwise, <span class="math inline">\(\Sigma\mathbin/
e\)</span> would be disconnected and thus have more than one face. The
map <span class="math inline">\(\Sigma\mathbin/ e \setminus e’\)</span>
is a smaller system of loops. By the inductive hypothesis, the
underlying surface of <span class="math inline">\(\Sigma\mathbin/ e
\setminus e’\)</span> can be reduced to a sphere by detaching handles.
<span class="math inline">\(\qquad\square\)</span>.
</dd>
</dl>
<p>This theorem is more commonly stated in terms of <em>attaching</em>
handles. For any integer <span class="math inline">\(g\ge 0\)</span>,
let <span class="math inline">\(\mathcal{S}(g, 0)\)</span> denote the
surface obtained from the sphere by attaching <span
class="math inline">\(g\)</span> handles. For example, <span
class="math inline">\(\mathcal{S}(0, 0)\)</span> is the sphere and <span
class="math inline">\(\mathcal{S}(1, 0)\)</span> is the torus. Up to
homeomorphism, it does not matter where or in what order the handles are
attached, as long as they are attached in a way that preserves the
orientability of the surface (as shown in Figure 1).</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every orientable surface is homeomorphic to <span
class="math inline">\(\mathcal{S}(g, 0)\)</span> for some integer <span
class="math inline">\(g\ge 0\)</span>.</em>
</dd>
</dl>
<p>The integer <span class="math inline">\(g\)</span> is called the
<em>genus</em> of the surface <span class="math inline">\(\mathcal{S}(g,
0)\)</span>, or the genus of any map on that surface.</p>
<h2 data-number="25.3" id="twists"><span
class="header-section-number">25.3</span> Twists</h2>
<p>A <em>twist</em> in a surface <span
class="math inline">\(\mathcal{S}\)</span> is any subspace <span
class="math inline">\(M\subset\mathcal{S}\)</span> homeomorphic to a
Möbius band. Because <span class="math inline">\(M\)</span> has only one
boundary edge, the complement <span
class="math inline">\(\mathcal{S}\setminus M\)</span> is always
connected. To detach the twist, we delete it from <span
class="math inline">\(\mathcal{S}\)</span> and glue a disk to the
resulting boundary circle, as shown in the figure below. (Here I am
drawing the Möbius band as a self-intersecting surface called a
<em>cross-cap</em>, whose boundary is a standard circle, instead of the
usual embedding as a twisted paper strip.)</p>
<figure>
<img src="Fig/add-mobius.png" style="width:75.0%"
alt="Detaching or attaching a twist." />
<figcaption aria-hidden="true">Detaching or attaching a
twist.</figcaption>
</figure>
<p>Now suppose our system of loops <span
class="math inline">\(\Sigma\)</span> is non-orientable, or
equivalently, that <span class="math inline">\(\Sigma\)</span> contains
at least one one-sided loop. Let <span class="math inline">\(e\)</span>
be any one-sided loop in <span class="math inline">\(\Sigma\)</span>.
Then the band decomposition <span
class="math inline">\(\Sigma^\square\)</span> contains a twist <span
class="math inline">\(M_e\)</span>, composed of <span
class="math inline">\(e^\square\)</span> and the rectangle in <span
class="math inline">\(v^\square\)</span> connecting the four vertices of
<span class="math inline">\(e^\square\)</span>; see Figure 4 below. In
this case, the two endpoints of <span class="math inline">\(e\)</span>
<em>can</em> be adjacent around <span
class="math inline">\(v\)</span>.</p>
<figure>
<img src="Fig/band-contract-1sided-loop.png" style="width:75.0%"
alt="Detaching a handle by contracting a one-sided loop." />
<figcaption aria-hidden="true">Detaching a handle by contracting a
one-sided loop.</figcaption>
</figure>
<p>Once again, consider the map <span class="math inline">\(\Sigma
\setminus e\)</span> obtained by contracting <span
class="math inline">\(e\)</span> using the usual formula for contraction
in a reflection system. Combinatorially, contracting <span
class="math inline">\(e\)</span> reverses the cyclic order of the
incoming darts on one side of <span class="math inline">\(e\)</span>.
(If the darts of <span class="math inline">\(e\)</span> are adjacent
around <span class="math inline">\(v\)</span>, then all other darts into
<span class="math inline">\(v\)</span> are on the same side of <span
class="math inline">\(e\)</span>, so nothing gets reversed.)
Topologically, the contraction detaches the twist <span
class="math inline">\(M_e\)</span>. The resulting map <span
class="math inline">\(\Sigma\mathbin/ e\)</span> is still a system of
loops.</p>
<p>Symmetrically, because <span class="math inline">\(e\)</span> is also
an isthmus, <em>deleting</em> <span class="math inline">\(e\)</span>
also detaches a twist in the band decomposition, this time consisting of
<span class="math inline">\(e^\square\)</span> and a rectangle inside
<span class="math inline">\(f^\square\)</span>. The resulting map <span
class="math inline">\(\Sigma\setminus e\)</span> is actually isomorphic
(not just homeomorphic!) to <span class="math inline">\(\Sigma\mathbin/
e\)</span>.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every surface can be reduced to a sphere by detaching zero or more
twists, and then detaching zero or more handles.</em>
</dd>
</dl>
<p>For any integers <span class="math inline">\(g\ge 0\)</span> and
<span class="math inline">\(h\ge 0\)</span>, let <span
class="math inline">\(\mathcal{S}(g, h)\)</span> denote the surface
obtained from the sphere by attaching <span
class="math inline">\(g\)</span> handles and <span
class="math inline">\(h\)</span> twists. Up to homeomorphism, it does
not matter where or in what order the handles and twists are attached.
In particular, if <span class="math inline">\(h&gt;0\)</span>, we can
even attach <em>disorienting</em> handles that destroy the orientability
of the surface. The surface <span class="math inline">\(\mathcal{S}(g,
h)\)</span> is orientable if and only if <span
class="math inline">\(h=0\)</span>.</p>
<figure>
<img src="Fig/add-twisted-handle.png" style="width:75.0%"
alt="Detaching or attaching a disorienting handle." />
<figcaption aria-hidden="true">Detaching or attaching a disorienting
handle.</figcaption>
</figure>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every non-orientable surface is homeomorphic to <span
class="math inline">\(\mathcal{S}(g, h)\)</span> for some integers <span
class="math inline">\(g\ge 0\)</span> and <span class="math inline">\(h
&gt; 0\)</span>.</em>
</dd>
</dl>
<h2 data-number="25.4" id="dycks-surface"><span
class="header-section-number">25.4</span> Dyck’s Surface</h2>
<p>Our classification of surfaces into classes <span
class="math inline">\(\mathcal{S}(g, h)\)</span> is not yet complete,
because the same non-orientable surface can have multiple
classifications, depending on the order in which we contract one-sided
loops.</p>
<p>Consider the following example, called <em>Dyck’s surface</em> after
its discoverer Walter von Dyck (1888).<a href="#fn62"
class="footnote-ref" id="fnref62" role="doc-noteref"><sup>62</sup></a>
Let <span class="math inline">\(\Sigma\)</span> be a system of three
one-sided loops <span class="math inline">\(x, y, z\)</span> incident to
the unique vertex in the order <span class="math inline">\(x, y, x, z,
y, z\)</span>. Contracting <span class="math inline">\(y\)</span> gives
us an orientable system of loops on the torus <span
class="math inline">\(\mathcal{S}(1, 0)\)</span>, implying that <span
class="math inline">\(|\Sigma| = \mathcal{S}(1, 1)\)</span>. On the
other hand, contracting either <span class="math inline">\(x\)</span> or
<span class="math inline">\(z\)</span> yields a non-orientable system of
loops on the Klein bottle <span class="math inline">\(\mathcal{S}(0,
2)\)</span>, implying that <span class="math inline">\(|\Sigma| =
\mathcal{S}(0, 3)\)</span>. We conclude that <span
class="math inline">\(\mathcal{S}(1, 1)\)</span> and <span
class="math inline">\(\mathcal{S}(0, 3)\)</span> are actually the same
surface.</p>
<figure>
<img src="Fig/Dyck-contract.png" style="width:90.0%"
alt="Contracting different one-sided loops on Dyck’s surface yields either a torus (top) or a Klein bottle (bottom)." />
<figcaption aria-hidden="true">Contracting different one-sided loops on
Dyck’s surface yields either a torus (top) or a Klein bottle
(bottom).</figcaption>
</figure>
<p>A straightforward inductive argument now implies the following more
general equivalence, which in turn implies a simpler classification of
non-orientable surfaces.</p>
<p><strong>Lemma (Dyck):</strong> <em><span
class="math inline">\(\mathcal{S}(g,h) = \mathcal{S}(0,h+2g)\)</span>
for all positive integers <span class="math inline">\(g\)</span> and
<span class="math inline">\(h\)</span>.</em></p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every non-orientable surface is homeomorphic to <span
class="math inline">\(\mathcal{S}(0, g)\)</span> for some positive
integer <span class="math inline">\(g &gt; 0\)</span>.</em>
</dd>
</dl>
<p>Again, the integer <span class="math inline">\(g\)</span> is called
the <em>genus</em> of the surface <span
class="math inline">\(\mathcal{S}(0, g)\)</span>, or of any map on that
surface.</p>
<h2 data-number="25.5" id="canonical-polygonal-schemata"><span
class="header-section-number">25.5</span> Canonical Polygonal
Schemata</h2>
<p><strong><em>Write this</em></strong></p>
<h2 data-number="25.6" id="oilers-formula"><span
class="header-section-number">25.6</span> “Oiler’s” Formula</h2>
<p>The <em>Euler characteristic</em> <span
class="math inline">\(\chi(\Sigma)\)</span> of a surface map <span
class="math inline">\(\Sigma = (V, E, F)\)</span> is the integer <span
class="math inline">\(|V|-|E|+|F|\)</span>. Euler’s formula states that
every planar map has Euler characteristic <span
class="math inline">\(2\)</span>. The following generalization, first
proposed<a href="#fn63" class="footnote-ref" id="fnref63"
role="doc-noteref"><sup>63</sup></a> by the French mathematician Simon
Antoine Jean l’Huillier in 1811, implies that the Euler characteristic
is actually an invariant of the underlying surface.</p>
<dl>
<dt><strong>Theorem:</strong></dt>
<dd>
<em>Every map on the surface <span class="math inline">\(\mathcal{S}(g,
h)\)</span> has Euler characteristic <span
class="math inline">\(2-2g-h\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Contraction and deletion preserve both the underlying surface and the
Euler characteristic, so it suffices to consider a system of loops <span
class="math inline">\(\Sigma\)</span>. There are three cases to
consider:
</dd>
<dd>
<p>The trivial map (with one vertex, one face, and no edges) on the
sphere <span class="math inline">\(\mathcal{S}(0,0)\)</span> clearly has
Euler characteristic <span class="math inline">\(2\)</span>.</p>
</dd>
<dd>
<p>Suppose <span class="math inline">\(\Sigma\)</span> is orientable but
not planar. Let <span class="math inline">\(e\)</span> be any loop in
<span class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(e’\)</span> be any edge between the two vertices
of <span class="math inline">\(\Sigma\mathbin/ e\)</span>. The system of
loops <span class="math inline">\(\Sigma\mathbin/ e \setminus
e’\)</span> has two fewer loops than <span
class="math inline">\(\Sigma\)</span>, and therefore has Euler
characteristic <span class="math inline">\(\chi(\Sigma) + 2\)</span>. It
follows by induction that <span
class="math inline">\(\chi(\mathcal{S}(g, 0)) = 2-2g\)</span>.</p>
</dd>
<dd>
<p>Finally, suppose <span class="math inline">\(\Sigma\)</span> is
non-orientable. Let <span class="math inline">\(e\)</span> be any
one-sided loop in <span class="math inline">\(\Sigma\)</span>. The
system of loops <span class="math inline">\(\Sigma\mathbin/ e\)</span>
has one fewer loops than <span class="math inline">\(\Sigma\)</span>,
and therefore has Euler characteristic <span
class="math inline">\(\chi(\Sigma) + 1\)</span>. It follows by induction
that <span class="math inline">\(\chi(\mathcal{S}(g, h)) =
\chi(\mathcal{S}(g, 0)) - h = 2-2g-h\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Two surface maps lie on the same underlying 2-manifold if and only
if (1) they are either both orientable or both non-orientable and (2)
their Euler characteristics (or their genera) are equal.</em>
</dd>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>For any tree-cotree decomposition <span class="math inline">\((T, L,
C)\)</span> of any surface map <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math inline">\(|L|= 2 - \chi(\Sigma)\)</span>. Thus, <span
class="math inline">\(|L| = 2g\)</span> if <span
class="math inline">\(\Sigma\)</span> is orientable, and <span
class="math inline">\(|L| = g\)</span> if <span
class="math inline">\(\Sigma\)</span> is not orientable.</em>
</dd>
</dl>
<p>In contexts where both orientable and non-orientable surface maps are
being discussed, it is often convenient to use the <em>Euler genus</em>
<span class="math inline">\(\overline{g}\)</span> instead of the
standard genus <span class="math inline">\(g\)</span>. The Euler genus
of a map <span class="math inline">\(\Sigma\)</span> is equal to the
number of leftover edges in any tree-cotree decomposition of <span
class="math inline">\(\Sigma\)</span>: <span class="math display">\[
    \overline{g} ~:=~ |L| ~=~ 2 - \chi ~=~
    \begin{cases}
        2g &amp; \text{if $\Sigma$ is orientable} \\
        g &amp; \text{if $\Sigma$ is not orientable}
    \end{cases}
\]</span></p>
<p>The Combinatorial Gauss-Bonnet theorem also immediately generalizes
from planar maps to surface maps. Let <span
class="math inline">\(\Sigma\)</span> be any surface map. Assign an
arbitrary real value <span class="math inline">\(\angle c\)</span> to
each corner <span class="math inline">\(c\)</span> of a planar map <span
class="math inline">\(\Sigma\)</span>, called the <em>exterior
angle</em> at <span class="math inline">\(c\)</span>. Recall that
<em>combinatorial curvature</em> of a face <span
class="math inline">\(f\)</span> or a vertex <span
class="math inline">\(v\)</span>, with respect to this angle assignment,
is defined as follows: <span class="math display">\[
    \kappa(f) := 1 - \sum_{c\in f} \angle c
    \qquad\qquad
    \kappa(v) := 1 - \frac{1}{2} \deg(v) + \sum_{c\in v} \angle c
\]</span></p>
<dl>
<dt><strong>The Combinatorial Gauss-Bonnet Theorem:</strong></dt>
<dd>
<em>For any surface map <span class="math inline">\(\Sigma = (V, E,
F)\)</span> and for any assignment of angles to the corners of <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math inline">\(\sum_{v \in V} \kappa(v) + \sum_{f \in F}
\kappa(f) = \chi(\Sigma)\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
We immediately have <span class="math inline">\(\sum_f \kappa(f) = |F| -
\sum_c \angle c\)</span> and <span class="math inline">\(\sum_v
\kappa(f) = |V| - |E| + \sum_c \angle c\)</span>, which implies that
<span class="math inline">\(\sum_v \kappa(v) + \sum_f \kappa(f) = |V| -
|E| + |F| = \chi(\Sigma)\)</span> by definition. <span
class="math inline">\(\qquad\square\)</span>.
</dd>
</dl>
<!--

## Die Hauptvermutung

**Theorem:**
: _Any two maps on the same surface have a common refinement._

-->
<h2 data-number="25.7" id="references-15"><span
class="header-section-number">25.7</span> References</h2>
<ol type="1">
<li><p>Norman Biggs. <a
href="http://doi.org/10.1016/0095-8956(71)90022-0">Spanning trees of
dual graphs</a>. <em>J. Comb. Theory Ser. B</em> 11:127–131,
1971.</p></li>
<li><p>David Eppstein. <a
href="https://dl.acm.org/citation.cfm?id=644208">Dynamic generators of
topologically embedded graphs</a>. <em>Proc. 14th Ann. ACM-SIAM Symp.
Discrete Algorithms</em>, 599–608, 2003. arXiv:<a
href="https://arxiv.org/abs/cs/0207082">cs/0207082</a>.</p></li>
<li><p>R. Bruce Richter and Herbert Shank. <a
href="http://doi.org/10.1002/jgt.3190080304">The cycle space of an
embedded graph</a>. <em>J. Graph Theory</em> 8:365–369, 1984.</p></li>
</ol>
<h2 data-number="25.8" id="aptly-named-sir"><span
class="header-section-number">25.8</span> Aptly Named Sir</h2>
<h1 data-number="26" id="homotopy-in-surface-mapsalpha"><span
class="header-section-number">26</span> Homotopy in Surface Maps<span
class="math inline">\(^\alpha\)</span></h1>
<p>There’s not a lot in this section about <em>algorithms</em>, but
there is a lot of important <em>structure</em>. Everything described in
this note is based on <em>tree-cotree</em> decompositions.</p>
<p>Recall from the previous lecture that a <em>tree-cotree
decomposition</em> of a surface map <span
class="math inline">\(\Sigma\)</span> is a partition of the edges <span
class="math inline">\(E\)</span> into three disjoint subsets <span
class="math inline">\(T\sqcup L\sqcup C\)</span>, where</p>
<ul>
<li><span class="math inline">\(T\)</span> is a spanning tree of <span
class="math inline">\(\Sigma\)</span>,</li>
<li><span class="math inline">\(C^*\)</span> is a spanning tree of the
dual map <span class="math inline">\(\Sigma^*\)</span>, and</li>
<li><span class="math inline">\(L = E\setminus (C\cup T)\)</span> is the
set of <em>leftover</em> edges.</li>
</ul>
<p>Every surface map has a tree-cotree decomposition <span
class="math inline">\((T,L,C)\)</span>. In fact, we can choose either
the spanning tree <span class="math inline">\(T\)</span> or the
complementary dual spanning tree <span class="math inline">\(C\)</span>
arbitrarily, just as we did for tree-cotree decompositions of planar
maps.</p>
<p>More generally, suppose we modify a map <span
class="math inline">\(\Sigma\)</span> by repeatedly either (1)
contracting an arbitrary non-loop edge or (2) deleting an arbitrary
non-isthmus edge, until eery edge is both a loop and an isthmus. Let
<span class="math inline">\(T\)</span> be the set of contracted edges,
let <span class="math inline">\(V\)</span> be the set of deleted edges,
and let <span class="math inline">\(L\)</span> be the final set of
isthmus-loops (loop-isthmuses?). Then <span
class="math inline">\((T,L,C)\)</span> is a tree-cotree decomposition of
the original map <span class="math inline">\(\Sigma\)</span>.</p>
<p>Equivalently, suppose we color the edges of <span
class="math inline">\(\Sigma\)</span> red, green, or blue in arbitrary
order so that (1) every cycle contains at least one blue edge, (2) every
edge cut contains at least one red edge, and (3) an edge is green if and
only if it cannot be colored either red or blue. Then the red, green,
and blue edges respectively define the spanning tree, leftover edges,
and spanning cotree of a tree-cotree decomposition.</p>
<p><strong><em>[[[Figure! Running example on a genus-2
map?]]]</em></strong></p>
<h2 data-number="26.1" id="cut-graphs"><span
class="header-section-number">26.1</span> Cut Graphs</h2>
<p>A <em>cut graph</em> of a map <span
class="math inline">\(\Sigma\)</span> on surface <span
class="math inline">\(\mathcal{S}\)</span> is any subgraph <span
class="math inline">\(X\)</span> of <span
class="math inline">\(\Sigma\)</span> such that <span
class="math inline">\(\mathcal{S} \setminus X\)</span> an open
topological disk. (Let me emphasize that here <span
class="math inline">\(\setminus\)</span> means to remove the points from
the space, not merely deleting the edges from the map.)</p>
<p>Alternatively, we can define cut graphs in terms of a generalization
of the <em>slicing</em> operation we already saw in the context of
separators and minimum cuts. Slicing a map <span
class="math inline">\(\Sigma\)</span> along a subgraph <span
class="math inline">\(X\)</span> produces a new map <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
X\)</span> which contains <span class="math inline">\(\deg_X(v)\)</span>
copies of every vertex <span class="math inline">\(v\)</span> of <span
class="math inline">\(X\)</span>, two copies of every edge of <span
class="math inline">\(X\)</span>, and at least one new face in addition
to the faces of <span class="math inline">\(\Sigma\)</span>. By
convention, we think of the faces of <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
X\)</span> that are not faces of <span
class="math inline">\(\Sigma\)</span> as <em>holes</em> that are missing
from the surface; thus, <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
X\)</span> is always a map of a surface <em>with boundary</em>. At least
intuitively, <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
X\)</span> is the map obtained by gluing together the faces of <span
class="math inline">\(\Sigma\)</span> along every edge that is
<em>not</em> in <span class="math inline">\(X\)</span>. Then a cut graph
of <span class="math inline">\(\Sigma\)</span> is any subgraph <span
class="math inline">\(X\)</span> such that <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
X\)</span> is a closed disk.</p>
<p><strong><em>[[[Figure]]]</em></strong></p>
<p>For any tree-cotree decomposition <span
class="math inline">\((T,L,C)\)</span> of <span
class="math inline">\(\Sigma\)</span>, the subgraph <span
class="math inline">\(T\cup L\)</span> is a cut graph of <span
class="math inline">\(\Sigma\)</span>. Typically the cut graph <span
class="math inline">\(X = T\cup L\)</span> will contain several vertices
with degree <span class="math inline">\(1\)</span>; removing any such
vertex from <span class="math inline">\(X\)</span> yields a smaller cut
graph. A <em>reduced</em> cut graph is a cut graph with no degree-1
vertices at all; equivalently, a reduced cut graph is a <em>minimal</em>
subgraph <span class="math inline">\(X\)</span> such that <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
X\)</span> is a disk. We can <em>reduce</em> any cut graph by repeatedly
removing degree-1 vertices until none are left.<a href="#fn64"
class="footnote-ref" id="fnref64"
role="doc-noteref"><sup>64</sup></a></p>
<p>In any surface map with Euler genus <span
class="math inline">\(\bar{g} = 2-\chi &gt; 1\)</span>, every reduced
cut graph can be further decomposed into at most <span
class="math inline">\(2\bar{g}-2\)</span> <em>cut paths</em> between at
most <span class="math inline">\(3\bar{g}-3\)</span> vertices with
degree at least <span class="math inline">\(3\)</span>, called
<em>branch points</em>. In particular, if every branch point has degree
exactly <span class="math inline">\(3\)</span>, there are exactly <span
class="math inline">\(3\bar{g}-3\)</span> branch points and <span
class="math inline">\(2\bar{g}-2\)</span> cut paths. (The only two
exceptional surfaces are the projective plane (non-orientable genus
<span class="math inline">\(1\)</span>), where every reduced cut graph
is a single one-sided cycle, and the sphere (orientable genus <span
class="math inline">\(0\)</span>), where by convention every reduced cut
graph is a single vertex.)</p>
<p><strong><em>[[[Figure!]]]</em></strong></p>
<h2 data-number="26.2" id="systems-of-loops-and-homotopy"><span
class="header-section-number">26.2</span> Systems of Loops and
Homotopy</h2>
<p>Fix an arbitrary vertex <span class="math inline">\(x\)</span>,
called the <em>basepoint</em>. For each vertex <span
class="math inline">\(v\)</span>, let <span
class="math inline">\(\textsf{path}(v)\)</span> denote the unique
directed path in the spanning tree <span
class="math inline">\(T\)</span> from <span
class="math inline">\(x\)</span> to <span
class="math inline">\(v\)</span>. For every dart <span
class="math inline">\(d\)</span>, let <span
class="math inline">\(\textsf{loop}(d)\)</span> denote the following
directed closed walk: <span class="math display">\[
    \textsf{loop}(d)
    :=
    \textsf{path}(\textsf{tail}(d))
        \cdot d
        \cdot \textsf{rev}(\textsf{path}(\textsf{head}(d))).
\]</span> Notice that <span
class="math inline">\(\textsf{loop}(\textsf{rev}(d)) =
\textsf{rev}(\textsf{loop}(d))\)</span>.</p>
<p>Finally, let <span class="math inline">\(\mathcal{L} = \{
\textsf{loop}(e^+) \mid e\in L \}\)</span>, where <span
class="math inline">\(e^+\)</span> denotes an arbitrary
<em>reference</em> dart for edge <span class="math inline">\(e\)</span>.
The set <span class="math inline">\(\mathcal{L}\)</span> is called a
<em>system of loops</em> for <span
class="math inline">\(\Sigma\)</span>.</p>
<p>Recall that two closed curves in some space <span
class="math inline">\(X\)</span> are <em>(freely) homotopic</em> if one
curve can be continuously deformed into the other on <span
class="math inline">\(X\)</span>. Similarly, two paths in <span
class="math inline">\(X\)</span> with the same endpoints are
<em>homotopic</em> if one path can be continuously deformed into the
other while keeping the endpoints fixed. A system of loops gives us the
necessary structure to decide whether two curves are homotopic,
similarly to the “fences” in our planar homotopy-testing algorithm.</p>
<h2 data-number="26.3" id="whats-a-curve"><span
class="header-section-number">26.3</span> What’s a “curve”?</h2>
<p>But before we can start talking concretely about algorithms, we have
to nail down the phrase “given two curves” and “given a surface”. Our
planar homotopy algorithm assumes that input curves are given as
<em>polygons</em>, specified as a sequence of vertex coordinates; while
it is possible to <em>impose</em> coordinates on surfaces that would
permit a natural generalization of “polygons”, imposing geometry is
almost always both wasteful and unnecessary.<a href="#fn65"
class="footnote-ref" id="fnref65"
role="doc-noteref"><sup>65</sup></a></p>
<p>It is usually simpler and more efficient to treat curves on surfaces
purely combinatorially, representing surfaces as <em>maps</em> (using
rotation systems or reflection systems), and representing curves using
one of two natural combinatorial models:</p>
<ul>
<li><p><em>Traversal</em>: We consider only curves that are walks in the
graph of <span class="math inline">\(\Sigma\)</span>; curves cannot
intersect faces, and if a curve intersects an edge, it must traverse
that edge monotonically from one end to the other. We can represent any
such curve as an alternating sequence of vertices and darts (directed
edges). If the edges of <span class="math inline">\(\Sigma\)</span> are
weighted, the <em>length</em> of a curve <span
class="math inline">\(\alpha\)</span> is the sum of the weights of the
edges that <span class="math inline">\(\alpha\)</span> traverses,
counted with appropriate multiplicity.</p></li>
<li><p><em>Crossing</em>: We consider only curves that intersect the
edges of <span class="math inline">\(\Sigma\)</span> transversely, away
from the vertices, and whose intersection with each face of <span
class="math inline">\(\Sigma\)</span> is simple (injective). We can
represent any such curve as an alternating sequence of faces and knives
(oriented edges). If the edges of <span
class="math inline">\(\Sigma\)</span> are weighted, the <em>length</em>
of a curve <span class="math inline">\(\alpha\)</span> is the sum of the
weights of the edges that <span class="math inline">\(\alpha\)</span>
crosses, counted with appropriate multiplicity.</p></li>
</ul>
<p>These two models are clearly dual to each other; a crossing curve in
<span class="math inline">\(\Sigma\)</span> is equivalent to—or more
formally, <strong>IS</strong>—a traversing curve in the dual map <span
class="math inline">\(\Sigma^*\)</span>, and vice versa. Which curve
model we choose is strictly a matter of convenience. For the rest of
this lecture, I’ll use the traversal model.</p>
<h2 data-number="26.4" id="spur-and-face-moves"><span
class="header-section-number">26.4</span> Spur and Face Moves</h2>
<p>Even though we do not allow the <em>input</em> curves to intersect
the interiors of faces, we cannot impose the same restriction on
<em>homotopies</em>. Recall that we can think of any homotopy as a
continuously deforming curve. Even though the deforming curve starts and
ends on the vertices and edges of <span
class="math inline">\(\Sigma\)</span>, it may pass through faces in some
or all intermediate stages.</p>
<p>However, just as with generic curves in the plane, it turns out that
any homotopy between traversal curves in surface maps can be decomposed
into a finite sequence of combinatorial <em>moves</em>, of two
types:</p>
<ul>
<li><p>A <em>spur</em> move either inserts or deletes a subpath
consisting of a dart followed by its reversal; we call such a subpath a
<em>spur</em> (or sometimes a <em>spike</em>).</p></li>
<li><p>A <em>face</em> move replaces a subpath of the boundary of some
face <span class="math inline">\(f\)</span> with the complementary
subpath on the boundary of <span
class="math inline">\(f\)</span>.</p></li>
</ul>
<figure>
<img src="Fig/traversal-homotopy-moves.png" style="width:90.0%"
alt="Traversal homotopy moves: A spur move followed by a face move." />
<figcaption aria-hidden="true">Traversal homotopy moves: A spur move
followed by a face move.</figcaption>
</figure>
<p>Thus, asking whether a closed walk <span
class="math inline">\(W\)</span> in some map <span
class="math inline">\(\Sigma\)</span> is contractible is a purely
combinatorial problem: Is there a sequence of spur and face moves that
transforms <span class="math inline">\(W\)</span> into a trivial
walk?</p>
<p>There is a dual pair of homotopy moves for crossing curves. The dual
of a spur move, called a <em>bigon</em> move, deforms the curve to
either insert or remove two consecutive crossings of the same edge. The
dual of a face move, called a <em>vertex</em> move, deforms the curve
across one vertex.</p>
<figure>
<img src="Fig/crossing-homotopy-moves.png" style="width:90.0%"
alt="Crossing homotopy moves: A bigon move followed by a vertex move." />
<figcaption aria-hidden="true">Crossing homotopy moves: A bigon move
followed by a vertex move.</figcaption>
</figure>
<h2 data-number="26.5" id="characterizing-homotopy"><span
class="header-section-number">26.5</span> Characterizing Homotopy</h2>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(x\)</span> be a vertex of <span
class="math inline">\(\Sigma\)</span>. Every directed walk from <span
class="math inline">\(x\)</span> to <span
class="math inline">\(x\)</span> in <span
class="math inline">\(\Sigma\)</span> is homotopic to a directed walk
from <span class="math inline">\(x\)</span> to <span
class="math inline">\(x\)</span> in the cut graph <span
class="math inline">\(T\cup L\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
It suffices to prove that any dart <span
class="math inline">\(d\)</span> in <span
class="math inline">\(C\)</span> (or more formally, any dart whose edge
is in <span class="math inline">\(C\)</span>) is homotopic to a walk in
<span class="math inline">\(T\cup L\)</span> from <span
class="math inline">\(\textsl{tail}(d)\)</span> to <span
class="math inline">\(\textsl{head}(d)\)</span>.
</dd>
<dd>
<p>Consider the fundamental domain <span class="math inline">\(\Delta =
\Sigma \mathbin{\backslash\!\!\backslash} (T\cup L)\)</span>. The dart
<span class="math inline">\(d\)</span> is a boundary-to-boundary chord
through the interior of <span class="math inline">\(\Delta\)</span>.
Using a sequence of face moves, we can deform <span
class="math inline">\(d\)</span> to a path <span
class="math inline">\(\pi\)</span> around the boundary of <span
class="math inline">\(\Delta\)</span> from <span
class="math inline">\(\textsf{tail}_\Delta(d)\)</span> to <span
class="math inline">\(\textsf{head}_\Delta(d)\)</span>. This boundary
path <span class="math inline">\(\pi\)</span> projects to a walk in the
cut graph <span class="math inline">\(T\cup L\)</span> from <span
class="math inline">\(\textsf{tail}_\Sigma(d)\)</span> to <span
class="math inline">\(\textsf{head}_\Sigma(d)\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Let <span class="math inline">\(\mathcal{L}^*\)</span> denote the set
of all loops formed by concatenating a finite sequence of loops in <span
class="math inline">\(\mathcal{L}\)</span> and their reversals. That is,
<span class="math inline">\(\ell \in \mathcal{L}^*\)</span> if and only
if one of the following recursive conditions is satisfied:</p>
<ul>
<li><span class="math inline">\(\ell\)</span> is the empty loop</li>
<li><span class="math inline">\(\ell = \textsf{loop}(e^+) \cdot
\ell’\)</span> for some edge <span class="math inline">\(e\in L\)</span>
and some loop <span class="math inline">\(\ell’ \in
\mathcal{L}^*\)</span>.</li>
<li><span class="math inline">\(\ell = \textsf{loop}(e^-) \cdot
\ell’\)</span> for some edge <span class="math inline">\(e\in L\)</span>
and some loop <span class="math inline">\(\ell’ \in
\mathcal{L}^*\)</span>.</li>
</ul>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(x\)</span> be a vertex of <span
class="math inline">\(\Sigma\)</span>. Every directed walk from <span
class="math inline">\(x\)</span> to <span
class="math inline">\(x\)</span> in <span
class="math inline">\(\Sigma\)</span> is homotopic to a loop in <span
class="math inline">\(\mathcal{L}^*\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
In light of the previous lemma, it suffices to consider only walks in
the cut graph <span class="math inline">\(T\cup L\)</span>. Consider the
closed walk <span class="math inline">\(w =
v_0{\to}v_1{\to}v_2{\to}\cdots{\to}v_L\)</span>, where <span
class="math inline">\(v_0 = v_L = x\)</span>. We easily observe that
<span class="math inline">\(w\)</span> is homotopic to the concatenation
of paths <span class="math display">\[
\begin{aligned}
\textsf{path}(v_0)
    \cdot v_0{\to}v_1
    \cdot \textsf{rev}(\textsf{path}(v_1))
&amp;\cdot
    \textsf{path}(v_1)
    \cdot v_1{\to}v_2
    \cdot \textsf{rev}(\textsf{path}(v_2))
\cdots
\\
&amp;\cdots
    \textsf{path}(v_{i-1})
    \cdot v_{i-1}{\to}v_i
    \cdot \textsf{rev}(\textsf{path}(v_i)) \cdots
\\
&amp;\cdots
\textsf{path}(v_{L-1})
    \cdot v_{L-1}{\to}v_L
    \cdot \textsf{rev}(\textsf{path}(v_L))
\\
= \textsf{loop}(v_0{\to}v_1)
    \cdot \textsf{loop}(v_1{\to}v_2)
    \cdots &amp; \textsf{loop}(v_{i-1}{\to}v_i)
    \cdots \textsf{loop}(v_{L-1}{\to}v_L)
\end{aligned}
\]</span> because the initial path <span
class="math inline">\(\textsf{path}(v_0)\)</span> and final path <span
class="math inline">\(\textsf{rev}(\textsf{path}(v_L))\)</span> are both
empty, and every intermediate path through <span
class="math inline">\(T\)</span> is immediately followed by its
reversal.
</dd>
<dd>
<p>Thus, it suffices to argue that every fundamental loop <span
class="math inline">\(\textsf{loop}(d)\)</span> is homotopic to a loop
in <span class="math inline">\(\mathcal{L}^*\)</span>. Again, in light
of the previous lemma, there are only two cases to consider:</p>
</dd>
<dd>
<ul>
<li>If <span class="math inline">\(|d|\in L\)</span>, then by definition
either <span class="math inline">\(\textsf{loop}(d) \in
\mathcal{L}\)</span> or <span
class="math inline">\(\textsf{rev}(\textsf{loop}(d)) =
\textsf{loop}(\textsf{rev}(d)) \in \mathcal{L}\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>Suppose <span class="math inline">\(|d| \in T\)</span>. Then <span
class="math inline">\(\textsf{loop}(d) = \textsf{path}(v) \cdot
\textsf{rev}(\textsf{path}(v))\)</span>, where <span
class="math inline">\(v\)</span> is one of the endpoints of <span
class="math inline">\(d\)</span>, so we can deform <span
class="math inline">\(\textsf{loop}(d)\)</span> to the empty loop,
through a finite sequence of spur moves. <span
class="math inline">\(\qquad\square\)</span></li>
</ul>
</dd>
</dl>
<p><strong><em>[[[Figure!]]]</em></strong></p>
<p>This lemma does not <em>uniquely</em> characterize homotopy classes
of loops; in fact, every loop based at <span
class="math inline">\(x\)</span> is homotopic to <em>infinitely</em>
many loops in <span class="math inline">\(\mathcal{L}^*\)</span>. In the
next lecture, we’ll develop an efficient algorithm to decide whether two
loops are homotopic, in effect by defining a <em>canonical</em> loop in
<span class="math inline">\(\mathcal{L}^*\)</span> for each homotopy
class.</p>
<h2 data-number="26.6" id="references-16"><span
class="header-section-number">26.6</span> References</h2>
<h2 data-number="26.7" id="aptly-named-sir-1"><span
class="header-section-number">26.7</span> Aptly Named Sir</h2>
<ul>
<li>Pants decompositions (except possibly in passing)</li>
</ul>
<h1 data-number="27" id="planarization-and-separationalphabeta"><span
class="header-section-number">27</span> Planarization and
Separation<span class="math inline">\(^{\alpha/\beta}\)</span></h1>
<p>In this note I’ll describe how to generalize several results about
planar separators to more complex surface maps. These generalizations
imply reductions from several problems on arbitrary surface maps to
related (or even identical) problems on planar graphs, possibly with
larger complexity.</p>
<p>The first step in any such reduction is to either delete or slice a
subgraph of the input map to remove any interesting topology. We’ve
already seen one example of such a subgraph: A <em>cut graph</em> in a
surface map <span class="math inline">\(\Sigma\)</span> is a subgraph
<span class="math inline">\(X\)</span> such that the sliced surface
<span class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
X\)</span> is a disk. Unfortunately, it is easy to construct surface
maps in which every cut graph uses a constant fraction of the edges, and
we need sublinear complexity to support efficient reductions.</p>
<p>So instead we consider a weaker structure. A <em>planarizing</em> or
<em>degenerating<a href="#fn66" class="footnote-ref" id="fnref66"
role="doc-noteref"><sup>66</sup></a> subgraph</em> of <span
class="math inline">\(\Sigma\)</span> is any subgraph <span
class="math inline">\(X\)</span> such that the sliced surface <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
X\)</span> has genus <span class="math inline">\(0\)</span>, but
possibly with more than one boundary cycle. Once we have planarizing
subgraphs with sublinear complexity, we can use standard
planar-separator techniques to balanced separators with sublinear
complexity.</p>
<p>Throughout this note, we fix a surface <em>triangulation</em> <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and Euler genus <span
class="math inline">\(\bar{g} = o(n)\)</span>. (Surface maps with Euler
genus <span class="math inline">\(\Omega(n)\)</span> do not have small
planarizing subgraphs or small separators.) Euler’s formula implies that
<span class="math inline">\(\Sigma\)</span> has exactly <span
class="math inline">\(3n-6+3\bar{g} &lt; 6n\)</span> edges and <span
class="math inline">\(2n-4+2\bar{g} &lt; 4n\)</span> faces.</p>
<h2 data-number="27.1" id="multiple-short-cycles"><span
class="header-section-number">27.1</span> Multiple Short Cycles</h2>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span> be cycles in a surface map <span
class="math inline">\(\Sigma\)</span>. If either <span
class="math inline">\(\sigma\)</span> or <span
class="math inline">\(\tau\)</span> is a separating cycle, then <span
class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span> cross an even number of times.
Equivalently, if <span class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span> cross an odd number of times, both
<span class="math inline">\(\sigma\)</span> and <span
class="math inline">\(\tau\)</span> are nonseparating.</em></p>
<p><strong>Lemma [Albertson and Hutchinson]:</strong> <em>Every
orientable surface triangulation contains a nonseparating cycle of
length at most <span class="math inline">\(2\sqrt{n}\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be an orientable surface
triangulation, and let <span class="math inline">\(\sigma\)</span> be
the shortest nonseparating cycle in <span
class="math inline">\(\Sigma\)</span>. Let <span
class="math inline">\(\sigma^\flat\)</span> and <span
class="math inline">\(\sigma^\sharp\)</span> denote the two copies of
<span class="math inline">\(\sigma\)</span> in the sliced map <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
\sigma\)</span>, and let <span class="math inline">\(m\)</span> denote
the number of vertices in <span class="math inline">\(\sigma\)</span>.
</dd>
<dd>
<p>Let <span class="math inline">\(S\)</span> be the smallest subset of
vertices of <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
\sigma\)</span> that separates <span
class="math inline">\(\sigma^\flat\)</span> and <span
class="math inline">\(\sigma^\sharp\)</span>. The subgraph of <span
class="math inline">\(\Sigma\)</span> induced by <span
class="math inline">\(S\)</span> must contain (and therefore must
<em>be</em>) a cycle <span class="math inline">\(\tau\)</span> that is
homologous with <span class="math inline">\(\sigma\)</span> and
therefore nonseparating. Thus, <span class="math inline">\(\tau\)</span>
has at least <span class="math inline">\(m\)</span> vertices. Menger’s
Theorem now immediately implies that there are at least <span
class="math inline">\(m\)</span> vertex-disjoint paths from <span
class="math inline">\(\sigma^\flat\)</span> to <span
class="math inline">\(\sigma^\sharp\)</span> in <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
\sigma\)</span>.</p>
</dd>
<dd>
<p>On the other hand, let <span class="math inline">\(\pi\)</span> be
the shortest path in <span
class="math inline">\(\Sigma\mathbin{\backslash\!\!\backslash}
\sigma\)</span> from a node in <span
class="math inline">\(\sigma^\flat\)</span> to its clone in <span
class="math inline">\(\sigma^\sharp\)</span>. The edges of <span
class="math inline">\(\pi\)</span> comprise a cycle in <span
class="math inline">\(\Sigma\)</span> that crosses <span
class="math inline">\(\sigma\)</span> once and thus is nonseparating. It
follows that <span class="math inline">\(\pi\)</span> has length at
least <span class="math inline">\(m\)</span>. At most <span
class="math inline">\(m/2\)</span> edges in <span
class="math inline">\(\pi\)</span> lie in either <span
class="math inline">\(\sigma^\flat\)</span> or <span
class="math inline">\(\sigma^\sharp\)</span>. Thus, every path from
<span class="math inline">\(\sigma^\flat\)</span> to <span
class="math inline">\(\sigma^\sharp\)</span> has at least <span
class="math inline">\(m/2\)</span> edges.</p>
</dd>
<dd>
<p>We conclude that <span class="math inline">\(n\ge m^2/2\)</span>.
<span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Alberston and Hutchinson’s proof requires orientability. If <span
class="math inline">\(\sigma\)</span> is a one-sided cycle in a
nonorientable surface map <span class="math inline">\(\Sigma\)</span>,
the sliced map <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span> has a single boundary
cycle that covers <span class="math inline">\(\sigma\)</span> twice.
However, a similar result can be proved for nonorientable surface maps
by considering the oriented double cover <span
class="math inline">\(\Sigma^2\)</span>.</p>
<p><strong>Corollary [Gilbert, Hutchinson, and Tarjan]:</strong> <em>Any
surface map <span class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and genus <span
class="math inline">\(g\)</span> can be transformed into a genus-<span
class="math inline">\(0\)</span> map by slicing along <span
class="math inline">\(g\)</span> cycles of total length <span
class="math inline">\(O(g\sqrt{n})\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be an orientable surface
map with genus <span class="math inline">\(g\)</span>. Without loss of
generality, we can assume that <span
class="math inline">\(\Sigma\)</span> is a simple triangulation;
otherwise, remove all loops, remove all but one edge in every family of
homotopic parallel edges, and triangulate every face with more than
three sides. If <span class="math inline">\(g=0\)</span>, there is
nothing to do, so assume otherwise. Let <span
class="math inline">\(\sigma\)</span> be the shortest noncontractible
cycle in <span class="math inline">\(\Sigma\)</span>. The map <span
class="math inline">\(\Sigma’ = \Sigma\mathbin{\backslash\!\!\backslash}
\sigma\)</span> has at most <span class="math inline">\(n +
2\sqrt{n}\)</span> edges has genus <span
class="math inline">\(g-1\)</span>. The result now follows by induction.
<span class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>Hutchinson proved that every orientable surface triangulation
contains a noncontractible cycle of length <span
class="math inline">\(O(\sqrt{n/g} \log g)\)</span>; the same inductive
argument implies that we can planarize any orientable surface map by
slicing along <span class="math inline">\(g\)</span> cycles of total
length <span class="math inline">\(O(\sqrt{ng} \log g)\)</span>. Colin
de Verdière, Hubard, and Lazarus proved that there are surface maps in
which every noncontractible cycle has length at least <span
class="math inline">\(\Omega(\sqrt{n/g} \log g)\)</span>; so
Hutchinson’s bound is tight in the worst case. Nevertheless it is
possible to compute (slightly) smaller planarizing subgraphs.</p>
<h2 data-number="27.2" id="slabification"><span
class="header-section-number">27.2</span> Slabification</h2>
<p>The following construction of a smaller planarizing subgraph is based
on results of David Eppstein, which refines an earlier construction of
Aleksandrov and Djidjev; similar techniques were also described by
Hutchinson and Miller. Eppstein’s construction uses the same notion of
<em>depth contours</em> as Miller’s planar cycle-separator algorithm,
which we saw in Chapter 12.</p>
<p>Without loss of generality, assume that <span
class="math inline">\(\Sigma\)</span> is a simple triangulation. We
start by building a tree-cotree decomposition <span
class="math inline">\((T, L, C)\)</span>, where <span
class="math inline">\(T\)</span> is a breadth-first spanning tree rooted
at an arbitrary source vertex <span class="math inline">\(s\)</span>.
For any vertex <span class="math inline">\(v\)</span>, let <span
class="math inline">\(\textsf{depth}(v)\)</span> denote the unweighted
shortest-path distance from <span class="math inline">\(s\)</span> to
<span class="math inline">\(v\)</span>, and define the depth of an edge
or face to be the maximum depth of its vertices.</p>
<p>For any index <span class="math inline">\(j\)</span>, the <span
class="math inline">\(j\)</span>th <em>depth contour</em> <span
class="math inline">\(D_j\)</span> of <span
class="math inline">\(\Sigma\)</span> is the subgraph induced by edges
incident to both a face with depth <span
class="math inline">\(j\)</span> and a face with depth <span
class="math inline">\(j+1\)</span>.</p>
<p>For any integers <span class="math inline">\(i&lt;j\)</span>, let
<span class="math inline">\(\Sigma[i,j]\)</span> denote the subcomplex
of <span class="math inline">\(\Sigma\)</span> containing all faces
<span class="math inline">\(f\)</span> such that <span
class="math inline">\(i &lt; \textsf{depth}(f) \le j\)</span>, along
with their incident edges and vertices; notice that the range of
face-depths excludes the lower index <span
class="math inline">\(i\)</span>. We refer to <span
class="math inline">\(\Sigma[i,j]\)</span> as a <em>slab</em> of <span
class="math inline">\(\Sigma\)</span>. In particular, <span
class="math inline">\(\Sigma[0,j]\)</span> is the subcomplex of
vertices, edges, and faces with depth at most <span
class="math inline">\(j\)</span>, or equivalently, the component of
<span class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
D_j\)</span> containing <span class="math inline">\(s\)</span>. The
boundary of <span class="math inline">\(\Sigma[i,j]\)</span> naturally
partitions into its <em>upper</em> boundary <span
class="math inline">\(D_{i-1}\)</span> and its <em>lower</em> boundary
<span class="math inline">\(D_j\)</span>.</p>
<p>For any subset <span class="math inline">\(L’ \subseteq L\)</span>,
let <span class="math inline">\(Q(L’) = \bigcup \{ \textsf{loop}_T(\ell)
\mid \ell\in L’ \}\)</span>. In particular, <span
class="math inline">\(Q(L)\)</span> is a (possibly unreduced) <span
class="math inline">\(Q\)</span>ut graph of <span
class="math inline">\(\Sigma\)</span>, and <span
class="math inline">\(Q(\varnothing)\)</span> is the empty subgraph.</p>
<p>Finally, for all indices <span class="math inline">\(i&lt;j\)</span>,
let <span class="math inline">\(L[i,j] = L\cap \Sigma[i,j]\)</span> and
<span class="math inline">\(Q[i,j] = \Sigma[i,j] \cap
Q(L[i,j])\)</span>. Each subgraph <span
class="math inline">\(Q[i,j]\)</span> contains all edges <span
class="math inline">\(\ell\in L[i,j]\)</span>, along with shortest paths
(through <span class="math inline">\(T\)</span>) from the endpoints of
<span class="math inline">\(\ell\)</span> “up” to the depth contour
<span class="math inline">\(D_{i-1}\)</span>.</p>
<p><strong>Lemma:</strong> <em>For all indices <span
class="math inline">\(i&lt;j\)</span>, <span
class="math inline">\(Q[i,j]\)</span> is a planarizing subgraph of <span
class="math inline">\(\Sigma[i,j]\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Every submap of a genus-<span class="math inline">\(0\)</span> map has
genus <span class="math inline">\(0\)</span>, so it suffices to consider
the spacial case <span class="math inline">\(i=0\)</span>. Let <span
class="math inline">\(\Sigma’\)</span> be the surface map obtained from
<span class="math inline">\(\Sigma[0,j]\)</span> by gluing a disk to
each boundary cycle.
</dd>
<dd>
<p>The intersection <span class="math inline">\(T’ = T \cap
\Sigma’\)</span> is a breadth-first spanning tree of <span
class="math inline">\(\Sigma[0,j]\)</span>, consisting of the first
<span class="math inline">\(j\)</span> levels of the global
breadth-first spanning tree tree <span
class="math inline">\(T\)</span>.</p>
</dd>
<dd>
<p>The intersection <span class="math inline">\(C \cap \Sigma’\)</span>
defines a forest in the dual map <span
class="math inline">\((\Sigma’)^*\)</span>, which spans every face
except the caps. We can extend this coforest to a spanning cotree <span
class="math inline">\(C’\)</span> by adding edges that are not in <span
class="math inline">\(T’\)</span> (in fact, only edges on the boundary
of <span class="math inline">\(\Sigma[0,j]\)</span>).</p>
</dd>
<dd>
<p>Thus, we have a tree-cotree decomposition <span
class="math inline">\((T’, L’, C’)\)</span> of <span
class="math inline">\(\Sigma’\)</span>, where <span
class="math inline">\(L’ = E(\Sigma’) \setminus (C’ \cup T’) \subseteq
L[0,j]\)</span>. It follows that <span class="math inline">\(Q’ =
Q(L’)\)</span> is a cut graph for <span
class="math inline">\(\Sigma’\)</span>. On the other hand, <span
class="math inline">\(Q’\)</span> is a subgraph of <span
class="math inline">\(Q[i,j]\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>For any integers <span class="math inline">\(0 \le i &lt; k\)</span>,
let <span class="math inline">\(D(i,k) = \bigcup\{D_j \mid j\bmod k =
i\}\)</span>. Slicing <span class="math inline">\(\Sigma\)</span> along
these depth contours patitions it into several slabs: <span
class="math display">\[  
    \Sigma \mathbin{\backslash\!\!\backslash} D(i,k)
    =
    \bigcup_a \Sigma[ak+i, (a+1)k+i].
\]</span> Let <span class="math inline">\(Q(i,k)\)</span> denote the
corresponding subgraph of the cut graph <span
class="math inline">\(Q(L)\)</span>: <span class="math display">\[
    Q(i,k) = \bigcup_a Q[ak+i, (a+1)k+i].
\]</span> Finally, let <span class="math inline">\(P(i,k) = D(i,k) \cup
Q(i,k)\)</span>. The previous lemma implies that <span
class="math inline">\(P(i,k)\)</span> is a planarizing subgraph of <span
class="math inline">\(\Sigma\)</span>, for all indices <span
class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span>.</p>
<p><strong>Lemma:</strong> <em>For some integers <span
class="math inline">\(i\)</span> and <span
class="math inline">\(k\)</span>, the subgraph <span
class="math inline">\(P(i,k)\)</span> has at most <span
class="math inline">\(2\sqrt{\bar{g}n}\)</span> vertices.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
For each endpoint <span class="math inline">\(v\)</span> of each edge in
<span class="math inline">\(L\)</span>, the subgraph <span
class="math inline">\(Q(i,k)\)</span> contains the shortest path from
<span class="math inline">\(v\)</span> to its nearest ancestor in <span
class="math inline">\(T\)</span> that lies on the depth contour <span
class="math inline">\(D(i,k)\)</span>. This path has length <span
class="math inline">\((\textsf{depth}(v) - i) \bmod k\)</span>.
Moreover, <span class="math inline">\(Q(i,k)\)</span> is the union of
all <span class="math inline">\(\bar{g}\)</span> such subpaths with
<span class="math inline">\(L\)</span>. It follows that for any fixed
<span class="math inline">\(k\)</span>, we have <span
class="math display">\[
\sum_{i=0}^{k-1} |V(Q(i,k))|
\le
\sum_{v\in V(L)} \sum_{i=0}^{k-1} (\textsl{depth}(v) - i)\bmod k
=
\bar{g} k(k-1) &lt; \bar{g}k^2.
\]</span> Each vertex and edge of <span
class="math inline">\(\Sigma\)</span> belongs to at most one depth
contour <span class="math inline">\(D_i\)</span>, so <span
class="math display">\[
\sum_{i=0}^{k-1} |V(D(i,k))| \le n.
\]</span> We conclude that <span class="math display">\[
\sum_{i=0}^{k-1} |V(P(i,k))| \le \bar{g}k^2 + n
\]</span> which implies that for some index <span
class="math inline">\(i\)</span>, the subgraph <span
class="math inline">\(P(i,k)\)</span> has at most <span
class="math inline">\(\bar{g}k + n/k\)</span> vertices. In particular,
some subgraph <span class="math inline">\(P(i,\sqrt{n/\bar{g}})\)</span>
has at most <span class="math inline">\(2\sqrt{\bar{g}n}\)</span>
vertices.<a href="#fn67" class="footnote-ref" id="fnref67"
role="doc-noteref"><sup>67</sup></a> <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>Let <span class="math inline">\(k^* = \sqrt{n/\bar{g}}\)</span>, and
let <span class="math inline">\(i^*\)</span> be the index <span
class="math inline">\(i\)</span> that minimizes the number of vertices
in <span class="math inline">\(P(i, k^*)\)</span>. Euler’s formula
implies that <span class="math inline">\(P(i^*, k^*)\)</span> has at
most <span class="math inline">\(12\sqrt{\bar{g}n}\)</span> edges.</p>
<p><strong>Theorem:</strong> <em>Every surface triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and Euler genus <span
class="math inline">\(\bar{g} &lt; n\)</span> has a planarizing subgraph
<span class="math inline">\(P(i^*, k^*)\)</span> with <span
class="math inline">\(O(\sqrt{\bar{g}n})\)</span> vertices and edges,
which can be computed in <span class="math inline">\(O(n)\)</span>
time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
We can compute the breadth-first spanning tree <span
class="math inline">\(T\)</span> and the depths of every vertex, edge,
and face of <span class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n)\)</span> time via (surprise, surprise)
breadth-first search. Computing the depth contours <span
class="math inline">\(D_j\)</span>, the number of vertices in each
subgraph <span class="math inline">\(D(i,k^*)\)</span>, and the optimal
index <span class="math inline">\(i^*\)</span> in <span
class="math inline">\(O(n)\)</span> time is straightforward. Then for
each endpoint <span class="math inline">\(v\)</span> of each edge in
<span class="math inline">\(L\)</span>, we walk upward in <span
class="math inline">\(T\)</span> marking edges, until we encounter
either a marked edge or a vertex in <span
class="math inline">\(D(i^*,k^*\)</span>)$. Because each edge of <span
class="math inline">\(\Sigma\)</span> is marked at most once, the total
time to find the marked edges is their number plus <span
class="math inline">\(O(\bar{g})\)</span>, which is <span
class="math inline">\(O(n)\)</span>. The marked edges and <span
class="math inline">\(L\)</span> comprise the subgraph <span
class="math inline">\(Q(i^*,k^*)\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Corollary:</strong> <em>Every surface triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and Euler genus <span
class="math inline">\(\bar{g} &lt; n\)</span> has a <span
class="math inline">\((3/4)\)</span>-separator with <span
class="math inline">\(O(\sqrt{\bar{g}n})\)</span> vertices and edges,
which can be computed in <span class="math inline">\(O(n)\)</span>
time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The sliced surface <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} P(i^*, k^*)\)</span> has at most one
component with more than <span class="math inline">\(3/4\)</span> of the
faces of <span class="math inline">\(\Sigma\)</span>. If there is such a
component, apply the planar separator theorem within that component.
<span class="math inline">\(\qquad\square\)</span>.
</dd>
</dl>
<h2 data-number="27.3" id="nice-r-divisions"><span
class="header-section-number">27.3</span> Nice <span
class="math inline">\(r\)</span>-divisions</h2>
<p>A <em>nice <span class="math inline">\(r\)</span>-division</em> of a
surface map <span class="math inline">\(\Sigma\)</span> is a subdivision
of <span class="math inline">\(\Sigma\)</span> into subcomplexes called
<em>pieces</em> with the following properties:</p>
<ul>
<li>Every face of <span class="math inline">\(\Sigma\)</span> lies in
exactly one piece.</li>
<li>There are <span class="math inline">\(O(n/r)\)</span> pieces.</li>
<li>Each piece has <span class="math inline">\(O(r)\)</span>
vertices.</li>
<li>Each piece has <span class="math inline">\(O(\sqrt{r})\)</span>
<em>boundary</em> vertices.</li>
<li>Each piece has <span class="math inline">\(O(1)\)</span>
<em>holes</em> (boundary cycles).</li>
<li>Each piece has genus <span class="math inline">\(0\)</span>.</li>
</ul>
<p>This definition is identical to our definition of nice <span
class="math inline">\(r\)</span>-divisions of planar maps, except for
the last condition, which is obviously redundant if <span
class="math inline">\(\Sigma\)</span> has genus <span
class="math inline">\(0\)</span>. The definition implies that any nice
<span class="math inline">\(r\)</span>-division has a total of <span
class="math inline">\(O(n/\sqrt{r})\)</span> boundary vertices.</p>
<p>Now suppose we wanted to extend our planarizing subgraph <span
class="math inline">\(P(i^*, k^*)\)</span> to obtain a nice <span
class="math inline">\(r\)</span>-division. The number of vertices in
<span class="math inline">\(P(i^*, k^*)\)</span> suggests we should try
<span class="math inline">\(r = O(n/\bar{g})\)</span>. Unfortunately,
the partition <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} P(i^*, k^*)\)</span> has <span
class="math inline">\(\Theta(\sqrt{\bar{g}n})\)</span> face-connected
componentnts, which is more than the <span
class="math inline">\(O(\bar{g})\)</span> pieces we need for a nice
<span class="math inline">\(O(n/\bar{g})\)</span>-division. Moreover, we
have no control over the number of vertices, boundary vertices, and
holes in each individual piece of <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} P(i^*, k^*)\)</span>.</p>
<p>We can modify <span class="math inline">\(P(i^*, k^*)\)</span> to
obtain a nice <span class="math inline">\(r\)</span>-division, first by
removing redundant cycles, and then by adding cycles to make the pieces
nice.</p>
<p>First, consider the face-connected fragments of the map <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash} D(i^*,
k^*)\)</span> obtained by slicing only along the short depth contours
<span class="math inline">\(D(i^*,k^*)\)</span>. We call each fragment
<em>interesting</em> if it contains at least one path through <span
class="math inline">\(T\)</span> from an endpoint of an edge in <span
class="math inline">\(L\)</span> to the upper boundary of that fragment.
There are clearly at most <span class="math inline">\(2\bar{g}\)</span>
interesting fragments. Let <span
class="math inline">\(U(i^*,k^*)\)</span> denote the Union of the Upper
boundaries of the interesting fragments, and let <span
class="math inline">\(P’(i^*,k^*) = U(i^*,k^*) \cup
Q(i^*,k^*)\)</span>.</p>
<p><strong>Lemma:</strong> <em><span
class="math inline">\(P’(i^*,k^*)\)</span> is a planarizing subgraph of
<span class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(O(\sqrt{\bar{g}n})\)</span> vertices and edges.
Moreover, <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} P’(i^*, k^*)\)</span> consists of
<span class="math inline">\(O(\bar{g})\)</span> face-connected
fragments.</em></p>
<p>The subgraph <span class="math inline">\(P’(i^*, k^*)\)</span>
induces a partition <span class="math inline">\(\mathcal{P}\)</span> of
<span class="math inline">\(\Sigma\)</span> into <span
class="math inline">\(O(\bar{g})\)</span> genus-<span
class="math inline">\(0\)</span> pieces, with a <em>total</em> of <span
class="math inline">\(O(\sqrt{\bar{g}n})\)</span> boundary vertices and
<span class="math inline">\(O(\bar{g})\)</span> holes. But the vertices,
boundary vertices, and holes are not distributed evenly among the
pieces, so we do not yet have a nice <span
class="math inline">\(O(n/\bar{g})\)</span>-division. We apply a variant
of the algorithm of Klein, Mozes, and Sommer to construct a nice <span
class="math inline">\(O(n/bar{g})\)</span>-division of each
face-connected fragment of <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} P’(i^*, k^*)\)</span> in three
phases.</p>
<ul>
<li><p>We repeatedly split pieces with more than <span
class="math inline">\(n/\bar{g}\)</span> vertices using balanced cycle
separators, until every piece has at most <span
class="math inline">\(n/bar{g})\)</span> vertices. This phase requires
at most <span class="math inline">\(O(\bar{g})\)</span> splits. Naively,
if we compute each cycle separator independently, the total time for
this phase of the algorithm is <span class="math inline">\(O(n\log
g)\)</span>, but the time reduces to <span
class="math inline">\(O(n)\)</span> if we use the faster
Klein-Mozes-Sommer algorithm. The total number of boundary vertices at
the end of this phase is <span
class="math inline">\(O(\sqrt{\bar{g}n})\)</span>.</p></li>
<li><p>Next, we repeatedly split pieces whose boundary has more than
<span class="math inline">\(\sqrt{n/\bar{g}}\)</span> vertices until no
such pieces remain. We split each piece by giving each boundary vertex
weight <span class="math inline">\(1\)</span> and each interior vertex
weight <span class="math inline">\(0\)</span>, and then computing a
balanced cycle separator. Finding a cycle separator in a piece with
<span class="math inline">\(O(n/\bar{g})\)</span> vertices takes <span
class="math inline">\(O(n/\bar{g})\)</span> time. This phase requires at
most <span class="math inline">\(O(\bar{g})\)</span> splits to evenly
partition the <span class="math inline">\(O(\sqrt{\bar{g}n})\)</span>
boundary vertices, so the total time for this phase is <span
class="math inline">\(O(n)\)</span>, even if we compute each cycle
separator independently.</p></li>
<li><p>Finally, we repeatedly split pieces that have more than (say)
<span class="math inline">\(20\)</span> boundary cycles until no such
pieces remain. We split each piece by triangulating each hole with one
additional vertex, giving the added vertices weight <span
class="math inline">\(1\)</span> and all other vertices weight <span
class="math inline">\(0\)</span>, and then computing a balanced cycle
separator. Finding a cycle separator in a piece with <span
class="math inline">\(O(n/\bar{g})\)</span> vertices takes <span
class="math inline">\(O(n/\bar{g})\)</span> time. This phase requires at
most <span class="math inline">\(O(\bar{g})\)</span> splits to evenly
partition the <span class="math inline">\(O(\bar{g})\)</span> holes, so
the total time for this phase is <span
class="math inline">\(O(n)\)</span>.</p></li>
</ul>
<p><strong>Theorem:</strong> <em>Given a surface map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and Euler genus <span
class="math inline">\(\bar{g} = o(n)\)</span>, we can compute a nice
<span class="math inline">\((n/\bar{g})\)</span>-division of <span
class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n)\)</span> time.</em></p>
<p>We can now compute <span class="math inline">\(r\)</span>-divisions
for smaller values of <span class="math inline">\(r\)</span>, or even
hierarchies of such $r$0divisions, by applying planar algorithms to the
individual pieces of this <span
class="math inline">\((n/\bar{g})\)</span>-division.</p>
<p><strong>Corollary:</strong> <em>Given a surface map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and Euler genus <span
class="math inline">\(\bar{g} = o(n)\)</span>, and any integer <span
class="math inline">\(r &lt; n/\bar{g}\)</span>, we can compute a nice
<span class="math inline">\(r\)</span>-division of <span
class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n)\)</span> time.</em></p>
<p><strong>Corollary:</strong> <em>Given a planar triangulation <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices, and any exponentially
decreasing vector <span class="math inline">\(\vec{r} = (r_1, r_2,
\dots, r_t)\)</span> with <span class="math inline">\(r_1 &lt;
n/\bar{g}\)</span>, we can construct a good <span
class="math inline">\(\vec{r}\)</span>-division of <span
class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n)\)</span> time.</em></p>
<h2 data-number="27.4" id="applications-1"><span
class="header-section-number">27.4</span> Applications</h2>
<p>This construction allows us to extend several algorithms for planar
maps to surface maps with no change in the running time, provided the
genus is sufficiently small. For example, using the planar algorithms
described earlier in these notes, we obtain the following:</p>
<p><strong>Corollary:</strong> <em>Given a surface map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and genus <span
class="math inline">\(g = o(n/\log^2 n)\)</span>, with non-negatively
weighted darts, we can compute a single-source shortest path tree in
<span class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(n\log\log n)\)</span> time.</em></p>
<p>(This time bound can be improved to <span
class="math inline">\(O(n)\)</span>.)</p>
<p><strong>Corollary:</strong> <em>Given a surface map <span
class="math inline">\(\Sigma\)</span> with <span
class="math inline">\(n\)</span> vertices and genus <span
class="math inline">\(g = o(n/\log^2 n)\)</span>, with arbitrarily
weighted darts, we can compute either a single-source shortest path tree
or a negative cycle in <span class="math inline">\(\Sigma\)</span> in
<span class="math inline">\(O(n\log^2 n/\log\log n)\)</span>
time.</em></p>
<p>The only significant subtlety in generalizing the planar algorithms
is some pieces in the relevant <span
class="math inline">\(r\)</span>-divisions can be adjacent to themselves
across one of the paths in <span
class="math inline">\(Q(i^*,k^*)\)</span>. Thus, “boundary vertex” does
not mean “vertex that belongs to more than one piece”; rather, pieces
are defined by slicing the surface map along certain paths and cycles,
and “boundary vertex” means a vertex on one of these slicing curves. The
dense-distance graph of a piece is defined by shortest
boundary-to-boundary paths <em>within</em> the piece, even though there
may be shorter paths that use only vertices and edges of the piece but
that that cross the boundary of the piece.</p>
<h2 data-number="27.5" id="references-17"><span
class="header-section-number">27.5</span> References</h2>
<ol type="1">
<li><p>Lyudmil Aleksandrov and Hristo Djidjev. <a
href="https://doi.org/10.1137/S0895480194272183">Linear algorithms for
partitioning embedded graphs of bounded genus</a>. <em>SIAM J. Discrete
Math.</em> 9(1):129–150, 1996.</p></li>
<li><p>Éric Colin de Verdière, Alfredo Hubard, and Arnaud de Mesmay. <a
href="http://doi.org/10.1007/s00454-015-9679-9">Discrete systolic
inequalities and decompositions of triangulated surfaces</a>.
<em>Discrete Comput. Geom.</em> 53(3):587–620, 2015.</p></li>
<li><p>Hristo N. Djidjev. A separator theorem. <em>C. R. Acad. Bulg.
Sci.</em> 34:643–645, 1981.</p></li>
<li><p>David Eppstein. <a
href="https://dl.acm.org/doi/10.5555/644108.644208">Dynamic generators
of topologically embedded graphs</a>. <em>Proc. 14th Ann. ACM-SIAM Symp.
Discrete Algorithms</em>, 599–608, 2003. arXiv:<a
href="https://arxiv.org/abs/cs/0207082">cs/0207082</a>.</p></li>
<li><p>John R. Gilbert, Joan P. Hutchinson, and Robert Endre Tarjan. <a
href="http://doi.org/10.1016/0196-6774(84)90019-1">A separator theorem
for graphs of bounded genus</a>. <em>J. Algorithms</em> 5(3):391–407,
1984.</p></li>
<li><p>Joan P. Hutchinson. <a href="https://doi.org/10.1137/0401020">On
short noncontractible cycles in embedded graphs</a>. <em>SIAM J.
Discrete Math.</em> 1(2):185–192, 1988.</p></li>
<li><p>Joan P. Hutchinson and Gary L. Miller. <a
href="https://doi.org/10.1016/B978-0-12-386870-1.50011-3">Deleting
vertices to make graphs of positive genus planar</a>. <em>Discrete
Algorithms and Complexity Theory, Proc. Japan-US Joint Seminar, Kyoto,
Japan</em>, 81–98, 1987. Academic Press.</p></li>
</ol>
<h2 data-number="27.6" id="aptly-named-sir-2"><span
class="header-section-number">27.6</span> Aptly Named Sir</h2>
<ul>
<li>Local approximation (Baker-Eppstein)</li>
</ul>
<h1 data-number="28" id="homotopy-testing-on-surface-mapsbeta"><span
class="header-section-number">28</span> Homotopy Testing on Surface
Maps<span class="math inline">\(^\beta\)</span></h1>
<p>Let’s return to one of the earliest problems we saw this semester:
Given two curves in the same surface, decide whether they are
<em>homotopic</em>, meaning one can be continuously deformed into the
other. Here I’ll describe a linear-time algorithm that slightly improves
a classical algorithm of Max Dehn (1911).</p>
<p>To keep things simple, I’ll focus on the following special case:
Given a <em>closed</em> curve <span
class="math inline">\(\gamma\)</span> in some surface <span
class="math inline">\(\mathcal{S}\)</span>, is <span
class="math inline">\(\gamma\)</span> <em>contractible</em> in <span
class="math inline">\(\mathcal{S}\)</span>? That is, can <span
class="math inline">\(\gamma\)</span> be continuously deformed on the
surface <span class="math inline">\(\mathcal{S}\)</span> to a single
point?</p>
<p>This question is obviously trivial in the plane or the sphere, and it
turns out to be easy on the projective plane, torus, or Klein bottle, so
without loss of generality, I will assume that the underlying surface
has negative Euler characteristic <span
class="math inline">\(\chi&lt;0\)</span>. Let <span
class="math inline">\(\bar{g} = 2-\chi\)</span> denote the <em>Euler
genus</em> of the input surface; recall that the Euler genus is equal to
the standard genus if the surface is non-orientable, and twice the
standard genus otherwise.</p>
<h2 data-number="28.1" id="reducing-to-a-system-of-loops"><span
class="header-section-number">28.1</span> Reducing to a System of
Loops</h2>
<p>Let <span class="math inline">\(W\)</span> be a given closed walk
through some surface map <span class="math inline">\(\Sigma\)</span>.
Like every other surface-map algorithm, we begin by computing an
arbitrary tree-cotree decomposition <span class="math inline">\((T, L,
C)\)</span> of <span class="math inline">\(\Sigma\)</span>. We then
reduce <span class="math inline">\(\Sigma\)</span> to a system of <span
class="math inline">\(\bar{g}\)</span> loops <span
class="math inline">\(\Lambda = \Sigma \mathbin / T \setminus C\)</span>
by contracting every edge in <span class="math inline">\(T\)</span> and
then deleting every edge in <span class="math inline">\(C\)</span>.
simultaneously modifying the closed walk <span
class="math inline">\(W\)</span> as follows:</p>
<ul>
<li><p>When we contract edges in <span class="math inline">\(T\)</span>,
we simply remove any darts of <span class="math inline">\(T\)</span>
from <span class="math inline">\(W\)</span>. After all edges in <span
class="math inline">\(T\)</span> are contracted, all remaining edges are
loops.</p></li>
<li><p>Then when we delete edges in <span
class="math inline">\(C\)</span>, we replace each dart in <span
class="math inline">\(W\)</span> whose edge is in <span
class="math inline">\(C\)</span> with a walk around the boundary of the
unique face of <span class="math inline">\(\Lambda\)</span>, as shown in
the figure below.</p></li>
</ul>
<figure>
<img src="Fig/sysloops-reduction.png" style="width:60.0%"
alt="Reducing to a system of loops." />
<figcaption aria-hidden="true">Reducing to a system of
loops.</figcaption>
</figure>
<p>The reduction takes <span class="math inline">\(O(n + \ell’) = O(n +
\bar{g}\ell)\)</span> time to compute, where <span
class="math inline">\(n\)</span> is the complexity of the input map
<span class="math inline">\(\Sigma\)</span>, <span
class="math inline">\(\ell\)</span> is the length of the input walk
<span class="math inline">\(W\)</span> in <span
class="math inline">\(\Sigma\)</span>, and <span
class="math inline">\(\ell’\)</span> is the length of the transformed
walk <span class="math inline">\(W’\)</span> in <span
class="math inline">\(\Lambda\)</span>. (Later I’ll remove the factor of
<span class="math inline">\(\bar{g}\)</span> by reducing to a slightly
different map.)</p>
<p>We have now reached the special case of the homotopy problem that
Dehn actually solved in 1911: Given a closed walk in a system of loops,
is there a sequence of spur and face moves that reduce it to a trivial
walk?</p>
<h2 data-number="28.2" id="universal-cover"><span
class="header-section-number">28.2</span> Universal Cover</h2>
<p>The <em>universal cover <span
class="math inline">\(\tilde\Lambda\)</span></em> of <span
class="math inline">\(\Lambda\)</span> is an infinite planar map
obtained by gluing an infinite lattice of copies of the single face of
<span class="math inline">\(\Lambda\)</span> along corresponding edges.
Combinatorially, <span class="math inline">\(\tilde\Lambda\)</span> is
isomorphic to a regular tiling of the <em>hyperbolic</em> plane by
regular <span class="math inline">\(2\bar{g}\)</span>-gons meeting <span
class="math inline">\(2\bar{g}\)</span> at each vertex. For example, if
the input map <span class="math inline">\(\Sigma\)</span> is an
orientable map with genus <span class="math inline">\(2\)</span>, and
therefore Euler genus <span class="math inline">\(4\)</span>, we reduce
<span class="math inline">\(\Sigma\)</span> to a system of loops <span
class="math inline">\(\Lambda\)</span> containing four loops. The
universal cover <span class="math inline">\(\tilde\Lambda\)</span> of
<span class="math inline">\(\Lambda\)</span> is an <span
class="math inline">\(8\)</span>-regular hyperbolic tiling by
octagons.</p>
<figure>
<img src="Fig/universal-cover-8x8.png" style="width:40.0%"
alt="The universal cover of an orientable system of loops with genus 2." />
<figcaption aria-hidden="true">The universal cover of an orientable
system of loops with genus <span
class="math inline">\(2\)</span>.</figcaption>
</figure>
<p>Formally, a <em>covering map</em> is a continuous surjection <span
class="math inline">\(\pi\colon X’\to X\)</span> between topological
spaces, such that each point <span class="math inline">\(x\in X\)</span>
lies in an open neighborhood <span class="math inline">\(U\subset
X\)</span> whose preimage <span
class="math inline">\(\pi^{-1}(U)\)</span> is the disjoint union of open
sets <span class="math inline">\(\bigsqcup_{i\in I} U_i\)</span>, where
the restriction of <span class="math inline">\(\pi\)</span> to each set
<span class="math inline">\(U_i\)</span> is a homeomorphism to <span
class="math inline">\(U\)</span>. Space <span
class="math inline">\(X&#39;\)</span> is called a <em>covering
space</em> of <span class="math inline">\(X\)</span> if there is a
covering map from <span class="math inline">\(X&#39;\)</span> to <span
class="math inline">\(X\)</span>. By convention, covering spaces are
assumed to be connected.</p>
<p>Covering maps can also be formulated combinatorially as follows. A
<em>map-covering map</em> is a surjective function <span
class="math inline">\(\pi\colon \Sigma’\to\Sigma\)</span> between
<em>surface maps</em> that sends vertices to vertices, darts to darts,
and faces to faces, and that preserves degrees of vertices and faces.
For example, if the maps <span class="math inline">\(\Sigma’\)</span>
and <span class="math inline">\(\Sigma\)</span> are represented rotation
systems <span class="math inline">\((D’, \textsf{rev}’,
\textsf{succ}’)\)</span> and <span class="math inline">\((D,
\textsf{rev}, \textsf{succ})\)</span>, a covering map is a function
<span class="math inline">\(\pi\colon D’\to D\)</span> such that <span
class="math inline">\(\textsf{rev}\circ \pi = \pi\circ
\textsf{rev}’\)</span> and <span
class="math inline">\(\textsf{succ}\circ \pi = \pi\circ
\textsf{succ}’\)</span>, and <span class="math inline">\(\pi\)</span>
sends every orbit of <span class="math inline">\(\textsf{succ}’\)</span>
or <span class="math inline">\(\textsf{rev}’(\textsf{succ})’\)</span>
<em>bijectively</em> to an orbit of <span
class="math inline">\(\textsf{succ}\)</span> or <span
class="math inline">\(\textsf{rev}(\textsf{succ})\)</span>,
respectively. There is a similar combinatorial formulation for
reflection systems.</p>
<p>A <em>lift</em> of any vertex <span class="math inline">\(v\)</span>
of <span class="math inline">\(\Sigma\)</span> to a covering space <span
class="math inline">\(\Sigma’\)</span> is a vertex <span
class="math inline">\(v’\)</span> of <span
class="math inline">\(\Sigma’\)</span> such that <span
class="math inline">\(\pi(v’)=v\)</span>. Lifts of darts, edges, and
faces are defined similarly. Locally, it is impossible to distinguish
between a feature of <span class="math inline">\(\Sigma\)</span> and any
of its lifts in <span class="math inline">\(\Sigma’\)</span>.</p>
<p>The <em>universal cover</em> of a space <span
class="math inline">\(X\)</span> is the unique (connected) covering
space <span class="math inline">\(\tilde{X}\)</span> that is
<em>simply</em> connected, meaning all closed curves are contractible.
The universal cover <span class="math inline">\(\tilde{X}\)</span> is
also the “largest” (connected) covering space of <span
class="math inline">\(X\)</span>, meaning <span
class="math inline">\(\tilde{X}\)</span> is a covering space of every
(connected) covering space of <span class="math inline">\(X\)</span>.
For almost all surfaces, the universal cover is homeomorphic to the
plane. (The only exceptions are the sphere, which is its own universal
cover, and the projective plane, whose universal cover is the sphere.)
Similarly, universal cover of any surface <em>map</em> <span
class="math inline">\(\Sigma\)</span> is a spherical map if <span
class="math inline">\(\Sigma\)</span> lies on the sphere or the
projective plane, and an <em>infinite</em> planar map otherwise.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>A closed walk <span class="math inline">\(W\)</span> in a surface
map <span class="math inline">\(\Sigma\)</span> is contractible if and
only if <span class="math inline">\(W\)</span> is the projection of a
closed walk <span class="math inline">\(\tilde{W}\)</span> in the
universal cover <span class="math inline">\(\tilde\Sigma\)</span>.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\pi\colon\tilde\Sigma\to\Sigma\)</span>
denote the universal covering map.
</dd>
<dd>
<p>First, let <span class="math inline">\(\tilde{W}\)</span> be any
closed walk in <span class="math inline">\(\tilde\Sigma\)</span>, and
let <span class="math inline">\(W = \pi(\tilde{W})\)</span>. Because
<span class="math inline">\(\tilde\Sigma\)</span> is simply connected,
<span class="math inline">\(\tilde{W}\)</span> must be contractible.
Consider any sequence of spur moves and face moves <span
class="math inline">\(\tilde{W}_0 \to \tilde{W}_1 \to \tilde{W}_2 \to
\cdots \to \tilde{W}_N\)</span> that reduces <span
class="math inline">\(\tilde{W} = \tilde{W}_0\)</span> to a trivial
closed walk <span class="math inline">\(\tilde{W}_N\)</span>. For each
index <span class="math inline">\(i\)</span>, let <span
class="math inline">\(W_i = \pi(\tilde{W}_i)\)</span>. Then <span
class="math inline">\(W_0 \to W_1 \to W_2 \to \cdots \to W_N\)</span> is
also a sequence of spur moves and face moves that reduces <span
class="math inline">\(W = W_0\)</span> to a trivial walk <span
class="math inline">\(W_N\)</span>. Specifically, if <span
class="math inline">\(\tilde{W}_{i-1}\to \tilde{W}_i\)</span> is a spur
move on some edge <span class="math inline">\(\tilde{e}\)</span>, then
<span class="math inline">\({W}_{i-1}\to {W}_i\)</span> is a spur move
on the edge <span class="math inline">\(\pi(\tilde{e})\)</span>, and if
<span class="math inline">\(\tilde{W}_{i-1}\to \tilde{W}_i\)</span> is a
face move on some edge <span class="math inline">\(\tilde{f}\)</span>,
then <span class="math inline">\({W}_{i-1}\to {W}_i\)</span> is a face
move on the edge <span class="math inline">\(\pi(\tilde{f})\)</span>. We
conclude that <span class="math inline">\(W\)</span> is
contractible.</p>
</dd>
<dd>
<p>Conversely, let <span class="math inline">\(W\)</span> be
<em>any</em> closed walk in <span class="math inline">\(\Sigma\)</span>.
Formally, <span class="math inline">\(W\)</span> is an alternating
sequence <span class="math inline">\(v_0, d_1, v_1, d_2, \dots, d_\ell,
v_\ell\)</span> of vertices and darts, where <span
class="math inline">\(v_\ell = v_0\)</span> and for each index <span
class="math inline">\(i\)</span>, we have <span
class="math inline">\(v_{i-1} = \textsf{tail}(d_i)\)</span> and <span
class="math inline">\(v_i = \textsf{head}(d_i)\)</span>. We can
iteratively lift <span class="math inline">\(W\)</span> to a (not
necessarily closed) walk <span class="math inline">\(\tilde{W}\)</span>
as follows. First, let <span class="math inline">\(\tilde{v}_0\)</span>
be any lift of <span class="math inline">\(v_0\)</span>, and then for
each index <span class="math inline">\(i&gt;0\)</span>, let <span
class="math inline">\(\tilde{d}_i\)</span> be the unique lift of <span
class="math inline">\(d_i\)</span> whose tail is <span
class="math inline">\(\tilde{v}_{i-1}\)</span>, and let <span
class="math inline">\(\tilde{v}_i =
\textsf{head}(\tilde{d}_i)\)</span>.</p>
</dd>
<dd>
<p>Now suppose <span class="math inline">\(W\)</span> is contractible.
Then there is a sequence <span class="math inline">\(W_0 \to W_1 \to W_2
\to \cdots \to W_N\)</span> of spur and face moves transforming some
trivial walk <span class="math inline">\(W_0\)</span> into <span
class="math inline">\(W_N = W\)</span>. (Yes, we are expanding here
rather than contracting.) Fix an arbitrary lift <span
class="math inline">\(\tilde{W}_0\)</span> of <span
class="math inline">\(W_0\)</span>. Then for each index <span
class="math inline">\(j\)</span>, let <span
class="math inline">\(\tilde{W}_j\)</span> be the closed walk in <span
class="math inline">\(\tilde{X}\)</span> obtained from <span
class="math inline">\(\tilde{W}_{j-1}\)</span> by lifting the move <span
class="math inline">\(W_{j-1}\to W_j\)</span>. Specifically, if <span
class="math inline">\(W_{j-1}\to W_j\)</span> inserts a spur <span
class="math inline">\(v_i\mathord\to w\mathord\to v_i\)</span> into
<span class="math inline">\(W_{j-1}\)</span> at its <span
class="math inline">\(i\)</span>th vertex <span
class="math inline">\(v_i\)</span>, then <span
class="math inline">\(\tilde{W}_j\)</span> is obtained by inserting a
spur <span class="math inline">\(\tilde{v}_i\mathord\to
\tilde{w}\mathord\to \tilde{v}_i\)</span> into <span
class="math inline">\(\tilde{W}_{j-1}\)</span> at its <span
class="math inline">\(i\)</span>th vertex <span
class="math inline">\(\tilde{v}_i\)</span>, where <span
class="math inline">\(\tilde{v}_i\mathord\to \tilde{w}\)</span> is the
unique lift of dart <span class="math inline">\(v_i\mathord\to
w\)</span> whose tail is <span
class="math inline">\(\tilde{v}_i\)</span>. Face moves can be lifted
similarly. By induction, each of the resulting walks <span
class="math inline">\(\tilde{W}_j\)</span> is closed, and therefore the
final walk <span class="math inline">\(\tilde{W}_N\)</span> is a closed
walk such that <span class="math inline">\(\pi(\tilde{W}_N) =
W\)</span>. <span class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>With this lemma in hand, we can now phrase the contractibility
problem in the form that Dehn’ considered it. <em>Given a closed walk
<span class="math inline">\(W\)</span> in some system of loops <span
class="math inline">\(\Lambda\)</span>, is <span
class="math inline">\(W\)</span> the projection of a closed walk in the
universal cover <span
class="math inline">\(\tilde\Lambda\)</span>?</em></p>
<h2 data-number="28.3" id="dehns-lemma"><span
class="header-section-number">28.3</span> Dehn’s Lemma</h2>
<p>We use a version of the combinatorial Gauss-Bonnet theorem for
surfaces with boundary (some faces marked as missing). Here curvature is
defined as <span class="math display">\[
    \kappa(f) = 1 - \sum_{c\in f}\angle c
    \qquad
    \kappa(v) = 1 - \frac{1}{2} \deg(v) + \sum_{c\in v}\angle c
\]</span> where <span class="math inline">\(\deg(v)\)</span> is the
number of <em>darts</em> incident to <span
class="math inline">\(v\)</span>, not the number of corners. Then as
usual we have <span class="math inline">\(\sum_v \kappa(v) + \sum_f
\kappa(f) = \chi\)</span>. In our application, we will always set <span
class="math inline">\(\angle c = 1/4\)</span>, so <span
class="math display">\[
    \kappa(f) = 1 - \frac{1}{4}\deg(f)
    \qquad
    \kappa(v) = 1 - \frac{1}{2}\deg(v) + \frac{1}{4}\deg_2(v)
\]</span> where <span class="math inline">\(\deg_2(v)\)</span> is the
number of <em>corners</em> incident to <span
class="math inline">\(v\)</span>.</p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every nontrivial closed walk <span
class="math inline">\(\tilde{W}\)</span> in <span
class="math inline">\(\tilde\Lambda\)</span> contains either a spur or
at least <span class="math inline">\(2\bar{g}-2\)</span> consecutive
edges on the boundary of some face.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
First consider the special case where <span
class="math inline">\(\tilde{W}\)</span> is a nontrivial <em>simple</em>
closed walk; in particular, <span
class="math inline">\(\tilde{W}\)</span> has no spurs. Let <span
class="math inline">\(\Delta = (V, E, F)\)</span> denote the map of the
<em>disk</em> consisting of faces inside <span
class="math inline">\(\tilde{W}\)</span>. Assign every corner of <span
class="math inline">\(\Delta\)</span> the angle <span
class="math inline">\(1/4\)</span>.
</dd>
<dd>
<ul>
<li>For any face <span class="math inline">\(f\)</span>, we have <span
class="math inline">\(\kappa(f) = 1 - \deg(f)/4 = 1 - \bar{g}/2 &lt;
0\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>For any interior vertex <span class="math inline">\(v\)</span>, we
have <span class="math inline">\(\deg_2(v) = \deg(v)\)</span> and
therefore <span class="math inline">\(\kappa(v) = 1 - \deg(v)/4 = 1 -
\bar{g}/2 &lt; 0\)</span>.</li>
</ul>
</dd>
<dd>
<ul>
<li>For any boundary vertex <span class="math inline">\(v\)</span>, we
have we have <span class="math inline">\(\deg_2(v) = \deg(v)-1\)</span>
and therefor <span class="math inline">\(\kappa(v) = 3/4 -
\deg(v)\)</span>.</li>
</ul>
</dd>
<dd>
<p>Call a boundary vertex of <span class="math inline">\(\Delta\)</span>
<em>convex</em> if it is incident to exactly one face of <span
class="math inline">\(\Delta\)</span>. Every convex boundary vertex has
degree <span class="math inline">\(2\)</span> in <span
class="math inline">\(\Delta\)</span> and therefore has curvature <span
class="math inline">\(1/4\)</span>; all other vertices of <span
class="math inline">\(\Delta\)</span> have curvature at most <span
class="math inline">\(0\)</span>.</p>
</dd>
<dd>
<p>The combinatorial Gauss-Bonnet theorem implies that <span
class="math inline">\(\sum_v\kappa(v) + \sum_f\kappa(f) = 1\)</span>,
which implies that <span class="math display">\[
\left(1-\frac{\bar{g}}{2}\right) |F| + \frac{1}{4} |V_+| \ge 1
~\implies~
|V_+| \ge (2\bar{g}-4) |F| + 4
\]</span> where <span class="math inline">\(V_+\)</span> is the set of
convex vertices. It follows that some face <span
class="math inline">\(f\)</span> is incident to <span
class="math inline">\(2\bar{g}-3\)</span> convex boundary vertices.
These must be consecutive around the boundary of <span
class="math inline">\(f\)</span>. We conclude that <span
class="math inline">\(f\)</span> has <span
class="math inline">\(2\bar{g}-2\)</span> consecutive edges on the
boundary of <span class="math inline">\(\Delta\)</span>. In fact, there
must be at least two such face, unless <span
class="math inline">\(\Delta\)</span> consists of a single face.</p>
</dd>
<dd>
<p>Now suppose <span class="math inline">\(\tilde{W}\)</span> is a
non-simple closed walk in <span
class="math inline">\(\tilde\Lambda\)</span>. If <span
class="math inline">\(\tilde{W}\)</span> contains a sure, we are done,
so assume otherwise. Let <span class="math inline">\(\tilde{x}\)</span>
be the first vertex to appear more than once along <span
class="math inline">\(\tilde{W}\)</span>, and let <span
class="math inline">\(\tilde{X}\)</span> be subwalk of <span
class="math inline">\(\tilde{W}\)</span> from the first occurrence of
<span class="math inline">\(\tilde{x}\)</span> to the second. If <span
class="math inline">\(\tilde{X}\)</span> is the boundary of a single
face <span class="math inline">\(f\)</span>, then <span
class="math inline">\(\tilde{W}\)</span> contains <span
class="math inline">\(2\bar{g}\)</span> consecutive boundary edges of
<span class="math inline">\(f\)</span>. Otherwise, there are at least
two faces <span class="math inline">\(f\)</span> such that <span
class="math inline">\(\tilde{X}\)</span> contains at least <span
class="math inline">\(2\bar{g}-2\)</span> consecutive edges on the
boundary of <span class="math inline">\(f\)</span>. These two subpaths
are disjoint, so at most one of them contains <span
class="math inline">\(x\)</span>, so at least one of them is a subpath
of <span class="math inline">\(\tilde{W}\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p>Projection back to the system of loops immediately gives us the
following corollary.</p>
<dl>
<dt><strong>Corollary:</strong></dt>
<dd>
<em>Every nontrivial contractible closed walk <span
class="math inline">\(W\)</span> in <span
class="math inline">\(\Lambda\)</span> contains either a spur or at
least <span class="math inline">\(2\bar{g}-2\)</span> edges on the
boundary of some face.</em>
</dd>
</dl>
<h2 data-number="28.4" id="dehns-algorithm"><span
class="header-section-number">28.4</span> Dehn’s algorithm!</h2>
<p>Finally, Dehn’s algorithm uses a simple greedy improvement strategy:
Repeatedly remove spurs (using spur moves) and long boundary subpaths
(using face moves) from <span class="math inline">\(W’\)</span> until no
more remain, and then return <span
class="math inline">\(\textsf{true}\)</span> if and only if the
remaining walk is trivial. Correctness follows immediately from Dehn’s
lemma.</p>
<p>To find long boundary subpaths efficiently, we assign a unique label
to each dart and represent <span class="math inline">\(W\)</span> as a
(circular) string of dart labels, sorted in a circular linked list. Then
we slide a window of length <span
class="math inline">\(2\bar{g}-2\)</span> over the string, checking each
of the <span class="math inline">\(O(\bar{g})\)</span> possible long
boundary subpaths at each position. Using brute force string
comparisons, this check takes <span
class="math inline">\(O(\bar{g}^2)\)</span> time per position. We can
improve this to <span class="math inline">\(O(1)\)</span> time per
position by building a DFA that matches all long boundary subpaths;
building this DFA adds <span class="math inline">\(O(\bar{g}^2)\)</span>
time to preprocessing.</p>
<p>Whenever we find a long boundary subpath, we replace it with its
complement (of length <span class="math inline">\(2\)</span>) and move
the window back <span class="math inline">\(2\bar{g}\)</span> steps; we
charge both the deletion and the time to find the long boundary subpath
to the decrease in string length. Similarly, whenever we notice a spur,
we can remove it in <span class="math inline">\(O(1)\)</span> time. The
algorithm ends after <span class="math inline">\(O(\ell’)\)</span>
iterations.</p>
<p>Thus, the overall running time of Dehn’s algorithm, starting with an
arbitrary surface map <span class="math inline">\(\Sigma\)</span> with
complexity <span class="math inline">\(n\)</span> and Euler genus <span
class="math inline">\(\bar{g}\)</span>, is <span
class="math inline">\(O(n + \bar{g}^2 + \bar{g}\ell)\)</span>.</p>
<h2 data-number="28.5" id="system-of-quads"><span
class="header-section-number">28.5</span> System of quads</h2>
<p>To remove the dependence on <span
class="math inline">\(\bar{g}\)</span> in the running time, we reduce to
a different elementary map called a <em>system of quads</em>.</p>
<p>For any surface map <span class="math inline">\(\Sigma = (V, E,
F)\)</span>, the <em>radial map</em> <span
class="math inline">\(\Sigma^\diamond = (V^\diamond, E^\diamond,
F^\diamond)\)</span> is defined as follows:</p>
<ul>
<li><span class="math inline">\(V^\diamond = V \cup F^*\)</span>, where
<span class="math inline">\(f^*\)</span> is the set of vertices of the
dual map <span class="math inline">\(\Sigma^*\)</span>.</li>
<li>Edges in <span class="math inline">\(E^\diamond\)</span> correspond
to corners in <span class="math inline">\(\Sigma\)</span>. Any primal
vertex <span class="math inline">\(v\)</span> and dual vertex <span
class="math inline">\(f^*\)</span> are connected by one radial edge for
each incidence between <span class="math inline">\(v\)</span> and <span
class="math inline">\(f\)</span>.</li>
<li>Faces in <span class="math inline">\(F^\diamond\)</span> correspond
to edges in <span class="math inline">\(\Sigma\)</span>. Every face
<span class="math inline">\(e^\diamond \in F^\diamond\)</span> has
degree 4; its vertices are the endpoints of <span
class="math inline">\(e\)</span> and the endpoints of the dual edge
<span class="math inline">\(e^*\)</span>.</li>
</ul>
<figure>
<img src="Fig/derived-maps/radial.png" style="width:35.0%"
alt="The radial map (black) of a surface map (white)." />
<figcaption aria-hidden="true">The radial map (black) of a surface map
(white).</figcaption>
</figure>
<p>A <em>system of quads</em> is the radial map of a system of loops:
<span class="math inline">\(Q = \Lambda^\diamond\)</span>. This map has
exactly <span class="math inline">\(2\)</span> vertices, <span
class="math inline">\(2\bar{g}\)</span> edges, and <span
class="math inline">\(\bar{g}\)</span> quadrilateral faces.</p>
<figure>
<img src="Fig/genus-2-quads-wrapped.png" style="width:50.0%"
alt="A system of quads on an orientable surface of genus 2 (and thus Euler genus 4). Each face has a unique color." />
<figcaption aria-hidden="true">A system of quads on an orientable
surface of genus <span class="math inline">\(2\)</span> (and thus Euler
genus <span class="math inline">\(4\)</span>). Each face has a unique
color.</figcaption>
</figure>
<p>We can reduce an arbitrary closed walk <span
class="math inline">\(W\)</span> in an arbitrary map <span
class="math inline">\(\Sigma\)</span> to a homotopic closed walk <span
class="math inline">\(W’\)</span> in a system of quads <span
class="math inline">\(Q\)</span> by modifying our earlier reduction to a
system of loops. Fix an arbitrary tree-cotree decomposition <span
class="math inline">\((T, L, C)\)</span>, and contract the edges in the
spanning tree <span class="math inline">\(T\)</span>. Let <span
class="math inline">\(v\)</span> and <span
class="math inline">\(f\)</span> respectively denote the only vertex and
the only face of the system of loops <span class="math inline">\(\Lambda
= \Sigma\setminus T \mathbin/ C\)</span>. Each edge <span
class="math inline">\(e\)</span> of <span
class="math inline">\(\Sigma\setminus T\)</span> can be considered (or
perturbed into) a path through <span class="math inline">\(f\)</span>
from one corner to another. We replace each such edge with the
corresponding path of length <span class="math inline">\(2\)</span> in
<span class="math inline">\(Q = \Lambda^\diamond\)</span>, from <span
class="math inline">\(v\)</span> to <span
class="math inline">\(f^*\)</span> to <span
class="math inline">\(v\)</span>. The resulting walk <span
class="math inline">\(W’\)</span> in <span
class="math inline">\(Q\)</span> has length at most <span
class="math inline">\(2\ell\)</span>, and the reduction requires <span
class="math inline">\(O(n+\ell)\)</span> time.</p>
<figure>
<img src="Fig/sysquads-reduction.png" style="width:60.0%"
alt="Reducing to a system of quads. (Pairs of triangles with the same color comprise faces.)" />
<figcaption aria-hidden="true">Reducing to a system of quads. (Pairs of
triangles with the same color comprise faces.)</figcaption>
</figure>
<p>The universal cover of <span class="math inline">\(Q\)</span> is a
hyperbolic tiling by squares meeting <span
class="math inline">\(2\bar{g}\)</span> at each vertex. Our earlier
arguments imply that <span class="math inline">\(W’\)</span> (and
therefore <span class="math inline">\(W\)</span>) is contractible if and
only if <span class="math inline">\(W’\)</span> is the projection of a
closed walk in the universal cover <span
class="math inline">\(\tilde{Q}\)</span>.</p>
<figure>
<img src="Fig/universal-cover-quads.png" style="width:40.0%"
alt="The universal cover of an orientable system of quads with genus 2." />
<figcaption aria-hidden="true">The universal cover of an orientable
system of quads with genus <span
class="math inline">\(2\)</span>.</figcaption>
</figure>
<h2 data-number="28.6" id="brackets"><span
class="header-section-number">28.6</span> Brackets</h2>
<p>Dehn’s lemma still applies to the infinite hyperbolic tiling <span
class="math inline">\(\tilde{Q}\)</span>—Every closed walk in <span
class="math inline">\(\tilde{Q}\)</span> contains either a spur of a
subpath that covers all but two edges of some face. But now the
complement of a “long” boundary subpath also has length <span
class="math inline">\(2\)</span>; a single face move does not
necessarily decrease the length of the walk. We need to find larger
moves that are still simple enough to find and execute quickly, but that
are guaranteed to shrink any closed walk.</p>
<p>To make this easier, we encode the walk <span
class="math inline">\(W’\)</span> as a <em>turn sequence</em>. The
<em>turn</em> of any subwalk <span class="math inline">\(u\mathord\to
v\mathord\to w\)</span> of <span class="math inline">\(W\)</span> is the
number of corners at the middle vertex <span
class="math inline">\(v\)</span> to the left of that subpath, modulo
<span class="math inline">\(\bar{g}\)</span>. Thus, for example, a
<em>spur</em> is any subpath of <span class="math inline">\(W\)</span>
with turn <span class="math inline">\(0\)</span>. The regularity of the
tiling <span class="math inline">\(\tilde{Q}\)</span> implies that the
contractibility of any closed walk depends only on its (cyclic) turn
sequence. Moreover, we can easily compute the turn sequence of any walk
in time proportional to its length.</p>
<p>A <em>right bracket</em> is any subpath whose turn sequence consists
of <span class="math inline">\(1\)</span>, followed by zero or more
<span class="math inline">\(2\)</span>s, followed by <span
class="math inline">\(1\)</span>. A <em>left bracket</em> is any subpath
whose turn sequence has the form <span class="math inline">\(-1, -2,
\dots, -2, -1\)</span>, for any number of <span
class="math inline">\(-2\)</span>s. (In the interest of readability,
from now on I will indicate negation with a bar instead of a minus sign;
for example, <span class="math inline">\(\bar{2} = -2\)</span>.)</p>
<p><strong>Bracket figure</strong></p>
<dl>
<dt><strong>Lemma:</strong></dt>
<dd>
<em>Every nontrivial contractible closed walk in <span
class="math inline">\(Q\)</span> contains a spur or a bracket.</em>
</dd>
<dt><strong>Proof:</strong></dt>
<dd>
<strong><em>[Combinatorial Gauss-Bonnet again.]</em></strong>
</dd>
</dl>
<p>The previous lemma implies that we can reduce any nontrivial
contractible closed walk in <span class="math inline">\(Q\)</span>
either using a spur move or by “sliding” a bracket. Both of these moves
can be performed entirely by modifying the turn sequence. For example,
removing a spur preceded by turn <span class="math inline">\(x\)</span>
and followed by turn <span class="math inline">\(y\)</span> leaves a
single turn with value <span class="math inline">\(x+y\)</span>. (All
turn arithmetic is implicitly performed modulo <span
class="math inline">\(\bar{g}\)</span>.) <span class="math display">\[
    \begin{aligned}
        x, ~ 0, ~ y
            &amp;\leadsto x+y \\
        x, ~ 1, ~ 2^k, ~ 1, ~ y
            &amp;\leadsto x-1, ~ \bar2^k, ~ y-1 \\
        x, ~ \bar1, ~ \bar2^k, ~ \bar1, ~ y
            &amp;\leadsto x+1, ~ 2^k, ~ y+1 \\
    \end{aligned}
\]</span> Here superscripts represent repetition, not
exponentiation.</p>
<p><strong><em>[[bracket slide figure]]</em></strong></p>
<h2 data-number="28.7" id="reduction-algorithm"><span
class="header-section-number">28.7</span> Reduction algorithm</h2>
<p>To make detecting and sliding brackets easier, we actually store and
manipulate a <em>run-length encoding</em> of the turn sequence. Instead
of recording repeated turns explicitly, we store a sequence of pairs
<span class="math inline">\(((\tau_0, r_0), (\tau_1, r_1),
\dots)\)</span> to represent <span class="math inline">\(r_0\)</span>
repetitions of turn <span class="math inline">\(\tau_0\)</span>,
followed by <span class="math inline">\(r_1\)</span> repetitions of
<span class="math inline">\(\tau_1\)</span>, and so on. Thus, any
bracket turn sequence overlaps at most five runs. (In fact, it suffices
to encode only runs of <span class="math inline">\(2\)</span>s and <span
class="math inline">\(\bar2\)</span>s.)</p>
<p>We now proceed as in Dehn’s classical algorithm. We slide a window of
width <span class="math inline">\(5\)</span> over the run-length-encoded
turn sequence; whenever the window contains a spur or a bracket, we
modify the runs within the window to perform a spur move or bracket
move, and then move the window back five steps. At each window position,
we need <span class="math inline">\(O(1)\)</span> time to detect spurs
and brackets, and <span class="math inline">\(O(1)\)</span> time to
perform each spur of bracket move. The algorithm iterates until we have
made a complete scan with no reductions, in which case we are done, or
at most five runs remain in the run sequence, in which case we can
complete the algorithm in O(1) additional time. Standard amortisation
arguments imply that the reduction algorithm runs in <span
class="math inline">\(O(\ell)\)</span> time.</p>
<p>Thus, the overall running time of Dehn’s algorithm, starting with an
arbitrary surface map <span class="math inline">\(\Sigma\)</span> with
complexity <span class="math inline">\(n\)</span>, is <span
class="math inline">\(O(n + \ell)\)</span>, with no hidden dependence on
the surface genus.</p>
<h2 data-number="28.8" id="references-18"><span
class="header-section-number">28.8</span> References</h2>
<ol type="1">
<li><p>Max Dehn. <a href="https://doi.org/10.1007/BF01456932">Über
unendliche diskontinuierliche Gruppen</a>. <em>Math. Ann.</em>
71(1):116–144, 1911.</p></li>
<li><p>Max Dehn. <a
href="http://doi.org/10.1007/BF01456725">Transformation der Kurven auf
zweiseitigen Flächen</a>. <em>Math. Ann.</em> 72(3):413–421,
1912.</p></li>
<li><p>Tamal K. Dey and Sumanta Guha. <a
href="http://doi.org/10.1006/jcss.1998.1619">Transforming curves on
surfaces</a>. <em>J. Comput. Syst. Sci.</em> 58:297–325, 1999.</p></li>
<li><p>Jeff Erickson and Kim Whittlesey. <a
href="http://doi.org/10.1137/1.9781611973105.118">Transforming curves on
surfaces redux</a>. <em>Proc. 24th Ann. ACM-SIAM Symp. Discrete
Algorithms</em>, 1646–1655, 2013.</p></li>
<li><p>Francis Lazarus and Julien Rivaud. <a
href="http://doi.org/10.1109/FOCS.2012.12">On the homotopy test on
surfaces</a>. <em>Proc. 53rd Ann. IEEE Symp. Found. Comput. Sci.</em>,
440–449, 2012. arXiv:<a
href="https://arxiv.org/abs/1110.4573">1110.4573</a>.</p></li>
</ol>
<h2 data-number="28.9" id="sir-not"><span
class="header-section-number">28.9</span> Sir Not</h2>
<ul>
<li>surfaces with boundary</li>
<li>projective plane, torus, and Klein bottle</li>
<li>testing free homotopy between cycles</li>
<li>isotopy testing for graph embeddings [Ladegaillerie 74] [Colin de
Verdière and De Mesmay 14]</li>
</ul>
<h1 data-number="29" id="systems-of-cycles-and-homologyalpha"><span
class="header-section-number">29</span> Systems of Cycles and
Homology<span class="math inline">\(^\alpha\)</span></h1>
<p><em>Homology</em> is a natural equivalence relation between cycles,
similar to but both simpler and coarser than homotopy; where homotopy
treats cycles as <em>sequences</em> of darts, homology treats cycles as
<em>sets of edges</em> (or more generally, <em>linear combinations</em>
of darts). Homology can be defined with respect to any “coefficient
ring”, but to keep the presentation simple, I’ll describe only the
simplest special case (<span
class="math inline">\(\mathbb{Z}_2\)</span>-homology) in this section,
and return to a slightly more complicated special case (<span
class="math inline">\(\mathbb{R}\)</span>-homology) in a later note.</p>
<h2 data-number="29.1" id="cycles-and-boundaries"><span
class="header-section-number">29.1</span> Cycles and Boundaries</h2>
<p>Fix a surface map <span class="math inline">\(\Sigma =
(V,E,F)\)</span> with Euler genus <span
class="math inline">\(\bar{g}\)</span>.</p>
<p><span class="math inline">\(\mathbb{Z}_2\)</span>-homology is an
equivalence relation between certain <em>subgraphs</em> of <span
class="math inline">\(\Sigma\)</span>, formally represented as subsets
of <span class="math inline">\(E\)</span>.</p>
<p>An <em>even subgraph</em> of <span
class="math inline">\(\Sigma\)</span> is a subgraph <span
class="math inline">\(H\)</span> such that <span
class="math inline">\(\deg_H(v)\)</span> is even for every vertex <span
class="math inline">\(v\in V(\Sigma)\)</span>. The empty subgraph is an
even subgraph, as is every simple cycle. Every even subgraph is the
union (or symmetric difference) of simple edge-disjoint cycles.</p>
<p>For every edge <span class="math inline">\(e\not\in T\)</span>, let
<span class="math inline">\(\textsf{cycle}_T(e)\)</span> denote the
unique simple undirected cycle in the graph <span
class="math inline">\(T+e\)</span>; we call <span
class="math inline">\(\textsf{cycle}_T(e)\)</span> a <em>fundamental
cycle</em> with respect to <span class="math inline">\(T\)</span>. Let
<span class="math inline">\(\mathcal{C} = \{ \textsf{cycle}_T(e) \mid
e\in L \}\)</span>. The set <span
class="math inline">\(\mathcal{C}\)</span> is called a <em>system of
cycles</em> for the map <span class="math inline">\(\Sigma\)</span>.</p>
<p><strong>Fundamental Cycle Lemma:</strong> <em>Let <span
class="math inline">\(T\)</span> be an arbitrary spanning tree of an
arbitrary graph <span class="math inline">\(G\)</span> (sic). For every
even subgraph <span class="math inline">\(H\)</span> of <span
class="math inline">\(G\)</span>, we have <span class="math display">\[H
= \bigoplus_{e\in H\setminus T} \textsf{cycle}_T(e).\]</span> Thus, even
subgraphs are symmetric differences of fundamental cycles.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(H\)</span> be an arbitrary even subgraph
of <span class="math inline">\(G\)</span>, and let <span
class="math inline">\(H’ = \bigoplus_{e\in H\setminus T}
\textsf{cycle}_T(e)\)</span>. The symmetric difference of any two even
subgraphs is even, so <span class="math inline">\(H\oplus H’\)</span> is
an even subgraph and therefore the union of edge-disjoint cycles. On the
other hand, <span class="math inline">\(H\oplus H’\)</span> is a
subgraph of <span class="math inline">\(T\)</span> and therefore
acyclic. We conclude that <span class="math inline">\(H\oplus
H’\)</span> is empty, or equivalently, <span class="math inline">\(H =
H’\)</span>. <span class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p>Mnemonically, any even subgraph can be <em>named</em> by listing its
edges in <span class="math inline">\(C\cup L\)</span>.</p>
<p>Let <span class="math inline">\(Z\)</span> be a subset of the faces
of <span class="math inline">\(\Sigma\)</span>. The <em>boundary</em> of
<span class="math inline">\(Z\)</span>, denoted <span
class="math inline">\(\partial Z\)</span>, is the subgraph of <span
class="math inline">\(\Sigma\)</span> containing every edge that is
incident to both a face in <span class="math inline">\(Z\)</span> and a
face in <span class="math inline">\(F\setminus Z\)</span>. A
<em>boundary subgraph</em> is any subgraph that is the boundary of a
subset of faces. Every boundary subgraph is an even subgraph.
Conversely, if <span class="math inline">\(\Sigma\)</span> is a planar
map, the Jordan curve theorem implies that every even subgraph is a
boundary subgraph, but this equivalence does not extend to more complex
surfaces.</p>
<p><strong>Fundamental Boundary Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. For every boundary subgraph <span
class="math inline">\(B\)</span> of <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math display">\[B = \bigoplus_{e\in B\cap C}
\textsf{bdry}_C(e).\]</span> Thus, boundary subgraphs are symmetric
differences of fundamental boundaries.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
We mirror the proof of the Fundamental Cycle lemma. Let <span
class="math inline">\(B\)</span> be any boundary subgraph, and let <span
class="math inline">\(B’ = \bigoplus_{e\in B\cap C}
\textsf{bdry}_C(e)\)</span>. The boundary space is closed under
symmetric difference, so <span class="math inline">\(B’\oplus B\)</span>
is a boundary subgraph. On the other hand, <span
class="math inline">\(B\oplus B’\)</span> has no edges in <span
class="math inline">\(C\)</span>, so <span class="math inline">\(B\oplus
B’\)</span> is a subgraph of the cut graph <span
class="math inline">\(T\cup L\)</span>. We conclude that <span
class="math inline">\(B\oplus B’\)</span> is empty, or equivalently,
<span class="math inline">\(B = B’\)</span>. <span
class="math inline">\(\qquad\square\)</span>.
</dd>
</dl>
<p>Mnemonically, any boundary subgraph can be <em>named</em> by listing
its edges in <span class="math inline">\(C\)</span>.</p>
<h2 data-number="29.2" id="homology"><span
class="header-section-number">29.2</span> Homology</h2>
<p>Finally, two subgraphs <span class="math inline">\(A\)</span> and
<span class="math inline">\(B\)</span> of <span
class="math inline">\(\Sigma\)</span> are <em>(<span
class="math inline">\(\mathbb{Z}_2\)</span>)-homologous</em> if their
symmetric difference <span class="math inline">\(A\oplus B\)</span> is a
boundary subgraph of <span class="math inline">\(\Sigma\)</span>. For
example, every boundary subgraph is homologous with the empty subgraph,
which is why boundary subgraphs are also called <em>null-homologous</em>
subgraphs. Straightforward definition-chasing implies that (<span
class="math inline">\(\mathbb{Z}_2\)</span>)-homology is an equivalence
relation, whose equivalence classes are obviously called <em>(<span
class="math inline">\(\mathbb{Z}_2\)</span>)-homology classes</em>. We
usually omit “<span class="math inline">\(\mathbb{Z}_2\)</span>” if the
type of homology is clear from context.</p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. The only boundary subgraph of the
cut graph <span class="math inline">\(T\cup L\)</span> is the empty
graph.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(H\)</span> be a non-empty cut graph in
<span class="math inline">\(\Sigma\)</span>; <span
class="math inline">\(H\)</span> must be the boundary of a non-empty
proper subset <span class="math inline">\(Z\)</span> of the faces in
<span class="math inline">\(\Sigma\)</span>. Consider the fundamental
domain <span class="math inline">\(\Delta = \Sigma
\mathbin{\backslash\!\!\backslash} (T\cup L)\)</span>. Because both
<span class="math inline">\(Z\)</span> and its complement are non-empty,
some interior edge <span class="math inline">\(e\)</span> of <span
class="math inline">\(\Delta\)</span> separates a face in <span
class="math inline">\(Z\)</span> from a face not in <span
class="math inline">\(Z\)</span>. But the interior edges of <span
class="math inline">\(\Delta\)</span> are precisely the edges in <span
class="math inline">\(C\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. Every even subgraph in <span
class="math inline">\(\Sigma\)</span> is homologous with an even
subgraph of the cut graph <span class="math inline">\(T\cup
L\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
It suffices to prove that every edge <span class="math inline">\(e\in
C\)</span> is homologous with a subgraph of <span
class="math inline">\(T\cup L\)</span> that has even degree everywhere
except the endpoints of <span class="math inline">\(e\)</span>.
</dd>
<dd>
<p>Consider the fundamental domain <span class="math inline">\(\Delta =
\Sigma \mathbin{\backslash\!\!\backslash} (T\cup L)\)</span>. Every edge
<span class="math inline">\(e \in C\)</span> appears in <span
class="math inline">\(\Delta\)</span> as a boundary-to-boundary chord,
which partitions the faces of <span
class="math inline">\(\Delta\)</span> into two disjoint subsets <span
class="math inline">\(Y\sqcup Z\)</span>. (Recall that no edge in <span
class="math inline">\(C\)</span> can be an isthmus!) Every face of <span
class="math inline">\(\Delta\)</span> is a face of the original map
<span class="math inline">\(\Sigma\)</span> and vice versa; let <span
class="math inline">\(\beta\)</span> denote the boundary of <span
class="math inline">\(Y\)</span> (or equivalently, the boundary of <span
class="math inline">\(Z\)</span>) in <span
class="math inline">\(\Sigma\)</span>. Because <span
class="math inline">\(\beta\)</span> is a boundary subgraph in <span
class="math inline">\(\Sigma\)</span>, <span
class="math inline">\(e\)</span> is homologous with <span
class="math inline">\(\beta\oplus e\)</span>. Finally, every edge in
<span class="math inline">\(\beta \oplus e\)</span> is an edge in the
cut graph <span class="math inline">\(T\cup L\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. Every subgraph of <span
class="math inline">\(\Sigma\)</span> is homologous with a symmetric
difference of cycles in <span
class="math inline">\(\mathcal{C}\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
By the previous lemma, it suffices to consider only even subgraphs of
the cur graph <span class="math inline">\(T\cup L\)</span>. Every even
subgraph of <span class="math inline">\(T\cup L\)</span> is the
symmetric difference of simple cycles in <span
class="math inline">\(T\cup L\)</span>. The simple cycles in <span
class="math inline">\(T\cup L\)</span> are precisely the cycles in <span
class="math inline">\(\mathcal{C}\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Homology Basis Theorem:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. For every even subgraph <span
class="math inline">\(H\)</span> of <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math display">\[
    H =
    \left(\bigoplus_{i\in \smash{I(H)}} \textsf{cycle}_T(\ell_i)\right)
        \oplus
    \left(\bigoplus_{e\in H\cap C} \textsf{bdry}_T(e)\right)
\]</span> for some subset <span class="math inline">\(I(H) \subseteq
\{1,2,\dots,\bar{g}\}\)</span>. Thus, every even subgraph is homologous
with the symmetric difference of a <strong>unique</strong> subset of
cycles in <span class="math inline">\(\mathcal{C}\)</span>, which is
nonempty if and only if <span class="math inline">\(H\)</span> is a
boundary subgraph.</em></p>
<p>The Homology Basis Theorem immediately implies an algorithm to decide
if two even subgraphs <span class="math inline">\(H\)</span> and <span
class="math inline">\(H’\)</span> are homologous: Compute their
canonical decompositions into fundamental cycles and boundaries, with
respect to the same tree-cotree decomposition, and then compare the
index sets <span class="math inline">\(I(H)\)</span> and <span
class="math inline">\(I’(H)\)</span>. A careful implementation of this
algorithm runs in <span class="math inline">\(O(\bar{g} n)\)</span>
time; details are left as an exercise (because we’re about to describe
simpler algorithms).</p>
<h2 data-number="29.3" id="relax-its-just-linear-algebra"><span
class="header-section-number">29.3</span> Relax, it’s just linear
algebra!</h2>
<p>Unlike our earlier characterization of homotopy, our characterization
of homology is unique; every even subgraph is homologous with the
symmetric difference of <em>exactly one</em> subset of cycles in <span
class="math inline">\(\mathcal{C}\)</span>. The easiest way to prove
this fact is to observe that subgraphs, even subgraphs, boundary
subgraphs, and homology classes all define vector spaces over the finite
field <span class="math inline">\(\mathbb{Z}_2 = (\{0,1\}, \oplus,
\cdot)\)</span>. In particular, homology can be viewed as a linear map
between vector spaces.</p>
<p>Subgraphs (subsets of <span class="math inline">\(E\)</span>)
comprise the <strong><em>edge space</em></strong> (or <em>first chain
space</em>) <span class="math inline">\(C_1(\Sigma) =
\mathbb{Z}_2^{|E|}\)</span>. The (indicator vectors of) individual edges
in <span class="math inline">\(\Sigma\)</span> comprise a basis of the
edge space.</p>
<p>Even subgraphs of <span class="math inline">\(\Sigma\)</span>
comprise a subspace of <span class="math inline">\(C_1(\Sigma)\)</span>
called the <strong><em>cycle space</em></strong> <span
class="math inline">\(Z_1(\Sigma)\)</span>. The Fundamental Cycle Lemma
implies that the fundamental cycles <span
class="math inline">\(\textsf{cycle}_T(e)\)</span>, for all <span
class="math inline">\(e\not\in T\)</span>, define a basis for the cycle
space. The number of fundamental cycles is equal to the number of edges
not in <span class="math inline">\(T\)</span>, which is <span
class="math inline">\(|E|-(|V|-1)\)</span>. Thus, <span
class="math inline">\(Z_1(\Sigma) = \mathbb{Z}_2^{|E| - |V| +
1}\)</span>.</p>
<p>Boundary subgraphs of <span class="math inline">\(\Sigma\)</span>
comprise a subspace of <span class="math inline">\(Z_1(\Sigma)\)</span>
called the <strong><em>boundary space</em></strong> <span
class="math inline">\(B_1(\Sigma)\)</span>. The Fundamental Boundary
lemma implies that the fundamental boundaries <span
class="math inline">\(\textsf{bdry}_C(e)\)</span>, for all <span
class="math inline">\(e\in C\)</span>, define a basis for the boundary
space. The number of fundamental boundaries is equal to the number of
edges of <span class="math inline">\(C\)</span>, which is <span
class="math inline">\(|F|-1\)</span>. Thus, <span
class="math inline">\(B_1(\Sigma) = \mathbb{Z}_2^{|F| - 1}\)</span>.</p>
<p>Finally, the set of homology classes of even subgraphs of <span
class="math inline">\(\Sigma\)</span> comprise the <strong><em>(first)
homology space</em></strong>, which is the quotient space <span
class="math display">\[
    \begin{aligned}
    H_1(\Sigma)
    &amp;~:=~ Z_1(\Sigma) / B_1(\Sigma) \\
    &amp;~=~ \mathbb{Z}_2^{|E| - |V| + 1} \big/ \mathbb{Z}_2^{|F| - 1}
\\
    &amp;~\cong~ \mathbb{Z}_2^{|E| - (|V|-1) - (|F|-1)} \\
    &amp;~=~ \mathbb{Z}_2^{|E| - |T| - |C|}
    ~=~ \mathbb{Z}_2^{|L|}
    ~=~ \mathbb{Z}_2^{\bar{g}}.
    \end{aligned}
\]</span> (Hey look, we proved Euler’s formula again!) The Homology
Basis Theorem implies that homology classes of fundamental cycles <span
class="math inline">\(\textsf{cycle}_T(e)\)</span>, for all <span
class="math inline">\(e\in L\)</span>, define a basis for the homology
space. In particular, there are exactly <span
class="math inline">\(2^{\bar{g}}\)</span> distinct homology
classes.</p>
<h2 data-number="29.4" id="crossing-numbers"><span
class="header-section-number">29.4</span> Crossing Numbers</h2>
<p>Another way to characterize the homology class of an even subgraph
<span class="math inline">\(H\)</span> is to determine which cycles in a
system of cycles <em>cross</em> <span class="math inline">\(H\)</span>.
The definition of “cross” is rather subtle, but mirrors the intuition of
transverse intersection.</p>
<p>Consider two distinct simple cycles <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>, and let <span
class="math inline">\(\pi\)</span> be one of the components of the
intersection <span class="math inline">\(\alpha\cap\beta\)</span>.
(Because <span class="math inline">\(\alpha\ne\beta\)</span>, the
intersection <span class="math inline">\(\pi\)</span> must be either a
single vertex of a common subpath.) We call <span
class="math inline">\(\pi\)</span> a <em>crossing</em> between <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> (or we say that <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> <em>cross</em> at <span
class="math inline">\(\pi\)</span>) if, after contracting the path <span
class="math inline">\(\pi\)</span> to a point <span
class="math inline">\(p\)</span>, the contracted curves <span
class="math inline">\(\alpha / \pi\)</span> and <span
class="math inline">\(\beta / \pi\)</span> intersect transversely at
<span class="math inline">\(p\)</span>.</p>
<p>Equivalently, <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> cross at <span
class="math inline">\(\pi\)</span> if, no matter how we perturb the two
curves within a small neighborhood of <span
class="math inline">\(\pi\)</span>, the two perturbed curves <span
class="math inline">\(\tilde\alpha\)</span> and <span
class="math inline">\(\tilde\beta\)</span> intersect. By convention, no
two-sided cycle crosses itself (because we can perturb two copies of a
two-sided cycle so that they are disjoint), but every one-sided cycle
crosses itself once (because we cannot).</p>
<p>For any simple cycles <span class="math inline">\(\alpha\)</span> and
<span class="math inline">\(\beta\)</span>, the <em>crossing number</em>
<span class="math inline">\(\mathsf{cr}(\alpha,\beta)\)</span> is the
number of crossings between <span class="math inline">\(\alpha\)</span>
and <span class="math inline">\(\beta\)</span>, modulo 2. In particular,
<span class="math inline">\(\textsf{cr}(\alpha, \alpha) = 0\)</span> if
for every two-sided cycle <span class="math inline">\(\alpha\)</span>,
and <span class="math inline">\(\textsf{cr}(\beta, \beta) = 1\)</span>
for every one-sided cycle <span
class="math inline">\(\beta\)</span>.</p>
<p>We can extend this definition of crossing number to even subgraphs by
linearity: <span class="math inline">\(\textsf{cr}(\alpha\oplus\beta,
\gamma) = \textsf{cr}(\alpha,\gamma) \oplus
\textsf{cr}(\beta,\gamma)\)</span>. Although one can express any even
subgraph as a symmetric difference of cycles in many different ways,
crossing numbers are the same for every such decomposition.</p>
<p>For any face <span class="math inline">\(f\)</span> and any cycle
<span class="math inline">\(\gamma\)</span>, we have <span
class="math inline">\(\textsf{cr}(\partial f, \gamma) = 0\)</span>. It
follows by linearity that if either <span
class="math inline">\(\gamma\)</span> or <span
class="math inline">\(\delta\)</span> is a boundary subgraph, then <span
class="math inline">\(\textsf{cr}(\delta,\gamma) = 0\)</span>. More
generally, it follows that crossing numbers are a <em>homology
invariant</em>: if <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> are homologous even subgraphs, then
<span class="math inline">\(\textsf{cr}(\alpha, \gamma) =
\textsf{cr}(\beta, \gamma)\)</span> for every cycle <span
class="math inline">\(\gamma\)</span>, because <span
class="math inline">\(\alpha\oplus\beta\)</span> is the symmetric
difference of face boundaries.</p>
<p><strong>Lemma:</strong> <em>For any even subgraphs <span
class="math inline">\(H\)</span> and <span
class="math inline">\(H’\)</span>, if <span
class="math inline">\(\textsf{cr}(H,H’) = 1\)</span>, then neither <span
class="math inline">\(H\)</span> nor <span
class="math inline">\(H’\)</span> is a boundary subgraph.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
If (say) <span class="math inline">\(H\)</span> is a boundary subgraph,
then <span class="math inline">\(H\)</span> is the symmetric difference
of face boundaries, and therefore <span
class="math inline">\(\textsf{cr}(H, H’) = 0\)</span> by linearity.
<span class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\sigma\)</span> be a simple cycle and let <span
class="math inline">\(\mathcal{C} = \{ \gamma_1, \gamma_2, \dots,
\gamma_{\bar{g}} \}\)</span> be a system of cycles in a surface map
<span class="math inline">\(\Sigma\)</span>. Then <span
class="math inline">\(\sigma\)</span> is boundary cycle if and only if
<span class="math inline">\(\mathsf{cr}(\sigma, \gamma_i) = 0\)</span>
for every cycle <span class="math inline">\(\gamma_i\in
\mathcal{C}\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
If <span class="math inline">\(\sigma\)</span> is a boundary cycle,
homology invariance immediately implies <span
class="math inline">\(\textsf{cr}(\sigma, \gamma_i) =
\textsf{cr}(\varnothing, \gamma_i) = 0\)</span>.
</dd>
<dd>
<p>Suppose on the other hand that <span
class="math inline">\(\sigma\)</span> is not a boundary cycle. Then by
definition the sliced surface <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span> is connected. Let
<span class="math inline">\(v\)</span> be a vertex of <span
class="math inline">\(\sigma\)</span>, and let <span
class="math inline">\(\pi\)</span> be any path from <span
class="math inline">\(v^+\)</span> to <span
class="math inline">\(v^-\)</span> in <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span>. This path <span
class="math inline">\(\pi\)</span> appears in <span
class="math inline">\(\Sigma\)</span> as a closed walk that crosses
<span class="math inline">\(\sigma\)</span> exactly once, so <span
class="math inline">\(\textsf{cr}(\pi,\sigma) = 1\)</span>. It follows
from the previous lemma that <span class="math inline">\(\pi\)</span> is
not a boundary cycle. Thus, by the Homology Basis theorem, <span
class="math inline">\(\pi\)</span> is homologous with <span
class="math inline">\(\bigoplus_{i\in I} \gamma_i\)</span> for some
non-empty subset <span class="math inline">\(I \subseteq \{
1,2,\dots,\bar{g} \}\)</span>. Finally, homology invariance implies
<span class="math inline">\(\textsf{cr}(\pi, \sigma) = \bigoplus_{i\in
I} \textsf{cr}(\gamma_i, \sigma) = 1\)</span>, so we must have <span
class="math inline">\(\textsf{cr}(\gamma_i, \sigma) = 1\)</span> for an
odd number of indices <span class="math inline">\(i\in I\)</span>, and
therefore for at least one such index. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Corollary:</strong> <em>Let <span
class="math inline">\(\mathcal{C}\)</span> be a system of cycles in a
surface map <span class="math inline">\(\Sigma\)</span>. An even
subgraph <span class="math inline">\(H\)</span> of <span
class="math inline">\(\Sigma\)</span> is a boundary subgraph if and only
if <span class="math inline">\(\mathsf{cr}(H, \gamma_i) = 0\)</span> for
every cycle <span class="math inline">\(\gamma_i\in
\mathcal{C}\)</span>. Two even subgraphs <span
class="math inline">\(H\)</span> and <span
class="math inline">\(H’\)</span> of <span
class="math inline">\(\Sigma\)</span> are homologous if and only if
<span class="math inline">\(\mathsf{cr}(H, \gamma_i) = \mathsf{cr}(H’,
\gamma_i)\)</span> for every cycle <span
class="math inline">\(\gamma_i\in \mathcal{C}\)</span>.</em></p>
<h2 data-number="29.5" id="systems-of-cocycles-and-cohomology"><span
class="header-section-number">29.5</span> Systems of Cocycles and
Cohomology</h2>
<p>Cohomology is the dual of homology. While homology is an equivalence
relation between subgraphs of maps, cohomology is an equivalence
relation between subgraphs of <em>dual</em> maps. In fact, it’s the
<em>dual</em> equivalence relation between subgraphs of dual maps. Two
subgraphs <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> of <span
class="math inline">\(\Sigma\)</span> are <em>cohomologous</em> if and
only if the corresponding dual subgraphs <span
class="math inline">\(A^*\)</span> and <span
class="math inline">\(B^*\)</span> of <span
class="math inline">\(\Sigma^*\)</span> are homologous.</p>
<p>I’ll adopt the convenient convention of adding the prefix “co” to
indicate the dual of a structure in the dual map. Mnemonically, a
cosnarfle in <span class="math inline">\(\Sigma\)</span> is the dual of
snarfle in <span class="math inline">\(\Sigma^*\)</span>.</p>
<ul>
<li>We’ve already defined a <em>spanning co-tree</em> of <span
class="math inline">\(\Sigma\)</span> is a subset of edges whose
corresponding dual edges comprise a spanning tree of <span
class="math inline">\(\Sigma^*\)</span>. Less formally, a spanning
cotree of <span class="math inline">\(\Sigma\)</span> is the dual of a
spanning tree of <span class="math inline">\(\Sigma^*\)</span>.</li>
<li>A <em>cocycle</em> in <span class="math inline">\(\Sigma\)</span> is
the dual of a cycle in <span class="math inline">\(\Sigma^*\)</span>.
(In planar graphs, every cocycle is a minimal edge cut, but that
equivalence does not extend to more complex surfaces.)</li>
<li>A <em>co-even subgraph</em> of <span
class="math inline">\(\Sigma\)</span> is the dual of an even subgraph of
<span class="math inline">\(\Sigma^*\)</span>. That is, a subgraph <span
class="math inline">\(H\)</span> of <span
class="math inline">\(\Sigma\)</span> is co-even if every face of <span
class="math inline">\(\Sigma\)</span> has an even number of incidences
with <span class="math inline">\(H\)</span>. No edge in a co-even
subgraph is a loop, because loops are co-isthmuses.</li>
<li>The <em>coboundary</em> if a subset <span
class="math inline">\(X\)</span> of vertices of <span
class="math inline">\(\Sigma\)</span>, denoted <span
class="math inline">\(\delta X\)</span>, is the dual of the boundary of
the corresponding subset <span class="math inline">\(X^*\)</span> of
faces of <span class="math inline">\(\Sigma^*\)</span> . That is, <span
class="math inline">\(\delta X\)</span> is the subset of edges with one
endpoint in <span class="math inline">\(X\)</span> and one endpoint not
in <span class="math inline">\(X\)</span>. A <em>coboundary</em>
subgraph is the coboundary of some subset of vertices. Every coboundary
subgraph is co-even.</li>
<li>Finally, two co-even subgraphs are cohomologous if their symmetric
difference is a coboundary subgraph.</li>
</ul>
<p>As usual, fix a tree-cotree decomposition <span
class="math inline">\((T,L,C)\)</span> of a surface map <span
class="math inline">\(\Sigma\)</span>. For every edge <span
class="math inline">\(e\in T\cup L\)</span>, let <span
class="math inline">\(\textsf{cocycle}_C(e)\)</span> denote the subgraph
of <span class="math inline">\(\Sigma\)</span> dual to the fundamental
cycle <span class="math inline">\(\textsf{cycle}_{c^*}(e^*)\)</span> in
the dual map <span class="math inline">\(\Sigma^*\)</span>. Finally, let
<span class="math inline">\(\mathcal{K} = \{ \textsf{cocycle}_C(e) \mid
e\in T \}\)</span>. The following lemmas follow immediately from our
earlier characterization of homology.</p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. Every co-even subgraph of <span
class="math inline">\(\Sigma\)</span> a symmetric difference of
fundamental cocycles <span
class="math inline">\(\textsf{cocycle}_C(e)\)</span> where <span
class="math inline">\(e\not\in C\)</span>.</em></p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. Every co-even subgraph of <span
class="math inline">\(\Sigma\)</span> is cohomologous with a co-even
subgraph of the cocut graph <span class="math inline">\(C\cup
L\)</span>.</em></p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\((T,L,C)\)</span> be an arbitrary tree-cotree
decomposition of a surface map <span
class="math inline">\(\Sigma\)</span>. Every co-even subgraph of <span
class="math inline">\(\Sigma\)</span> is cohomologous with a symmetric
difference of cocycles in <span
class="math inline">\(\mathcal{K}\)</span>.</em></p>
<h2 data-number="29.6" id="homology-signatures"><span
class="header-section-number">29.6</span> Homology Signatures</h2>
<p>More importantly, however, cohomology offers us a
<strong>CO</strong>nvenient method to efficiently
<strong>CO</strong>mpute homology classes of even subgraphs of the
primal map <span class="math inline">\(\Sigma\)</span>, by assigning a
<strong>CO</strong>ordinate system to the first homology space. Index
the leftover edges in <span class="math inline">\(L\)</span> as <span
class="math inline">\(\ell_1, \ell_2, \dots, \ell_{\bar{g}}\)</span>.<a
href="#fn68" class="footnote-ref" id="fnref68"
role="doc-noteref"><sup>68</sup></a> For every edge <span
class="math inline">\(e\)</span> in <span
class="math inline">\(\Sigma\)</span>, the <em>homology signature <span
class="math inline">\([e]\)</span></em> is the <span
class="math inline">\(\bar{g}\)</span>-bit vector indicating which
cocycles in <span class="math inline">\(\mathcal{K}\)</span> contain
<span class="math inline">\(e\)</span>. Specifically: <span
class="math display">\[
    [e]_i = 1 \iff e \in  \textsf{cocycle}_C(\ell_i).
\]</span> Finally, the homology signature <span
class="math inline">\([H]\)</span> of any subgraph <span
class="math inline">\(H\)</span> is the bitwise exclusive-or of the
homology signatures of its edges.</p>
<p>The function <span class="math inline">\(H \mapsto [H]\)</span> is a
<em>linear</em> function from the cycle space <span
class="math inline">\(Z_1(\Sigma)\)</span> to the vector space <span
class="math inline">\(\mathbb{Z}_2^{\bar{g}}\)</span> of homology
signatures. In particular:</p>
<p><strong>Linearity Lemma:</strong> <em>For any two even subgraphs
<span class="math inline">\(H\)</span> and <span
class="math inline">\(H’\)</span> of <span
class="math inline">\(\Sigma\)</span>, we have <span
class="math inline">\([H \oplus H’] = [H]\oplus [H’]\)</span>.</em></p>
<p><strong>Basis Lemma:</strong> <em>For all indices <span
class="math inline">\(i\)</span> and <span
class="math inline">\(j\)</span>, we have <span
class="math inline">\([\textsf{cycle}_T(\ell_i)]_j = 1\)</span> if and
only if <span class="math inline">\(i=j\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The only edge in any fundamental <span
class="math inline">\(\textsf{cycle}_T(e)\)</span> that is <em>not</em>
in <span class="math inline">\(T\)</span> is the determining edge <span
class="math inline">\(e\)</span>. Similarly, the only edge in any
fundamental <span class="math inline">\(\textsf{cocycle}_C(e)\)</span>
that is <em>not</em> in <span class="math inline">\(C\)</span> is the
determining edge <span class="math inline">\(e\)</span>. Thus, <span
class="math inline">\(\textsf{cycle}_T(ell_i) \cap
\textsf{cocycle}_C(\ell_j) = \varnothing\)</span> whenever <span
class="math inline">\(i\ne j\)</span>, and <span
class="math inline">\(\textsf{cycle}_T(\ell_i) \cap
\textsf{cocycle}_C(\ell_i) = \ell_i\)</span> for every index <span
class="math inline">\(i\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Theorem:</strong> <em>Two even subgraphs <span
class="math inline">\(H\)</span> and <span
class="math inline">\(H’\)</span> of <span
class="math inline">\(\Sigma\)</span> are homologous if and only if
<span class="math inline">\([H] = [H’]\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
By the Linearity Lemma, it suffices to prove that an even subgraph <span
class="math inline">\(H\)</span> is a boundary subgraph if and only if
<span class="math inline">\([H] = 0\)</span>.
</dd>
<dd>
<p>Let <span class="math inline">\(f\)</span> be any face of <span
class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(\lambda\)</span> be any cocycle in <span
class="math inline">\(\Sigma\)</span>. The boundary of <span
class="math inline">\(f\)</span> either contains no edges of <span
class="math inline">\(\lambda\)</span> or exactly two edges of <span
class="math inline">\(\lambda\)</span>, depending on whether the dual
cycle <span class="math inline">\(\lambda^*\)</span> contains the dual
vertex <span class="math inline">\(f^*\)</span>. It follows that <span
class="math inline">\([\partial f] = 0\)</span> for every face <span
class="math inline">\(f\)</span>. The Linearity Lemma implies that <span
class="math inline">\([H] = 0\)</span> for every boundary subgraph <span
class="math inline">\(H\)</span>.</p>
</dd>
<dd>
<p>Conversely, suppose <span class="math inline">\(H\)</span> is not
null-homologous. Then we can write <span class="math display">\[
H =
\left(\bigoplus_{i\in I} \textsf{cycle}_T(\ell_i)\right)
    \oplus
\left(\bigoplus_{e\in H\cap C} \textsf{bdry}_T(e)\right)
\]</span> for some nonempty subset <span
class="math inline">\(I\subseteq\{1, 2, \dots, \bar{g}\}\)</span>. The
Linearity and Basis lemmas imply that <span class="math display">\[
[H]
=
\left(\bigoplus_{i\in I} [\textsf{cycle}_T(\ell_i)]\right)
\]</span> and therefore <span class="math inline">\([H]_i = 1\)</span>
if and only if <span class="math inline">\(i\in I\)</span>. Because
<span class="math inline">\(I\)</span> is non-empty, <span
class="math inline">\([H]\ne 0\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="29.7" id="separating-cycles"><span
class="header-section-number">29.7</span> Separating Cycles</h2>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\gamma\)</span> be a simple cycle in a surface map
<span class="math inline">\(\Sigma\)</span>. The sliced map <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
\gamma\)</span> is disconnected if and only if <span
class="math inline">\([\gamma]=0\)</span></em></p>
<h2 data-number="29.8" id="references-19"><span
class="header-section-number">29.8</span> References</h2>
<h2 data-number="29.9" id="aptly-named-sir-3"><span
class="header-section-number">29.9</span> Aptly Named Sir</h2>
<ul>
<li>Pants decompositions (except possibly in passing)</li>
</ul>
<!-- see “shortest-noncontractible.tex” -->
<h1 data-number="30" id="shortest-interesting-cyclesalpha"><span
class="header-section-number">30</span> Shortest Interesting Cycles<span
class="math inline">\(^\alpha\)</span></h1>
<p>In this lecture, I’ll describe algorithms to find the shortest cycle
in a surface map that is topologically interesting. I’ll specifically
consider two different definitions of “interesting”:</p>
<ul>
<li>A cycle is <em>noncontractible</em> if it cannot be continuously
deformed to a single point; noncontractible cycles are
<em>homotopically</em> nontrivial.</li>
<li>A cycle is <em>nonseparating</em> if slicing along the cycle does
not disconnect the surface; nonseparating cycles are
<em>homologically</em> nontrivial.</li>
</ul>
<p>The input to our algorithms is a surface map <span
class="math inline">\(\Sigma\)</span> with positively weighted edges.<a
href="#fn69" class="footnote-ref" id="fnref69"
role="doc-noteref"><sup>69</sup></a> I will assume throughout this
presentation that there is a unique shortest path between any pair of
vertices; this assumption can be enforced with standard perturbation
schemes. Crucially, we will treat the underlying graph of <span
class="math inline">\(\Sigma\)</span> as a continuous topologically
space; any edge with weight <span class="math inline">\(\ell\)</span> is
isometric to the interval <span class="math inline">\([0,\ell]\)</span>
on the real line. Thus, we can reasonably consider shortest paths
between points that lie in the interior of edges.</p>
<h2 data-number="30.1"
id="properties-of-shortest-nontrivial-cycles"><span
class="header-section-number">30.1</span> Properties of Shortest
Nontrivial Cycles</h2>
<p>It is unfortunately common for papers on surface-map algorithms to
use the word “cycle” in two different senses. For topologists, a
<em>cycle</em> is the continuous image of the circle <span
class="math inline">\(S^1\)</span>, but for graph theorists, a
<em>cycle</em> is a closed walk with no repeated vertices. That is,
graph theorists assume that cycles are <em>simple</em> (or
<em>injective</em>), but topologists do not. Fortunately for us,
shortest nontrivial <em>cycles</em> are the same for both tribes.</p>
<p><strong>Lemma:</strong> <em>The shortest noncontractible (or
nonseparating) closed walk in a positively edge-weighted surface map is
a simple cycle.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
For the sake of argument, suppose the shortest noncontractible closed
walk <span class="math inline">\(W\)</span> is <em>not</em> simple. We
can decompose <span class="math inline">\(W\)</span> into two closed
walks <span class="math inline">\(X\cdot Y\)</span> at any vertex that
<span class="math inline">\(W\)</span> visits more than once. <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are both shorter than <span
class="math inline">\(W\)</span>, so they must both be contractible. The
concatenation of two contractible closed walks is contractible. So <span
class="math inline">\(W\)</span> is contractible, contradicting its
definition. Essentially the same argument applies to the shortest
nonseparating closed walk. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>3-Path Condition (Carsten Thomassen):</strong> <em>Let <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> be two points (either at vertices or in
edge interiors) in a surface map <span
class="math inline">\(\Sigma\)</span>, and let <span
class="math inline">\(\alpha, \beta, \gamma\)</span> be paths in <span
class="math inline">\(\Sigma\)</span> from <span
class="math inline">\(x\)</span> to <span
class="math inline">\(y\)</span>. If the cycles <span
class="math inline">\(\alpha\cdot\textsf{rev}(\beta)\)</span> and <span
class="math inline">\(\beta\cdot\textsf{rev}(\gamma)\)</span> are
contractible (resp. separating), then the cycle <span
class="math inline">\(\alpha\cdot\textsf{rev}(\gamma)\)</span> is also
contractible (resp. separating).</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
The concatenation of any two contractible closed walks is contractible.
</dd>
<dd>
The symmetric difference of any two separating cycles is separating.
<span class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Antipodality Condition (Carsten Thomassen):</strong> <em>Let
<span class="math inline">\(\sigma\)</span> be the shortest
noncontractible (resp. nonseparating) cycle in a surface map <span
class="math inline">\(\Sigma\)</span>. Any pair of antipodal points
partition <span class="math inline">\(\sigma\)</span> into two
equal-length shortest paths.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Fix a pair <span class="math inline">\(x\)</span> and <span
class="math inline">\(\bar{x}\)</span> of antipodal points in <span
class="math inline">\(\sigma\)</span>. These points clearly partition
<span class="math inline">\(\sigma\)</span> into two equal-length paths;
call these paths <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span>. Suppose <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> are <em>not</em> shortest paths,
and let <span class="math inline">\(\gamma\)</span> be a shortest path
from <span class="math inline">\(x\)</span> to <span
class="math inline">\(\bar{x}\)</span>. The cycles <span
class="math inline">\(\alpha\cdot\textsf{rev}(\gamma)\)</span> and <span
class="math inline">\(\beta\cdot\textsf{rev}(\gamma)\)</span> are both
shorter than <span class="math inline">\(\alpha\cdot\textsf{rev}(\beta)
= \sigma\)</span> and thus are contractible (resp. separating). But then
the 3-path property implies that <span
class="math inline">\(\sigma\)</span> is contractible (resp.
separating), contradicting its definition. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<p><strong>Crossing Condition:</strong> <em>Any shortest path crosses
the shortest noncontractible (resp. nonseparating) cycle at most
once.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\pi\)</span> be a shortest path and let
<span class="math inline">\(\sigma\)</span> be a simple noncontractible
(resp. separating) cycle, and suppose the intersection <span
class="math inline">\(\pi\cap\sigma\)</span> is disconnected. Then we
can decompose <span class="math inline">\(\pi\)</span> into three
subpaths <span
class="math inline">\(\pi^-\cdot\pi^\circ\cdot\pi^+\)</span>, where
<span class="math inline">\(\pi^\circ\)</span> starts and ends at
vertices of <span class="math inline">\(\sigma\)</span> but is otherwise
disjoint from <span class="math inline">\(\sigma\)</span>. Because <span
class="math inline">\(\pi\)</span> is a shortest path, its subpath <span
class="math inline">\(\pi^circ\)</span> is also a shortest path.
Similarly, we can decompose <span class="math inline">\(\sigma\)</span>
into two paths <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\beta\)</span> at the endpoints of <span
class="math inline">\(\pi^\circ\)</span>. The 3-path condition implies
that at least one of the cycles <span
class="math inline">\(\alpha\cdot\textsf{rev}(\pi^\circ)\)</span> and
<span class="math inline">\(\beta\cdot\textsf{rev}(\pi^\circ)\)</span>
is noncontractible (resp. nonseparating). Because vertex-to-vertex
shortest paths are unique, both of these cycles are shorter than <span
class="math inline">\(\sigma\)</span>. <span
class="math inline">\(\qquad\square\)</span>
</dd>
</dl>
<h2 data-number="30.2" id="a-polynomial-time-algorithm"><span
class="header-section-number">30.2</span> A polynomial-time
algorithm</h2>
<p>Thomassen’s 3-path condition implies the following algorithm to find
the shortest noncontractible cycle <span
class="math inline">\(\sigma\)</span>. The antipodality condition
implies that <span class="math inline">\(\sigma\)</span> must consist of
a shortest path from a vertex <span class="math inline">\(x\)</span> to
another vertex <span class="math inline">\(y\)</span>, the edge <span
class="math inline">\(yz\)</span>, and the shortest path from <span
class="math inline">\(z\)</span> back to <span
class="math inline">\(x\)</span>. (Uniqueness of vertex-to-vertex
shortest paths implies that the antipodal point <span
class="math inline">\(\bar{x}\)</span> lies in the interior of the edge
<span class="math inline">\(yz\)</span>.) There are only <span
class="math inline">\(O(n^2)\)</span> loops of this form. We compute the
distance between every pair of vertices in <span
class="math inline">\(O(n^2\log n)\)</span> time by running Dijkstra’s
algorithm <span class="math inline">\(n\)</span> times, after which we
can compute the length of each candidate cycle in <span
class="math inline">\(O(1)\)</span> time. Finally, for each candidate
loop <span class="math inline">\(\gamma\)</span>, we test whether <span
class="math inline">\(\gamma\)</span> is contractible in <span
class="math inline">\(O(n)\)</span> time, using Dehn’s algorithm.
Finally, we return the shortest candidate cycle that is
noncontractible.</p>
<p><strong>Theorem [Thomassen]:</strong> <em>Given any edge-weighted
surface map <span class="math inline">\(\Sigma\)</span> with complexity
<span class="math inline">\(n\)</span>, we can compute the shortest
noncontractible cycle in <span class="math inline">\(\Sigma\)</span> in
<span class="math inline">\(O(n^3)\)</span> time.</em></p>
<p>In fact, Dehn’s algorithm is overkill for testing the contractibility
of simple cycles. Instead we can rely on the classical lemma:</p>
<p><strong>Lemma [David Epstein<a href="#fn70" class="footnote-ref"
id="fnref70" role="doc-noteref"><sup>70</sup></a>]:</strong> <em>A
nontrivial simple cycle <span class="math inline">\(\sigma\)</span> on
any surface <span class="math inline">\(\mathcal{S}\)</span> is
contractible if and only if <span
class="math inline">\(\mathcal{S}\setminus \sigma\)</span> is
disconnected and at least one component is an open disk.</em></p>
<p>We can test whether a simple cycle <span
class="math inline">\(\sigma\)</span> is the boundary of a disk as
follows. First, we perform a whatever-first search in the dual map <span
class="math inline">\(\Sigma^*\)</span> to determine whether the sliced
map <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span> (or alternatively,
the contracted map <span class="math inline">\(\Sigma / \sigma\)</span>)
is connected. If <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span> is connected, then
<span class="math inline">\(\sigma\)</span> is noncontractible.
Otherwise, we compute the Euler characteristics and orientability of
both components in <span class="math inline">\(O(n)\)</span> time. If
either component is orientable with genus <span
class="math inline">\(1\)</span>, that component is a disk and <span
class="math inline">\(\sigma\)</span> is contractible; otherwise, <span
class="math inline">\(\sigma\)</span> is non-contractible.</p>
<p>We can find the shortest <em>nonseparating</em> cycle in the same
time bound, using a slightly <em>simpler</em> algorithm. A given simple
cycle <span class="math inline">\(\sigma\)</span> is non-separating if
and only if <span class="math inline">\(\Sigma
\mathbin{\backslash\!\!\backslash} \sigma\)</span> is connected; we can
test this condition in <span class="math inline">\(O(n)\)</span> time
using whatever-first search in the dual map <span
class="math inline">\(\Sigma^*\)</span>. Otherwise, the algorithm is the
same.</p>
<p><strong>Theorem [Thomassen]:</strong> <em>Given any edge-weighted
surface map <span class="math inline">\(\Sigma\)</span> with complexity
<span class="math inline">\(n\)</span>, we can compute the shortest
nonseparating cycle in <span class="math inline">\(\Sigma\)</span> in
<span class="math inline">\(O(n^3)\)</span> time.</em></p>
<h2 data-number="30.3" id="near-quadratic-time"><span
class="header-section-number">30.3</span> Near-quadratic time</h2>
<ul>
<li><p>Build a tree-cotree decomposition <span
class="math inline">\((T,L,C)\)</span> where <span
class="math inline">\(T\)</span> is a shortest-path tree, in <span
class="math inline">\(O(n\log n)\)</span> time, using Dijkstra’s
algorithm.</p></li>
<li><p>Let <span class="math inline">\(X^*\)</span> be the <em>dual</em>
cut graph <span class="math inline">\((C\cup L)^*\)</span>. A
fundamental loop <span
class="math inline">\(\textsf{loop}(x,yz)\)</span> is separating if and
only if <span class="math inline">\((yz)^*\)</span> is a bridge of <span
class="math inline">\(X^*\)</span>, and contractible if and only if at
least one component of <span class="math inline">\(X^*\setminus
(yz)^*\)</span> is a tree.</p></li>
<li><p>We can classify every edge of <span
class="math inline">\(X^*\)</span> as hair, bridge, or neither in <span
class="math inline">\(O(n)\)</span> time. So we can find shortest
noncontractible and nonseparating loops based at <span
class="math inline">\(x\)</span> in <span class="math inline">\(O(n\log
n)\)</span> time.</p></li>
<li><p>Try all basepoints <span class="math inline">\(\implies O(n^2\log
n)\)</span> time.</p></li>
</ul>
<p>The high-level approach of this algorithm is due to Sariel Har-Peled
and me, but we used a much more complicated algorithm to find shortest
interesting loops, which interleaves Dijkstra steps and brute-force
traversal of the dual map. Replacing Dijkstra’s algorithm with a
linear-time shortest-path algorithm reduces the overall running time to
<span class="math inline">\(O(n^2)\)</span>.</p>
<p>This is the fastest algorithm known for arbitrary genus. However,
Martin Kutz proved that for any <em>constant</em> genus <span
class="math inline">\(g\)</span>, it is possible to computer shortest
nontrivial cycles in only <span class="math inline">\(O(n\log
n)\)</span> time, by a reduction to the planar minimum-cut problem (or
more properly, to the dual problem of finding the shortest generating
cycle in an annulus). The running time of Kutz’s algorithm depends
exponentially on the genus. Later work by Sergio Cabello and Erin
Chambers reduced the dependence on <span
class="math inline">\(g\)</span> to a small polynomial.</p>
<h2 data-number="30.4" id="multiple-source-shortest-paths"><span
class="header-section-number">30.4</span> Multiple-Source Shortest
Paths</h2>
<p>We can significantly improve Thomassen’s algorithm using a
generalization of either of the multiple-source shortest path algorithms
that we saw earlier for planar maps.</p>
<p><strong><em>[The rest of this section is only an
outline.]</em></strong></p>
<h3 class="unnumbered" id="parametric">Parametric</h3>
<p>Grove decomposition of the dual cut graph <span
class="math inline">\(T\cup L\)</span> into <span
class="math inline">\(O(g)\)</span> trees, each with a central cut path.
Each pivot requires <span class="math inline">\(O(g)\)</span>
dynamic-forest operations, and thus takes <span
class="math inline">\(O(g\log n)\)</span> amortised time. Each dart
pivots into the shortest path tree <span
class="math inline">\(T\)</span> at most <span
class="math inline">\(O(g)\)</span> times. Total time is <span
class="math inline">\(O(g^2 n\log n)\)</span>, assuming generic edge
weights. This can be improved to <span class="math inline">\(O(gn\log
n)\)</span> time with more careful data structures and analysis.</p>
<figure>
<img src="Fig/grove-link-cut.png" style="width:75.0%"
alt="Pivoting one edge into a grove decomposition." />
<figcaption aria-hidden="true">Pivoting one edge into a grove
decomposition.</figcaption>
</figure>
<dl>
<dt><strong>Surface-Tree Lemma:</strong></dt>
<dd>
<em>Let <span class="math inline">\(T\)</span> be any tree embedded on a
surface with exactly one boundary cycle <span
class="math inline">\(B\)</span>; call any vertex in <span
class="math inline">\(T\cap B\)</span> a boundary vertex. Let <span
class="math inline">\(e\)</span> be any edge of <span
class="math inline">\(T\)</span>, and let <span
class="math inline">\(U\)</span> and <span
class="math inline">\(W\)</span> be the components of <span
class="math inline">\(T\setminus e\)</span>. Either <span
class="math inline">\(U\)</span> contains every boundary vertex, or
boundary vertices in <span class="math inline">\(U\)</span> induce at
most <span class="math inline">\(g+1\)</span> paths in <span
class="math inline">\(B\)</span>.</em>
</dd>
<dt><strong>Proof(?):</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma\)</span> be the surface map
induced by <span class="math inline">\(T \cup B\)</span>, and let <span
class="math inline">\(o\)</span> be the face of <span
class="math inline">\(\Sigma\)</span> bounded by <span
class="math inline">\(B\)</span>. Let <span
class="math inline">\((T,L,C)\)</span> be any tree-cotree decomposition
of <span class="math inline">\(\Sigma\)</span> with the given spanning
tree <span class="math inline">\(T\)</span>.
</dd>
<dd>
<p>Consider the subgraph <span class="math inline">\(X^* = C^*\cup L^*
\cup \{e^*\}\)</span> of the dual map <span
class="math inline">\(\Sigma^*\)</span>. The induced embedding of <span
class="math inline">\(X^*\)</span> has exactly two faces, each
containing (the faces of <span class="math inline">\(\Sigma^*\)</span>
dual to vertices of) one component of <span class="math inline">\(T
\setminus e\)</span>. Let <span class="math inline">\(Y^*\)</span> be
the boundary subgraph comprised of the non-isthmus edges of <span
class="math inline">\(X^*\)</span>. This boundary subgraph can be
decomposed into at most <span class="math inline">\(g+1\)</span> simple
non-crossing cycles. (Recall the the <em>definition</em> of the genus
<span class="math inline">\(G\)</span> is the maximum number of disjoint
cycles whose deletion does not disconnect the surface.) Each of these
cycles crosses <span class="math inline">\(B\)</span> at most twice.
Thus, either <span class="math inline">\(X^*\)</span> does not cross
<span class="math inline">\(B\)</span> at all, or <span
class="math inline">\(X^*\)</span> splits <span
class="math inline">\(B\)</span> into at most <span
class="math inline">\(2g+2\)</span> intervals, which alternate between
vertices of <span class="math inline">\(U\)</span> and vertices of <span
class="math inline">\(W\)</span>. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h3 class="unnumbered" id="recursive">Recursive</h3>
<p>Precompute homology annotations (via a system of cocycles) once at
the start. Compute shortest-path trees <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_j\)</span> in <span
class="math inline">\(O(n\log n)\)</span> time. Compute homology
signatures of all shortest paths from <span
class="math inline">\(s_i\)</span> and <span
class="math inline">\(s_k\)</span> in <span
class="math inline">\(O(gn)\)</span> time. Dart <span
class="math inline">\({u{\to}v}\)</span> is properly shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span> if it satisfies the following
conditions:</p>
<ul>
<li><span class="math inline">\(\textsf{pred}_i(v) = \textsf{pred}_k(v)
= u\)</span></li>
<li><span class="math inline">\([\textsf{path}_i(u)] =
[\textsf{path}_k(u)]\)</span> — <strong>This condition is
new!</strong></li>
<li>If <span class="math inline">\(t = \textsf{pred}_i(u) =
\textsf{pred}_k(u)\)</span>, then <span
class="math inline">\(t{\to}u\)</span> is properly shared by <span
class="math inline">\(T_i\)</span> and <span
class="math inline">\(T_k\)</span>.</li>
<li>Otherwise, darts <span
class="math inline">\(\textsf{pred}_i(u){\to}u\)</span> and <span
class="math inline">\(v{\to}u\)</span> and <span
class="math inline">\(\textsf{pred}_k(u){\to}u\)</span> are oriented
clockwise around <span class="math inline">\(u\)</span>.</li>
</ul>
<p>The second condition holds if and only if these two shortest paths
define a separating arc from <span class="math inline">\(s_i\)</span>
through <span class="math inline">\(u\)</span> to <span
class="math inline">\(s_k\)</span>.</p>
<p>Finding and contracting all properly shared darts takes <span
class="math inline">\(O(gn)\)</span> time. Each vertex has <span
class="math inline">\(O(g\deg(v))\)</span> interesting sources, so the
total size of all maps at each level of recursion is <span
class="math inline">\(O(gn)\)</span>. The total preprocessing time is
<span class="math inline">\(O(gn\log n + g^2 n)\)</span>; the query time
is still <span class="math inline">\(O(\log n)\)</span>. It’s unclear
whether <span class="math inline">\(O(gn\log n)\)</span> time can be
achieved with this approach.</p>
<h2 data-number="30.5"
id="shortest-nonseparating-cycles-in-near-linear-time"><span
class="header-section-number">30.5</span> Shortest Nonseparating Cycles
in Near-Linear Time</h2>
<p><strong>Lemma [Cabello Mohar]:</strong> <em>The shortest
nonseparating cycle in any surface map <span
class="math inline">\(\Sigma\)</span> crosses at least one cycle in a
greedy system of cycles for <span class="math inline">\(\Sigma\)</span>
exactly once.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
<strong><em>[[[to be written. The usual exchange argument implies 3
crossings is impossible, and every nonseparating cycle crosses some
basis cycle an odd number of times]]]</em></strong>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>For any cycle <span
class="math inline">\(\gamma\)</span>, the shortest cycle that crosses
<span class="math inline">\(\gamma\)</span> exactly once can be computed
in <span class="math inline">\(O(\bar{g}^2 n\log n)\)</span>
time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\(\Sigma’ = \Sigma
\mathbin{\backslash\!\!\backslash} \gamma\)</span>. If <span
class="math inline">\(\gamma\)</span> is two-sided, then <span
class="math inline">\(\Sigma’\)</span> has two boundary cycles <span
class="math inline">\(\gamma^-\)</span> and <span
class="math inline">\(\gamma^+\)</span>, each of which is a copy of
<span class="math inline">\(\gamma\)</span>. If <span
class="math inline">\(\gamma\)</span> is one-sided, then <span
class="math inline">\(\Sigma’\)</span> has a single boundary cycle <span
class="math inline">\(\gamma^\pm\)</span> that covers <span
class="math inline">\(\gamma\)</span> twice. In either case, <span
class="math inline">\(\Sigma’\)</span> contains two copies <span
class="math inline">\(v^-\)</span> and <span
class="math inline">\(v^+\)</span> of every vertex <span
class="math inline">\(v\)</span> of <span
class="math inline">\(\gamma\)</span>.
</dd>
<dd>
<p>Now let <span class="math inline">\(\sigma\)</span> be the shortest
cycle in <span class="math inline">\(\Sigma\)</span> that crosses <span
class="math inline">\(\gamma\)</span> once. This cycle appears in <span
class="math inline">\(\Sigma’\)</span> as a shortest path from <span
class="math inline">\(v^-\)</span> to <span
class="math inline">\(v^+\)</span> for some vertex <span
class="math inline">\(v\)</span> of <span
class="math inline">\(\Sigma\)</span>. We can compute all such shortest
paths in <span class="math inline">\(O(\bar{g}^2 n\log n)\)</span> time
using either MSSP algorithm, using either <span
class="math inline">\(\gamma^+\)</span> or <span
class="math inline">\(\gamma^\pm\)</span> as the “outer” face. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<p><strong>Theorem:</strong> <em>The shortest nonseparating cycle in a
surface map with Euler genus <span
class="math inline">\(\bar{g}\)</span> and complexity <span
class="math inline">\(n\)</span> can be computed in <span
class="math inline">\(O(\bar{g}^3 n\log n)\)</span> time.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\((T,L,C)\)</span> be a tree-cotree
decomposition of <span class="math inline">\(\Sigma\)</span> where <span
class="math inline">\(T\)</span> is a shortest-path tree. Let <span
class="math inline">\(Q\)</span> be the reduced cur graph obtained by
removing degree-1 vertices from <span class="math inline">\(T\cup
L\)</span>, and let <span class="math inline">\(\mathcal{C} =
\{\gamma_1, \gamma_2, \dots, \gamma_{\bar{g}} \}\)</span> be the system
of cycles induced by <span class="math inline">\(T\)</span> and <span
class="math inline">\(L\)</span>.
</dd>
<dd>
<p>For each cycle <span class="math inline">\(\gamma_i\)</span>, we
compute the shortest cycle in <span
class="math inline">\(\Sigma\)</span> that crosses <span
class="math inline">\(\gamma_i\)</span> exactly once, in <span
class="math inline">\(O(\bar{g}n\log n)\)</span> time, by running a
multiple-source shortest-path algorithm in <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
\gamma_i\)</span>. The shortest of these <span
class="math inline">\(\bar{g}\)</span> cycles is the shortest
nonseparating cycle. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<h2 data-number="30.6"
id="shortest-noncontractible-cycles-in-near-linear-time-sketch"><span
class="header-section-number">30.6</span> Shortest Noncontractible
Cycles in Near-Linear Time (sketch)</h2>
<p>This one is a bit more complicated.</p>
<p><strong>Lemma:</strong> <em>Every noncontractible cycle in any
surface map <span class="math inline">\(\Sigma\)</span> crosses any cut
graph of <span class="math inline">\(\Sigma\)</span> at least
once.</em></p>
<p>The following lemma distills a more complex argument of Cabello,
Chambers, and Erickson. <strong><em>[[[Take this with a grain of salt
until I wrote down a complete proof.]]]</em></strong></p>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\sigma\)</span> be the shortest noncontractible
cycle in some surface map <span class="math inline">\(\Sigma\)</span>.
Let <span class="math inline">\((T,L,C)\)</span> be a tree-cotree
decomposition of <span class="math inline">\(\Sigma\)</span> where <span
class="math inline">\(T\)</span> is a shortest path tree and <span
class="math inline">\(C\)</span> is a maximum spanning tree. Let <span
class="math inline">\(\mathcal{C}\)</span> denote the corresponding
system of cycles.</em></p>
<ol type="a">
<li><em><span class="math inline">\(\sigma\)</span> crosses each cycle
in <span class="math inline">\(\mathcal{C}\)</span> at most
once.</em></li>
<li><em><span class="math inline">\(\sigma\)</span> is a nonseparating
cycle if and only if <span class="math inline">\(\sigma\)</span> crosses
some cycle in <span class="math inline">\(\mathcal{C}\)</span> at least
once.</em></li>
<li><em>If <span class="math inline">\(\sigma\)</span> is a separating
cycle, then <span class="math inline">\(\sigma\)</span> is also the
shortest non-contractible cycle in <span class="math inline">\(\Sigma’ =
\Sigma {\backslash\!\!\backslash} \mathcal{C}\)</span>.</em></li>
</ol>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
<strong><em>[[[To be written. Notice that (a) is a stronger claim than
the nonseparating crossing lemma!]]]</em></strong>
</dd>
</dl>
<p><strong>Lemma:</strong> <em>Let <span
class="math inline">\(\sigma\)</span> be the shortest noncontractible
cycle in some surface map <span class="math inline">\(\Sigma’\)</span>
with genus <span class="math inline">\(0\)</span> and at least two
boundaries. Let <span class="math inline">\(\pi\)</span> be the shortest
path between any two boundaries of <span
class="math inline">\(\Sigma’\)</span>. Either (a) <span
class="math inline">\(\sigma\)</span> crosses <span
class="math inline">\(\pi\)</span> exactly once, or (b) <span
class="math inline">\(\sigma\)</span> does not cross <span
class="math inline">\(\pi\)</span> and <span
class="math inline">\(\sigma\)</span> is the shortest noncontractible
cycle in <span class="math inline">\(\Sigma’ {\backslash\!\!\backslash}
\pi\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
<strong><em>[[[Mostly follows from the Crossing
Condition.]]]</em></strong>
</dd>
</dl>
<p><strong>Theorem:</strong> <em>The shortest noncontractible cycle in a
surface map with Euler genus <span
class="math inline">\(\bar{g}\)</span> and complexity <span
class="math inline">\(n\)</span> can be computed in <span
class="math inline">\(O(\bar{g}^3 n\log n)\)</span>.</em></p>
<dl>
<dt><strong>Proof:</strong></dt>
<dd>
Let <span class="math inline">\((T,L,C)\)</span> be a tree-cotree
decomposition of <span class="math inline">\(\Sigma\)</span> where <span
class="math inline">\(T\)</span> is a shortest-path tree and <span
class="math inline">\(C\)</span> is a maximum spanning tree. Let <span
class="math inline">\(\mathcal{C} = \{\gamma_1, \gamma_2, \dots,
\gamma_{\bar{g}} \}\)</span> be the system of cycles induced by <span
class="math inline">\(T\)</span> and <span
class="math inline">\(L\)</span>.
</dd>
<dd>
<p>First, for each cycle <span class="math inline">\(\gamma_i\)</span>,
we compute the shortest cycle in <span
class="math inline">\(\Sigma\)</span> that crosses <span
class="math inline">\(\gamma_i\)</span> exactly once, in <span
class="math inline">\(O(\bar{g}^2 n\log n)\)</span> time, by running a
multiple-source shortest-path algorithm in <span
class="math inline">\(\Sigma \mathbin{\backslash\!\!\backslash}
\gamma_i\)</span>. The shortest of these <span
class="math inline">\(\bar{g}\)</span> cycles is the shortest
nonseparating cycle. Thus, if the shortest noncontractible cycle is
nonseparating, then the shortest of these <span
class="math inline">\(\bar{g}\)</span> cycles is the shortest
noncontractible cycle. Otherwise, we need to compute the shortest
noncontractible cycle in the sliced surface <span
class="math inline">\(\Sigma’ = \Sigma
\mathbin{\backslash\!\!\backslash} \mathcal{C}\)</span>.</p>
</dd>
<dd>
<p>The surface <span class="math inline">\(\Sigma’\)</span> has genus 0
and <span class="math inline">\(b\)</span> boundary cycles, for some
<span class="math inline">\(1\le b\le \bar{g}\)</span>. If <span
class="math inline">\(b=1\)</span>, then <span
class="math inline">\(\Sigma’\)</span> is a disk, so every cycle in
<span class="math inline">\(\Sigma’\)</span> is contractible. Otherwise,
we compute a shortest path <span class="math inline">\(\pi\)</span>
between any two boundary cycles, compute the shortest cycle <span
class="math inline">\(\sigma^\times\)</span> in <span
class="math inline">\(\Sigma’\)</span> that crosses <span
class="math inline">\(\pi\)</span> exactly once via multiple-source
shortest paths, and recursively search <span
class="math inline">\(\Sigma’ \mathbin{\backslash\!\!\backslash}
\pi\)</span>. The algorithm halts after computing <span
class="math inline">\(b-1\)</span> cycles; the shortest of these is the
shortest noncontractible cycle in <span
class="math inline">\(\Sigma’\)</span>.</p>
</dd>
<dd>
<p>Altogether the algorithm runs multiple-source shortest paths <span
class="math inline">\(\bar{g} + b = O(\bar{g})\)</span> times, each on a
surface map with complexity <span class="math inline">\(O(n)\)</span>
and genus less than <span class="math inline">\(\bar{g}\)</span>. So the
overall running time is <span class="math inline">\(O(\bar{g}^3 n\log
n)\)</span>, as claimed. <span
class="math inline">\(\qquad\square\)</span></p>
</dd>
</dl>
<!--

## Making Shortest Paths Unique

1. Randomized weight perturbation (with high probability)
2. Lexicographic perturbation ($\times O(\log n)$)
3. holiest perturbation ($\times O(g)$)

## Shortest System of Loops

$\Lambda = \Sigma / T \ C$, where $T$ is shortest-path tree from basepoint and $C$ is maximum spanning tree.  Éric’s optimality proof via pointed homology.

## Shortest System of Arcs

$\Lambda = \Sigma / F \ C$, where $F$ is shortest-path forest from boundary and $C$ is maximum spanning tree.  Optimality proof via relative homology.

## Shortest (Co)Homology Bases
Matroid optimization
-->
<h2 data-number="30.7" id="references-20"><span
class="header-section-number">30.7</span> References</h2>
<ol type="1">
<li><p>Sergio Cabello, Erin W. Chambers, and Jeff Erickson. <a
href="http://doi.org/10.1137/12086427">Multiple-source shortest paths in
embedded graphs</a>. <em>SIAM J. Comput.</em> 42(4):1542–1571, 2013.
arXiv:<a href="https://arxiv.org/abs/1804.01045">1202.0314</a>.</p></li>
<li><p>Sergio Cabello and Bojan Mohar. <a
href="http://doi.org/10.1007/s00454-006-1292-5">Finding shortest
non-separating and non-contractible cycles for topologically embedded
graphs</a>. <em>Discrete Comput. Geom.</em> 37(2):213–235,
2007.</p></li>
<li><p>David B. A. Epstein. <a
href="http://doi.org/10.1007/BF02392203">Curves on 2-manifolds and
isotopies</a>. <em>Acta Math.</em> 115:83–107, 1966.</p></li>
<li><p>Jeff Erickson. <a
href="http://doi.org/10.1145/1998196.1998231">Shortest non-trivial
cycles in directed surface graphs</a>. <em>Proc. 27th Ann. Symp. Comput.
Geom.</em>, 236–243, 2011.</p></li>
<li><p>Jeff Erickson, Emily Kyle Fox, and Luvsandondov Lkhamsuren. <a
href="http://doi.org/10.1145/3188745.3188904">Holiest minimum-cost paths
and flows in surface graphs</a>. <em>Proc. 50th Ann. ACM Symp. Theory
Comput.</em>, 1319–1332, 2018. arXiv:<a
href="https://arxiv.org/abs/1804.01045">1804.01045</a>.</p></li>
<li><p>Jeff Erickson and Sariel Har-Peled. <a
href="http://doi.org/10.1007/s00454-003-2948-z">Optimally cutting a
surface into a disk</a>. <em>Discrete Comput. Geom.</em> 31(1):37–59,
2004. arXiv:<a
href="https://arxiv.org/abs/cs/0207004">cs/0207004</a>.</p></li>
<li><p>Emily Kyle Fox. <a
href="http://doi.org/10.1137/1.9781611973105.26">Shortest non-trivial
cycles in directed and undirected surface graphs</a>. <em>Proc. 24th
Ann. ACM-SIAM Symp. Discrete Algorithms</em>, 352–364, 2013. arXiv:<a
href="https://arxiv.org/abs/1111.6990">1111.6990</a>.</p></li>
<li><p>Martin Kutz. <a
href="http://doi.org/10.1145/1137856.1137919">Computing shortest
non-trivial cycles on orientable surfaces of bounded genus in almost
linear time</a>. <em>Proc. 22nd Ann. Symp. Comput. Geom.</em>, 430–438,
2006. arXiv:<a
href="https://arxiv.org/abs/cs/0512064">cs/0512064</a>.</p></li>
<li><p>Carsten Thomassen. <a
href="http://doi.org/10.1016/0095-8956(90)90115-G">Embeddings of graphs
with no short noncontractible cycles</a>. <em>J. Comb. Theory Ser.
B</em> 48(2):155–177, 1990.</p></li>
</ol>
<h2 data-number="30.8" id="aptly-named-sir-4"><span
class="header-section-number">30.8</span> Aptly Named Sir</h2>
<ul>
<li>Enforcing shortest-path and optimal-cycle uniqueness</li>
<li>Tight cycles</li>
<li>Directed graphs</li>
<li>Shortest systems of loops, arcs, or cycles</li>
<li>Shortest <em>homotopic</em> paths, cycles, systems of loops, pants
decompositions</li>
</ul>
<h1 data-number="31" id="surfaces-with-boundaryvarnothing"><span
class="header-section-number">31</span> Surfaces with Boundary<span
class="math inline">\(^\varnothing\)</span></h1>
<h2 data-number="31.1" id="arcs-and-slicing"><span
class="header-section-number">31.1</span> Arcs and Slicing</h2>
<h2 data-number="31.2" id="forest-cotree-decompositions"><span
class="header-section-number">31.2</span> Forest-Cotree
Decompositions</h2>
<h2 data-number="31.3" id="cut-graphs-and-systems-of-arcs"><span
class="header-section-number">31.3</span> Cut Graphs and Systems of
Arcs</h2>
<h2 data-number="31.4"
id="tree-coforest-decompositions-and-systems-of-coarcs"><span
class="header-section-number">31.4</span> Tree-Coforest Decompositions
and Systems of Coarcs</h2>
<h2 data-number="31.5" id="references-21"><span
class="header-section-number">31.5</span> References</h2>
<h2 data-number="31.6" id="aptly-named-sir-5"><span
class="header-section-number">31.6</span> Aptly Named Sir</h2>
<ul>
<li>Pants decompositions (except possibly in passing)</li>
</ul>
<h1 data-number="32" id="minimum-cuts-in-surface-graphsvarnothing"><span
class="header-section-number">32</span> Minimum Cuts in Surface
Graphs<span class="math inline">\(^\varnothing\)</span></h1>
<p>Only describe the homology-cover algorithm. Mention the crossing
sequence algorithm in passing, if at all. (But remember that the
homology cover algorithm still needs some simple crossing arguments to
enable MSSP!)</p>
<h2 data-number="32.1" id="duality-with-even-subgraphs"><span
class="header-section-number">32.1</span> Duality with Even
Subgraphs</h2>
<h2 data-number="32.2" id="mathbbz_2-homology-cover"><span
class="header-section-number">32.2</span> <span
class="math inline">\(\mathbb{Z}_2\)</span>-Homology Cover</h2>
<figure>
<img src="Fig/hom-cover-example.png" style="width:90.0%"
alt="Building the homology cover of a pair of pants" />
<figcaption aria-hidden="true">Building the homology cover of a pair of
pants</figcaption>
</figure>
<h2 data-number="32.3" id="mathbbz_2-minimal-cycles"><span
class="header-section-number">32.3</span> <span
class="math inline">\(\mathbb{Z}_2\)</span>-Minimal Cycles</h2>
<p>Build the homology cover. Also lift greedy primal system of arcs.</p>
<h2 data-number="32.4" id="mathbbz_2-minimal-even-subgraphs"><span
class="header-section-number">32.4</span> <span
class="math inline">\(\mathbb{Z}_2\)</span>-Minimal Even Subgraphs</h2>
<p>Dynamic programming!</p>
<h2 data-number="32.5" id="np-hardness"><span
class="header-section-number">32.5</span> NP-hardness (??)</h2>
<h2 data-number="32.6" id="references-22"><span
class="header-section-number">32.6</span> References</h2>
<ol type="1">
<li><p>Chambers Erickson Fox Nayyeri</p></li>
<li><p>Kutz</p></li>
</ol>
<h2 data-number="32.7" id="aptly-named-sir-6"><span
class="header-section-number">32.7</span> Aptly Named Sir</h2>
<ul>
<li>Crossing-bound/homotopy algorithm</li>
<li>Global mincut</li>
</ul>
<h1 data-number="33"
id="maximum-flows-in-surface-graphsvarnothing"><span
class="header-section-number">33</span> Maximum Flows in Surface
Graphs<span class="math inline">\(^\varnothing\)</span></h1>
<h2 data-number="33.1" id="real-homology"><span
class="header-section-number">33.1</span> Real Homology</h2>
<h2 data-number="33.2" id="homologous-feasible-flows"><span
class="header-section-number">33.2</span> Homologous Feasible Flows</h2>
<h2 data-number="33.3" id="shortest-paths-with-negative-edges"><span
class="header-section-number">33.3</span> Shortest Paths with Negative
Edges</h2>
<p><span class="math inline">\(O(n \log^2 n / \log\log n)\)</span> time
(Real RAM)</p>
<pre><code>- ***[[[Move to planarization chapter?]]]$$$</code></pre>
<h2 data-number="33.4" id="ellipsoid-method-sketch"><span
class="header-section-number">33.4</span> Ellipsoid Method (Sketch)</h2>
<h2 data-number="33.5" id="summary"><span
class="header-section-number">33.5</span> Summary</h2>
<p>To simplify notation, assume <span class="math inline">\(C =
n^{O(1)}\)</span> and (because off-the-shelf algorithms are faster
otherwise) <span class="math inline">\(g = o(n^{1/4})\)</span>.</p>
<ul>
<li><p><span class="math inline">\(\#\)</span> iterations <span
class="math inline">\(N = O(d \log \Delta)\)</span></p></li>
<li><p>Dimension <span class="math inline">\(d = O(g)\)</span></p></li>
<li><p>Aspect ratio <span class="math inline">\(\Delta =
C^{O(g)}\)</span></p></li>
<li><p>So <span class="math inline">\(N = O(g^2 \log
C)\)</span></p></li>
<li><p>Oracle time <span class="math inline">\(T_s = O(n\log^2
n)\)</span></p></li>
<li><p>Iteration time <span class="math inline">\(O(T_s + d^2)\)</span>
arithmetic operations</p></li>
<li><p><span class="math inline">\(k\)</span>th iteration requires <span
class="math inline">\(O(k)\)</span> bits of precision</p></li>
<li><p>So <span class="math inline">\(k\)</span>th iteration takes <span
class="math inline">\(O(T_s A(k) + d^2 M(k))\)</span> time</p></li>
<li><p>Total time is <span class="math inline">\(O(N\,A(N)\,T_s + d^2\,
N\, M(N))\)</span></p></li>
<li><p>Real RAM <em>without</em> square roots: <span
class="math inline">\(A(N) = O(1)\)</span> and <span
class="math inline">\(M(N) = O(\log\log N)\)</span> (for square roots)
<span class="math display">\[
  \begin{aligned}
      O(N\,A(N)\,T_s + d^2\,N\,M(N))
      &amp;=
      O(N\, T_s + d^2\, N \log\log N)
  \\  &amp;=
      O(g^2 \log C)\cdot O(n\log^2 n)
      +
      O(g^2) \cdot O(g^2 \log C\log\log (g\log C))
  \\  &amp;=
      O(g^2 n\log^2 n \log^2 C)
      +
      O(g^4 \log C \log\log (g\log C))
  \\  &amp;=
      O(g^2 n\log^4 n)
  \end{aligned}
\]</span></p></li>
<li><p>Bit RAM, grade school arithmetic: <span
class="math inline">\(A(N) = O(N)\)</span> and <span
class="math inline">\(M(N) = O(N^2)\)</span> <span
class="math display">\[
  \begin{aligned}
      O(N\,A(N)\, T_s + d^2\,N\,M(N))
      &amp;=
      O(N^2 T_s + N^3 d^2)
  \\  &amp;=
      O(g^4 \log^2 C)\cdot O(n\log^2 n)
      +
      O(g^6 \log^3 C)\cdot O(g^2)
  \\  &amp;=
      O(g^4 n\log^2 n \log^2 C)
      +
      O(g^8 \log^3 C)
  \\  &amp;=
      O(g^4 n\log^4 n)
      +
      O(g^8 \log^3 n)
  \end{aligned}
\]</span> First term dominates because <span class="math inline">\(g =
O((n\log n)^{1/4})\)</span>.</p></li>
<li><p>Fast bit RAM: <span class="math inline">\(A(N) = O(N)\)</span>
and <span class="math inline">\(M(N) = O(N\log N)\)</span> <span
class="math display">\[
  \begin{aligned}
      O(N\,A(N)\, T_s + d^2\,N\,M(N))
      &amp;=
      O(N^2 T_s +  d^2 N^2\log N)
  \\  &amp;=
      O(g^4 \log^2 C)\cdot O(n\log^2 n)
      \\
      &amp;\qquad {}+
      O(g^2)\cdot O(g^4 \log^2 C \log (g\log C))
  \\  &amp;=
      O(g^4 n\log^2 n \log^2 C)
      +
      O(g^6 \log^2 C \log (g\log C))
  \\  &amp;=
      O(g^4 n\log^4 n)
  \end{aligned}
\]</span> First term dominates because <span class="math inline">\(g =
o(\sqrt{n\log n})\)</span>.</p></li>
<li><p>Fast word RAM: <span class="math inline">\(A(N) = M(N) =
O(N)\)</span> — Need to verify square root time <span
class="math display">\[
  \begin{aligned}
      O(N\,A(N)\, T_s + d^2\,N\,M(N))
      &amp;=
      O(N^2 T_s + d^2 N^2)
  \\  &amp;=
      O(g^4 \log^2 C)\cdot O(n\log^2 n)
      +
      O(g^2)\cdot O(g^4 \log^2 C)
  \\  &amp;=
      O(g^4 n\log^2 n \log^2 C) + O(g^6 \log^2 C)
  \\  &amp;=
      O(g^4 n\log^4 n)
  \end{aligned}
\]</span> <span class="math inline">\(\dots\)</span> because <span
class="math inline">\(g = o(\sqrt{n})\)</span></p></li>
</ul>
<p><strong>Theorem:</strong> <em>Let <span
class="math inline">\(\Sigma\)</span> be a surface map with <span
class="math inline">\(n\)</span> vertices, genus <span
class="math inline">\(g = o(\sqrt{n\log n})\)</span>, positive integer
edge capacities less than <span class="math inline">\(n^{O(1)}\)</span>,
and two vertices <span class="math inline">\(s\)</span> and <span
class="math inline">\(t\)</span>. We can compute the maximum <span
class="math inline">\((s,t)\)</span>-flow in <span
class="math inline">\(\Sigma\)</span> in <span
class="math inline">\(O(g^4 n\log^4 n)\)</span> time.</em></p>
<h2 data-number="33.6" id="references-23"><span
class="header-section-number">33.6</span> References</h2>
<ol type="1">
<li><p>Alt JACM 1988</p></li>
<li><p>Brent JACM 1976</p></li>
<li><p>Chambers Erickson Nayyeri</p></li>
<li><p>fast integer multiplication</p></li>
<li><p>Fürer arXiv:1402.1811</p></li>
</ol>
<h2 data-number="33.7" id="aptly-named-sir-7"><span
class="header-section-number">33.7</span> Aptly Named Sir</h2>
<ul>
<li>Directed graphs</li>
<li>Non-orientable surfaces(?)</li>
<li>Multi-dimensional parametric search</li>
<li>Min-cost homologous circulations</li>
<li>Spectral min-cost-flow algorithms, scaling</li>
</ul>
<h1 data-number="34" id="geodesic-embeddingsvarnothing"><span
class="header-section-number">34</span> Geodesic Embeddings<span
class="math inline">\(^\varnothing\)</span></h1>
<p>This is by far the least developed chapter, even in my head.</p>
<h2 data-number="34.1" id="flat-torus"><span
class="header-section-number">34.1</span> Flat Torus</h2>
<h3 data-number="34.1.1" id="spring-embeddings"><span
class="header-section-number">34.1.1</span> Spring Embeddings</h3>
<h2 data-number="34.2" id="spring-embeddings-on-other-surfaces"><span
class="header-section-number">34.2</span> Spring Embeddings on Other
Surfaces</h2>
<p>Colin de Verdière, Hass: simplicial complexes, negative curvature</p>
<p>Ideally: essentially (strongly) 3-connected, homotopic to embedding
<span class="math inline">\(\implies\)</span> strictly convex
embedding.</p>
<h2 data-number="34.3" id="circle-packing-on-other-surfaces"><span
class="header-section-number">34.3</span> Circle Packing on Other
Surfaces</h2>
<p>Algorithms: Colin de Verdière, Mohar (Rivin, Bobenko/Springborn,
Stephenson?)</p>
<h2 data-number="34.4" id="references-24"><span
class="header-section-number">34.4</span> References</h2>
<h2 data-number="34.5" id="named-sir-not"><span
class="header-section-number">34.5</span> Named Sir Not</h2>
<h1 data-number="35" id="closing-the-loopvarnothing"><span
class="header-section-number">35</span> Closing the Loop<span
class="math inline">\(^\varnothing\)</span></h1>
<p>We covered several topics related to <em>planar</em> curves and maps
early in the course, which we did not revisit in the context of more
complex surfaces. For some topics, I decided not to cover the surface
generalization because the results are considerably more technical. For
others, I didn’t cover the surface generalization because little or
nothing is known. In this final chapter, I’ll walk through each of the
early planar topics and describe the state of the art for the surface
generalization.</p>
<h2 data-number="35.1" id="simple-polygons"><span
class="header-section-number">35.1</span> Simple Polygons</h2>
<p>As we’ve already seen, the Jordan curve theorem does not generalize
to surfaces with positive genus. Indeed, the <em>definition</em> of the
genus of a surface <span class="math inline">\(\mathcal{S}\)</span> is
the maximum number of disjoint simple closed curves in <span
class="math inline">\(\mathcal{S}\)</span> whose complement is
connected. Nevertheless, some of our most basic results on simple
polygons do generalize to “polygons” on more complex surfaces.</p>
<p>To properly generalize <em>polygons</em> in the plane to more complex
surfaces, we need an appropriate generalization of <em>line
segments</em>, which in turn relies on appropriate generalizations of
<em>lengths</em> and <em>angles</em>.</p>
<p><strong>Theorem:</strong> <em>Any geodesic embedding of a graph on
any surface with constant Gaussian curvature can be extended to a
geodesic triangulation without adding vertices.</em></p>
<h2 data-number="35.2" id="winding-numbers-1"><span
class="header-section-number">35.2</span> Winding Numbers</h2>
<p>These are only well-defined for null-homologous curves; these are
sometimes called <em>lacets</em>. For non-orientable surfaces, winding
numbers are only defined modulo <span class="math inline">\(2\)</span>;
for orientable surfaces, they can be defined either as integers or a
residues with respect to any integer modulus.</p>
<h2 data-number="35.3" id="curve-homotopy"><span
class="header-section-number">35.3</span> Curve Homotopy</h2>
<p>Homotopy moves; Dehn’s algorithm</p>
<h2 data-number="35.4" id="shortest-homotopic-paths-and-cycles"><span
class="header-section-number">35.4</span> Shortest Homotopic Paths and
Cycles</h2>
<p>Algorithms for traversal/crossing curves with respect to any
edge-weighted surface map. Given a walk <span
class="math inline">\(W\)</span> with hop-length <span
class="math inline">\(k\)</span> in a surface map with complexity <span
class="math inline">\(n\)</span> and genus <span
class="math inline">\(g\)</span>, we can find the minimum-length walk
homotopic to <span class="math inline">\(W\)</span> (with fixed
endpoints) in <span class="math inline">\(O(gnk)\)</span> time. if <span
class="math inline">\(W\)</span> is a closed walk, we can find the
shortest closed walk homotopic to <span class="math inline">\(W\)</span>
in <span class="math inline">\(O(gnk \log nk)\)</span> time.</p>
<p>Shortest homotopic systems of loops, pants decompositions, graph
embeddings</p>
<h2 data-number="35.5" id="gauss-codes"><span
class="header-section-number">35.5</span> Gauss codes</h2>
<p>Unsigned Gauss codes are well-defined for any (multi)curve on any
surface; signed Gauss codes require the underlying surface to be
orientable.</p>
<p>A signed Gauss code of length <span class="math inline">\(n\)</span>
can be interpreted as a rotation system for a <span
class="math inline">\(4\)</span>-regular graph with <span
class="math inline">\(n\)</span> vertices, and thus represents a unique
curve (up to homeomorphism) on a unique orientable surface.</p>
<p>Given an unsigned Gauss code <span class="math inline">\(x\)</span>
and a surface <span class="math inline">\(\mathcal{S}\)</span>
(specified by orientability and genus), we can determine whether <span
class="math inline">\(x\)</span> is consistent with a curve on <span
class="math inline">\(\mathcal{S}\)</span> in time <span
class="math inline">\(g^{O(g)}n\)</span> as follows.</p>
<ol type="1">
<li><p>Construct the Nagy graph <span
class="math inline">\(G(X)\)</span>.</p></li>
<li><p>Compute any Euler tour of <span
class="math inline">\(G(X)\)</span>.</p></li>
<li><p>Construct the Dehn <em>diagram</em> <span
class="math inline">\(D(X)\)</span> of this Euler tour (not just the
Dehn <em>code</em>).</p></li>
<li><p>Finally, check whether the Dehn diagram <span
class="math inline">\(D(X)\)</span> can be embedded on <span
class="math inline">\(\mathcal{S}\)</span>. This, of course, is the hard
part.</p></li>
</ol>
<h2 data-number="35.6" id="curve-invariants-and-simplification"><span
class="header-section-number">35.6</span> Curve Invariants and
Simplification</h2>
<h2 data-number="35.7" id="geodesic-embeddings"><span
class="header-section-number">35.7</span> Geodesic Embeddings</h2>
<h3 class="unnumbered" id="inductive">Inductive</h3>
<h3 class="unnumbered" id="tutte">Tutte</h3>
<h3 class="unnumbered" id="koebe">Koebe</h3>
<h3 class="unnumbered" id="schnyder">Schnyder</h3>
<h2 data-number="35.8" id="maxwellcremona"><span
class="header-section-number">35.8</span> Maxwell–Cremona</h2>
<h3 class="unnumbered"
id="non-planar-frameworks-in-the-plane">Non-planar Frameworks in the
Plane</h3>
<p>Let <span class="math inline">\(\Sigma\)</span> be an orientable
surface map—that is, a graph <span class="math inline">\(G\)</span>
together with a rotation system <span
class="math inline">\(\textsf{succ}\)</span>—with positive genus. (The
underlying graph <span class="math inline">\(G\)</span> might be
planar!) Any position function <span class="math inline">\(p\colon
V(\Sigma) \to \mathbb{R}^2\)</span> induces a straight-line drawing of
<span class="math inline">\(G\)</span> in the plane. I will call the
pair <span class="math inline">\((G,p)\)</span> a <em>framework</em> and
(for lack of better standard terminology) the pair <span
class="math inline">\((\Sigma, p)\)</span> an <em>ordered
framework</em>. The <em>displacement</em> of any dart <span
class="math inline">\(u{\to}v\)</span> in <span
class="math inline">\(G\)</span> with respect to <span
class="math inline">\(p\)</span> is the vector <span
class="math inline">\(\Delta(u{to}v) = p(v)-p(u)\)</span>. The dual
graph <span class="math inline">\(G^*\)</span> is the underlying graph
of the dual surface map <span
class="math inline">\(\Sigma^*\)</span>.</p>
<p>The definitions of non-zero, strict, and equilibrium stresses and
closed and exact 1-forms all generalize directly from the setting where
<span class="math inline">\(\Sigma\)</span> is a planar map.</p>
<p>However, closed discrete 1-forms on positive-genus maps are not
necessarily exact. Consider, for example, the 1-form defined on a
toroidal grid, where all “upward” darts have value <span
class="math inline">\(1\)</span>, and all “horizontal” darts have value
<span class="math inline">\(0\)</span>; this discrete 1-form is closed
but not exact.</p>
<p>The difference between closed and exact 1-forms is captured by
<em>cohomology</em> on the surface map <span
class="math inline">\(\Sigma\)</span>. Closed 1-forms are duals of
circulations; exact 1-forms are duals of boundary circulations; thus,
two closed 1-forms are cohomologous if and only if their difference is
an exact 1-form.</p>
<p>Not every equilibrium stress on a framework induces a reciprocal
framework. First, the definition of “reciprocal” requires a rotation
system to define the dual graph <span
class="math inline">\(G^*\)</span>; only <em>ordered</em> frameworks
have reciprocals. But even with a fixed rotation system, the dual
displacement function <span class="math inline">\(\Delta^*(d^*) :=
\omega(d)\cdot\Delta(d)^\bot\)</span> is not necessarily an exact 1-form
on the dual graph <span class="math inline">\(G^*\)</span> (although it
is always closed). I will call a stress <span
class="math inline">\(\omega\)</span> <em>reciprocal</em> for an ordered
framework <span class="math inline">\((\Sigma,p)\)</span> if the dual
displacement function <span class="math inline">\(\Delta^*\)</span> is a
closed 1-form on <span class="math inline">\(G^*\)</span>.</p>
<p><strong>Theorem:</strong> <em>An equilibrium stress <span
class="math inline">\(\omega\)</span> for an ordered framework <span
class="math inline">\((\Sigma,p)\)</span> induces a reciprocal framework
<span class="math inline">\((\Sigma^*, p^*)\)</span> if and only if
<span class="math inline">\(\omega\)</span> is a reciprocal stress for
<span class="math inline">\((\Sigma,p)\)</span>. Conversely, any
reciprocal framework <span class="math inline">\((\Sigma^*,p^*)\)</span>
defines a unique reciprocal stress <span
class="math inline">\(\omega\)</span> for <span
class="math inline">\((\Sigma, p)\)</span>.</em></p>
<p>Notice that this theorem describes restrictions on both the stress
<span class="math inline">\(\omega\)</span> and the rotation system
defining <span class="math inline">\(\Sigma\)</span>. The same stress
<span class="math inline">\(\omega\)</span> can be reciprocal for some
rotations systems but not others.</p>
<h3 class="unnumbered" id="the-petrie-cube">The Petrie Cube</h3>
<p>As a simple example of a non-planar ordered framework, consider the
<em>Petrie cube</em>. The Petrie cube is a map of the torus with six
vertices, twelve edges, and six hexagonal faces, whose underlying graph
is identical to the graph of the cube. Each face of the Petrie cube is
bounded by the cycle obtained by deleting two opposite vertices of the
cube graph. Equivalently, the Petrie cube is the map obtained from the
standard cube by reversing the rotation system at four independent
vertices.</p>
<!--
$$
\begin{aligned}
    P &= \begin{bmatrix}
        +1 & +2 \\
        -1 & +2 \\
        +1 & -2 \\
        -1 & -2 \\
        +2 & +1 \\
        -2 & +1 \\
        +2 & -1 \\
        -2 & -1
    \end{bmatrix}
    &
    L &= \begin{bmatrix}
        -5 & 6 & 3 & \cdot & \cdot & \cdot & \cdot & -4 \\ 
        6 & -5 & \cdot & 3 & \cdot & \cdot & -4 & \cdot \\
        3 & \cdot & -5 & 6 & \cdot & -4 & \cdot & \cdot \\
        \cdot & 3 & 6 & -5 & -4 & \cdot & \cdot & \cdot \\
        \cdot & \cdot & \cdot & -4 & -5 & 3 & 6 & \cdot \\ 
        \cdot & \cdot & -4 & \cdot & 3 & -5 & \cdot & 6 \\
        \cdot & -4 & \cdot & \cdot & 6 & \cdot & -5 & 3 \\
        -4 & \cdot & \cdot & \cdot & \cdot & 6 & 3 & -5 
    \end{bmatrix}
    &
    \ker L &= \begin{bmatrix}
        +1 & +2 & 1 \\
        -1 & +2 & 1 \\
        +1 & -2 & 1 \\
        -1 & -2 & 1 \\
        +2 & +1 & 1 \\
        -2 & +1 & 1 \\
        +2 & -1 & 1 \\
        -2 & -1 & 1
    \end{bmatrix}
\end{aligned}
$$

$$
\begin{aligned}
    \Delta &=
    \begin{bmatrix}
        -2 & 0 \\
        0 & -4 \\
        -3 & -3 \\
        0 & -4 \\
        +3 & -3 \\
        -2 & 0 \\
        -3 & 3 \\
        +3 & +3 \\
        -4 & 0 \\
        0 & -2 \\
        0 & -2 \\
        -4 & 0
    \end{bmatrix}
    ~
    \textcolor{pink}
    {\begin{matrix}
        \arc12 \\ \arc13 \\ \arc18 \\ \arc24 \\
        \arc27 \\ \arc34 \\ \arc36 \\ \arc45 \\
        \arc56 \\ \arc57 \\ \arc68 \\ \arc78
    \end{matrix}}
    \quad
    \textcolor{cyan}
    {\begin{matrix}
        \fence{B}{A} \\ \fence{A}{C} \\ \fence{C}{B} \\ \fence{D}{A} \\
        \fence{B}{D} \\ \fence{A}{E} \\ \fence{E}{C} \\ \fence{D}{E} \\
        \fence{F}{E} \\ \fence{D}{F} \\ \fence{F}{C} \\ \fence{B}{F}
    \end{matrix}}
    &
    \Delta^* &=
    \begin{bmatrix}
        0 & -12  \\
        +12 & 0  \\
        -12 & +12 \\
        +12 & 0 \\
        -12 & -12 \\
        0 & -12 \\
        +12 & +12 \\
        +12 & -12 \\
        0 & -12 \\
        +12 & 0 \\
        +12 & 0 \\
        0 & -12
    \end{bmatrix}
    ~
    \textcolor{pink}
    {\begin{matrix}
        \fence12 \\ \fence13 \\ \fence18 \\ \fence24 \\
        \fence27 \\ \fence34 \\ \fence36 \\ \fence45 \\
        \fence56 \\ \fence57 \\ \fence68 \\ \fence78
    \end{matrix}}
    \quad
    \textcolor{cyan}
    {\begin{matrix}
        \arc{B}{A} \\ \arc{A}{C} \\ \arc{C}{B} \\ \arc{D}{A} \\
        \arc{B}{D} \\ \arc{A}{E} \\ \arc{E}{C} \\ \arc{D}{E} \\
        \arc{F}{E} \\ \arc{D}{F} \\ \arc{F}{C} \\ \arc{B}{F}
    \end{matrix}}
\end{aligned}
$$

$$
\begin{aligned}
    [P, Z] &= \begin{bmatrix}[cc:c]
        +1 & +2 & 0 \\
        -1 & +2 & 0 \\
        +1 & -2 & 0 \\
        -1 & -2 & 0 \\
        +2 & +1 & 36 \\
        -2 & +1 & 36 \\
        +2 & -1 & 36 \\
        -2 & -1 & 36
    \end{bmatrix}
    \textcolor{Gray}    {\begin{matrix} 1\\2\\3\\4\\5\\6\\7\\8 \end{matrix}}
    &
    [P^*, Z^*] &= \begin{bmatrix}[cc:c]
        0 & 0 & 0 \\
        0 & +12 & 24 \\
        +12 & 0 & 12 \\
        -12 & 0 & 12 \\
        0 & -12 & 24 \\
        0 & 0 & 36
    \end{bmatrix}
    \textcolor{Gray}    {\begin{matrix} A\\B\\C\\D\\E\\F \end{matrix}}
    &   
    \phi^\diamond &= 
    \begin{bmatrix}
        0 \\ +24 \\ +12 \\ 
        0 \\ +24 \\ +12 \\
        0 \\ +12 \\ +24 \\
        0 \\ +12 \\ +24 \\\hdashline
        -24 \\ -12 \\ 0 \\
        -24 \\ -12 \\ 0 \\
        -12 \\ -24 \\ 0 \\
        -12 \\ -24 \\ 0
    \end{bmatrix}
    \textcolor{Gray}
    {\begin{matrix}
        \arc{1}{A} \\ \arc{1}{B} \\ \arc{1}{C} \\
        \arc{2}{A} \\ \arc{2}{B} \\ \arc{2}{D} \\
        \arc{3}{A} \\ \arc{3}{C} \\ \arc{3}{E} \\
        \arc{4}{A} \\ \arc{4}{D} \\ \arc{4}{E} \\\hdashline
        \arc{5}{D} \\ \arc{5}{E} \\ \arc{5}{F} \\
        \arc{6}{C} \\ \arc{6}{E} \\ \arc{6}{F} \\
        \arc{7}{B} \\ \arc{7}{D} \\ \arc{7}{F} \\
        \arc{8}{B} \\ \arc{8}{C} \\ \arc{8}{F}
    \end{matrix}}
\end{aligned}
$$
-->
<h3 class="unnumbered"
id="polyhedral-lifts-of-non-planar-frameworks">Polyhedral Lifts of
Non-planar Frameworks</h3>
<p>What about the correspondence between reciprocal diagrams and
polyhedral lifts?</p>
<h3 class="unnumbered" id="toroidal-frameworks">Toroidal Frameworks</h3>
<h2 data-number="35.9" id="references-25"><span
class="header-section-number">35.9</span> References</h2>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>I would like to include a section describing related
state-of-the-art results at the end of each chapter. These annotations
ignore those missing sections.)<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Historically, the definition of “simple closed curve”
was a point of serious confusion for several decades, starting with
Bolzano around 1840s. This confusion was finally resolved only when
Jordan defined closed curves as <em>functions</em> instead of
<em>subsets of the plane</em>.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The plane separation axiom states that the complement
<span class="math inline">\(\mathbb{R}^2\setminus \ell\)</span> of any
<em>straight line</em> <span class="math inline">\(\ell\)</span> in the
plane has exactly two components. This axiom follows easily from the
intermediate value theorem; it is also formally equivalent to
<em>Pasch’s axiom</em>: If a line <span
class="math inline">\(\ell\)</span> does not contain any vertex of a
triangle <span class="math inline">\(\triangle\)</span>, then <span
class="math inline">\(\ell\)</span> intersects an even number of edges
of <span class="math inline">\(\triangle\)</span>. In 1882, Moritz Pasch
proved that his axiom is independent of Euclid’s postulates, but that
some theorems in the <em>Elements</em> require it. Yes, there is such a
thing as non-Paschian geometry. It’s weeeeeird.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>There is another completely different “Fast and Loose”
con game, also known as called “Pricking the Garter”, that’s usually
performed with a belt. It’s less self-working, less mathematically
interesting (despite <em>seeming</em> to invoke the Jordan curve
theorem) , and less <em>shiny</em> than the Endless Chain.<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Hint: cofactor expansion<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>This is, of course, the only <em>correct</em> way to
measure angles, as opposed to radians or degrees or some other heresy.<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>We’re admittedly getting a little ahead of ourselves
here. A <em>plane graph</em> is any graph whose vertices are points in
the plane, and whose edges are <em>interior-disjoint</em> paths between
their endpoints.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Stop trying to make “digon” and “trigon” happen,
Gretchen. They’re not going to happen.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>A knot diagram is generic closed curve with additional
data at each crossing, indicating which branch of the curve passes in
front of the other. Homotopy moves that sensibly preserves this crossing
data are called <em>Reidemeister moves</em>.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Nagy’s algorithm attempts to construct a <em>Seifert
decomposition</em> of the encoded curve. I’m afraid I don’t understand
Nagy’s solution well enough to describe it, or even to be confident that
it is correct.<a href="#fnref10" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><strong><em>Dozens</em></strong> of other combinatorial
and algebraic characterizations of planar Gauss codes have been
published since Dehn’s solution, but as far as I know, none lead to a
simpler or more efficient algorithm (except through the use of
linear-time algorithms to test graph planarity, which is cheating).<a
href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>The terms “Dehn code” and “Dehn diagram” are
nonstandard.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Tree-onion figures are also closely related to
tree-cotree decompositions of planar maps. Specifically, there is a
bijection between tree-cotree decompositions of a planar map <span
class="math inline">\(\Sigma\)</span> and tree-onion figures of
non-crossing Euler tours of the medial map <span
class="math inline">\(\Sigma^\times\)</span>. (Don’t worry; those words
will make sense soon.) So it’s really tempting to refer to the partition
of inner and outer chords in a tree-onion figure as a <em>coonion-onion
decomposition</em>.<a href="#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Our definition of graphs allows graphs with infinitely
(even uncountably) many vertices and edges, and in particular, vertices
with infinite (even uncountable) degree. Most of the graphs we consider
in this course are finite, and obviously algorithms can only
<em>explicitly</em> construct finite graphs. However, we do sometimes
implicitly represent infinite graphs with certain symmetries using
finite graphs. For example, any triangulation of a polygon with holes (a
finite planar map, whose dual is another planar map) is an implicit
representation of its universal over (an infinite planar map whose dual
is an infinite tree).<a href="#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>And again, the definition allows topological graphs
with infinitely (even uncountably) many vertices and edges, and infinite
(even uncountable) vertex degrees.<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Even worse, graph theorists use the phrase “topological
graph” to mean a <em>generic drawing</em> or <em>immersion</em> of a
graph in the plane. In a generic drawing, vertices are represented by
distinct points; edges are represented by paths between their endpoints;
no edge passes through a vertex except its endpoints; all
(self-)intersections between edge interiors are transverse; and all
pairwise (self-)intersection points are distinct.<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>For readers familiar with topology, a triangulation is
<em>not</em> necessarily a simplicial complex, but rather what Hatcher
calls a <em><span class="math inline">\(\Delta\)</span>-complex.</em><a
href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Because the edges of a planar embedding can be
<em>arbitrary</em> paths, it is not immediately obvious that this cyclic
order is well-defined. In fact, the existence of a consistent order
follows from careful application of the Jordan-Schönflies theorem.<a
href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>or into the sphere, or an isotopy/homeomorphism class
of such embeddings<a href="#fnref19" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>Even worse, graph theorists use the phrase “topological
graph” to mean a <em>generic drawing</em> or <em>immersion</em> of a
graph in the plane. In a generic drawing, vertices are represented by
distinct points; edges are represented by paths between their endpoints;
no edge passes through a vertex except its endpoints; all
(self-)intersections between edge interiors are transverse; and all
pairwise (self-)intersection points are distinct.<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>The dual rotation system of a planar map is sometimes
also called a <em>polygonal schema</em>, because it describes how to
construct the map from a collection of disjoint planar polygons (the
faces) by identifying pairs of boundary edges.<a href="#fnref21"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>You should verify this claim!<a href="#fnref22"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>I can’t resist quoting Herodotus’ <em>Histories</em>,
written around 440BCE: “The ordinary [Greek] practice at sea is to make
sheets fast to ring-bolts fitted outboard; the Egyptians fit them
inboard. The Greeks write and calculate from left to right; the
Egyptians do the opposite. Yet they say that their way of writing is
toward the right, and the Greek way toward the left.” Herodotus was
strangely silent on which end of the egg the Egyptians ate first, or
whether they preferred to fight a hundred duck-sized horses or one
horse-sized duck.<a href="#fnref23" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>Well, okay, we only proved this formula for
<em>curves</em>, but extending our inductive proof to multicurves
requires us to consider only one additional case. Suppose some <span
class="math inline">\(2\to0\)</span> move disconnects a multicurve <span
class="math inline">\(\Gamma\)</span> into two smaller connected
multicurves <span class="math inline">\(\Gamma^\sharp\)</span> and <span
class="math inline">\(\Gamma^\flat\)</span>. The original map <span
class="math inline">\(\Gamma\)</span> has <span
class="math inline">\(n^\sharp + n^\flat + 2\)</span> vertices and <span
class="math inline">\(f^\sharp + f^\flat\)</span> faces (including the
deleted bigon and the common outer face), and the induction hypothesis
implies that <span class="math inline">\(f^\sharp = n^\sharp +
2\)</span> and <span class="math inline">\(f ^\flat =
n^\flat+2\)</span>. Later we will see yet another proof of Euler’s
formula (not on David’s list) based on Schnyder woods.<a href="#fnref24"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><span class="math inline">\(\dots\)</span> on display
in the bottom of a locked filing cabinet stuck in a disused lavatory
with a sign on the door saying ‘Beware of the Leonhard’.<a
href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><span class="math inline">\(\dots\)</span> and the
formula isn’t <em>Euler’s</em>.<a href="#fnref26" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p>The formulation and proof of Tutte’s theorem that I’m
presenting here follows a lecture note by Dan Spielman (2018), which is
based on papers by Michael Floater (1997); László Lovász (1999); Steven
Gortler, Craig Gotsman, and Dylan Thurston (2006); and Jim Geelen
(2012).<a href="#fnref27" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p>This modification is called a <em>star-mesh
transformation</em>; the special case of removing a vertex of degree
<span class="math inline">\(3\)</span> is called a <em>Y-<span
class="math inline">\(\Delta\)</span> transformation</em>.<a
href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p>It is sometimes more convenient to formalize Tutte’s
description as <span class="math inline">\(\lambda_{u\mathord\to v} =
1/\deg(v)\)</span>, so that the weights of all darts into each vertex
<span class="math inline">\(v\)</span> sum to <span
class="math inline">\(1\)</span>. This formalization is inconsistent
with the physical spring analogy, but instead treats weights as
transition probabilities of a (backward) random walk. Both
formalizations lead to the same Tutte drawing.<a href="#fnref29"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p>The Hessian of <span
class="math inline">\(\Phi\)</span> is positive definite, meaning all of
its eigenvalues are positive.<a href="#fnref30" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p>The Laplacian matrix is just the Hessian of <span
class="math inline">\(\Phi\)</span>.<a href="#fnref31"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p>In fact, we only need the weaker assumption that <span
class="math inline">\(G\)</span> is <em>internally</em> 3-connected,
meaning each interior vertex has three vertex-disjoint paths to the
outer face.<a href="#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p>It may seem more natural to draw each edges of the
force diagram <em>parallel</em> to the corresponding funicular edge;
indeed, many sources define force diagrams this way. The perpendicular
formulation makes the <em>duality</em> between reciprocal diagrams more
apparent. It also simplifies the derivation of polyhedral lifts; in
particular, perpendicular reciprocal diagrams have polyhedral lifts that
are projective polars through the unit paraboloid <span
class="math inline">\(z = (x^2+y^2)/2\)</span>.<a href="#fnref33"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p>Computational geometers might see some resemblance
between Varignon’s figure and the geometric duality between Delaunay
triangulations and Voronoi diagrams. That is <em>not</em> a coincidence.
Neither is the appearance of the unit paraboloid in the previous
footnote.<a href="#fnref34" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p>The fact that not all <em>voltage</em> assignments
satisfy Kirchhoff’s <em>voltage</em> law is an unfortunate byproduct of
the term’s history. See “red herring principle”.<a href="#fnref35"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p>Normally we would consider the faces of the radial
<em>map</em> <span class="math inline">\(\Sigma^\diamond\)</span> of a
planar <em>map</em> <span class="math inline">\(\Sigma\)</span>.
However, because <span class="math inline">\(G\)</span> is 3-connected,
it has only one combinatorial embedding, its radial <em>graph</em> and
the faces thereof are well-defined.<a href="#fnref36"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p>In fact the algorithm I’m about to describe can be
extended to directed graphs, where a dart and its reversal may have
different weights, but for ease of exposition, I’ll stick to undirected
graphs in this lecture.<a href="#fnref37" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p>The <span class="math inline">\(O(n\log\log
n)\)</span>-time shortest-path algorithm from Lecture 15 uses the
<em>parametric</em> MSSP algorithm from the previous lecture as a
subroutine. If we instead recursively apply the recursive MSSP strategy
described in this lecture, the resulting doubly-recursive MSSP algorithm
runs in <span class="math inline">\(O(n\log h\,\log\log n\,\log\log\log
n\,\log\log\log\log n\dots)\)</span> time.<a href="#fnref38"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p>This <span class="math inline">\(O(n)\)</span>-time
shortest-path algorithm does <em>not</em> use MSSP as a subroutine.<a
href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p>David Eisenstat [2] implemented Chambers, Cabello, and
Erickson’s MSSP algorithm using both efficient dynamic trees and
brute-force to find pivots. His experimental evaluation showed that the
brute-force implementation was faster in practice for graphs with up to
200000 vertices.
<!-- Hoch and Wang performed a similar comparison with my planar maximum-flow algorithm; for planar graphs with up to 12000 vertices, they observed that the brute-force implementation is fastest. -->
More generally, in a large-scale experimental comparison of several
dynamic-forest data structures by Tarjan and Werneck [6, 7], brute-force
implementation beat all other data structures for trees with depth less
than 1000.<a href="#fnref40" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p>The algorithms I describe in this note use hashing in
multiple places. It is possible to achieve the same running time without
hashing, at the expense of simplicity (and probably some efficiency).<a
href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p>Efficiently maintaining a <em>simple</em> planar graph
under arbitrary edge contractions is surprisingly subtle; see Holm et al
[2] and Kammer and Meintrup [3]. For this MSSP algorithm, it suffices to
resolve only <em>adjacent</em> parallel edges and delete <em>empty</em>
loops immediately after each contraction in <span
class="math inline">\(O(1)\)</span> time per deleted edge using only
standard graph data structures. The resulting planar map is no longer
necessarily simple, but every face has degree at least <span
class="math inline">\(3\)</span>, which is good enough.<a
href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p>To keep the space usage low, we store this vertex
information in four hash tables, each of size linear in the number of
vertices of <span class="math inline">\(H\)</span>. Alternatively, we
can avoid hash tables by compacting the incidence-list structure of
<span class="math inline">\(H’\)</span> during the cleanup phase of
<span class="math inline">\(\textsf{Filter}\)</span>, and storing the
index in the filtered map <span class="math inline">\(H’\)</span> of
each vertex of the input map <span class="math inline">\(H\)</span>.<a
href="#fnref43" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p>Fox-Eppstein et al. [1] describe an arguably simpler
algorithm that uses a dual breadth-first search tree rooted at the outer
face to define face levels, instead of a primal breadth-first search
tree.<a href="#fnref44" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p>I am ignoring two extreme cases. First, if <span
class="math inline">\(m &lt; \sqrt{n}\)</span>, we define <span
class="math inline">\(C^- = \varnothing\)</span>; similarly, if <span
class="math inline">\(m &gt; \textsf{level}(y) - \sqrt{n}\)</span>, we
define <span class="math inline">\(C^+ = \varnothing\)</span>. Handling
these special cases in the rest of the construction is
straightforward.<a href="#fnref45" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p>The two 1996 results are completely independent; so are
the two 2013 results.<a href="#fnref46" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn47"><p>If we are <em>given</em> the shortest-path tree rooted
at any boundary vertex, the remainder of the parametric MSSP algorithm
runs correctly, without modification, in <span
class="math inline">\(O(n\log n)\)</span> time.<a href="#fnref47"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn48"><p>In particular, the original graph <span
class="math inline">\(G\)</span> contains a negative cycle if and only
if, at after eliminating some subset of vertices, <span
class="math inline">\(G\)</span> contains an edge <span
class="math inline">\(xy\)</span> such that <span
class="math inline">\(\ell(x{\to}y) + \ell(y{\to}x) &lt; 0\)</span>.<a
href="#fnref48" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn49"><p>I’m playing a little fast and loose here. Recall that
the Klein-Mozes-Sommer separator hierarchy does not necessarily evenly
partition vertices at every level of recursion, but only at every third
level. So formalizing this analysis requires considering eight recursive
subproblems, not just two.<a href="#fnref49" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn50"><p>The formulation of optimal path problems as solving
linear systems over <span class="math inline">\((\min,+)\)</span>- and
<span class="math inline">\((\max,+)\)</span>-algebras dates back to at
least the 1960s. For example, in 1971 Bernard Carré observed that
different formulations of Bellman-Ford are <span
class="math inline">\((\min,+)\)</span>-variants of Jacobi and
Gauss-Seidel iteration, and the Floyd-Warshall all-pairs shortest-path
algorithm is a <span class="math inline">\((\min,+)\)</span>-variant of
Jordan elimination.<a href="#fnref50" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn51"><p>Specifically, Lipton, Rose, and Tarjan’s elimination
algorithm assumes that when a row is eliminated, its diagonal entry is
nonzero. (Recall that the algorithm chooses the elimination order before
doing any elimination.) This condition is automatically satisfied for
symmetric positive-definition linear systems over <span
class="math inline">\(\mathbb{R}\)</span>, but is not satisfied in
general.<a href="#fnref51" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn52"><p>At least, first <em>explicitly</em> proposed. Arguably
the repricing technique is already implicit in Jacobi’s mid-19th-century
description of the “Hungarian” algorithm for the assignment problem.<a
href="#fnref52" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn53"><p>Mehlhorn and Schmidt’s algorithm reprices the vertices
in each piece, and then runs Dijkstra’s algorithm from each separator
vertex, in <span class="math inline">\(O(n^{3/2}\log n)\)</span> total
time.<a href="#fnref53" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn54"><p>If you’re uncomfortable with symbolic infinities, it
suffices to set <span class="math display">\[
\pi(\hat{r}) =
    \max\left\{
            \textsf{dist}_A(r, u) - \textsf{dist}_\Sigma(r, u), ~
            \textsf{dist}_B(r, u) - \textsf{dist}_\Sigma(r, u)
    \bigm| u\in S \right\}
\]</span><a href="#fnref54" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn55"><p>Mehlhorn and Schmidt compute <span
class="math inline">\(\textsf{dist}_\Sigma(r, \Sigma)\)</span> by brute
force in <span class="math inline">\(O(n^{3/2})\)</span> time, by
observing that <span class="math inline">\(\textsf{dist}_\Sigma(r, v) =
\min_{u\in S} \{\textsf{dist}_\Sigma(r, u) +
\textsf{dist}_A(u,v)\}\)</span> for every vertex <span
class="math inline">\(v\in A\)</span>, and similarly for <span
class="math inline">\(B\)</span>.<a href="#fnref55"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn56"><p>Without the second base case, it is possible for a
constant fraction of the vertices to appear in a constant fraction of
the recursive subproblems, leading to a running time of <span
class="math inline">\(O(kn\log n)\)</span>.<a href="#fnref56"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn57"><p>In the lecture on the Maxwell-Cremona correspondence,
we used exactly the same definition for <em>discrete 1-forms</em> or
<em>1-cochains</em>, but topologists should really think of pseudoflows
as <em>1-chains</em>.<a href="#fnref57" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn58"><p>A more common textbook definition of (pseudo)flow is
any function <span class="math inline">\(\phi \colon D(G) \to
\mathbb{R}\)</span> such that for every dart <span
class="math inline">\(d\)</span>, we have <span
class="math inline">\(\phi(d)\ge 0\)</span> and either <span
class="math inline">\(\phi(d) = 0\)</span> or <span
class="math inline">\(\phi(\textsf{rev}(d)) = 0\)</span>. That is, for
each edge, instead of choosing an arbitrary values for the darts that
sum to <span class="math inline">\(0\)</span>, we choose both a
direction and a non-negative value for the edge. Converting between the
antisymmetric formulation and the non-negative formulation is
straightforward.<a href="#fnref58" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn59"><p>This construction breaks down when <span
class="math inline">\(D = \varnothing\)</span>; in this case, the space
<span class="math inline">\(\mathcal{S}(\Pi)\)</span> is the sphere and
<span class="math inline">\(\Sigma(\Pi)\)</span> is the trivial map with
one vertex, one face, and no edges.<a href="#fnref59"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn60"><p>The term “reflection system” is non-standard, but I
think it’s both sufficiently evocative and sufficiently similar to
“rotation system” to justify its use. Reflection systems are also called
<em>graph-encoded maps</em> or <em>graph-encoded manifolds</em> or
<em>gems</em> (Lins 1983), but the most common term seems to be
“combinatorial map” (or just “map”). Yeah.<a href="#fnref60"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn61"><p>This claim may seem obvious; in fact is <em>was</em>
considered obvious until the early 20th century. The same claim is
<em>false</em> for 4-dimensional manifolds!<a href="#fnref61"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn62"><p>Dyck may be better known to computer scientists for
proposing the <em>Dyck language</em>, which is the language of all
properly balanced strings of brackets <code>[</code> and <code>]</code>.
The Dyck language is also the set of all possible crossing sequence of a
closed curve with winding number <span class="math inline">\(0\)</span>
around the origin with an arbitrary ray from the origin.<a
href="#fnref62" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn63"><p>Actually, l’Huillier only proposed this formula for the
special (orientable) case of polyhedra with disjoint prismatic tunnels.
The full classification theorem is arguably due to August Möbius (1863),
but was not properly formalized until the early 20th century, after the
proof of the Jordan Curve Theorem.<a href="#fnref63"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn64"><p>A few papers refer to degree-vertices in a cut graph as
<em>hair</em> and the reduction process as <em>shaving</em> the cut
graph.<a href="#fnref64" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn65"><p>One natural exception to this rule is the <em>flat
torus</em>, which is the metric space obtained by gluing opposite sides
of the unit square (or any other parallelogram) in the plane. Homotopy
testing on the flat torus is nearly trivial.<a href="#fnref65"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn66"><p><span class="math inline">\(\dots\)</span>because it
removes all the genus.<a href="#fnref66" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn67"><p>More careful analysis implies the upper bound <span
class="math inline">\(\sqrt{\bar{g} n} = \sqrt{2gn}\)</span> when <span
class="math inline">\(\Sigma\)</span> is orientable.<a href="#fnref67"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn68"><p>Here I’m using <span
class="math inline">\(\ell\)</span> as a mnemonic for “leftover edge”
instead of “loop”. We have a lot of other <span
class="math inline">\(e\)</span>’s flying around, so I don’t want to use
<span class="math inline">\(e_i\)</span> to denote the <span
class="math inline">\(i\)</span>th edge in <span
class="math inline">\(L\)</span>.<a href="#fnref68"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn69"><p>With more effort, these algorithms can be generalized
to <em>directed</em> surface maps with asymmetrically weighted
<em>darts</em>.<a href="#fnref69" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn70"><p>David Epstein-with-one-p is a curly-haired English
mathematician who was born in South Africa. David Eppstein-with-two-p’s
is a curly-haired American mathematician (and computer scientist) who
was born in England. It’s a minor miracle that they have never been
coauthors.<a href="#fnref70" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
            </div>
    </div>
  </div>
  <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>

</body>
</html>
